
Parameters:
ALLOW_SOFT_PLACEMENT=True
BATCH_SIZE=64
CHECKPOINT_EVERY=40
DECAY_COEFFICIENT=2.5
DEV_SAMPLE_PERCENTAGE=0.1
DROPOUT_KEEP_PROB=0.5
EMBEDDING_DIM=1
ENABLE_WORD_EMBEDDINGS=True
EVALUATE_EVERY=40
FILTER_SIZES=3,4,5
L2_REG_LAMBDA=0.0
LOG_DEVICE_PLACEMENT=False
NUM_CHECKPOINTS=5
NUM_EPOCHS=80
NUM_FILTERS=128

Loading data...
6954
[[1 0 0 0 0]
 [1 0 0 0 0]
 [1 0 0 0 0]
 ..., 
 [0 0 0 0 1]
 [0 0 0 0 1]
 [0 0 0 0 1]]
Vocabulary Size: 46116
Train/Dev split: 6259/695
Writing to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174

2017-09-28T16:29:36.713784: step 1, loss 1.58964, acc 0.328125, learning_rate 0.005
2017-09-28T16:29:36.796555: step 2, loss 1.66704, acc 0.25, learning_rate 0.00498
2017-09-28T16:29:36.880909: step 3, loss 1.57034, acc 0.296875, learning_rate 0.00496008
2017-09-28T16:29:36.960877: step 4, loss 1.64722, acc 0.265625, learning_rate 0.00494024
2017-09-28T16:29:37.041230: step 5, loss 1.64245, acc 0.28125, learning_rate 0.00492049
2017-09-28T16:29:37.124952: step 6, loss 1.47113, acc 0.3125, learning_rate 0.00490081
2017-09-28T16:29:37.208667: step 7, loss 1.55209, acc 0.3125, learning_rate 0.00488121
2017-09-28T16:29:37.289495: step 8, loss 1.59461, acc 0.34375, learning_rate 0.0048617
2017-09-28T16:29:37.371627: step 9, loss 1.49412, acc 0.375, learning_rate 0.00484226
2017-09-28T16:29:37.452758: step 10, loss 1.52227, acc 0.390625, learning_rate 0.00482291
2017-09-28T16:29:37.532401: step 11, loss 1.56446, acc 0.375, learning_rate 0.00480363
2017-09-28T16:29:37.613832: step 12, loss 1.84087, acc 0.171875, learning_rate 0.00478443
2017-09-28T16:29:37.694492: step 13, loss 1.47868, acc 0.390625, learning_rate 0.00476531
2017-09-28T16:29:37.777426: step 14, loss 1.6508, acc 0.3125, learning_rate 0.00474627
2017-09-28T16:29:37.857575: step 15, loss 1.58476, acc 0.265625, learning_rate 0.0047273
2017-09-28T16:29:37.939732: step 16, loss 1.60145, acc 0.3125, learning_rate 0.00470841
2017-09-28T16:29:38.021380: step 17, loss 1.54487, acc 0.28125, learning_rate 0.0046896
2017-09-28T16:29:38.102355: step 18, loss 1.68917, acc 0.171875, learning_rate 0.00467087
2017-09-28T16:29:38.182785: step 19, loss 1.56979, acc 0.203125, learning_rate 0.00465221
2017-09-28T16:29:38.266237: step 20, loss 1.46752, acc 0.296875, learning_rate 0.00463363
2017-09-28T16:29:38.350404: step 21, loss 1.55931, acc 0.25, learning_rate 0.00461513
2017-09-28T16:29:38.433078: step 22, loss 1.56695, acc 0.21875, learning_rate 0.0045967
2017-09-28T16:29:38.517932: step 23, loss 1.63724, acc 0.328125, learning_rate 0.00457834
2017-09-28T16:29:38.600848: step 24, loss 1.58231, acc 0.296875, learning_rate 0.00456006
2017-09-28T16:29:38.683979: step 25, loss 1.71361, acc 0.28125, learning_rate 0.00454186
2017-09-28T16:29:38.764952: step 26, loss 1.72671, acc 0.21875, learning_rate 0.00452373
2017-09-28T16:29:38.842954: step 27, loss 1.6024, acc 0.28125, learning_rate 0.00450567
2017-09-28T16:29:38.923285: step 28, loss 1.63612, acc 0.21875, learning_rate 0.00448769
2017-09-28T16:29:39.006742: step 29, loss 1.6631, acc 0.328125, learning_rate 0.00446978
2017-09-28T16:29:39.087048: step 30, loss 1.67411, acc 0.25, learning_rate 0.00445194
2017-09-28T16:29:39.167389: step 31, loss 1.61276, acc 0.296875, learning_rate 0.00443418
2017-09-28T16:29:39.251243: step 32, loss 1.58857, acc 0.28125, learning_rate 0.00441649
2017-09-28T16:29:39.332471: step 33, loss 1.66268, acc 0.1875, learning_rate 0.00439887
2017-09-28T16:29:39.416533: step 34, loss 1.62315, acc 0.28125, learning_rate 0.00438132
2017-09-28T16:29:39.497950: step 35, loss 1.60035, acc 0.296875, learning_rate 0.00436385
2017-09-28T16:29:39.578934: step 36, loss 1.59723, acc 0.328125, learning_rate 0.00434644
2017-09-28T16:29:39.658986: step 37, loss 1.45658, acc 0.34375, learning_rate 0.00432911
2017-09-28T16:29:39.740989: step 38, loss 1.69409, acc 0.234375, learning_rate 0.00431185
2017-09-28T16:29:39.821607: step 39, loss 1.62843, acc 0.265625, learning_rate 0.00429465
2017-09-28T16:29:39.902962: step 40, loss 1.61467, acc 0.25, learning_rate 0.00427753

Evaluation:
2017-09-28T16:29:40.192201: step 40, loss 1.49567, acc 0.315108

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-40

2017-09-28T16:29:40.762526: step 41, loss 1.45341, acc 0.328125, learning_rate 0.00426048
2017-09-28T16:29:40.841518: step 42, loss 1.37302, acc 0.5, learning_rate 0.0042435
2017-09-28T16:29:40.921807: step 43, loss 1.56949, acc 0.296875, learning_rate 0.00422659
2017-09-28T16:29:41.003011: step 44, loss 1.56022, acc 0.34375, learning_rate 0.00420974
2017-09-28T16:29:41.086091: step 45, loss 1.47108, acc 0.34375, learning_rate 0.00419297
2017-09-28T16:29:41.170179: step 46, loss 1.63457, acc 0.234375, learning_rate 0.00417626
2017-09-28T16:29:41.250595: step 47, loss 1.59246, acc 0.34375, learning_rate 0.00415962
2017-09-28T16:29:41.332023: step 48, loss 1.56759, acc 0.328125, learning_rate 0.00414305
2017-09-28T16:29:41.413526: step 49, loss 1.54887, acc 0.265625, learning_rate 0.00412655
2017-09-28T16:29:41.496746: step 50, loss 1.50826, acc 0.265625, learning_rate 0.00411011
2017-09-28T16:29:41.578446: step 51, loss 1.63575, acc 0.328125, learning_rate 0.00409375
2017-09-28T16:29:41.661619: step 52, loss 1.53512, acc 0.25, learning_rate 0.00407744
2017-09-28T16:29:41.740883: step 53, loss 1.48928, acc 0.28125, learning_rate 0.00406121
2017-09-28T16:29:41.822727: step 54, loss 1.45799, acc 0.390625, learning_rate 0.00404504
2017-09-28T16:29:41.905257: step 55, loss 1.49139, acc 0.34375, learning_rate 0.00402894
2017-09-28T16:29:41.985758: step 56, loss 1.59916, acc 0.265625, learning_rate 0.0040129
2017-09-28T16:29:42.065900: step 57, loss 1.45895, acc 0.359375, learning_rate 0.00399693
2017-09-28T16:29:42.147607: step 58, loss 1.48012, acc 0.40625, learning_rate 0.00398102
2017-09-28T16:29:42.228954: step 59, loss 1.59303, acc 0.328125, learning_rate 0.00396518
2017-09-28T16:29:42.311694: step 60, loss 1.55591, acc 0.265625, learning_rate 0.00394941
2017-09-28T16:29:42.390492: step 61, loss 1.63692, acc 0.21875, learning_rate 0.00393369
2017-09-28T16:29:42.472385: step 62, loss 1.56445, acc 0.34375, learning_rate 0.00391804
2017-09-28T16:29:42.556974: step 63, loss 1.63104, acc 0.3125, learning_rate 0.00390246
2017-09-28T16:29:42.636236: step 64, loss 1.47676, acc 0.40625, learning_rate 0.00388694
2017-09-28T16:29:42.717089: step 65, loss 1.47251, acc 0.40625, learning_rate 0.00387148
2017-09-28T16:29:42.800121: step 66, loss 1.4759, acc 0.359375, learning_rate 0.00385609
2017-09-28T16:29:42.885052: step 67, loss 1.63289, acc 0.25, learning_rate 0.00384076
2017-09-28T16:29:42.967607: step 68, loss 1.45245, acc 0.390625, learning_rate 0.00382549
2017-09-28T16:29:43.051154: step 69, loss 1.53995, acc 0.34375, learning_rate 0.00381028
2017-09-28T16:29:43.132343: step 70, loss 1.58707, acc 0.3125, learning_rate 0.00379514
2017-09-28T16:29:43.212279: step 71, loss 1.50953, acc 0.359375, learning_rate 0.00378005
2017-09-28T16:29:43.292756: step 72, loss 1.46924, acc 0.3125, learning_rate 0.00376503
2017-09-28T16:29:43.373537: step 73, loss 1.61301, acc 0.28125, learning_rate 0.00375007
2017-09-28T16:29:43.456304: step 74, loss 1.50335, acc 0.328125, learning_rate 0.00373517
2017-09-28T16:29:43.538375: step 75, loss 1.36629, acc 0.453125, learning_rate 0.00372034
2017-09-28T16:29:43.620237: step 76, loss 1.4959, acc 0.328125, learning_rate 0.00370556
2017-09-28T16:29:43.702549: step 77, loss 1.49788, acc 0.328125, learning_rate 0.00369084
2017-09-28T16:29:43.786510: step 78, loss 1.36227, acc 0.390625, learning_rate 0.00367619
2017-09-28T16:29:43.869110: step 79, loss 1.55027, acc 0.34375, learning_rate 0.00366159
2017-09-28T16:29:43.951082: step 80, loss 1.43316, acc 0.4375, learning_rate 0.00364705

Evaluation:
2017-09-28T16:29:44.236650: step 80, loss 1.47851, acc 0.332374

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-80

2017-09-28T16:29:44.799809: step 81, loss 1.51635, acc 0.34375, learning_rate 0.00363257
2017-09-28T16:29:44.879959: step 82, loss 1.49667, acc 0.3125, learning_rate 0.00361815
2017-09-28T16:29:44.962967: step 83, loss 1.57261, acc 0.296875, learning_rate 0.00360379
2017-09-28T16:29:45.044988: step 84, loss 1.45007, acc 0.46875, learning_rate 0.00358949
2017-09-28T16:29:45.127844: step 85, loss 1.52634, acc 0.328125, learning_rate 0.00357525
2017-09-28T16:29:45.210892: step 86, loss 1.47273, acc 0.40625, learning_rate 0.00356106
2017-09-28T16:29:45.292736: step 87, loss 1.43754, acc 0.421875, learning_rate 0.00354694
2017-09-28T16:29:45.376805: step 88, loss 1.55287, acc 0.375, learning_rate 0.00353287
2017-09-28T16:29:45.458185: step 89, loss 1.48459, acc 0.328125, learning_rate 0.00351885
2017-09-28T16:29:45.541826: step 90, loss 1.5101, acc 0.296875, learning_rate 0.0035049
2017-09-28T16:29:45.626396: step 91, loss 1.36437, acc 0.453125, learning_rate 0.003491
2017-09-28T16:29:45.707558: step 92, loss 1.51922, acc 0.359375, learning_rate 0.00347716
2017-09-28T16:29:45.788832: step 93, loss 1.57237, acc 0.34375, learning_rate 0.00346338
2017-09-28T16:29:45.870012: step 94, loss 1.56522, acc 0.359375, learning_rate 0.00344965
2017-09-28T16:29:45.952850: step 95, loss 1.54683, acc 0.390625, learning_rate 0.00343597
2017-09-28T16:29:46.034228: step 96, loss 1.4585, acc 0.375, learning_rate 0.00342236
2017-09-28T16:29:46.112593: step 97, loss 1.57792, acc 0.28125, learning_rate 0.0034088
2017-09-28T16:29:46.178502: step 98, loss 1.41968, acc 0.352941, learning_rate 0.00339529
2017-09-28T16:29:46.258182: step 99, loss 1.49183, acc 0.28125, learning_rate 0.00338184
2017-09-28T16:29:46.341427: step 100, loss 1.43497, acc 0.421875, learning_rate 0.00336844
2017-09-28T16:29:46.424755: step 101, loss 1.49541, acc 0.34375, learning_rate 0.0033551
2017-09-28T16:29:46.506561: step 102, loss 1.45721, acc 0.4375, learning_rate 0.00334182
2017-09-28T16:29:46.588315: step 103, loss 1.37875, acc 0.453125, learning_rate 0.00332858
2017-09-28T16:29:46.671016: step 104, loss 1.36943, acc 0.4375, learning_rate 0.00331541
2017-09-28T16:29:46.752764: step 105, loss 1.35018, acc 0.453125, learning_rate 0.00330228
2017-09-28T16:29:46.836375: step 106, loss 1.5592, acc 0.296875, learning_rate 0.00328921
2017-09-28T16:29:46.917336: step 107, loss 1.6014, acc 0.390625, learning_rate 0.00327619
2017-09-28T16:29:47.001082: step 108, loss 1.49199, acc 0.390625, learning_rate 0.00326323
2017-09-28T16:29:47.080629: step 109, loss 1.61112, acc 0.296875, learning_rate 0.00325032
2017-09-28T16:29:47.163147: step 110, loss 1.40423, acc 0.453125, learning_rate 0.00323746
2017-09-28T16:29:47.245302: step 111, loss 1.39494, acc 0.453125, learning_rate 0.00322465
2017-09-28T16:29:47.325746: step 112, loss 1.49918, acc 0.390625, learning_rate 0.0032119
2017-09-28T16:29:47.407762: step 113, loss 1.50673, acc 0.375, learning_rate 0.0031992
2017-09-28T16:29:47.489602: step 114, loss 1.43922, acc 0.46875, learning_rate 0.00318655
2017-09-28T16:29:47.574068: step 115, loss 1.58394, acc 0.34375, learning_rate 0.00317395
2017-09-28T16:29:47.658986: step 116, loss 1.37756, acc 0.484375, learning_rate 0.0031614
2017-09-28T16:29:47.740904: step 117, loss 1.57596, acc 0.265625, learning_rate 0.0031489
2017-09-28T16:29:47.823037: step 118, loss 1.36065, acc 0.5, learning_rate 0.00313646
2017-09-28T16:29:47.901924: step 119, loss 1.54254, acc 0.3125, learning_rate 0.00312407
2017-09-28T16:29:47.982098: step 120, loss 1.45849, acc 0.40625, learning_rate 0.00311172

Evaluation:
2017-09-28T16:29:48.266721: step 120, loss 1.4017, acc 0.497842

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-120

2017-09-28T16:29:48.827750: step 121, loss 1.48964, acc 0.390625, learning_rate 0.00309943
2017-09-28T16:29:48.910615: step 122, loss 1.38214, acc 0.484375, learning_rate 0.00308719
2017-09-28T16:29:48.992598: step 123, loss 1.42837, acc 0.4375, learning_rate 0.00307499
2017-09-28T16:29:49.073923: step 124, loss 1.30783, acc 0.546875, learning_rate 0.00306285
2017-09-28T16:29:49.157215: step 125, loss 1.47632, acc 0.328125, learning_rate 0.00305076
2017-09-28T16:29:49.239118: step 126, loss 1.36287, acc 0.4375, learning_rate 0.00303871
2017-09-28T16:29:49.318539: step 127, loss 1.41373, acc 0.359375, learning_rate 0.00302672
2017-09-28T16:29:49.398770: step 128, loss 1.40801, acc 0.359375, learning_rate 0.00301477
2017-09-28T16:29:49.480354: step 129, loss 1.47233, acc 0.328125, learning_rate 0.00300287
2017-09-28T16:29:49.563247: step 130, loss 1.58246, acc 0.328125, learning_rate 0.00299102
2017-09-28T16:29:49.646390: step 131, loss 1.30473, acc 0.578125, learning_rate 0.00297922
2017-09-28T16:29:49.730482: step 132, loss 1.36791, acc 0.484375, learning_rate 0.00296747
2017-09-28T16:29:49.813775: step 133, loss 1.49495, acc 0.359375, learning_rate 0.00295577
2017-09-28T16:29:49.897511: step 134, loss 1.38466, acc 0.53125, learning_rate 0.00294411
2017-09-28T16:29:49.981853: step 135, loss 1.35515, acc 0.46875, learning_rate 0.0029325
2017-09-28T16:29:50.063856: step 136, loss 1.56088, acc 0.328125, learning_rate 0.00292094
2017-09-28T16:29:50.147660: step 137, loss 1.33184, acc 0.46875, learning_rate 0.00290943
2017-09-28T16:29:50.227258: step 138, loss 1.29752, acc 0.546875, learning_rate 0.00289796
2017-09-28T16:29:50.309660: step 139, loss 1.27334, acc 0.5625, learning_rate 0.00288654
2017-09-28T16:29:50.392636: step 140, loss 1.37668, acc 0.53125, learning_rate 0.00287516
2017-09-28T16:29:50.475041: step 141, loss 1.37297, acc 0.421875, learning_rate 0.00286384
2017-09-28T16:29:50.558923: step 142, loss 1.37597, acc 0.5, learning_rate 0.00285256
2017-09-28T16:29:50.652978: step 143, loss 1.24812, acc 0.578125, learning_rate 0.00284132
2017-09-28T16:29:50.733426: step 144, loss 1.45095, acc 0.421875, learning_rate 0.00283013
2017-09-28T16:29:50.818910: step 145, loss 1.35289, acc 0.390625, learning_rate 0.00281899
2017-09-28T16:29:50.901953: step 146, loss 1.49229, acc 0.390625, learning_rate 0.00280789
2017-09-28T16:29:50.983166: step 147, loss 1.28226, acc 0.515625, learning_rate 0.00279684
2017-09-28T16:29:51.064397: step 148, loss 1.30314, acc 0.5, learning_rate 0.00278583
2017-09-28T16:29:51.145026: step 149, loss 1.32766, acc 0.5, learning_rate 0.00277486
2017-09-28T16:29:51.228567: step 150, loss 1.38702, acc 0.4375, learning_rate 0.00276395
2017-09-28T16:29:51.310595: step 151, loss 1.34518, acc 0.515625, learning_rate 0.00275307
2017-09-28T16:29:51.389399: step 152, loss 1.2143, acc 0.53125, learning_rate 0.00274224
2017-09-28T16:29:51.470146: step 153, loss 1.39663, acc 0.484375, learning_rate 0.00273146
2017-09-28T16:29:51.552333: step 154, loss 1.31047, acc 0.515625, learning_rate 0.00272072
2017-09-28T16:29:51.636408: step 155, loss 1.28381, acc 0.515625, learning_rate 0.00271002
2017-09-28T16:29:51.717588: step 156, loss 1.29511, acc 0.421875, learning_rate 0.00269937
2017-09-28T16:29:51.797669: step 157, loss 1.44321, acc 0.453125, learning_rate 0.00268876
2017-09-28T16:29:51.877321: step 158, loss 1.23143, acc 0.609375, learning_rate 0.00267819
2017-09-28T16:29:51.959650: step 159, loss 1.28756, acc 0.515625, learning_rate 0.00266767
2017-09-28T16:29:52.045305: step 160, loss 1.48758, acc 0.375, learning_rate 0.00265719

Evaluation:
2017-09-28T16:29:52.328013: step 160, loss 1.29603, acc 0.497842

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-160

2017-09-28T16:29:52.895027: step 161, loss 1.26324, acc 0.5625, learning_rate 0.00264675
2017-09-28T16:29:52.976252: step 162, loss 1.19085, acc 0.625, learning_rate 0.00263635
2017-09-28T16:29:53.058915: step 163, loss 1.27635, acc 0.546875, learning_rate 0.002626
2017-09-28T16:29:53.141207: step 164, loss 1.36817, acc 0.53125, learning_rate 0.00261569
2017-09-28T16:29:53.220630: step 165, loss 1.28428, acc 0.546875, learning_rate 0.00260542
2017-09-28T16:29:53.302513: step 166, loss 1.37944, acc 0.515625, learning_rate 0.0025952
2017-09-28T16:29:53.386146: step 167, loss 1.31697, acc 0.515625, learning_rate 0.00258501
2017-09-28T16:29:53.469632: step 168, loss 1.36852, acc 0.453125, learning_rate 0.00257487
2017-09-28T16:29:53.550117: step 169, loss 1.30961, acc 0.484375, learning_rate 0.00256477
2017-09-28T16:29:53.635114: step 170, loss 1.1906, acc 0.578125, learning_rate 0.0025547
2017-09-28T16:29:53.717426: step 171, loss 1.25708, acc 0.484375, learning_rate 0.00254469
2017-09-28T16:29:53.800451: step 172, loss 1.22986, acc 0.625, learning_rate 0.00253471
2017-09-28T16:29:53.882358: step 173, loss 1.48081, acc 0.421875, learning_rate 0.00252477
2017-09-28T16:29:53.962620: step 174, loss 1.24924, acc 0.578125, learning_rate 0.00251487
2017-09-28T16:29:54.041859: step 175, loss 1.27179, acc 0.53125, learning_rate 0.00250501
2017-09-28T16:29:54.125499: step 176, loss 1.23522, acc 0.5625, learning_rate 0.0024952
2017-09-28T16:29:54.208279: step 177, loss 1.33434, acc 0.5, learning_rate 0.00248542
2017-09-28T16:29:54.292018: step 178, loss 1.31269, acc 0.546875, learning_rate 0.00247568
2017-09-28T16:29:54.377327: step 179, loss 1.23441, acc 0.5625, learning_rate 0.00246599
2017-09-28T16:29:54.462137: step 180, loss 1.41997, acc 0.4375, learning_rate 0.00245633
2017-09-28T16:29:54.544084: step 181, loss 1.1562, acc 0.578125, learning_rate 0.00244671
2017-09-28T16:29:54.628504: step 182, loss 1.37676, acc 0.453125, learning_rate 0.00243713
2017-09-28T16:29:54.711030: step 183, loss 1.31664, acc 0.484375, learning_rate 0.00242759
2017-09-28T16:29:54.793371: step 184, loss 1.2404, acc 0.546875, learning_rate 0.00241809
2017-09-28T16:29:54.875012: step 185, loss 1.15611, acc 0.5625, learning_rate 0.00240863
2017-09-28T16:29:54.957523: step 186, loss 1.36511, acc 0.515625, learning_rate 0.00239921
2017-09-28T16:29:55.041905: step 187, loss 1.35285, acc 0.484375, learning_rate 0.00238982
2017-09-28T16:29:55.125376: step 188, loss 1.18159, acc 0.609375, learning_rate 0.00238048
2017-09-28T16:29:55.207872: step 189, loss 1.12837, acc 0.59375, learning_rate 0.00237117
2017-09-28T16:29:55.290840: step 190, loss 1.49554, acc 0.46875, learning_rate 0.0023619
2017-09-28T16:29:55.374392: step 191, loss 1.2007, acc 0.578125, learning_rate 0.00235267
2017-09-28T16:29:55.458886: step 192, loss 1.33138, acc 0.5, learning_rate 0.00234347
2017-09-28T16:29:55.539619: step 193, loss 1.1948, acc 0.546875, learning_rate 0.00233431
2017-09-28T16:29:55.621394: step 194, loss 1.09248, acc 0.609375, learning_rate 0.00232519
2017-09-28T16:29:55.708954: step 195, loss 1.18211, acc 0.65625, learning_rate 0.00231611
2017-09-28T16:29:55.772905: step 196, loss 1.21876, acc 0.588235, learning_rate 0.00230707
2017-09-28T16:29:55.857285: step 197, loss 1.27243, acc 0.4375, learning_rate 0.00229806
2017-09-28T16:29:55.939723: step 198, loss 1.27556, acc 0.546875, learning_rate 0.00228908
2017-09-28T16:29:56.022878: step 199, loss 1.23332, acc 0.515625, learning_rate 0.00228015
2017-09-28T16:29:56.103690: step 200, loss 1.26828, acc 0.5625, learning_rate 0.00227125

Evaluation:
2017-09-28T16:29:56.389324: step 200, loss 1.15616, acc 0.569784

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-200

2017-09-28T16:29:56.956728: step 201, loss 1.18193, acc 0.546875, learning_rate 0.00226239
2017-09-28T16:29:57.037578: step 202, loss 1.35754, acc 0.46875, learning_rate 0.00225356
2017-09-28T16:29:57.118012: step 203, loss 1.23263, acc 0.5625, learning_rate 0.00224477
2017-09-28T16:29:57.201188: step 204, loss 1.16915, acc 0.546875, learning_rate 0.00223602
2017-09-28T16:29:57.283355: step 205, loss 1.23743, acc 0.484375, learning_rate 0.0022273
2017-09-28T16:29:57.363942: step 206, loss 1.2159, acc 0.609375, learning_rate 0.00221862
2017-09-28T16:29:57.448314: step 207, loss 1.02728, acc 0.671875, learning_rate 0.00220997
2017-09-28T16:29:57.532402: step 208, loss 1.36869, acc 0.5, learning_rate 0.00220136
2017-09-28T16:29:57.617602: step 209, loss 1.14456, acc 0.578125, learning_rate 0.00219278
2017-09-28T16:29:57.697751: step 210, loss 1.26629, acc 0.46875, learning_rate 0.00218424
2017-09-28T16:29:57.779854: step 211, loss 1.27296, acc 0.53125, learning_rate 0.00217573
2017-09-28T16:29:57.862458: step 212, loss 1.2955, acc 0.546875, learning_rate 0.00216726
2017-09-28T16:29:57.942808: step 213, loss 1.16731, acc 0.578125, learning_rate 0.00215882
2017-09-28T16:29:58.023729: step 214, loss 1.23389, acc 0.59375, learning_rate 0.00215041
2017-09-28T16:29:58.108012: step 215, loss 1.36321, acc 0.421875, learning_rate 0.00214204
2017-09-28T16:29:58.187839: step 216, loss 1.13189, acc 0.609375, learning_rate 0.00213371
2017-09-28T16:29:58.270616: step 217, loss 1.10225, acc 0.640625, learning_rate 0.00212541
2017-09-28T16:29:58.351554: step 218, loss 1.15709, acc 0.5625, learning_rate 0.00211714
2017-09-28T16:29:58.431213: step 219, loss 1.18159, acc 0.546875, learning_rate 0.00210891
2017-09-28T16:29:58.515511: step 220, loss 1.02945, acc 0.6875, learning_rate 0.00210071
2017-09-28T16:29:58.595972: step 221, loss 1.335, acc 0.5, learning_rate 0.00209254
2017-09-28T16:29:58.678164: step 222, loss 1.10738, acc 0.609375, learning_rate 0.00208441
2017-09-28T16:29:58.760972: step 223, loss 1.04619, acc 0.640625, learning_rate 0.00207631
2017-09-28T16:29:58.841603: step 224, loss 1.08685, acc 0.59375, learning_rate 0.00206824
2017-09-28T16:29:58.924240: step 225, loss 1.1236, acc 0.59375, learning_rate 0.00206021
2017-09-28T16:29:59.007883: step 226, loss 1.14206, acc 0.53125, learning_rate 0.00205221
2017-09-28T16:29:59.093071: step 227, loss 1.05871, acc 0.65625, learning_rate 0.00204424
2017-09-28T16:29:59.174452: step 228, loss 0.99587, acc 0.671875, learning_rate 0.0020363
2017-09-28T16:29:59.257597: step 229, loss 1.27861, acc 0.53125, learning_rate 0.0020284
2017-09-28T16:29:59.340696: step 230, loss 1.25537, acc 0.53125, learning_rate 0.00202053
2017-09-28T16:29:59.426672: step 231, loss 1.2207, acc 0.53125, learning_rate 0.00201269
2017-09-28T16:29:59.509019: step 232, loss 1.297, acc 0.515625, learning_rate 0.00200488
2017-09-28T16:29:59.592016: step 233, loss 1.03799, acc 0.625, learning_rate 0.00199711
2017-09-28T16:29:59.671787: step 234, loss 0.967544, acc 0.671875, learning_rate 0.00198936
2017-09-28T16:29:59.750884: step 235, loss 1.03952, acc 0.578125, learning_rate 0.00198165
2017-09-28T16:29:59.831820: step 236, loss 1.1911, acc 0.53125, learning_rate 0.00197397
2017-09-28T16:29:59.916573: step 237, loss 1.18003, acc 0.546875, learning_rate 0.00196632
2017-09-28T16:29:59.994787: step 238, loss 1.12523, acc 0.578125, learning_rate 0.0019587
2017-09-28T16:30:00.077810: step 239, loss 1.0366, acc 0.640625, learning_rate 0.00195112
2017-09-28T16:30:00.163897: step 240, loss 1.02468, acc 0.640625, learning_rate 0.00194356

Evaluation:
2017-09-28T16:30:00.448913: step 240, loss 1.10035, acc 0.576978

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-240

2017-09-28T16:30:01.017018: step 241, loss 1.13396, acc 0.5625, learning_rate 0.00193604
2017-09-28T16:30:01.096536: step 242, loss 1.13308, acc 0.609375, learning_rate 0.00192854
2017-09-28T16:30:01.177192: step 243, loss 1.27154, acc 0.546875, learning_rate 0.00192108
2017-09-28T16:30:01.259500: step 244, loss 1.01872, acc 0.65625, learning_rate 0.00191364
2017-09-28T16:30:01.341029: step 245, loss 0.996257, acc 0.65625, learning_rate 0.00190624
2017-09-28T16:30:01.425946: step 246, loss 1.21396, acc 0.484375, learning_rate 0.00189887
2017-09-28T16:30:01.509538: step 247, loss 1.31248, acc 0.515625, learning_rate 0.00189153
2017-09-28T16:30:01.594114: step 248, loss 1.23949, acc 0.546875, learning_rate 0.00188421
2017-09-28T16:30:01.675939: step 249, loss 1.08233, acc 0.578125, learning_rate 0.00187693
2017-09-28T16:30:01.757411: step 250, loss 1.22261, acc 0.53125, learning_rate 0.00186968
2017-09-28T16:30:01.841119: step 251, loss 1.06662, acc 0.5625, learning_rate 0.00186245
2017-09-28T16:30:01.923856: step 252, loss 1.29696, acc 0.484375, learning_rate 0.00185526
2017-09-28T16:30:02.006200: step 253, loss 1.02626, acc 0.5625, learning_rate 0.0018481
2017-09-28T16:30:02.089608: step 254, loss 1.04739, acc 0.625, learning_rate 0.00184096
2017-09-28T16:30:02.167932: step 255, loss 1.21656, acc 0.5, learning_rate 0.00183385
2017-09-28T16:30:02.248846: step 256, loss 1.23003, acc 0.46875, learning_rate 0.00182678
2017-09-28T16:30:02.332044: step 257, loss 1.22537, acc 0.546875, learning_rate 0.00181973
2017-09-28T16:30:02.416356: step 258, loss 1.07256, acc 0.578125, learning_rate 0.00181271
2017-09-28T16:30:02.499879: step 259, loss 1.09437, acc 0.625, learning_rate 0.00180572
2017-09-28T16:30:02.580905: step 260, loss 1.14528, acc 0.5625, learning_rate 0.00179876
2017-09-28T16:30:02.662865: step 261, loss 1.16286, acc 0.5625, learning_rate 0.00179182
2017-09-28T16:30:02.747146: step 262, loss 1.06997, acc 0.609375, learning_rate 0.00178492
2017-09-28T16:30:02.831683: step 263, loss 1.03153, acc 0.609375, learning_rate 0.00177804
2017-09-28T16:30:02.912761: step 264, loss 1.13265, acc 0.546875, learning_rate 0.00177119
2017-09-28T16:30:02.997447: step 265, loss 1.0833, acc 0.609375, learning_rate 0.00176437
2017-09-28T16:30:03.079267: step 266, loss 1.00878, acc 0.65625, learning_rate 0.00175758
2017-09-28T16:30:03.162940: step 267, loss 1.11851, acc 0.578125, learning_rate 0.00175081
2017-09-28T16:30:03.247440: step 268, loss 1.16025, acc 0.515625, learning_rate 0.00174407
2017-09-28T16:30:03.330619: step 269, loss 1.12342, acc 0.625, learning_rate 0.00173736
2017-09-28T16:30:03.411974: step 270, loss 1.16376, acc 0.546875, learning_rate 0.00173068
2017-09-28T16:30:03.494228: step 271, loss 0.939504, acc 0.703125, learning_rate 0.00172402
2017-09-28T16:30:03.572332: step 272, loss 1.1733, acc 0.484375, learning_rate 0.00171739
2017-09-28T16:30:03.658816: step 273, loss 1.16204, acc 0.53125, learning_rate 0.00171079
2017-09-28T16:30:03.743206: step 274, loss 1.29203, acc 0.46875, learning_rate 0.00170422
2017-09-28T16:30:03.826278: step 275, loss 1.13559, acc 0.53125, learning_rate 0.00169767
2017-09-28T16:30:03.907790: step 276, loss 1.06337, acc 0.640625, learning_rate 0.00169115
2017-09-28T16:30:03.992370: step 277, loss 1.26568, acc 0.515625, learning_rate 0.00168465
2017-09-28T16:30:04.072091: step 278, loss 1.04514, acc 0.5625, learning_rate 0.00167818
2017-09-28T16:30:04.152437: step 279, loss 1.01394, acc 0.65625, learning_rate 0.00167174
2017-09-28T16:30:04.234617: step 280, loss 0.946992, acc 0.6875, learning_rate 0.00166533

Evaluation:
2017-09-28T16:30:04.522699: step 280, loss 1.05165, acc 0.581295

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-280

2017-09-28T16:30:05.087247: step 281, loss 1.06822, acc 0.625, learning_rate 0.00165894
2017-09-28T16:30:05.169288: step 282, loss 1.23994, acc 0.515625, learning_rate 0.00165257
2017-09-28T16:30:05.251632: step 283, loss 0.944252, acc 0.625, learning_rate 0.00164624
2017-09-28T16:30:05.332414: step 284, loss 1.15097, acc 0.578125, learning_rate 0.00163993
2017-09-28T16:30:05.415988: step 285, loss 0.982034, acc 0.671875, learning_rate 0.00163364
2017-09-28T16:30:05.498260: step 286, loss 1.00572, acc 0.6875, learning_rate 0.00162738
2017-09-28T16:30:05.580571: step 287, loss 1.16979, acc 0.5625, learning_rate 0.00162115
2017-09-28T16:30:05.661746: step 288, loss 1.12363, acc 0.59375, learning_rate 0.00161494
2017-09-28T16:30:05.751768: step 289, loss 1.11467, acc 0.59375, learning_rate 0.00160875
2017-09-28T16:30:05.829968: step 290, loss 1.21259, acc 0.515625, learning_rate 0.00160259
2017-09-28T16:30:05.910351: step 291, loss 0.901882, acc 0.65625, learning_rate 0.00159646
2017-09-28T16:30:05.990580: step 292, loss 1.21334, acc 0.546875, learning_rate 0.00159035
2017-09-28T16:30:06.073071: step 293, loss 1.11679, acc 0.578125, learning_rate 0.00158427
2017-09-28T16:30:06.136409: step 294, loss 1.16169, acc 0.54902, learning_rate 0.00157821
2017-09-28T16:30:06.222315: step 295, loss 1.01516, acc 0.640625, learning_rate 0.00157218
2017-09-28T16:30:06.305102: step 296, loss 1.26498, acc 0.484375, learning_rate 0.00156617
2017-09-28T16:30:06.388120: step 297, loss 1.07845, acc 0.578125, learning_rate 0.00156018
2017-09-28T16:30:06.470380: step 298, loss 1.13395, acc 0.546875, learning_rate 0.00155422
2017-09-28T16:30:06.549828: step 299, loss 1.01755, acc 0.6875, learning_rate 0.00154829
2017-09-28T16:30:06.630111: step 300, loss 1.01884, acc 0.625, learning_rate 0.00154238
2017-09-28T16:30:06.711855: step 301, loss 1.17239, acc 0.578125, learning_rate 0.00153649
2017-09-28T16:30:06.794826: step 302, loss 0.757944, acc 0.796875, learning_rate 0.00153063
2017-09-28T16:30:06.876204: step 303, loss 1.14052, acc 0.53125, learning_rate 0.00152479
2017-09-28T16:30:06.959073: step 304, loss 0.939729, acc 0.640625, learning_rate 0.00151897
2017-09-28T16:30:07.041793: step 305, loss 1.17735, acc 0.5, learning_rate 0.00151318
2017-09-28T16:30:07.123984: step 306, loss 0.975891, acc 0.671875, learning_rate 0.00150741
2017-09-28T16:30:07.206772: step 307, loss 1.03611, acc 0.578125, learning_rate 0.00150167
2017-09-28T16:30:07.288452: step 308, loss 1.09292, acc 0.609375, learning_rate 0.00149594
2017-09-28T16:30:07.368753: step 309, loss 1.05224, acc 0.5625, learning_rate 0.00149025
2017-09-28T16:30:07.450784: step 310, loss 0.948945, acc 0.640625, learning_rate 0.00148457
2017-09-28T16:30:07.533610: step 311, loss 1.07863, acc 0.59375, learning_rate 0.00147892
2017-09-28T16:30:07.617338: step 312, loss 1.14847, acc 0.5625, learning_rate 0.00147329
2017-09-28T16:30:07.699326: step 313, loss 1.10283, acc 0.53125, learning_rate 0.00146769
2017-09-28T16:30:07.782035: step 314, loss 1.307, acc 0.4375, learning_rate 0.0014621
2017-09-28T16:30:07.862778: step 315, loss 1.02675, acc 0.578125, learning_rate 0.00145654
2017-09-28T16:30:07.942801: step 316, loss 0.823247, acc 0.71875, learning_rate 0.00145101
2017-09-28T16:30:08.025659: step 317, loss 0.954122, acc 0.640625, learning_rate 0.00144549
2017-09-28T16:30:08.108382: step 318, loss 1.22932, acc 0.453125, learning_rate 0.00144
2017-09-28T16:30:08.190652: step 319, loss 0.996117, acc 0.625, learning_rate 0.00143453
2017-09-28T16:30:08.270838: step 320, loss 0.923966, acc 0.703125, learning_rate 0.00142908

Evaluation:
2017-09-28T16:30:08.555364: step 320, loss 1.01753, acc 0.598561

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-320

2017-09-28T16:30:09.042959: step 321, loss 0.974949, acc 0.703125, learning_rate 0.00142366
2017-09-28T16:30:09.123556: step 322, loss 1.07302, acc 0.515625, learning_rate 0.00141826
2017-09-28T16:30:09.206767: step 323, loss 1.08566, acc 0.5625, learning_rate 0.00141288
2017-09-28T16:30:09.288242: step 324, loss 0.978431, acc 0.65625, learning_rate 0.00140752
2017-09-28T16:30:09.368844: step 325, loss 1.04167, acc 0.5625, learning_rate 0.00140218
2017-09-28T16:30:09.453729: step 326, loss 1.19167, acc 0.515625, learning_rate 0.00139686
2017-09-28T16:30:09.535046: step 327, loss 0.923991, acc 0.625, learning_rate 0.00139157
2017-09-28T16:30:09.615455: step 328, loss 1.01972, acc 0.6875, learning_rate 0.0013863
2017-09-28T16:30:09.698839: step 329, loss 1.21109, acc 0.546875, learning_rate 0.00138105
2017-09-28T16:30:09.780557: step 330, loss 1.07404, acc 0.640625, learning_rate 0.00137582
2017-09-28T16:30:09.865872: step 331, loss 1.06906, acc 0.515625, learning_rate 0.00137061
2017-09-28T16:30:09.946854: step 332, loss 0.984167, acc 0.609375, learning_rate 0.00136543
2017-09-28T16:30:10.030136: step 333, loss 1.12659, acc 0.515625, learning_rate 0.00136026
2017-09-28T16:30:10.111043: step 334, loss 0.888038, acc 0.65625, learning_rate 0.00135512
2017-09-28T16:30:10.191226: step 335, loss 1.007, acc 0.625, learning_rate 0.00134999
2017-09-28T16:30:10.271220: step 336, loss 1.03123, acc 0.578125, learning_rate 0.00134489
2017-09-28T16:30:10.351729: step 337, loss 0.955717, acc 0.625, learning_rate 0.00133981
2017-09-28T16:30:10.432442: step 338, loss 0.965705, acc 0.65625, learning_rate 0.00133475
2017-09-28T16:30:10.514506: step 339, loss 1.13194, acc 0.5625, learning_rate 0.00132971
2017-09-28T16:30:10.596801: step 340, loss 1.1533, acc 0.546875, learning_rate 0.00132469
2017-09-28T16:30:10.680458: step 341, loss 1.08494, acc 0.578125, learning_rate 0.00131969
2017-09-28T16:30:10.766366: step 342, loss 1.00658, acc 0.609375, learning_rate 0.00131471
2017-09-28T16:30:10.850119: step 343, loss 1.03681, acc 0.625, learning_rate 0.00130975
2017-09-28T16:30:10.930415: step 344, loss 0.964464, acc 0.65625, learning_rate 0.00130482
2017-09-28T16:30:11.014010: step 345, loss 1.03114, acc 0.59375, learning_rate 0.0012999
2017-09-28T16:30:11.095649: step 346, loss 0.974972, acc 0.609375, learning_rate 0.001295
2017-09-28T16:30:11.178426: step 347, loss 1.25214, acc 0.46875, learning_rate 0.00129012
2017-09-28T16:30:11.259160: step 348, loss 1.0272, acc 0.53125, learning_rate 0.00128527
2017-09-28T16:30:11.338989: step 349, loss 1.01469, acc 0.578125, learning_rate 0.00128043
2017-09-28T16:30:11.423740: step 350, loss 0.945924, acc 0.671875, learning_rate 0.00127561
2017-09-28T16:30:11.505499: step 351, loss 0.934344, acc 0.671875, learning_rate 0.00127081
2017-09-28T16:30:11.587201: step 352, loss 1.05971, acc 0.640625, learning_rate 0.00126603
2017-09-28T16:30:11.668302: step 353, loss 0.993249, acc 0.5625, learning_rate 0.00126127
2017-09-28T16:30:11.754568: step 354, loss 0.961937, acc 0.640625, learning_rate 0.00125653
2017-09-28T16:30:11.837186: step 355, loss 1.08394, acc 0.59375, learning_rate 0.00125181
2017-09-28T16:30:11.921936: step 356, loss 1.11324, acc 0.578125, learning_rate 0.00124711
2017-09-28T16:30:12.007017: step 357, loss 1.13987, acc 0.546875, learning_rate 0.00124243
2017-09-28T16:30:12.089964: step 358, loss 0.967909, acc 0.59375, learning_rate 0.00123777
2017-09-28T16:30:12.172327: step 359, loss 1.03777, acc 0.625, learning_rate 0.00123312
2017-09-28T16:30:12.255087: step 360, loss 1.0093, acc 0.625, learning_rate 0.0012285

Evaluation:
2017-09-28T16:30:12.540655: step 360, loss 1.00031, acc 0.595683

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-360

2017-09-28T16:30:13.096178: step 361, loss 1.08127, acc 0.5625, learning_rate 0.00122389
2017-09-28T16:30:13.177348: step 362, loss 1.08041, acc 0.59375, learning_rate 0.0012193
2017-09-28T16:30:13.259186: step 363, loss 1.21129, acc 0.515625, learning_rate 0.00121473
2017-09-28T16:30:13.338378: step 364, loss 0.950241, acc 0.671875, learning_rate 0.00121018
2017-09-28T16:30:13.421455: step 365, loss 1.04741, acc 0.578125, learning_rate 0.00120565
2017-09-28T16:30:13.503459: step 366, loss 0.933837, acc 0.65625, learning_rate 0.00120114
2017-09-28T16:30:13.584548: step 367, loss 1.119, acc 0.5625, learning_rate 0.00119664
2017-09-28T16:30:13.666527: step 368, loss 1.0639, acc 0.53125, learning_rate 0.00119217
2017-09-28T16:30:13.749902: step 369, loss 1.18214, acc 0.484375, learning_rate 0.00118771
2017-09-28T16:30:13.834378: step 370, loss 0.878773, acc 0.6875, learning_rate 0.00118327
2017-09-28T16:30:13.912206: step 371, loss 1.13848, acc 0.546875, learning_rate 0.00117885
2017-09-28T16:30:13.996434: step 372, loss 0.968182, acc 0.609375, learning_rate 0.00117445
2017-09-28T16:30:14.078915: step 373, loss 1.27501, acc 0.5, learning_rate 0.00117006
2017-09-28T16:30:14.163191: step 374, loss 1.09526, acc 0.578125, learning_rate 0.00116569
2017-09-28T16:30:14.245908: step 375, loss 1.1539, acc 0.546875, learning_rate 0.00116134
2017-09-28T16:30:14.330511: step 376, loss 0.904544, acc 0.671875, learning_rate 0.00115701
2017-09-28T16:30:14.413791: step 377, loss 1.03442, acc 0.59375, learning_rate 0.0011527
2017-09-28T16:30:14.497923: step 378, loss 1.16663, acc 0.5625, learning_rate 0.0011484
2017-09-28T16:30:14.579793: step 379, loss 1.22712, acc 0.5, learning_rate 0.00114412
2017-09-28T16:30:14.661511: step 380, loss 1.03139, acc 0.59375, learning_rate 0.00113986
2017-09-28T16:30:14.743791: step 381, loss 0.986933, acc 0.640625, learning_rate 0.00113561
2017-09-28T16:30:14.824738: step 382, loss 1.0959, acc 0.59375, learning_rate 0.00113139
2017-09-28T16:30:14.903757: step 383, loss 1.08306, acc 0.59375, learning_rate 0.00112718
2017-09-28T16:30:14.985221: step 384, loss 1.41976, acc 0.34375, learning_rate 0.00112298
2017-09-28T16:30:15.063556: step 385, loss 1.13038, acc 0.5, learning_rate 0.00111881
2017-09-28T16:30:15.146386: step 386, loss 1.03338, acc 0.578125, learning_rate 0.00111465
2017-09-28T16:30:15.229711: step 387, loss 1.22471, acc 0.53125, learning_rate 0.00111051
2017-09-28T16:30:15.313776: step 388, loss 1.01769, acc 0.578125, learning_rate 0.00110638
2017-09-28T16:30:15.395566: step 389, loss 1.05473, acc 0.625, learning_rate 0.00110228
2017-09-28T16:30:15.477433: step 390, loss 1.13766, acc 0.5625, learning_rate 0.00109818
2017-09-28T16:30:15.562606: step 391, loss 0.917037, acc 0.640625, learning_rate 0.00109411
2017-09-28T16:30:15.629548: step 392, loss 1.26864, acc 0.470588, learning_rate 0.00109005
2017-09-28T16:30:15.713092: step 393, loss 0.882103, acc 0.640625, learning_rate 0.00108601
2017-09-28T16:30:15.800379: step 394, loss 1.0436, acc 0.578125, learning_rate 0.00108199
2017-09-28T16:30:15.880749: step 395, loss 0.930572, acc 0.65625, learning_rate 0.00107798
2017-09-28T16:30:15.961858: step 396, loss 0.951895, acc 0.65625, learning_rate 0.00107399
2017-09-28T16:30:16.044014: step 397, loss 0.971586, acc 0.671875, learning_rate 0.00107001
2017-09-28T16:30:16.126857: step 398, loss 1.11597, acc 0.5625, learning_rate 0.00106605
2017-09-28T16:30:16.207953: step 399, loss 0.983713, acc 0.5625, learning_rate 0.00106211
2017-09-28T16:30:16.289006: step 400, loss 1.0818, acc 0.59375, learning_rate 0.00105818

Evaluation:
2017-09-28T16:30:16.573905: step 400, loss 0.981816, acc 0.598561

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-400

2017-09-28T16:30:17.202626: step 401, loss 1.14159, acc 0.59375, learning_rate 0.00105427
2017-09-28T16:30:17.282709: step 402, loss 0.980131, acc 0.625, learning_rate 0.00105037
2017-09-28T16:30:17.367414: step 403, loss 0.978179, acc 0.609375, learning_rate 0.0010465
2017-09-28T16:30:17.449134: step 404, loss 1.05812, acc 0.59375, learning_rate 0.00104263
2017-09-28T16:30:17.532481: step 405, loss 1.04459, acc 0.625, learning_rate 0.00103878
2017-09-28T16:30:17.615663: step 406, loss 0.962745, acc 0.671875, learning_rate 0.00103495
2017-09-28T16:30:17.696842: step 407, loss 1.0062, acc 0.578125, learning_rate 0.00103114
2017-09-28T16:30:17.778645: step 408, loss 0.973403, acc 0.671875, learning_rate 0.00102734
2017-09-28T16:30:17.860931: step 409, loss 1.01094, acc 0.609375, learning_rate 0.00102355
2017-09-28T16:30:17.946575: step 410, loss 1.07516, acc 0.59375, learning_rate 0.00101978
2017-09-28T16:30:18.032665: step 411, loss 1.07197, acc 0.609375, learning_rate 0.00101603
2017-09-28T16:30:18.113862: step 412, loss 1.10742, acc 0.5, learning_rate 0.00101229
2017-09-28T16:30:18.194908: step 413, loss 1.0615, acc 0.578125, learning_rate 0.00100856
2017-09-28T16:30:18.275916: step 414, loss 1.16757, acc 0.53125, learning_rate 0.00100486
2017-09-28T16:30:18.359251: step 415, loss 0.899792, acc 0.65625, learning_rate 0.00100116
2017-09-28T16:30:18.439180: step 416, loss 1.17358, acc 0.46875, learning_rate 0.000997483
2017-09-28T16:30:18.523051: step 417, loss 0.990309, acc 0.59375, learning_rate 0.00099382
2017-09-28T16:30:18.606580: step 418, loss 0.9546, acc 0.65625, learning_rate 0.000990172
2017-09-28T16:30:18.686657: step 419, loss 0.966485, acc 0.671875, learning_rate 0.000986538
2017-09-28T16:30:18.767552: step 420, loss 0.896197, acc 0.671875, learning_rate 0.00098292
2017-09-28T16:30:18.849801: step 421, loss 1.04638, acc 0.546875, learning_rate 0.000979316
2017-09-28T16:30:18.933135: step 422, loss 0.86978, acc 0.65625, learning_rate 0.000975727
2017-09-28T16:30:19.013115: step 423, loss 0.87069, acc 0.6875, learning_rate 0.000972152
2017-09-28T16:30:19.093769: step 424, loss 1.0343, acc 0.59375, learning_rate 0.000968592
2017-09-28T16:30:19.176365: step 425, loss 1.11701, acc 0.484375, learning_rate 0.000965047
2017-09-28T16:30:19.256936: step 426, loss 0.909254, acc 0.6875, learning_rate 0.000961516
2017-09-28T16:30:19.338058: step 427, loss 0.954439, acc 0.6875, learning_rate 0.000958
2017-09-28T16:30:19.420933: step 428, loss 1.15539, acc 0.5, learning_rate 0.000954497
2017-09-28T16:30:19.500703: step 429, loss 1.05423, acc 0.625, learning_rate 0.00095101
2017-09-28T16:30:19.582886: step 430, loss 0.956669, acc 0.625, learning_rate 0.000947536
2017-09-28T16:30:19.663695: step 431, loss 1.0718, acc 0.5625, learning_rate 0.000944076
2017-09-28T16:30:19.746219: step 432, loss 0.910499, acc 0.703125, learning_rate 0.000940631
2017-09-28T16:30:19.828116: step 433, loss 1.02027, acc 0.59375, learning_rate 0.0009372
2017-09-28T16:30:19.911715: step 434, loss 0.966138, acc 0.5625, learning_rate 0.000933783
2017-09-28T16:30:19.994143: step 435, loss 0.894115, acc 0.65625, learning_rate 0.000930379
2017-09-28T16:30:20.077303: step 436, loss 0.937458, acc 0.6875, learning_rate 0.00092699
2017-09-28T16:30:20.159278: step 437, loss 0.96718, acc 0.65625, learning_rate 0.000923614
2017-09-28T16:30:20.242717: step 438, loss 1.0068, acc 0.609375, learning_rate 0.000920253
2017-09-28T16:30:20.324602: step 439, loss 0.956231, acc 0.640625, learning_rate 0.000916905
2017-09-28T16:30:20.407668: step 440, loss 0.835619, acc 0.6875, learning_rate 0.00091357

Evaluation:
2017-09-28T16:30:20.693690: step 440, loss 0.969647, acc 0.611511

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-440

2017-09-28T16:30:21.187387: step 441, loss 0.978883, acc 0.625, learning_rate 0.000910249
2017-09-28T16:30:21.269789: step 442, loss 0.966815, acc 0.609375, learning_rate 0.000906942
2017-09-28T16:30:21.350663: step 443, loss 1.03331, acc 0.640625, learning_rate 0.000903648
2017-09-28T16:30:21.431870: step 444, loss 1.14795, acc 0.515625, learning_rate 0.000900368
2017-09-28T16:30:21.512399: step 445, loss 1.04429, acc 0.59375, learning_rate 0.000897101
2017-09-28T16:30:21.596091: step 446, loss 1.15529, acc 0.46875, learning_rate 0.000893848
2017-09-28T16:30:21.676627: step 447, loss 1.14542, acc 0.53125, learning_rate 0.000890607
2017-09-28T16:30:21.758014: step 448, loss 0.906127, acc 0.625, learning_rate 0.00088738
2017-09-28T16:30:21.840925: step 449, loss 0.985451, acc 0.546875, learning_rate 0.000884166
2017-09-28T16:30:21.921631: step 450, loss 0.912866, acc 0.625, learning_rate 0.000880966
2017-09-28T16:30:22.004637: step 451, loss 1.08158, acc 0.5625, learning_rate 0.000877778
2017-09-28T16:30:22.084926: step 452, loss 1.02954, acc 0.609375, learning_rate 0.000874603
2017-09-28T16:30:22.166901: step 453, loss 0.934308, acc 0.609375, learning_rate 0.000871441
2017-09-28T16:30:22.247743: step 454, loss 0.956513, acc 0.65625, learning_rate 0.000868293
2017-09-28T16:30:22.329699: step 455, loss 1.01723, acc 0.625, learning_rate 0.000865157
2017-09-28T16:30:22.409578: step 456, loss 0.994276, acc 0.609375, learning_rate 0.000862033
2017-09-28T16:30:22.490695: step 457, loss 0.993485, acc 0.59375, learning_rate 0.000858923
2017-09-28T16:30:22.571335: step 458, loss 0.965556, acc 0.59375, learning_rate 0.000855825
2017-09-28T16:30:22.651635: step 459, loss 0.985446, acc 0.609375, learning_rate 0.00085274
2017-09-28T16:30:22.735400: step 460, loss 0.911393, acc 0.640625, learning_rate 0.000849668
2017-09-28T16:30:22.818644: step 461, loss 1.17157, acc 0.53125, learning_rate 0.000846608
2017-09-28T16:30:22.898732: step 462, loss 1.02902, acc 0.640625, learning_rate 0.00084356
2017-09-28T16:30:22.980803: step 463, loss 0.990315, acc 0.65625, learning_rate 0.000840525
2017-09-28T16:30:23.062626: step 464, loss 0.916942, acc 0.671875, learning_rate 0.000837502
2017-09-28T16:30:23.143675: step 465, loss 1.01762, acc 0.59375, learning_rate 0.000834492
2017-09-28T16:30:23.225547: step 466, loss 0.659621, acc 0.796875, learning_rate 0.000831494
2017-09-28T16:30:23.305478: step 467, loss 0.988811, acc 0.625, learning_rate 0.000828508
2017-09-28T16:30:23.389474: step 468, loss 0.873042, acc 0.6875, learning_rate 0.000825535
2017-09-28T16:30:23.469464: step 469, loss 0.979731, acc 0.640625, learning_rate 0.000822573
2017-09-28T16:30:23.548311: step 470, loss 0.953823, acc 0.625, learning_rate 0.000819624
2017-09-28T16:30:23.630651: step 471, loss 0.909912, acc 0.671875, learning_rate 0.000816687
2017-09-28T16:30:23.715505: step 472, loss 0.984814, acc 0.578125, learning_rate 0.000813761
2017-09-28T16:30:23.796549: step 473, loss 0.955466, acc 0.59375, learning_rate 0.000810848
2017-09-28T16:30:23.876374: step 474, loss 1.05409, acc 0.5625, learning_rate 0.000807946
2017-09-28T16:30:23.959752: step 475, loss 0.959256, acc 0.65625, learning_rate 0.000805057
2017-09-28T16:30:24.041270: step 476, loss 1.05206, acc 0.5625, learning_rate 0.000802179
2017-09-28T16:30:24.124119: step 477, loss 0.965409, acc 0.640625, learning_rate 0.000799313
2017-09-28T16:30:24.208458: step 478, loss 0.997156, acc 0.578125, learning_rate 0.000796458
2017-09-28T16:30:24.289449: step 479, loss 1.23452, acc 0.46875, learning_rate 0.000793616
2017-09-28T16:30:24.369393: step 480, loss 0.94469, acc 0.625, learning_rate 0.000790784

Evaluation:
2017-09-28T16:30:24.652878: step 480, loss 0.956347, acc 0.604317

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-480

2017-09-28T16:30:25.206355: step 481, loss 1.23597, acc 0.484375, learning_rate 0.000787965
2017-09-28T16:30:25.288091: step 482, loss 1.01442, acc 0.5625, learning_rate 0.000785157
2017-09-28T16:30:25.368346: step 483, loss 0.882592, acc 0.71875, learning_rate 0.00078236
2017-09-28T16:30:25.448579: step 484, loss 0.986156, acc 0.625, learning_rate 0.000779575
2017-09-28T16:30:25.530249: step 485, loss 0.889884, acc 0.640625, learning_rate 0.000776801
2017-09-28T16:30:25.611066: step 486, loss 0.8875, acc 0.6875, learning_rate 0.000774038
2017-09-28T16:30:25.692432: step 487, loss 1.02843, acc 0.578125, learning_rate 0.000771287
2017-09-28T16:30:25.777038: step 488, loss 0.975845, acc 0.640625, learning_rate 0.000768547
2017-09-28T16:30:25.863896: step 489, loss 0.924486, acc 0.640625, learning_rate 0.000765818
2017-09-28T16:30:25.928767: step 490, loss 0.784204, acc 0.764706, learning_rate 0.000763101
2017-09-28T16:30:26.009694: step 491, loss 0.930961, acc 0.609375, learning_rate 0.000760394
2017-09-28T16:30:26.090374: step 492, loss 0.951821, acc 0.65625, learning_rate 0.000757698
2017-09-28T16:30:26.174396: step 493, loss 1.05072, acc 0.546875, learning_rate 0.000755014
2017-09-28T16:30:26.261412: step 494, loss 0.964105, acc 0.65625, learning_rate 0.00075234
2017-09-28T16:30:26.345268: step 495, loss 0.882524, acc 0.625, learning_rate 0.000749677
2017-09-28T16:30:26.431613: step 496, loss 1.04058, acc 0.546875, learning_rate 0.000747026
2017-09-28T16:30:26.512964: step 497, loss 0.977983, acc 0.625, learning_rate 0.000744385
2017-09-28T16:30:26.595272: step 498, loss 0.940567, acc 0.640625, learning_rate 0.000741754
2017-09-28T16:30:26.680819: step 499, loss 0.999236, acc 0.609375, learning_rate 0.000739135
2017-09-28T16:30:26.761623: step 500, loss 1.07745, acc 0.59375, learning_rate 0.000736526
2017-09-28T16:30:26.841598: step 501, loss 1.02545, acc 0.546875, learning_rate 0.000733928
2017-09-28T16:30:26.923271: step 502, loss 1.06066, acc 0.578125, learning_rate 0.00073134
2017-09-28T16:30:27.006924: step 503, loss 0.946593, acc 0.578125, learning_rate 0.000728763
2017-09-28T16:30:27.090657: step 504, loss 0.958642, acc 0.578125, learning_rate 0.000726197
2017-09-28T16:30:27.175688: step 505, loss 1.1702, acc 0.53125, learning_rate 0.000723641
2017-09-28T16:30:27.256640: step 506, loss 1.07521, acc 0.53125, learning_rate 0.000721095
2017-09-28T16:30:27.336889: step 507, loss 0.946201, acc 0.65625, learning_rate 0.00071856
2017-09-28T16:30:27.419955: step 508, loss 0.925633, acc 0.625, learning_rate 0.000716036
2017-09-28T16:30:27.500293: step 509, loss 0.954326, acc 0.71875, learning_rate 0.000713521
2017-09-28T16:30:27.582476: step 510, loss 1.08234, acc 0.53125, learning_rate 0.000711017
2017-09-28T16:30:27.665594: step 511, loss 1.07704, acc 0.546875, learning_rate 0.000708523
2017-09-28T16:30:27.750836: step 512, loss 0.960087, acc 0.65625, learning_rate 0.000706039
2017-09-28T16:30:27.833891: step 513, loss 1.07431, acc 0.515625, learning_rate 0.000703565
2017-09-28T16:30:27.915895: step 514, loss 0.854083, acc 0.6875, learning_rate 0.000701102
2017-09-28T16:30:27.994858: step 515, loss 1.0023, acc 0.59375, learning_rate 0.000698648
2017-09-28T16:30:28.078928: step 516, loss 0.895069, acc 0.65625, learning_rate 0.000696204
2017-09-28T16:30:28.161013: step 517, loss 0.992821, acc 0.625, learning_rate 0.000693771
2017-09-28T16:30:28.242176: step 518, loss 1.24148, acc 0.5, learning_rate 0.000691347
2017-09-28T16:30:28.325219: step 519, loss 0.769288, acc 0.734375, learning_rate 0.000688934
2017-09-28T16:30:28.407422: step 520, loss 0.824712, acc 0.640625, learning_rate 0.00068653

Evaluation:
2017-09-28T16:30:28.694689: step 520, loss 0.94522, acc 0.611511

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-520

2017-09-28T16:30:29.335659: step 521, loss 0.935528, acc 0.625, learning_rate 0.000684136
2017-09-28T16:30:29.422904: step 522, loss 1.00832, acc 0.625, learning_rate 0.000681751
2017-09-28T16:30:29.503446: step 523, loss 0.997355, acc 0.59375, learning_rate 0.000679377
2017-09-28T16:30:29.584128: step 524, loss 0.952691, acc 0.578125, learning_rate 0.000677012
2017-09-28T16:30:29.666712: step 525, loss 1.05269, acc 0.625, learning_rate 0.000674657
2017-09-28T16:30:29.750395: step 526, loss 0.889274, acc 0.671875, learning_rate 0.000672311
2017-09-28T16:30:29.833073: step 527, loss 1.01104, acc 0.640625, learning_rate 0.000669975
2017-09-28T16:30:29.912617: step 528, loss 0.950679, acc 0.6875, learning_rate 0.000667648
2017-09-28T16:30:29.992184: step 529, loss 0.924151, acc 0.625, learning_rate 0.000665331
2017-09-28T16:30:30.073830: step 530, loss 1.00366, acc 0.609375, learning_rate 0.000663024
2017-09-28T16:30:30.154948: step 531, loss 0.927286, acc 0.625, learning_rate 0.000660726
2017-09-28T16:30:30.237767: step 532, loss 1.01003, acc 0.59375, learning_rate 0.000658437
2017-09-28T16:30:30.320023: step 533, loss 0.945829, acc 0.640625, learning_rate 0.000656158
2017-09-28T16:30:30.411774: step 534, loss 0.988429, acc 0.609375, learning_rate 0.000653888
2017-09-28T16:30:30.497129: step 535, loss 1.11283, acc 0.515625, learning_rate 0.000651627
2017-09-28T16:30:30.581704: step 536, loss 0.912816, acc 0.65625, learning_rate 0.000649375
2017-09-28T16:30:30.665589: step 537, loss 0.952435, acc 0.609375, learning_rate 0.000647133
2017-09-28T16:30:30.753582: step 538, loss 0.97954, acc 0.59375, learning_rate 0.000644899
2017-09-28T16:30:30.837132: step 539, loss 0.954162, acc 0.625, learning_rate 0.000642675
2017-09-28T16:30:30.928582: step 540, loss 0.978977, acc 0.625, learning_rate 0.00064046
2017-09-28T16:30:31.013630: step 541, loss 0.876619, acc 0.625, learning_rate 0.000638254
2017-09-28T16:30:31.100040: step 542, loss 1.00932, acc 0.609375, learning_rate 0.000636057
2017-09-28T16:30:31.182827: step 543, loss 0.898229, acc 0.625, learning_rate 0.000633869
2017-09-28T16:30:31.266362: step 544, loss 0.901189, acc 0.578125, learning_rate 0.00063169
2017-09-28T16:30:31.348596: step 545, loss 0.841408, acc 0.65625, learning_rate 0.00062952
2017-09-28T16:30:31.432416: step 546, loss 0.991311, acc 0.609375, learning_rate 0.000627358
2017-09-28T16:30:31.514587: step 547, loss 0.923074, acc 0.609375, learning_rate 0.000625206
2017-09-28T16:30:31.597944: step 548, loss 0.9863, acc 0.609375, learning_rate 0.000623062
2017-09-28T16:30:31.679562: step 549, loss 0.971949, acc 0.5625, learning_rate 0.000620927
2017-09-28T16:30:31.760376: step 550, loss 1.06352, acc 0.609375, learning_rate 0.000618801
2017-09-28T16:30:31.838741: step 551, loss 0.996615, acc 0.640625, learning_rate 0.000616683
2017-09-28T16:30:31.920494: step 552, loss 0.886451, acc 0.671875, learning_rate 0.000614574
2017-09-28T16:30:32.006388: step 553, loss 0.901415, acc 0.640625, learning_rate 0.000612474
2017-09-28T16:30:32.087206: step 554, loss 0.832169, acc 0.640625, learning_rate 0.000610382
2017-09-28T16:30:32.169922: step 555, loss 1.00405, acc 0.578125, learning_rate 0.000608299
2017-09-28T16:30:32.252566: step 556, loss 0.927682, acc 0.59375, learning_rate 0.000606224
2017-09-28T16:30:32.334570: step 557, loss 0.782163, acc 0.71875, learning_rate 0.000604158
2017-09-28T16:30:32.415832: step 558, loss 1.08002, acc 0.5, learning_rate 0.0006021
2017-09-28T16:30:32.497315: step 559, loss 1.0131, acc 0.5625, learning_rate 0.00060005
2017-09-28T16:30:32.578176: step 560, loss 0.885484, acc 0.6875, learning_rate 0.000598009

Evaluation:
2017-09-28T16:30:32.864978: step 560, loss 0.930332, acc 0.617266

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-560

2017-09-28T16:30:33.359960: step 561, loss 0.950284, acc 0.609375, learning_rate 0.000595977
2017-09-28T16:30:33.440537: step 562, loss 0.912907, acc 0.703125, learning_rate 0.000593952
2017-09-28T16:30:33.524348: step 563, loss 1.11902, acc 0.53125, learning_rate 0.000591936
2017-09-28T16:30:33.605296: step 564, loss 0.897576, acc 0.75, learning_rate 0.000589928
2017-09-28T16:30:33.690627: step 565, loss 0.928395, acc 0.640625, learning_rate 0.000587928
2017-09-28T16:30:33.773865: step 566, loss 0.996841, acc 0.578125, learning_rate 0.000585937
2017-09-28T16:30:33.858489: step 567, loss 0.814055, acc 0.671875, learning_rate 0.000583953
2017-09-28T16:30:33.940603: step 568, loss 0.736647, acc 0.703125, learning_rate 0.000581978
2017-09-28T16:30:34.022026: step 569, loss 1.00875, acc 0.59375, learning_rate 0.00058001
2017-09-28T16:30:34.106779: step 570, loss 1.02626, acc 0.625, learning_rate 0.000578051
2017-09-28T16:30:34.189650: step 571, loss 1.05579, acc 0.59375, learning_rate 0.0005761
2017-09-28T16:30:34.273183: step 572, loss 0.89537, acc 0.625, learning_rate 0.000574157
2017-09-28T16:30:34.354216: step 573, loss 0.978941, acc 0.625, learning_rate 0.000572221
2017-09-28T16:30:34.437766: step 574, loss 0.880075, acc 0.6875, learning_rate 0.000570294
2017-09-28T16:30:34.519242: step 575, loss 0.835919, acc 0.703125, learning_rate 0.000568374
2017-09-28T16:30:34.600400: step 576, loss 0.787597, acc 0.75, learning_rate 0.000566462
2017-09-28T16:30:34.682959: step 577, loss 0.995883, acc 0.609375, learning_rate 0.000564558
2017-09-28T16:30:34.764821: step 578, loss 0.942041, acc 0.578125, learning_rate 0.000562662
2017-09-28T16:30:34.847861: step 579, loss 0.854606, acc 0.6875, learning_rate 0.000560774
2017-09-28T16:30:34.929030: step 580, loss 0.909279, acc 0.65625, learning_rate 0.000558893
2017-09-28T16:30:35.012203: step 581, loss 0.889469, acc 0.609375, learning_rate 0.00055702
2017-09-28T16:30:35.094197: step 582, loss 0.927845, acc 0.578125, learning_rate 0.000555154
2017-09-28T16:30:35.178015: step 583, loss 0.925431, acc 0.640625, learning_rate 0.000553296
2017-09-28T16:30:35.260023: step 584, loss 0.95317, acc 0.625, learning_rate 0.000551446
2017-09-28T16:30:35.344614: step 585, loss 0.965137, acc 0.59375, learning_rate 0.000549604
2017-09-28T16:30:35.428221: step 586, loss 0.98711, acc 0.59375, learning_rate 0.000547768
2017-09-28T16:30:35.510427: step 587, loss 0.954266, acc 0.59375, learning_rate 0.000545941
2017-09-28T16:30:35.574850: step 588, loss 0.872205, acc 0.647059, learning_rate 0.00054412
2017-09-28T16:30:35.658043: step 589, loss 1.02016, acc 0.59375, learning_rate 0.000542308
2017-09-28T16:30:35.741136: step 590, loss 1.02095, acc 0.5625, learning_rate 0.000540502
2017-09-28T16:30:35.825092: step 591, loss 0.903428, acc 0.65625, learning_rate 0.000538704
2017-09-28T16:30:35.907674: step 592, loss 0.983495, acc 0.59375, learning_rate 0.000536914
2017-09-28T16:30:35.993217: step 593, loss 1.01554, acc 0.515625, learning_rate 0.00053513
2017-09-28T16:30:36.075060: step 594, loss 0.934922, acc 0.671875, learning_rate 0.000533354
2017-09-28T16:30:36.155537: step 595, loss 0.858182, acc 0.640625, learning_rate 0.000531585
2017-09-28T16:30:36.237851: step 596, loss 0.759489, acc 0.75, learning_rate 0.000529824
2017-09-28T16:30:36.316636: step 597, loss 1.03237, acc 0.59375, learning_rate 0.000528069
2017-09-28T16:30:36.397945: step 598, loss 0.851021, acc 0.6875, learning_rate 0.000526322
2017-09-28T16:30:36.476975: step 599, loss 0.8052, acc 0.671875, learning_rate 0.000524582
2017-09-28T16:30:36.558483: step 600, loss 0.942344, acc 0.609375, learning_rate 0.000522849

Evaluation:
2017-09-28T16:30:36.845722: step 600, loss 0.924784, acc 0.627338

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-600

2017-09-28T16:30:37.397978: step 601, loss 0.798828, acc 0.734375, learning_rate 0.000521123
2017-09-28T16:30:37.478072: step 602, loss 0.927116, acc 0.59375, learning_rate 0.000519404
2017-09-28T16:30:37.558193: step 603, loss 0.804754, acc 0.6875, learning_rate 0.000517692
2017-09-28T16:30:37.640965: step 604, loss 0.947697, acc 0.625, learning_rate 0.000515987
2017-09-28T16:30:37.720059: step 605, loss 0.766326, acc 0.71875, learning_rate 0.000514289
2017-09-28T16:30:37.806032: step 606, loss 1.13513, acc 0.625, learning_rate 0.000512598
2017-09-28T16:30:37.889550: step 607, loss 0.891276, acc 0.640625, learning_rate 0.000510914
2017-09-28T16:30:37.970290: step 608, loss 0.840529, acc 0.65625, learning_rate 0.000509237
2017-09-28T16:30:38.051791: step 609, loss 0.740878, acc 0.6875, learning_rate 0.000507566
2017-09-28T16:30:38.134221: step 610, loss 0.91546, acc 0.609375, learning_rate 0.000505903
2017-09-28T16:30:38.214220: step 611, loss 0.865868, acc 0.71875, learning_rate 0.000504246
2017-09-28T16:30:38.296261: step 612, loss 1.02465, acc 0.5625, learning_rate 0.000502596
2017-09-28T16:30:38.379638: step 613, loss 1.17619, acc 0.5625, learning_rate 0.000500953
2017-09-28T16:30:38.463118: step 614, loss 0.889354, acc 0.640625, learning_rate 0.000499316
2017-09-28T16:30:38.541832: step 615, loss 0.847999, acc 0.671875, learning_rate 0.000497686
2017-09-28T16:30:38.623017: step 616, loss 0.909412, acc 0.671875, learning_rate 0.000496063
2017-09-28T16:30:38.707023: step 617, loss 0.906842, acc 0.640625, learning_rate 0.000494446
2017-09-28T16:30:38.791275: step 618, loss 1.00799, acc 0.625, learning_rate 0.000492836
2017-09-28T16:30:38.881546: step 619, loss 1.00404, acc 0.65625, learning_rate 0.000491233
2017-09-28T16:30:38.966912: step 620, loss 0.924003, acc 0.59375, learning_rate 0.000489636
2017-09-28T16:30:39.049575: step 621, loss 1.19882, acc 0.5, learning_rate 0.000488045
2017-09-28T16:30:39.133223: step 622, loss 0.93525, acc 0.59375, learning_rate 0.000486461
2017-09-28T16:30:39.216403: step 623, loss 0.871154, acc 0.71875, learning_rate 0.000484884
2017-09-28T16:30:39.296524: step 624, loss 0.914211, acc 0.59375, learning_rate 0.000483313
2017-09-28T16:30:39.376705: step 625, loss 0.788517, acc 0.640625, learning_rate 0.000481748
2017-09-28T16:30:39.459602: step 626, loss 1.00118, acc 0.59375, learning_rate 0.00048019
2017-09-28T16:30:39.544565: step 627, loss 0.913753, acc 0.65625, learning_rate 0.000478638
2017-09-28T16:30:39.630470: step 628, loss 0.898155, acc 0.6875, learning_rate 0.000477093
2017-09-28T16:30:39.714924: step 629, loss 0.968732, acc 0.65625, learning_rate 0.000475554
2017-09-28T16:30:39.795580: step 630, loss 0.945057, acc 0.625, learning_rate 0.000474021
2017-09-28T16:30:39.877770: step 631, loss 0.917084, acc 0.609375, learning_rate 0.000472494
2017-09-28T16:30:39.959022: step 632, loss 1.00992, acc 0.578125, learning_rate 0.000470974
2017-09-28T16:30:40.042268: step 633, loss 0.747873, acc 0.765625, learning_rate 0.000469459
2017-09-28T16:30:40.126670: step 634, loss 0.859373, acc 0.65625, learning_rate 0.000467951
2017-09-28T16:30:40.209433: step 635, loss 1.07243, acc 0.546875, learning_rate 0.000466449
2017-09-28T16:30:40.289649: step 636, loss 0.97606, acc 0.5625, learning_rate 0.000464954
2017-09-28T16:30:40.375378: step 637, loss 0.785226, acc 0.75, learning_rate 0.000463464
2017-09-28T16:30:40.459105: step 638, loss 1.08879, acc 0.53125, learning_rate 0.00046198
2017-09-28T16:30:40.541113: step 639, loss 0.928798, acc 0.625, learning_rate 0.000460503
2017-09-28T16:30:40.625695: step 640, loss 0.901564, acc 0.609375, learning_rate 0.000459031

Evaluation:
2017-09-28T16:30:40.910888: step 640, loss 0.925546, acc 0.625899

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-640

2017-09-28T16:30:41.466956: step 641, loss 0.854699, acc 0.6875, learning_rate 0.000457566
2017-09-28T16:30:41.549231: step 642, loss 0.85954, acc 0.640625, learning_rate 0.000456106
2017-09-28T16:30:41.629451: step 643, loss 0.895415, acc 0.6875, learning_rate 0.000454653
2017-09-28T16:30:41.713478: step 644, loss 1.11058, acc 0.53125, learning_rate 0.000453205
2017-09-28T16:30:41.795830: step 645, loss 0.939273, acc 0.546875, learning_rate 0.000451764
2017-09-28T16:30:41.878633: step 646, loss 0.832316, acc 0.71875, learning_rate 0.000450328
2017-09-28T16:30:41.959581: step 647, loss 0.773958, acc 0.6875, learning_rate 0.000448898
2017-09-28T16:30:42.043249: step 648, loss 0.924029, acc 0.640625, learning_rate 0.000447474
2017-09-28T16:30:42.126411: step 649, loss 0.968203, acc 0.578125, learning_rate 0.000446055
2017-09-28T16:30:42.204728: step 650, loss 1.00583, acc 0.53125, learning_rate 0.000444643
2017-09-28T16:30:42.287448: step 651, loss 1.01581, acc 0.625, learning_rate 0.000443236
2017-09-28T16:30:42.368157: step 652, loss 1.16781, acc 0.4375, learning_rate 0.000441835
2017-09-28T16:30:42.447734: step 653, loss 0.905929, acc 0.65625, learning_rate 0.00044044
2017-09-28T16:30:42.530917: step 654, loss 0.866303, acc 0.671875, learning_rate 0.00043905
2017-09-28T16:30:42.612008: step 655, loss 0.898299, acc 0.671875, learning_rate 0.000437666
2017-09-28T16:30:42.695349: step 656, loss 1.04291, acc 0.6875, learning_rate 0.000436288
2017-09-28T16:30:42.781449: step 657, loss 0.837938, acc 0.671875, learning_rate 0.000434915
2017-09-28T16:30:42.864393: step 658, loss 0.789184, acc 0.75, learning_rate 0.000433548
2017-09-28T16:30:42.945435: step 659, loss 0.898611, acc 0.671875, learning_rate 0.000432187
2017-09-28T16:30:43.028005: step 660, loss 1.00258, acc 0.578125, learning_rate 0.000430831
2017-09-28T16:30:43.112621: step 661, loss 0.975944, acc 0.5625, learning_rate 0.000429481
2017-09-28T16:30:43.192723: step 662, loss 0.905167, acc 0.65625, learning_rate 0.000428136
2017-09-28T16:30:43.273271: step 663, loss 1.02187, acc 0.578125, learning_rate 0.000426796
2017-09-28T16:30:43.356358: step 664, loss 0.932727, acc 0.609375, learning_rate 0.000425463
2017-09-28T16:30:43.439857: step 665, loss 1.09145, acc 0.5, learning_rate 0.000424134
2017-09-28T16:30:43.520355: step 666, loss 0.809337, acc 0.609375, learning_rate 0.000422811
2017-09-28T16:30:43.601705: step 667, loss 0.869268, acc 0.65625, learning_rate 0.000421493
2017-09-28T16:30:43.686355: step 668, loss 0.888267, acc 0.65625, learning_rate 0.000420181
2017-09-28T16:30:43.770844: step 669, loss 0.790931, acc 0.71875, learning_rate 0.000418874
2017-09-28T16:30:43.856992: step 670, loss 0.962979, acc 0.609375, learning_rate 0.000417573
2017-09-28T16:30:43.940028: step 671, loss 1.01253, acc 0.609375, learning_rate 0.000416276
2017-09-28T16:30:44.021731: step 672, loss 0.965107, acc 0.625, learning_rate 0.000414985
2017-09-28T16:30:44.105079: step 673, loss 1.07972, acc 0.59375, learning_rate 0.0004137
2017-09-28T16:30:44.185457: step 674, loss 0.915391, acc 0.671875, learning_rate 0.000412419
2017-09-28T16:30:44.268751: step 675, loss 0.869783, acc 0.671875, learning_rate 0.000411144
2017-09-28T16:30:44.350513: step 676, loss 0.97704, acc 0.578125, learning_rate 0.000409874
2017-09-28T16:30:44.432072: step 677, loss 1.02402, acc 0.578125, learning_rate 0.000408609
2017-09-28T16:30:44.515350: step 678, loss 1.08508, acc 0.5625, learning_rate 0.00040735
2017-09-28T16:30:44.596727: step 679, loss 0.869514, acc 0.71875, learning_rate 0.000406095
2017-09-28T16:30:44.680102: step 680, loss 1.08276, acc 0.53125, learning_rate 0.000404846

Evaluation:
2017-09-28T16:30:44.966316: step 680, loss 0.915337, acc 0.625899

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-680

2017-09-28T16:30:45.593758: step 681, loss 0.908428, acc 0.5625, learning_rate 0.000403601
2017-09-28T16:30:45.676659: step 682, loss 0.918966, acc 0.671875, learning_rate 0.000402362
2017-09-28T16:30:45.757239: step 683, loss 1.14463, acc 0.5625, learning_rate 0.000401128
2017-09-28T16:30:45.848941: step 684, loss 0.829406, acc 0.71875, learning_rate 0.000399899
2017-09-28T16:30:45.939677: step 685, loss 0.907034, acc 0.65625, learning_rate 0.000398675
2017-09-28T16:30:46.014486: step 686, loss 0.793457, acc 0.72549, learning_rate 0.000397456
2017-09-28T16:30:46.098010: step 687, loss 0.949766, acc 0.578125, learning_rate 0.000396241
2017-09-28T16:30:46.178996: step 688, loss 0.786131, acc 0.71875, learning_rate 0.000395032
2017-09-28T16:30:46.259333: step 689, loss 0.908997, acc 0.625, learning_rate 0.000393828
2017-09-28T16:30:46.340560: step 690, loss 0.83141, acc 0.671875, learning_rate 0.000392629
2017-09-28T16:30:46.424322: step 691, loss 0.883139, acc 0.640625, learning_rate 0.000391434
2017-09-28T16:30:46.504691: step 692, loss 0.968253, acc 0.640625, learning_rate 0.000390245
2017-09-28T16:30:46.585057: step 693, loss 0.771618, acc 0.65625, learning_rate 0.00038906
2017-09-28T16:30:46.667504: step 694, loss 1.01196, acc 0.578125, learning_rate 0.00038788
2017-09-28T16:30:46.746717: step 695, loss 0.992854, acc 0.625, learning_rate 0.000386705
2017-09-28T16:30:46.827576: step 696, loss 0.969621, acc 0.65625, learning_rate 0.000385535
2017-09-28T16:30:46.908630: step 697, loss 1.0104, acc 0.609375, learning_rate 0.000384369
2017-09-28T16:30:46.990170: step 698, loss 0.816283, acc 0.671875, learning_rate 0.000383209
2017-09-28T16:30:47.070834: step 699, loss 1.16995, acc 0.546875, learning_rate 0.000382053
2017-09-28T16:30:47.149508: step 700, loss 0.805987, acc 0.6875, learning_rate 0.000380901
2017-09-28T16:30:47.229881: step 701, loss 0.93562, acc 0.671875, learning_rate 0.000379755
2017-09-28T16:30:47.310834: step 702, loss 1.01283, acc 0.53125, learning_rate 0.000378613
2017-09-28T16:30:47.396128: step 703, loss 0.926748, acc 0.609375, learning_rate 0.000377476
2017-09-28T16:30:47.475444: step 704, loss 0.946553, acc 0.625, learning_rate 0.000376343
2017-09-28T16:30:47.557526: step 705, loss 1.08695, acc 0.5625, learning_rate 0.000375215
2017-09-28T16:30:47.640630: step 706, loss 0.897437, acc 0.625, learning_rate 0.000374092
2017-09-28T16:30:47.723441: step 707, loss 1.09506, acc 0.53125, learning_rate 0.000372973
2017-09-28T16:30:47.805644: step 708, loss 0.975141, acc 0.578125, learning_rate 0.000371859
2017-09-28T16:30:47.885456: step 709, loss 0.945582, acc 0.625, learning_rate 0.000370749
2017-09-28T16:30:47.971746: step 710, loss 0.901399, acc 0.640625, learning_rate 0.000369644
2017-09-28T16:30:48.052713: step 711, loss 0.96604, acc 0.546875, learning_rate 0.000368543
2017-09-28T16:30:48.136724: step 712, loss 1.00506, acc 0.609375, learning_rate 0.000367447
2017-09-28T16:30:48.218069: step 713, loss 0.849135, acc 0.671875, learning_rate 0.000366356
2017-09-28T16:30:48.302089: step 714, loss 0.885331, acc 0.65625, learning_rate 0.000365268
2017-09-28T16:30:48.383464: step 715, loss 0.894813, acc 0.640625, learning_rate 0.000364186
2017-09-28T16:30:48.464370: step 716, loss 1.00878, acc 0.5625, learning_rate 0.000363107
2017-09-28T16:30:48.545971: step 717, loss 0.982967, acc 0.59375, learning_rate 0.000362033
2017-09-28T16:30:48.629995: step 718, loss 1.06487, acc 0.578125, learning_rate 0.000360964
2017-09-28T16:30:48.712686: step 719, loss 0.848975, acc 0.640625, learning_rate 0.000359899
2017-09-28T16:30:48.795081: step 720, loss 0.911343, acc 0.640625, learning_rate 0.000358838

Evaluation:
2017-09-28T16:30:49.082564: step 720, loss 0.914627, acc 0.640288

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-720

2017-09-28T16:30:49.574226: step 721, loss 0.928346, acc 0.65625, learning_rate 0.000357781
2017-09-28T16:30:49.656823: step 722, loss 0.845869, acc 0.703125, learning_rate 0.000356729
2017-09-28T16:30:49.738403: step 723, loss 0.89814, acc 0.6875, learning_rate 0.000355681
2017-09-28T16:30:49.821698: step 724, loss 0.924121, acc 0.65625, learning_rate 0.000354637
2017-09-28T16:30:49.904106: step 725, loss 0.95366, acc 0.609375, learning_rate 0.000353598
2017-09-28T16:30:49.985757: step 726, loss 0.972652, acc 0.640625, learning_rate 0.000352563
2017-09-28T16:30:50.067433: step 727, loss 1.02265, acc 0.59375, learning_rate 0.000351532
2017-09-28T16:30:50.147606: step 728, loss 0.830016, acc 0.71875, learning_rate 0.000350505
2017-09-28T16:30:50.229496: step 729, loss 0.732191, acc 0.703125, learning_rate 0.000349483
2017-09-28T16:30:50.313456: step 730, loss 0.807436, acc 0.703125, learning_rate 0.000348465
2017-09-28T16:30:50.393810: step 731, loss 0.783593, acc 0.703125, learning_rate 0.00034745
2017-09-28T16:30:50.476049: step 732, loss 0.827154, acc 0.671875, learning_rate 0.00034644
2017-09-28T16:30:50.556655: step 733, loss 0.915266, acc 0.59375, learning_rate 0.000345434
2017-09-28T16:30:50.639065: step 734, loss 0.826894, acc 0.671875, learning_rate 0.000344433
2017-09-28T16:30:50.721983: step 735, loss 0.976716, acc 0.609375, learning_rate 0.000343435
2017-09-28T16:30:50.803784: step 736, loss 1.04223, acc 0.59375, learning_rate 0.000342441
2017-09-28T16:30:50.886844: step 737, loss 0.868581, acc 0.671875, learning_rate 0.000341452
2017-09-28T16:30:50.971968: step 738, loss 0.982277, acc 0.640625, learning_rate 0.000340466
2017-09-28T16:30:51.066165: step 739, loss 0.81726, acc 0.640625, learning_rate 0.000339485
2017-09-28T16:30:51.147930: step 740, loss 0.722289, acc 0.71875, learning_rate 0.000338507
2017-09-28T16:30:51.232048: step 741, loss 0.650462, acc 0.796875, learning_rate 0.000337534
2017-09-28T16:30:51.314480: step 742, loss 0.868964, acc 0.65625, learning_rate 0.000336564
2017-09-28T16:30:51.399639: step 743, loss 0.753476, acc 0.703125, learning_rate 0.000335598
2017-09-28T16:30:51.482065: step 744, loss 0.997785, acc 0.625, learning_rate 0.000334637
2017-09-28T16:30:51.561981: step 745, loss 0.70199, acc 0.75, learning_rate 0.000333679
2017-09-28T16:30:51.643834: step 746, loss 1.04397, acc 0.546875, learning_rate 0.000332725
2017-09-28T16:30:51.723089: step 747, loss 0.937884, acc 0.609375, learning_rate 0.000331775
2017-09-28T16:30:51.805962: step 748, loss 0.831686, acc 0.703125, learning_rate 0.000330829
2017-09-28T16:30:51.886436: step 749, loss 1.12811, acc 0.5625, learning_rate 0.000329887
2017-09-28T16:30:51.968040: step 750, loss 0.830884, acc 0.6875, learning_rate 0.000328949
2017-09-28T16:30:52.049682: step 751, loss 0.874405, acc 0.640625, learning_rate 0.000328014
2017-09-28T16:30:52.138271: step 752, loss 0.960319, acc 0.546875, learning_rate 0.000327083
2017-09-28T16:30:52.221328: step 753, loss 0.906017, acc 0.609375, learning_rate 0.000326157
2017-09-28T16:30:52.305408: step 754, loss 1.06319, acc 0.578125, learning_rate 0.000325233
2017-09-28T16:30:52.386737: step 755, loss 1.01687, acc 0.59375, learning_rate 0.000324314
2017-09-28T16:30:52.468007: step 756, loss 0.96152, acc 0.578125, learning_rate 0.000323399
2017-09-28T16:30:52.552326: step 757, loss 0.935743, acc 0.609375, learning_rate 0.000322487
2017-09-28T16:30:52.634142: step 758, loss 0.826605, acc 0.71875, learning_rate 0.000321579
2017-09-28T16:30:52.713988: step 759, loss 0.85017, acc 0.5625, learning_rate 0.000320674
2017-09-28T16:30:52.794618: step 760, loss 0.794446, acc 0.671875, learning_rate 0.000319773

Evaluation:
2017-09-28T16:30:53.078866: step 760, loss 0.905481, acc 0.625899

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-760

2017-09-28T16:30:53.635445: step 761, loss 1.06144, acc 0.515625, learning_rate 0.000318876
2017-09-28T16:30:53.716674: step 762, loss 0.94135, acc 0.59375, learning_rate 0.000317983
2017-09-28T16:30:53.799419: step 763, loss 0.920785, acc 0.59375, learning_rate 0.000317093
2017-09-28T16:30:53.883228: step 764, loss 0.91073, acc 0.65625, learning_rate 0.000316207
2017-09-28T16:30:53.968276: step 765, loss 0.919993, acc 0.65625, learning_rate 0.000315325
2017-09-28T16:30:54.051613: step 766, loss 1.05725, acc 0.609375, learning_rate 0.000314446
2017-09-28T16:30:54.134887: step 767, loss 0.881986, acc 0.6875, learning_rate 0.00031357
2017-09-28T16:30:54.215089: step 768, loss 0.879135, acc 0.640625, learning_rate 0.000312699
2017-09-28T16:30:54.297536: step 769, loss 0.934649, acc 0.609375, learning_rate 0.00031183
2017-09-28T16:30:54.380761: step 770, loss 0.865479, acc 0.671875, learning_rate 0.000310966
2017-09-28T16:30:54.464956: step 771, loss 0.92598, acc 0.640625, learning_rate 0.000310105
2017-09-28T16:30:54.547423: step 772, loss 1.03714, acc 0.5, learning_rate 0.000309247
2017-09-28T16:30:54.629746: step 773, loss 0.86955, acc 0.640625, learning_rate 0.000308393
2017-09-28T16:30:54.712403: step 774, loss 1.03445, acc 0.5625, learning_rate 0.000307542
2017-09-28T16:30:54.798224: step 775, loss 0.872641, acc 0.703125, learning_rate 0.000306695
2017-09-28T16:30:54.880103: step 776, loss 0.927645, acc 0.65625, learning_rate 0.000305852
2017-09-28T16:30:54.963219: step 777, loss 0.893792, acc 0.65625, learning_rate 0.000305011
2017-09-28T16:30:55.044665: step 778, loss 0.726555, acc 0.75, learning_rate 0.000304174
2017-09-28T16:30:55.129689: step 779, loss 0.957703, acc 0.578125, learning_rate 0.000303341
2017-09-28T16:30:55.211214: step 780, loss 0.787203, acc 0.71875, learning_rate 0.000302511
2017-09-28T16:30:55.290967: step 781, loss 0.888773, acc 0.65625, learning_rate 0.000301684
2017-09-28T16:30:55.371337: step 782, loss 0.78967, acc 0.734375, learning_rate 0.000300861
2017-09-28T16:30:55.453519: step 783, loss 0.68636, acc 0.765625, learning_rate 0.000300041
2017-09-28T16:30:55.517686: step 784, loss 0.745261, acc 0.745098, learning_rate 0.000299225
2017-09-28T16:30:55.598304: step 785, loss 0.902496, acc 0.625, learning_rate 0.000298412
2017-09-28T16:30:55.678598: step 786, loss 1.07464, acc 0.53125, learning_rate 0.000297602
2017-09-28T16:30:55.759072: step 787, loss 0.966265, acc 0.59375, learning_rate 0.000296795
2017-09-28T16:30:55.840809: step 788, loss 0.701154, acc 0.78125, learning_rate 0.000295992
2017-09-28T16:30:55.923904: step 789, loss 0.869034, acc 0.65625, learning_rate 0.000295192
2017-09-28T16:30:56.006490: step 790, loss 0.858583, acc 0.703125, learning_rate 0.000294395
2017-09-28T16:30:56.100144: step 791, loss 1.06444, acc 0.515625, learning_rate 0.000293602
2017-09-28T16:30:56.182624: step 792, loss 0.866975, acc 0.609375, learning_rate 0.000292812
2017-09-28T16:30:56.262976: step 793, loss 1.05438, acc 0.59375, learning_rate 0.000292025
2017-09-28T16:30:56.344444: step 794, loss 1.00035, acc 0.59375, learning_rate 0.000291241
2017-09-28T16:30:56.423765: step 795, loss 1.0074, acc 0.578125, learning_rate 0.00029046
2017-09-28T16:30:56.505964: step 796, loss 0.933207, acc 0.65625, learning_rate 0.000289683
2017-09-28T16:30:56.586651: step 797, loss 0.980541, acc 0.640625, learning_rate 0.000288908
2017-09-28T16:30:56.668894: step 798, loss 0.898549, acc 0.640625, learning_rate 0.000288137
2017-09-28T16:30:56.753389: step 799, loss 0.813043, acc 0.6875, learning_rate 0.000287369
2017-09-28T16:30:56.834487: step 800, loss 0.743892, acc 0.6875, learning_rate 0.000286605

Evaluation:
2017-09-28T16:30:57.120454: step 800, loss 0.900732, acc 0.630216

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-800

2017-09-28T16:30:57.673988: step 801, loss 0.904037, acc 0.59375, learning_rate 0.000285843
2017-09-28T16:30:57.759477: step 802, loss 0.784931, acc 0.75, learning_rate 0.000285084
2017-09-28T16:30:57.840394: step 803, loss 0.951164, acc 0.625, learning_rate 0.000284329
2017-09-28T16:30:57.921936: step 804, loss 0.92092, acc 0.578125, learning_rate 0.000283577
2017-09-28T16:30:58.004953: step 805, loss 0.99325, acc 0.59375, learning_rate 0.000282827
2017-09-28T16:30:58.086380: step 806, loss 1.11468, acc 0.546875, learning_rate 0.000282081
2017-09-28T16:30:58.169788: step 807, loss 0.904417, acc 0.640625, learning_rate 0.000281338
2017-09-28T16:30:58.250526: step 808, loss 0.797956, acc 0.6875, learning_rate 0.000280598
2017-09-28T16:30:58.331155: step 809, loss 0.84558, acc 0.625, learning_rate 0.00027986
2017-09-28T16:30:58.414544: step 810, loss 1.06693, acc 0.578125, learning_rate 0.000279126
2017-09-28T16:30:58.495896: step 811, loss 0.914282, acc 0.609375, learning_rate 0.000278395
2017-09-28T16:30:58.576476: step 812, loss 1.01788, acc 0.578125, learning_rate 0.000277667
2017-09-28T16:30:58.659851: step 813, loss 1.01888, acc 0.625, learning_rate 0.000276942
2017-09-28T16:30:58.744948: step 814, loss 0.851425, acc 0.65625, learning_rate 0.00027622
2017-09-28T16:30:58.827261: step 815, loss 0.813435, acc 0.65625, learning_rate 0.0002755
2017-09-28T16:30:58.909353: step 816, loss 0.836661, acc 0.65625, learning_rate 0.000274784
2017-09-28T16:30:58.992075: step 817, loss 0.849495, acc 0.625, learning_rate 0.000274071
2017-09-28T16:30:59.073886: step 818, loss 0.941345, acc 0.625, learning_rate 0.00027336
2017-09-28T16:30:59.155225: step 819, loss 1.03721, acc 0.625, learning_rate 0.000272652
2017-09-28T16:30:59.238464: step 820, loss 0.794484, acc 0.671875, learning_rate 0.000271948
2017-09-28T16:30:59.322195: step 821, loss 1.017, acc 0.671875, learning_rate 0.000271246
2017-09-28T16:30:59.407626: step 822, loss 1.06816, acc 0.53125, learning_rate 0.000270547
2017-09-28T16:30:59.488757: step 823, loss 0.919873, acc 0.6875, learning_rate 0.000269851
2017-09-28T16:30:59.570805: step 824, loss 0.961231, acc 0.59375, learning_rate 0.000269157
2017-09-28T16:30:59.652496: step 825, loss 0.784098, acc 0.6875, learning_rate 0.000268467
2017-09-28T16:30:59.734885: step 826, loss 0.887987, acc 0.65625, learning_rate 0.000267779
2017-09-28T16:30:59.818315: step 827, loss 1.01504, acc 0.59375, learning_rate 0.000267094
2017-09-28T16:30:59.901113: step 828, loss 0.899843, acc 0.71875, learning_rate 0.000266412
2017-09-28T16:30:59.984299: step 829, loss 0.873169, acc 0.703125, learning_rate 0.000265733
2017-09-28T16:31:00.066592: step 830, loss 0.90205, acc 0.59375, learning_rate 0.000265057
2017-09-28T16:31:00.147425: step 831, loss 0.80789, acc 0.71875, learning_rate 0.000264383
2017-09-28T16:31:00.228198: step 832, loss 0.949289, acc 0.671875, learning_rate 0.000263712
2017-09-28T16:31:00.310077: step 833, loss 0.767013, acc 0.71875, learning_rate 0.000263044
2017-09-28T16:31:00.393776: step 834, loss 0.931094, acc 0.703125, learning_rate 0.000262378
2017-09-28T16:31:00.474091: step 835, loss 0.859868, acc 0.625, learning_rate 0.000261715
2017-09-28T16:31:00.556983: step 836, loss 0.791746, acc 0.640625, learning_rate 0.000261055
2017-09-28T16:31:00.638365: step 837, loss 0.916066, acc 0.609375, learning_rate 0.000260398
2017-09-28T16:31:00.722837: step 838, loss 0.975741, acc 0.59375, learning_rate 0.000259743
2017-09-28T16:31:00.804721: step 839, loss 0.787921, acc 0.6875, learning_rate 0.000259091
2017-09-28T16:31:00.889571: step 840, loss 0.884696, acc 0.671875, learning_rate 0.000258442

Evaluation:
2017-09-28T16:31:01.184281: step 840, loss 0.897591, acc 0.630216

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-840

2017-09-28T16:31:01.807868: step 841, loss 0.880799, acc 0.625, learning_rate 0.000257795
2017-09-28T16:31:01.887345: step 842, loss 1.18339, acc 0.484375, learning_rate 0.000257151
2017-09-28T16:31:01.966507: step 843, loss 0.975722, acc 0.625, learning_rate 0.00025651
2017-09-28T16:31:02.047239: step 844, loss 0.808334, acc 0.6875, learning_rate 0.000255871
2017-09-28T16:31:02.127424: step 845, loss 0.782757, acc 0.65625, learning_rate 0.000255235
2017-09-28T16:31:02.209674: step 846, loss 0.948827, acc 0.703125, learning_rate 0.000254601
2017-09-28T16:31:02.291606: step 847, loss 1.04082, acc 0.59375, learning_rate 0.00025397
2017-09-28T16:31:02.372305: step 848, loss 0.824532, acc 0.734375, learning_rate 0.000253341
2017-09-28T16:31:02.457178: step 849, loss 0.899172, acc 0.625, learning_rate 0.000252716
2017-09-28T16:31:02.539616: step 850, loss 0.84889, acc 0.671875, learning_rate 0.000252092
2017-09-28T16:31:02.623035: step 851, loss 0.904467, acc 0.609375, learning_rate 0.000251471
2017-09-28T16:31:02.704887: step 852, loss 1.02297, acc 0.578125, learning_rate 0.000250853
2017-09-28T16:31:02.790111: step 853, loss 1.05267, acc 0.515625, learning_rate 0.000250237
2017-09-28T16:31:02.873978: step 854, loss 0.75682, acc 0.65625, learning_rate 0.000249624
2017-09-28T16:31:02.958525: step 855, loss 0.824667, acc 0.640625, learning_rate 0.000249013
2017-09-28T16:31:03.039904: step 856, loss 0.837016, acc 0.671875, learning_rate 0.000248405
2017-09-28T16:31:03.122930: step 857, loss 0.998779, acc 0.5625, learning_rate 0.000247799
2017-09-28T16:31:03.206116: step 858, loss 0.893782, acc 0.625, learning_rate 0.000247196
2017-09-28T16:31:03.286360: step 859, loss 0.775675, acc 0.703125, learning_rate 0.000246595
2017-09-28T16:31:03.368659: step 860, loss 1.03169, acc 0.5625, learning_rate 0.000245997
2017-09-28T16:31:03.450497: step 861, loss 0.793025, acc 0.71875, learning_rate 0.000245401
2017-09-28T16:31:03.534826: step 862, loss 0.789069, acc 0.65625, learning_rate 0.000244808
2017-09-28T16:31:03.616846: step 863, loss 0.900292, acc 0.65625, learning_rate 0.000244216
2017-09-28T16:31:03.698982: step 864, loss 0.873579, acc 0.65625, learning_rate 0.000243628
2017-09-28T16:31:03.778528: step 865, loss 0.756534, acc 0.75, learning_rate 0.000243042
2017-09-28T16:31:03.862302: step 866, loss 0.831542, acc 0.640625, learning_rate 0.000242458
2017-09-28T16:31:03.945182: step 867, loss 0.914059, acc 0.640625, learning_rate 0.000241876
2017-09-28T16:31:04.030504: step 868, loss 0.724262, acc 0.671875, learning_rate 0.000241297
2017-09-28T16:31:04.113497: step 869, loss 0.823184, acc 0.65625, learning_rate 0.00024072
2017-09-28T16:31:04.194664: step 870, loss 0.958407, acc 0.5625, learning_rate 0.000240146
2017-09-28T16:31:04.280271: step 871, loss 0.994289, acc 0.546875, learning_rate 0.000239574
2017-09-28T16:31:04.361016: step 872, loss 0.874839, acc 0.6875, learning_rate 0.000239004
2017-09-28T16:31:04.448793: step 873, loss 0.978248, acc 0.578125, learning_rate 0.000238437
2017-09-28T16:31:04.530062: step 874, loss 0.966291, acc 0.578125, learning_rate 0.000237872
2017-09-28T16:31:04.613072: step 875, loss 0.897085, acc 0.671875, learning_rate 0.000237309
2017-09-28T16:31:04.697486: step 876, loss 0.924668, acc 0.640625, learning_rate 0.000236749
2017-09-28T16:31:04.780653: step 877, loss 0.827162, acc 0.640625, learning_rate 0.00023619
2017-09-28T16:31:04.864131: step 878, loss 0.950888, acc 0.671875, learning_rate 0.000235635
2017-09-28T16:31:04.947041: step 879, loss 0.941607, acc 0.609375, learning_rate 0.000235081
2017-09-28T16:31:05.029618: step 880, loss 0.915782, acc 0.625, learning_rate 0.00023453

Evaluation:
2017-09-28T16:31:05.314355: step 880, loss 0.895389, acc 0.638849

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-880

2017-09-28T16:31:05.803425: step 881, loss 0.879269, acc 0.671875, learning_rate 0.00023398
2017-09-28T16:31:05.866606: step 882, loss 0.917243, acc 0.607843, learning_rate 0.000233434
2017-09-28T16:31:05.949365: step 883, loss 0.878959, acc 0.640625, learning_rate 0.000232889
2017-09-28T16:31:06.033839: step 884, loss 0.868537, acc 0.625, learning_rate 0.000232346
2017-09-28T16:31:06.117176: step 885, loss 0.896568, acc 0.578125, learning_rate 0.000231806
2017-09-28T16:31:06.203517: step 886, loss 1.06718, acc 0.515625, learning_rate 0.000231268
2017-09-28T16:31:06.286448: step 887, loss 0.98954, acc 0.609375, learning_rate 0.000230732
2017-09-28T16:31:06.366965: step 888, loss 0.926815, acc 0.609375, learning_rate 0.000230199
2017-09-28T16:31:06.448340: step 889, loss 0.825922, acc 0.65625, learning_rate 0.000229667
2017-09-28T16:31:06.529943: step 890, loss 1.00116, acc 0.5625, learning_rate 0.000229138
2017-09-28T16:31:06.610377: step 891, loss 0.902722, acc 0.59375, learning_rate 0.000228611
2017-09-28T16:31:06.691899: step 892, loss 1.00386, acc 0.59375, learning_rate 0.000228086
2017-09-28T16:31:06.774774: step 893, loss 0.908261, acc 0.71875, learning_rate 0.000227563
2017-09-28T16:31:06.858593: step 894, loss 0.876795, acc 0.671875, learning_rate 0.000227043
2017-09-28T16:31:06.942392: step 895, loss 0.836248, acc 0.609375, learning_rate 0.000226524
2017-09-28T16:31:07.027320: step 896, loss 0.977284, acc 0.578125, learning_rate 0.000226008
2017-09-28T16:31:07.113704: step 897, loss 0.914584, acc 0.578125, learning_rate 0.000225493
2017-09-28T16:31:07.194054: step 898, loss 0.787029, acc 0.703125, learning_rate 0.000224981
2017-09-28T16:31:07.278041: step 899, loss 0.876124, acc 0.65625, learning_rate 0.000224471
2017-09-28T16:31:07.360474: step 900, loss 0.948021, acc 0.609375, learning_rate 0.000223963
2017-09-28T16:31:07.443251: step 901, loss 0.908478, acc 0.625, learning_rate 0.000223457
2017-09-28T16:31:07.529815: step 902, loss 0.916808, acc 0.65625, learning_rate 0.000222953
2017-09-28T16:31:07.619927: step 903, loss 0.932111, acc 0.578125, learning_rate 0.000222451
2017-09-28T16:31:07.710077: step 904, loss 0.894939, acc 0.640625, learning_rate 0.000221951
2017-09-28T16:31:07.801559: step 905, loss 0.958682, acc 0.578125, learning_rate 0.000221453
2017-09-28T16:31:07.888308: step 906, loss 0.765599, acc 0.75, learning_rate 0.000220958
2017-09-28T16:31:07.970511: step 907, loss 0.847389, acc 0.765625, learning_rate 0.000220464
2017-09-28T16:31:08.052859: step 908, loss 0.991427, acc 0.578125, learning_rate 0.000219972
2017-09-28T16:31:08.133285: step 909, loss 0.876653, acc 0.671875, learning_rate 0.000219483
2017-09-28T16:31:08.214621: step 910, loss 0.939492, acc 0.671875, learning_rate 0.000218995
2017-09-28T16:31:08.296206: step 911, loss 0.77176, acc 0.6875, learning_rate 0.000218509
2017-09-28T16:31:08.380798: step 912, loss 0.946205, acc 0.609375, learning_rate 0.000218025
2017-09-28T16:31:08.470092: step 913, loss 0.800768, acc 0.6875, learning_rate 0.000217544
2017-09-28T16:31:08.554579: step 914, loss 0.693316, acc 0.703125, learning_rate 0.000217064
2017-09-28T16:31:08.642294: step 915, loss 0.8377, acc 0.65625, learning_rate 0.000216586
2017-09-28T16:31:08.724675: step 916, loss 0.784183, acc 0.6875, learning_rate 0.00021611
2017-09-28T16:31:08.806019: step 917, loss 0.904132, acc 0.65625, learning_rate 0.000215636
2017-09-28T16:31:08.888919: step 918, loss 0.879947, acc 0.65625, learning_rate 0.000215164
2017-09-28T16:31:08.968754: step 919, loss 0.703615, acc 0.765625, learning_rate 0.000214694
2017-09-28T16:31:09.050676: step 920, loss 0.835349, acc 0.71875, learning_rate 0.000214226

Evaluation:
2017-09-28T16:31:09.334066: step 920, loss 0.889918, acc 0.634532

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-920

2017-09-28T16:31:09.884426: step 921, loss 0.918589, acc 0.625, learning_rate 0.00021376
2017-09-28T16:31:09.966301: step 922, loss 0.779329, acc 0.6875, learning_rate 0.000213295
2017-09-28T16:31:10.048781: step 923, loss 0.833126, acc 0.65625, learning_rate 0.000212833
2017-09-28T16:31:10.128344: step 924, loss 0.93436, acc 0.578125, learning_rate 0.000212372
2017-09-28T16:31:10.212741: step 925, loss 0.947469, acc 0.640625, learning_rate 0.000211914
2017-09-28T16:31:10.297871: step 926, loss 0.825621, acc 0.6875, learning_rate 0.000211457
2017-09-28T16:31:10.379852: step 927, loss 0.87147, acc 0.65625, learning_rate 0.000211002
2017-09-28T16:31:10.463497: step 928, loss 0.929248, acc 0.625, learning_rate 0.000210549
2017-09-28T16:31:10.543503: step 929, loss 1.06561, acc 0.515625, learning_rate 0.000210098
2017-09-28T16:31:10.625949: step 930, loss 0.934956, acc 0.6875, learning_rate 0.000209648
2017-09-28T16:31:10.708161: step 931, loss 0.79849, acc 0.71875, learning_rate 0.000209201
2017-09-28T16:31:10.791203: step 932, loss 0.87371, acc 0.609375, learning_rate 0.000208755
2017-09-28T16:31:10.875849: step 933, loss 0.774525, acc 0.6875, learning_rate 0.000208311
2017-09-28T16:31:10.958440: step 934, loss 0.86659, acc 0.59375, learning_rate 0.000207869
2017-09-28T16:31:11.038634: step 935, loss 0.776825, acc 0.6875, learning_rate 0.000207429
2017-09-28T16:31:11.123074: step 936, loss 0.909504, acc 0.671875, learning_rate 0.00020699
2017-09-28T16:31:11.202390: step 937, loss 0.993614, acc 0.625, learning_rate 0.000206554
2017-09-28T16:31:11.290725: step 938, loss 0.950746, acc 0.578125, learning_rate 0.000206119
2017-09-28T16:31:11.370554: step 939, loss 0.782054, acc 0.671875, learning_rate 0.000205685
2017-09-28T16:31:11.453348: step 940, loss 0.908531, acc 0.65625, learning_rate 0.000205254
2017-09-28T16:31:11.537274: step 941, loss 0.83299, acc 0.703125, learning_rate 0.000204824
2017-09-28T16:31:11.618391: step 942, loss 0.830746, acc 0.6875, learning_rate 0.000204397
2017-09-28T16:31:11.698299: step 943, loss 0.91878, acc 0.609375, learning_rate 0.00020397
2017-09-28T16:31:11.780332: step 944, loss 0.86797, acc 0.671875, learning_rate 0.000203546
2017-09-28T16:31:11.861885: step 945, loss 0.89898, acc 0.703125, learning_rate 0.000203123
2017-09-28T16:31:11.942563: step 946, loss 0.735537, acc 0.71875, learning_rate 0.000202702
2017-09-28T16:31:12.025647: step 947, loss 1.05503, acc 0.546875, learning_rate 0.000202283
2017-09-28T16:31:12.107272: step 948, loss 0.717962, acc 0.71875, learning_rate 0.000201866
2017-09-28T16:31:12.190051: step 949, loss 0.768911, acc 0.671875, learning_rate 0.00020145
2017-09-28T16:31:12.270788: step 950, loss 0.937202, acc 0.625, learning_rate 0.000201036
2017-09-28T16:31:12.355054: step 951, loss 0.730614, acc 0.71875, learning_rate 0.000200623
2017-09-28T16:31:12.439407: step 952, loss 0.992748, acc 0.5625, learning_rate 0.000200213
2017-09-28T16:31:12.520306: step 953, loss 0.775047, acc 0.6875, learning_rate 0.000199804
2017-09-28T16:31:12.603824: step 954, loss 1.00058, acc 0.578125, learning_rate 0.000199396
2017-09-28T16:31:12.685899: step 955, loss 1.1262, acc 0.46875, learning_rate 0.000198991
2017-09-28T16:31:12.767797: step 956, loss 0.930073, acc 0.65625, learning_rate 0.000198587
2017-09-28T16:31:12.850287: step 957, loss 0.822103, acc 0.671875, learning_rate 0.000198184
2017-09-28T16:31:12.932461: step 958, loss 1.10493, acc 0.578125, learning_rate 0.000197783
2017-09-28T16:31:13.011984: step 959, loss 0.831728, acc 0.734375, learning_rate 0.000197384
2017-09-28T16:31:13.094319: step 960, loss 0.993586, acc 0.546875, learning_rate 0.000196987

Evaluation:
2017-09-28T16:31:13.378050: step 960, loss 0.891972, acc 0.634532

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-960

2017-09-28T16:31:13.933440: step 961, loss 0.833602, acc 0.6875, learning_rate 0.000196591
2017-09-28T16:31:14.015714: step 962, loss 0.886293, acc 0.59375, learning_rate 0.000196197
2017-09-28T16:31:14.096844: step 963, loss 0.956312, acc 0.59375, learning_rate 0.000195804
2017-09-28T16:31:14.178007: step 964, loss 0.977492, acc 0.578125, learning_rate 0.000195413
2017-09-28T16:31:14.260013: step 965, loss 0.778104, acc 0.734375, learning_rate 0.000195023
2017-09-28T16:31:14.339915: step 966, loss 0.845825, acc 0.671875, learning_rate 0.000194636
2017-09-28T16:31:14.421369: step 967, loss 0.987881, acc 0.5625, learning_rate 0.000194249
2017-09-28T16:31:14.505431: step 968, loss 0.875811, acc 0.640625, learning_rate 0.000193865
2017-09-28T16:31:14.586210: step 969, loss 0.792482, acc 0.671875, learning_rate 0.000193482
2017-09-28T16:31:14.668087: step 970, loss 0.990265, acc 0.609375, learning_rate 0.0001931
2017-09-28T16:31:14.750346: step 971, loss 0.901456, acc 0.59375, learning_rate 0.00019272
2017-09-28T16:31:14.832919: step 972, loss 0.889902, acc 0.671875, learning_rate 0.000192341
2017-09-28T16:31:14.915961: step 973, loss 0.84501, acc 0.671875, learning_rate 0.000191965
2017-09-28T16:31:14.996729: step 974, loss 1.11287, acc 0.5625, learning_rate 0.000191589
2017-09-28T16:31:15.078085: step 975, loss 1.03424, acc 0.59375, learning_rate 0.000191215
2017-09-28T16:31:15.159155: step 976, loss 0.961201, acc 0.609375, learning_rate 0.000190843
2017-09-28T16:31:15.240653: step 977, loss 0.709856, acc 0.71875, learning_rate 0.000190472
2017-09-28T16:31:15.322153: step 978, loss 0.857874, acc 0.671875, learning_rate 0.000190103
2017-09-28T16:31:15.403783: step 979, loss 0.854159, acc 0.640625, learning_rate 0.000189735
2017-09-28T16:31:15.469292: step 980, loss 0.847988, acc 0.647059, learning_rate 0.000189369
2017-09-28T16:31:15.550418: step 981, loss 0.829548, acc 0.6875, learning_rate 0.000189004
2017-09-28T16:31:15.633780: step 982, loss 0.855355, acc 0.71875, learning_rate 0.000188641
2017-09-28T16:31:15.715801: step 983, loss 0.930686, acc 0.609375, learning_rate 0.000188279
2017-09-28T16:31:15.796902: step 984, loss 0.837198, acc 0.65625, learning_rate 0.000187919
2017-09-28T16:31:15.881149: step 985, loss 0.857268, acc 0.671875, learning_rate 0.00018756
2017-09-28T16:31:15.962457: step 986, loss 1.03633, acc 0.59375, learning_rate 0.000187202
2017-09-28T16:31:16.044963: step 987, loss 0.665429, acc 0.734375, learning_rate 0.000186846
2017-09-28T16:31:16.127857: step 988, loss 0.841434, acc 0.65625, learning_rate 0.000186492
2017-09-28T16:31:16.210911: step 989, loss 1.0264, acc 0.5625, learning_rate 0.000186139
2017-09-28T16:31:16.298594: step 990, loss 0.920497, acc 0.625, learning_rate 0.000185787
2017-09-28T16:31:16.380794: step 991, loss 1.13296, acc 0.53125, learning_rate 0.000185437
2017-09-28T16:31:16.463360: step 992, loss 0.871716, acc 0.578125, learning_rate 0.000185088
2017-09-28T16:31:16.543227: step 993, loss 1.02478, acc 0.515625, learning_rate 0.000184741
2017-09-28T16:31:16.625834: step 994, loss 0.936766, acc 0.609375, learning_rate 0.000184395
2017-09-28T16:31:16.707975: step 995, loss 0.982423, acc 0.609375, learning_rate 0.000184051
2017-09-28T16:31:16.792884: step 996, loss 0.839717, acc 0.6875, learning_rate 0.000183708
2017-09-28T16:31:16.875178: step 997, loss 0.996669, acc 0.609375, learning_rate 0.000183366
2017-09-28T16:31:16.961348: step 998, loss 0.883802, acc 0.609375, learning_rate 0.000183026
2017-09-28T16:31:17.043856: step 999, loss 1.05039, acc 0.59375, learning_rate 0.000182687
2017-09-28T16:31:17.126397: step 1000, loss 0.800285, acc 0.734375, learning_rate 0.000182349

Evaluation:
2017-09-28T16:31:17.411874: step 1000, loss 0.889012, acc 0.63741

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-1000

2017-09-28T16:31:18.040861: step 1001, loss 0.885317, acc 0.625, learning_rate 0.000182013
2017-09-28T16:31:18.122464: step 1002, loss 0.906465, acc 0.609375, learning_rate 0.000181678
2017-09-28T16:31:18.203857: step 1003, loss 0.792319, acc 0.71875, learning_rate 0.000181345
2017-09-28T16:31:18.284862: step 1004, loss 0.870643, acc 0.640625, learning_rate 0.000181013
2017-09-28T16:31:18.365559: step 1005, loss 0.912096, acc 0.609375, learning_rate 0.000180682
2017-09-28T16:31:18.446315: step 1006, loss 0.93487, acc 0.609375, learning_rate 0.000180353
2017-09-28T16:31:18.530544: step 1007, loss 0.89902, acc 0.609375, learning_rate 0.000180025
2017-09-28T16:31:18.610395: step 1008, loss 0.794881, acc 0.6875, learning_rate 0.000179698
2017-09-28T16:31:18.691920: step 1009, loss 0.800299, acc 0.703125, learning_rate 0.000179373
2017-09-28T16:31:18.773854: step 1010, loss 1.09871, acc 0.59375, learning_rate 0.000179049
2017-09-28T16:31:18.855581: step 1011, loss 0.820366, acc 0.65625, learning_rate 0.000178726
2017-09-28T16:31:18.935737: step 1012, loss 0.76946, acc 0.703125, learning_rate 0.000178405
2017-09-28T16:31:19.016466: step 1013, loss 0.847783, acc 0.703125, learning_rate 0.000178085
2017-09-28T16:31:19.096566: step 1014, loss 0.964426, acc 0.65625, learning_rate 0.000177766
2017-09-28T16:31:19.176538: step 1015, loss 1.03612, acc 0.609375, learning_rate 0.000177449
2017-09-28T16:31:19.258363: step 1016, loss 0.780735, acc 0.75, learning_rate 0.000177133
2017-09-28T16:31:19.343452: step 1017, loss 0.898926, acc 0.640625, learning_rate 0.000176818
2017-09-28T16:31:19.425945: step 1018, loss 0.892738, acc 0.640625, learning_rate 0.000176504
2017-09-28T16:31:19.505573: step 1019, loss 0.914674, acc 0.625, learning_rate 0.000176192
2017-09-28T16:31:19.586978: step 1020, loss 0.753694, acc 0.65625, learning_rate 0.000175881
2017-09-28T16:31:19.667526: step 1021, loss 0.868073, acc 0.65625, learning_rate 0.000175571
2017-09-28T16:31:19.748351: step 1022, loss 0.951413, acc 0.5625, learning_rate 0.000175263
2017-09-28T16:31:19.829482: step 1023, loss 0.605901, acc 0.84375, learning_rate 0.000174956
2017-09-28T16:31:19.913420: step 1024, loss 0.96408, acc 0.65625, learning_rate 0.00017465
2017-09-28T16:31:19.994910: step 1025, loss 0.871019, acc 0.65625, learning_rate 0.000174345
2017-09-28T16:31:20.078797: step 1026, loss 1.07806, acc 0.59375, learning_rate 0.000174042
2017-09-28T16:31:20.163259: step 1027, loss 0.988106, acc 0.65625, learning_rate 0.000173739
2017-09-28T16:31:20.245280: step 1028, loss 0.965487, acc 0.609375, learning_rate 0.000173438
2017-09-28T16:31:20.326746: step 1029, loss 0.906008, acc 0.609375, learning_rate 0.000173139
2017-09-28T16:31:20.408698: step 1030, loss 0.996837, acc 0.640625, learning_rate 0.00017284
2017-09-28T16:31:20.490320: step 1031, loss 0.826852, acc 0.6875, learning_rate 0.000172543
2017-09-28T16:31:20.573585: step 1032, loss 0.787417, acc 0.6875, learning_rate 0.000172247
2017-09-28T16:31:20.656362: step 1033, loss 0.808096, acc 0.671875, learning_rate 0.000171952
2017-09-28T16:31:20.740221: step 1034, loss 0.949684, acc 0.640625, learning_rate 0.000171658
2017-09-28T16:31:20.828892: step 1035, loss 0.816165, acc 0.59375, learning_rate 0.000171366
2017-09-28T16:31:20.912707: step 1036, loss 0.888376, acc 0.609375, learning_rate 0.000171074
2017-09-28T16:31:20.997135: step 1037, loss 0.929831, acc 0.609375, learning_rate 0.000170784
2017-09-28T16:31:21.076492: step 1038, loss 0.807889, acc 0.671875, learning_rate 0.000170495
2017-09-28T16:31:21.156317: step 1039, loss 0.939415, acc 0.609375, learning_rate 0.000170208
2017-09-28T16:31:21.239932: step 1040, loss 0.883829, acc 0.609375, learning_rate 0.000169921

Evaluation:
2017-09-28T16:31:21.527796: step 1040, loss 0.884815, acc 0.638849

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-1040

2017-09-28T16:31:22.024052: step 1041, loss 0.692199, acc 0.71875, learning_rate 0.000169636
2017-09-28T16:31:22.103767: step 1042, loss 0.733643, acc 0.71875, learning_rate 0.000169351
2017-09-28T16:31:22.186258: step 1043, loss 0.796824, acc 0.703125, learning_rate 0.000169068
2017-09-28T16:31:22.267765: step 1044, loss 0.80435, acc 0.71875, learning_rate 0.000168786
2017-09-28T16:31:22.351098: step 1045, loss 0.836412, acc 0.71875, learning_rate 0.000168506
2017-09-28T16:31:22.432945: step 1046, loss 0.895065, acc 0.640625, learning_rate 0.000168226
2017-09-28T16:31:22.514878: step 1047, loss 0.764319, acc 0.765625, learning_rate 0.000167947
2017-09-28T16:31:22.598105: step 1048, loss 0.91322, acc 0.59375, learning_rate 0.00016767
2017-09-28T16:31:22.681323: step 1049, loss 0.80121, acc 0.703125, learning_rate 0.000167394
2017-09-28T16:31:22.764388: step 1050, loss 1.01866, acc 0.59375, learning_rate 0.000167119
2017-09-28T16:31:22.845680: step 1051, loss 0.906891, acc 0.59375, learning_rate 0.000166845
2017-09-28T16:31:22.926562: step 1052, loss 1.05648, acc 0.578125, learning_rate 0.000166572
2017-09-28T16:31:23.008512: step 1053, loss 0.743547, acc 0.71875, learning_rate 0.0001663
2017-09-28T16:31:23.090696: step 1054, loss 0.986953, acc 0.609375, learning_rate 0.00016603
2017-09-28T16:31:23.169902: step 1055, loss 0.84172, acc 0.59375, learning_rate 0.00016576
2017-09-28T16:31:23.250842: step 1056, loss 0.972076, acc 0.640625, learning_rate 0.000165492
2017-09-28T16:31:23.333995: step 1057, loss 0.996372, acc 0.71875, learning_rate 0.000165224
2017-09-28T16:31:23.419141: step 1058, loss 0.731003, acc 0.6875, learning_rate 0.000164958
2017-09-28T16:31:23.500706: step 1059, loss 0.792399, acc 0.703125, learning_rate 0.000164693
2017-09-28T16:31:23.582756: step 1060, loss 0.847528, acc 0.671875, learning_rate 0.000164429
2017-09-28T16:31:23.665540: step 1061, loss 0.934605, acc 0.65625, learning_rate 0.000164166
2017-09-28T16:31:23.748392: step 1062, loss 0.812403, acc 0.6875, learning_rate 0.000163904
2017-09-28T16:31:23.831382: step 1063, loss 0.761068, acc 0.71875, learning_rate 0.000163643
2017-09-28T16:31:23.915475: step 1064, loss 0.916417, acc 0.625, learning_rate 0.000163383
2017-09-28T16:31:23.999683: step 1065, loss 0.847933, acc 0.6875, learning_rate 0.000163125
2017-09-28T16:31:24.083619: step 1066, loss 0.822613, acc 0.625, learning_rate 0.000162867
2017-09-28T16:31:24.161921: step 1067, loss 1.00263, acc 0.578125, learning_rate 0.00016261
2017-09-28T16:31:24.243760: step 1068, loss 0.816653, acc 0.703125, learning_rate 0.000162355
2017-09-28T16:31:24.327186: step 1069, loss 0.62904, acc 0.765625, learning_rate 0.0001621
2017-09-28T16:31:24.410200: step 1070, loss 0.795169, acc 0.6875, learning_rate 0.000161847
2017-09-28T16:31:24.491698: step 1071, loss 0.822984, acc 0.65625, learning_rate 0.000161594
2017-09-28T16:31:24.574584: step 1072, loss 1.1072, acc 0.546875, learning_rate 0.000161343
2017-09-28T16:31:24.656353: step 1073, loss 0.901114, acc 0.65625, learning_rate 0.000161093
2017-09-28T16:31:24.738996: step 1074, loss 0.87826, acc 0.625, learning_rate 0.000160843
2017-09-28T16:31:24.822123: step 1075, loss 0.911377, acc 0.578125, learning_rate 0.000160595
2017-09-28T16:31:24.903172: step 1076, loss 0.701986, acc 0.734375, learning_rate 0.000160348
2017-09-28T16:31:24.983399: step 1077, loss 0.849709, acc 0.671875, learning_rate 0.000160101
2017-09-28T16:31:25.048830: step 1078, loss 1.0412, acc 0.568627, learning_rate 0.000159856
2017-09-28T16:31:25.127848: step 1079, loss 0.776621, acc 0.625, learning_rate 0.000159612
2017-09-28T16:31:25.210505: step 1080, loss 0.762541, acc 0.796875, learning_rate 0.000159368

Evaluation:
2017-09-28T16:31:25.496566: step 1080, loss 0.885144, acc 0.63741

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-1080

2017-09-28T16:31:26.056491: step 1081, loss 0.864323, acc 0.609375, learning_rate 0.000159126
2017-09-28T16:31:26.136658: step 1082, loss 0.928936, acc 0.546875, learning_rate 0.000158885
2017-09-28T16:31:26.220901: step 1083, loss 0.949334, acc 0.640625, learning_rate 0.000158644
2017-09-28T16:31:26.305637: step 1084, loss 0.885195, acc 0.640625, learning_rate 0.000158405
2017-09-28T16:31:26.387126: step 1085, loss 0.91066, acc 0.6875, learning_rate 0.000158167
2017-09-28T16:31:26.474276: step 1086, loss 0.863787, acc 0.703125, learning_rate 0.000157929
2017-09-28T16:31:26.556792: step 1087, loss 0.787126, acc 0.6875, learning_rate 0.000157693
2017-09-28T16:31:26.639076: step 1088, loss 0.866105, acc 0.609375, learning_rate 0.000157457
2017-09-28T16:31:26.720120: step 1089, loss 1.00141, acc 0.578125, learning_rate 0.000157223
2017-09-28T16:31:26.801882: step 1090, loss 0.946245, acc 0.671875, learning_rate 0.000156989
2017-09-28T16:31:26.883593: step 1091, loss 0.814762, acc 0.71875, learning_rate 0.000156757
2017-09-28T16:31:26.964335: step 1092, loss 0.904882, acc 0.671875, learning_rate 0.000156525
2017-09-28T16:31:27.046032: step 1093, loss 0.821877, acc 0.640625, learning_rate 0.000156294
2017-09-28T16:31:27.129510: step 1094, loss 0.866569, acc 0.6875, learning_rate 0.000156064
2017-09-28T16:31:27.212426: step 1095, loss 0.986911, acc 0.59375, learning_rate 0.000155836
2017-09-28T16:31:27.295516: step 1096, loss 0.902408, acc 0.65625, learning_rate 0.000155608
2017-09-28T16:31:27.382983: step 1097, loss 0.956362, acc 0.640625, learning_rate 0.000155381
2017-09-28T16:31:27.471869: step 1098, loss 0.83338, acc 0.59375, learning_rate 0.000155155
2017-09-28T16:31:27.559866: step 1099, loss 0.769896, acc 0.703125, learning_rate 0.000154929
2017-09-28T16:31:27.647041: step 1100, loss 0.899136, acc 0.640625, learning_rate 0.000154705
2017-09-28T16:31:27.736957: step 1101, loss 0.889672, acc 0.703125, learning_rate 0.000154482
2017-09-28T16:31:27.820602: step 1102, loss 0.730462, acc 0.734375, learning_rate 0.00015426
2017-09-28T16:31:27.903806: step 1103, loss 0.9463, acc 0.625, learning_rate 0.000154038
2017-09-28T16:31:27.987887: step 1104, loss 1.10054, acc 0.59375, learning_rate 0.000153818
2017-09-28T16:31:28.070053: step 1105, loss 0.951703, acc 0.640625, learning_rate 0.000153598
2017-09-28T16:31:28.151230: step 1106, loss 0.862303, acc 0.671875, learning_rate 0.000153379
2017-09-28T16:31:28.235684: step 1107, loss 0.799896, acc 0.65625, learning_rate 0.000153161
2017-09-28T16:31:28.317541: step 1108, loss 0.644286, acc 0.734375, learning_rate 0.000152944
2017-09-28T16:31:28.401167: step 1109, loss 0.931207, acc 0.578125, learning_rate 0.000152728
2017-09-28T16:31:28.481910: step 1110, loss 0.725723, acc 0.671875, learning_rate 0.000152513
2017-09-28T16:31:28.563930: step 1111, loss 0.741518, acc 0.703125, learning_rate 0.000152299
2017-09-28T16:31:28.647291: step 1112, loss 0.982303, acc 0.5625, learning_rate 0.000152085
2017-09-28T16:31:28.732057: step 1113, loss 0.933494, acc 0.5625, learning_rate 0.000151872
2017-09-28T16:31:28.813220: step 1114, loss 0.987385, acc 0.546875, learning_rate 0.000151661
2017-09-28T16:31:28.896719: step 1115, loss 0.761177, acc 0.703125, learning_rate 0.00015145
2017-09-28T16:31:28.980965: step 1116, loss 0.848406, acc 0.671875, learning_rate 0.00015124
2017-09-28T16:31:29.063937: step 1117, loss 1.08971, acc 0.609375, learning_rate 0.000151031
2017-09-28T16:31:29.145482: step 1118, loss 0.836066, acc 0.671875, learning_rate 0.000150822
2017-09-28T16:31:29.228567: step 1119, loss 0.929067, acc 0.703125, learning_rate 0.000150615
2017-09-28T16:31:29.314516: step 1120, loss 0.881974, acc 0.703125, learning_rate 0.000150408

Evaluation:
2017-09-28T16:31:29.600626: step 1120, loss 0.88129, acc 0.640288

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-1120

2017-09-28T16:31:30.173094: step 1121, loss 0.863714, acc 0.625, learning_rate 0.000150203
2017-09-28T16:31:30.255111: step 1122, loss 0.755534, acc 0.71875, learning_rate 0.000149998
2017-09-28T16:31:30.343792: step 1123, loss 0.910695, acc 0.640625, learning_rate 0.000149794
2017-09-28T16:31:30.430501: step 1124, loss 0.838357, acc 0.671875, learning_rate 0.00014959
2017-09-28T16:31:30.516844: step 1125, loss 0.841114, acc 0.6875, learning_rate 0.000149388
2017-09-28T16:31:30.607837: step 1126, loss 0.812638, acc 0.640625, learning_rate 0.000149186
2017-09-28T16:31:30.690027: step 1127, loss 0.827666, acc 0.6875, learning_rate 0.000148986
2017-09-28T16:31:30.771848: step 1128, loss 0.867938, acc 0.671875, learning_rate 0.000148786
2017-09-28T16:31:30.854124: step 1129, loss 0.839944, acc 0.6875, learning_rate 0.000148587
2017-09-28T16:31:30.940692: step 1130, loss 0.631274, acc 0.75, learning_rate 0.000148388
2017-09-28T16:31:31.021633: step 1131, loss 0.817219, acc 0.671875, learning_rate 0.000148191
2017-09-28T16:31:31.105969: step 1132, loss 0.909948, acc 0.671875, learning_rate 0.000147994
2017-09-28T16:31:31.188144: step 1133, loss 0.793939, acc 0.6875, learning_rate 0.000147798
2017-09-28T16:31:31.269656: step 1134, loss 0.91657, acc 0.640625, learning_rate 0.000147603
2017-09-28T16:31:31.354447: step 1135, loss 1.05259, acc 0.625, learning_rate 0.000147409
2017-09-28T16:31:31.438535: step 1136, loss 1.10273, acc 0.484375, learning_rate 0.000147215
2017-09-28T16:31:31.530711: step 1137, loss 1.01817, acc 0.546875, learning_rate 0.000147022
2017-09-28T16:31:31.614027: step 1138, loss 0.882865, acc 0.65625, learning_rate 0.000146831
2017-09-28T16:31:31.695399: step 1139, loss 0.804632, acc 0.734375, learning_rate 0.000146639
2017-09-28T16:31:31.779724: step 1140, loss 0.945403, acc 0.609375, learning_rate 0.000146449
2017-09-28T16:31:31.860448: step 1141, loss 1.07004, acc 0.625, learning_rate 0.000146259
2017-09-28T16:31:31.944532: step 1142, loss 0.813228, acc 0.6875, learning_rate 0.000146071
2017-09-28T16:31:32.025583: step 1143, loss 0.900362, acc 0.640625, learning_rate 0.000145883
2017-09-28T16:31:32.109037: step 1144, loss 0.717421, acc 0.703125, learning_rate 0.000145695
2017-09-28T16:31:32.188644: step 1145, loss 0.751673, acc 0.78125, learning_rate 0.000145509
2017-09-28T16:31:32.269103: step 1146, loss 0.927945, acc 0.625, learning_rate 0.000145323
2017-09-28T16:31:32.351716: step 1147, loss 0.760939, acc 0.671875, learning_rate 0.000145138
2017-09-28T16:31:32.435489: step 1148, loss 0.821999, acc 0.640625, learning_rate 0.000144954
2017-09-28T16:31:32.521918: step 1149, loss 1.00955, acc 0.546875, learning_rate 0.00014477
2017-09-28T16:31:32.604066: step 1150, loss 0.734426, acc 0.703125, learning_rate 0.000144588
2017-09-28T16:31:32.687923: step 1151, loss 0.710169, acc 0.71875, learning_rate 0.000144406
2017-09-28T16:31:32.772953: step 1152, loss 0.839812, acc 0.71875, learning_rate 0.000144224
2017-09-28T16:31:32.857148: step 1153, loss 0.886357, acc 0.609375, learning_rate 0.000144044
2017-09-28T16:31:32.940763: step 1154, loss 0.768206, acc 0.75, learning_rate 0.000143864
2017-09-28T16:31:33.026285: step 1155, loss 0.834485, acc 0.640625, learning_rate 0.000143685
2017-09-28T16:31:33.110655: step 1156, loss 0.826447, acc 0.671875, learning_rate 0.000143507
2017-09-28T16:31:33.194143: step 1157, loss 0.95233, acc 0.671875, learning_rate 0.000143329
2017-09-28T16:31:33.276499: step 1158, loss 0.888443, acc 0.578125, learning_rate 0.000143152
2017-09-28T16:31:33.359351: step 1159, loss 1.09469, acc 0.578125, learning_rate 0.000142976
2017-09-28T16:31:33.443686: step 1160, loss 0.877398, acc 0.6875, learning_rate 0.000142801

Evaluation:
2017-09-28T16:31:33.730172: step 1160, loss 0.880222, acc 0.634532

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-1160

2017-09-28T16:31:35.256428: step 1161, loss 0.899881, acc 0.625, learning_rate 0.000142626
2017-09-28T16:31:35.338885: step 1162, loss 0.764154, acc 0.734375, learning_rate 0.000142452
2017-09-28T16:31:35.424668: step 1163, loss 0.827013, acc 0.609375, learning_rate 0.000142279
2017-09-28T16:31:35.506374: step 1164, loss 0.831877, acc 0.65625, learning_rate 0.000142106
2017-09-28T16:31:35.589512: step 1165, loss 0.803257, acc 0.671875, learning_rate 0.000141934
2017-09-28T16:31:35.672521: step 1166, loss 0.982161, acc 0.53125, learning_rate 0.000141763
2017-09-28T16:31:35.757829: step 1167, loss 1.12316, acc 0.515625, learning_rate 0.000141593
2017-09-28T16:31:35.843103: step 1168, loss 1.07513, acc 0.625, learning_rate 0.000141423
2017-09-28T16:31:35.927479: step 1169, loss 0.714155, acc 0.75, learning_rate 0.000141254
2017-09-28T16:31:36.015520: step 1170, loss 0.990056, acc 0.53125, learning_rate 0.000141085
2017-09-28T16:31:36.098816: step 1171, loss 0.899388, acc 0.59375, learning_rate 0.000140918
2017-09-28T16:31:36.182483: step 1172, loss 0.744216, acc 0.734375, learning_rate 0.000140751
2017-09-28T16:31:36.263407: step 1173, loss 0.925113, acc 0.625, learning_rate 0.000140584
2017-09-28T16:31:36.346281: step 1174, loss 0.821408, acc 0.703125, learning_rate 0.000140419
2017-09-28T16:31:36.430622: step 1175, loss 0.980559, acc 0.546875, learning_rate 0.000140254
2017-09-28T16:31:36.498949: step 1176, loss 0.682313, acc 0.705882, learning_rate 0.000140089
2017-09-28T16:31:36.586857: step 1177, loss 0.908399, acc 0.65625, learning_rate 0.000139926
2017-09-28T16:31:36.667993: step 1178, loss 0.963837, acc 0.625, learning_rate 0.000139763
2017-09-28T16:31:36.751401: step 1179, loss 1.16688, acc 0.578125, learning_rate 0.0001396
2017-09-28T16:31:36.834119: step 1180, loss 0.711985, acc 0.71875, learning_rate 0.000139439
2017-09-28T16:31:36.918528: step 1181, loss 0.897243, acc 0.578125, learning_rate 0.000139278
2017-09-28T16:31:37.001971: step 1182, loss 0.925179, acc 0.625, learning_rate 0.000139118
2017-09-28T16:31:37.086410: step 1183, loss 0.834976, acc 0.65625, learning_rate 0.000138958
2017-09-28T16:31:37.248183: step 1184, loss 0.831715, acc 0.6875, learning_rate 0.000138799
2017-09-28T16:31:37.329370: step 1185, loss 0.853912, acc 0.703125, learning_rate 0.00013864
2017-09-28T16:31:37.411249: step 1186, loss 0.791779, acc 0.671875, learning_rate 0.000138483
2017-09-28T16:31:37.494451: step 1187, loss 0.897552, acc 0.59375, learning_rate 0.000138326
2017-09-28T16:31:37.576419: step 1188, loss 0.936365, acc 0.578125, learning_rate 0.000138169
2017-09-28T16:31:37.657305: step 1189, loss 0.793039, acc 0.6875, learning_rate 0.000138013
2017-09-28T16:31:37.737911: step 1190, loss 0.829067, acc 0.640625, learning_rate 0.000137858
2017-09-28T16:31:37.821277: step 1191, loss 0.838008, acc 0.65625, learning_rate 0.000137704
2017-09-28T16:31:37.905129: step 1192, loss 0.758273, acc 0.671875, learning_rate 0.00013755
2017-09-28T16:31:37.985120: step 1193, loss 1.11095, acc 0.53125, learning_rate 0.000137397
2017-09-28T16:31:38.066844: step 1194, loss 0.912896, acc 0.578125, learning_rate 0.000137244
2017-09-28T16:31:38.151569: step 1195, loss 0.935458, acc 0.625, learning_rate 0.000137092
2017-09-28T16:31:38.232830: step 1196, loss 0.760072, acc 0.6875, learning_rate 0.000136941
2017-09-28T16:31:38.314697: step 1197, loss 0.920994, acc 0.578125, learning_rate 0.00013679
2017-09-28T16:31:38.396959: step 1198, loss 0.915226, acc 0.625, learning_rate 0.00013664
2017-09-28T16:31:38.480293: step 1199, loss 0.773575, acc 0.703125, learning_rate 0.00013649
2017-09-28T16:31:38.561078: step 1200, loss 0.824399, acc 0.640625, learning_rate 0.000136341

Evaluation:
2017-09-28T16:31:38.847295: step 1200, loss 0.878273, acc 0.643165

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-1200

2017-09-28T16:31:39.349144: step 1201, loss 0.730436, acc 0.734375, learning_rate 0.000136193
2017-09-28T16:31:39.432263: step 1202, loss 0.83284, acc 0.734375, learning_rate 0.000136045
2017-09-28T16:31:39.515194: step 1203, loss 0.864856, acc 0.671875, learning_rate 0.000135898
2017-09-28T16:31:39.597486: step 1204, loss 1.08673, acc 0.578125, learning_rate 0.000135751
2017-09-28T16:31:39.678547: step 1205, loss 0.749668, acc 0.671875, learning_rate 0.000135605
2017-09-28T16:31:39.764197: step 1206, loss 0.936274, acc 0.671875, learning_rate 0.00013546
2017-09-28T16:31:39.847986: step 1207, loss 0.985615, acc 0.59375, learning_rate 0.000135315
2017-09-28T16:31:39.932686: step 1208, loss 0.742947, acc 0.78125, learning_rate 0.000135171
2017-09-28T16:31:40.011868: step 1209, loss 0.987474, acc 0.5625, learning_rate 0.000135028
2017-09-28T16:31:40.093388: step 1210, loss 0.979416, acc 0.609375, learning_rate 0.000134885
2017-09-28T16:31:40.174522: step 1211, loss 0.815026, acc 0.71875, learning_rate 0.000134742
2017-09-28T16:31:40.258348: step 1212, loss 1.02173, acc 0.578125, learning_rate 0.0001346
2017-09-28T16:31:40.342184: step 1213, loss 0.826106, acc 0.671875, learning_rate 0.000134459
2017-09-28T16:31:40.426353: step 1214, loss 0.906857, acc 0.625, learning_rate 0.000134319
2017-09-28T16:31:40.508887: step 1215, loss 0.914321, acc 0.5625, learning_rate 0.000134178
2017-09-28T16:31:40.594660: step 1216, loss 0.865186, acc 0.640625, learning_rate 0.000134039
2017-09-28T16:31:40.682236: step 1217, loss 0.759185, acc 0.703125, learning_rate 0.0001339
2017-09-28T16:31:40.769136: step 1218, loss 0.772217, acc 0.71875, learning_rate 0.000133762
2017-09-28T16:31:40.851906: step 1219, loss 0.9633, acc 0.625, learning_rate 0.000133624
2017-09-28T16:31:40.936522: step 1220, loss 0.842537, acc 0.6875, learning_rate 0.000133487
2017-09-28T16:31:41.020866: step 1221, loss 1.00118, acc 0.53125, learning_rate 0.00013335
2017-09-28T16:31:41.104061: step 1222, loss 0.991475, acc 0.640625, learning_rate 0.000133214
2017-09-28T16:31:41.186157: step 1223, loss 0.913454, acc 0.640625, learning_rate 0.000133078
2017-09-28T16:31:41.268851: step 1224, loss 0.806518, acc 0.625, learning_rate 0.000132943
2017-09-28T16:31:41.353846: step 1225, loss 0.850825, acc 0.65625, learning_rate 0.000132809
2017-09-28T16:31:41.438848: step 1226, loss 0.859525, acc 0.609375, learning_rate 0.000132675
2017-09-28T16:31:41.522878: step 1227, loss 0.813964, acc 0.640625, learning_rate 0.000132541
2017-09-28T16:31:41.613369: step 1228, loss 0.889184, acc 0.640625, learning_rate 0.000132409
2017-09-28T16:31:41.697562: step 1229, loss 0.835346, acc 0.625, learning_rate 0.000132276
2017-09-28T16:31:41.782696: step 1230, loss 0.930643, acc 0.625, learning_rate 0.000132145
2017-09-28T16:31:41.867913: step 1231, loss 0.910579, acc 0.609375, learning_rate 0.000132013
2017-09-28T16:31:41.951274: step 1232, loss 0.79023, acc 0.6875, learning_rate 0.000131883
2017-09-28T16:31:42.035522: step 1233, loss 0.777453, acc 0.71875, learning_rate 0.000131753
2017-09-28T16:31:42.119246: step 1234, loss 0.86605, acc 0.6875, learning_rate 0.000131623
2017-09-28T16:31:42.205499: step 1235, loss 0.737977, acc 0.703125, learning_rate 0.000131494
2017-09-28T16:31:42.288721: step 1236, loss 0.841129, acc 0.640625, learning_rate 0.000131365
2017-09-28T16:31:42.372325: step 1237, loss 0.975536, acc 0.625, learning_rate 0.000131237
2017-09-28T16:31:42.455894: step 1238, loss 1.0561, acc 0.546875, learning_rate 0.00013111
2017-09-28T16:31:42.537577: step 1239, loss 0.965411, acc 0.53125, learning_rate 0.000130983
2017-09-28T16:31:42.619653: step 1240, loss 0.908721, acc 0.625, learning_rate 0.000130856

Evaluation:
2017-09-28T16:31:42.906857: step 1240, loss 0.876857, acc 0.638849

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-1240

2017-09-28T16:31:43.898927: step 1241, loss 0.969058, acc 0.609375, learning_rate 0.00013073
2017-09-28T16:31:43.983378: step 1242, loss 0.777194, acc 0.71875, learning_rate 0.000130605
2017-09-28T16:31:44.067533: step 1243, loss 0.733639, acc 0.65625, learning_rate 0.00013048
2017-09-28T16:31:44.151893: step 1244, loss 0.915938, acc 0.671875, learning_rate 0.000130356
2017-09-28T16:31:44.238333: step 1245, loss 0.844564, acc 0.609375, learning_rate 0.000130232
2017-09-28T16:31:44.320064: step 1246, loss 0.857692, acc 0.671875, learning_rate 0.000130108
2017-09-28T16:31:44.404724: step 1247, loss 0.91626, acc 0.609375, learning_rate 0.000129985
2017-09-28T16:31:44.494178: step 1248, loss 0.835432, acc 0.734375, learning_rate 0.000129863
2017-09-28T16:31:44.578417: step 1249, loss 0.752246, acc 0.71875, learning_rate 0.000129741
2017-09-28T16:31:44.660546: step 1250, loss 0.862636, acc 0.65625, learning_rate 0.00012962
2017-09-28T16:31:44.739882: step 1251, loss 0.870968, acc 0.609375, learning_rate 0.000129499
2017-09-28T16:31:44.822079: step 1252, loss 0.829098, acc 0.6875, learning_rate 0.000129378
2017-09-28T16:31:44.906688: step 1253, loss 0.843381, acc 0.609375, learning_rate 0.000129259
2017-09-28T16:31:44.989065: step 1254, loss 0.842478, acc 0.65625, learning_rate 0.000129139
2017-09-28T16:31:45.075442: step 1255, loss 0.655603, acc 0.828125, learning_rate 0.00012902
2017-09-28T16:31:45.158538: step 1256, loss 0.857028, acc 0.671875, learning_rate 0.000128902
2017-09-28T16:31:45.240851: step 1257, loss 0.753447, acc 0.796875, learning_rate 0.000128784
2017-09-28T16:31:45.325138: step 1258, loss 0.844428, acc 0.640625, learning_rate 0.000128666
2017-09-28T16:31:45.407924: step 1259, loss 0.673745, acc 0.765625, learning_rate 0.000128549
2017-09-28T16:31:45.488563: step 1260, loss 0.938767, acc 0.609375, learning_rate 0.000128433
2017-09-28T16:31:45.572656: step 1261, loss 0.812075, acc 0.703125, learning_rate 0.000128317
2017-09-28T16:31:45.656424: step 1262, loss 0.808424, acc 0.703125, learning_rate 0.000128201
2017-09-28T16:31:45.739805: step 1263, loss 0.845129, acc 0.625, learning_rate 0.000128086
2017-09-28T16:31:45.823768: step 1264, loss 0.958165, acc 0.609375, learning_rate 0.000127971
2017-09-28T16:31:45.910586: step 1265, loss 0.858957, acc 0.59375, learning_rate 0.000127857
2017-09-28T16:31:46.006796: step 1266, loss 0.752421, acc 0.703125, learning_rate 0.000127743
2017-09-28T16:31:46.092434: step 1267, loss 0.883877, acc 0.640625, learning_rate 0.00012763
2017-09-28T16:31:46.175780: step 1268, loss 0.960652, acc 0.59375, learning_rate 0.000127517
2017-09-28T16:31:46.262098: step 1269, loss 0.771613, acc 0.734375, learning_rate 0.000127405
2017-09-28T16:31:46.346909: step 1270, loss 0.938021, acc 0.640625, learning_rate 0.000127293
2017-09-28T16:31:46.433466: step 1271, loss 0.690087, acc 0.6875, learning_rate 0.000127182
2017-09-28T16:31:46.520247: step 1272, loss 1.03134, acc 0.5625, learning_rate 0.000127071
2017-09-28T16:31:46.603359: step 1273, loss 0.917525, acc 0.578125, learning_rate 0.00012696
2017-09-28T16:31:46.674250: step 1274, loss 1.04749, acc 0.588235, learning_rate 0.00012685
2017-09-28T16:31:46.757233: step 1275, loss 0.797502, acc 0.6875, learning_rate 0.000126741
2017-09-28T16:31:46.842040: step 1276, loss 0.882931, acc 0.625, learning_rate 0.000126632
2017-09-28T16:31:46.931020: step 1277, loss 0.852741, acc 0.65625, learning_rate 0.000126523
2017-09-28T16:31:47.012648: step 1278, loss 0.934108, acc 0.59375, learning_rate 0.000126415
2017-09-28T16:31:47.095722: step 1279, loss 0.867461, acc 0.625, learning_rate 0.000126307
2017-09-28T16:31:47.178003: step 1280, loss 0.673054, acc 0.78125, learning_rate 0.000126199

Evaluation:
2017-09-28T16:31:47.468437: step 1280, loss 0.876102, acc 0.641727

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-1280

2017-09-28T16:31:48.021774: step 1281, loss 0.948167, acc 0.609375, learning_rate 0.000126093
2017-09-28T16:31:48.107796: step 1282, loss 0.752626, acc 0.671875, learning_rate 0.000125986
2017-09-28T16:31:48.192326: step 1283, loss 0.805492, acc 0.6875, learning_rate 0.00012588
2017-09-28T16:31:48.274263: step 1284, loss 0.583869, acc 0.78125, learning_rate 0.000125774
2017-09-28T16:31:48.357338: step 1285, loss 0.927679, acc 0.609375, learning_rate 0.000125669
2017-09-28T16:31:48.441165: step 1286, loss 0.897599, acc 0.640625, learning_rate 0.000125564
2017-09-28T16:31:48.524794: step 1287, loss 0.750888, acc 0.65625, learning_rate 0.00012546
2017-09-28T16:31:48.607231: step 1288, loss 0.956177, acc 0.5625, learning_rate 0.000125356
2017-09-28T16:31:48.692227: step 1289, loss 0.878803, acc 0.671875, learning_rate 0.000125253
2017-09-28T16:31:48.779584: step 1290, loss 0.73253, acc 0.671875, learning_rate 0.00012515
2017-09-28T16:31:48.866650: step 1291, loss 0.646304, acc 0.765625, learning_rate 0.000125047
2017-09-28T16:31:48.949726: step 1292, loss 1.03446, acc 0.5625, learning_rate 0.000124945
2017-09-28T16:31:49.034330: step 1293, loss 0.726307, acc 0.796875, learning_rate 0.000124843
2017-09-28T16:31:49.118503: step 1294, loss 0.853409, acc 0.65625, learning_rate 0.000124741
2017-09-28T16:31:49.203799: step 1295, loss 0.773434, acc 0.75, learning_rate 0.00012464
2017-09-28T16:31:49.284912: step 1296, loss 0.906361, acc 0.671875, learning_rate 0.00012454
2017-09-28T16:31:49.365133: step 1297, loss 0.80362, acc 0.6875, learning_rate 0.00012444
2017-09-28T16:31:49.448953: step 1298, loss 0.753553, acc 0.671875, learning_rate 0.00012434
2017-09-28T16:31:49.529673: step 1299, loss 0.819393, acc 0.703125, learning_rate 0.000124241
2017-09-28T16:31:49.609859: step 1300, loss 1.01376, acc 0.59375, learning_rate 0.000124142
2017-09-28T16:31:49.692947: step 1301, loss 0.938799, acc 0.59375, learning_rate 0.000124043
2017-09-28T16:31:49.777338: step 1302, loss 0.678311, acc 0.78125, learning_rate 0.000123945
2017-09-28T16:31:49.863156: step 1303, loss 0.956831, acc 0.59375, learning_rate 0.000123847
2017-09-28T16:31:49.946759: step 1304, loss 0.878546, acc 0.671875, learning_rate 0.00012375
2017-09-28T16:31:50.029044: step 1305, loss 0.949873, acc 0.609375, learning_rate 0.000123653
2017-09-28T16:31:50.108385: step 1306, loss 0.944875, acc 0.640625, learning_rate 0.000123556
2017-09-28T16:31:50.191009: step 1307, loss 0.756235, acc 0.671875, learning_rate 0.00012346
2017-09-28T16:31:50.275368: step 1308, loss 0.885736, acc 0.6875, learning_rate 0.000123364
2017-09-28T16:31:50.357947: step 1309, loss 0.797657, acc 0.625, learning_rate 0.000123269
2017-09-28T16:31:50.441870: step 1310, loss 0.815857, acc 0.703125, learning_rate 0.000123174
2017-09-28T16:31:50.522388: step 1311, loss 0.835451, acc 0.671875, learning_rate 0.00012308
2017-09-28T16:31:50.608576: step 1312, loss 0.990973, acc 0.609375, learning_rate 0.000122985
2017-09-28T16:31:50.688454: step 1313, loss 0.735213, acc 0.71875, learning_rate 0.000122892
2017-09-28T16:31:50.771230: step 1314, loss 0.834024, acc 0.609375, learning_rate 0.000122798
2017-09-28T16:31:50.854520: step 1315, loss 0.990296, acc 0.59375, learning_rate 0.000122705
2017-09-28T16:31:50.939108: step 1316, loss 0.771572, acc 0.65625, learning_rate 0.000122612
2017-09-28T16:31:51.023205: step 1317, loss 0.787683, acc 0.671875, learning_rate 0.00012252
2017-09-28T16:31:51.108930: step 1318, loss 0.780519, acc 0.765625, learning_rate 0.000122428
2017-09-28T16:31:51.191336: step 1319, loss 0.986379, acc 0.53125, learning_rate 0.000122337
2017-09-28T16:31:51.276188: step 1320, loss 0.781688, acc 0.71875, learning_rate 0.000122245

Evaluation:
2017-09-28T16:31:51.567647: step 1320, loss 0.875747, acc 0.643165

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-1320

2017-09-28T16:31:52.209977: step 1321, loss 0.915894, acc 0.546875, learning_rate 0.000122155
2017-09-28T16:31:52.295856: step 1322, loss 0.871121, acc 0.65625, learning_rate 0.000122064
2017-09-28T16:31:52.379686: step 1323, loss 0.892839, acc 0.625, learning_rate 0.000121974
2017-09-28T16:31:52.464674: step 1324, loss 1.0367, acc 0.578125, learning_rate 0.000121884
2017-09-28T16:31:52.549676: step 1325, loss 0.904126, acc 0.609375, learning_rate 0.000121795
2017-09-28T16:31:52.634271: step 1326, loss 0.783247, acc 0.703125, learning_rate 0.000121706
2017-09-28T16:31:52.717078: step 1327, loss 0.780576, acc 0.671875, learning_rate 0.000121618
2017-09-28T16:31:52.799650: step 1328, loss 0.750871, acc 0.734375, learning_rate 0.000121529
2017-09-28T16:31:52.880823: step 1329, loss 1.14077, acc 0.484375, learning_rate 0.000121441
2017-09-28T16:31:52.966916: step 1330, loss 1.1324, acc 0.46875, learning_rate 0.000121354
2017-09-28T16:31:53.051199: step 1331, loss 0.783418, acc 0.640625, learning_rate 0.000121267
2017-09-28T16:31:53.133646: step 1332, loss 1.02528, acc 0.53125, learning_rate 0.00012118
2017-09-28T16:31:53.218420: step 1333, loss 0.771089, acc 0.671875, learning_rate 0.000121093
2017-09-28T16:31:53.303798: step 1334, loss 0.706641, acc 0.71875, learning_rate 0.000121007
2017-09-28T16:31:53.386867: step 1335, loss 0.950797, acc 0.625, learning_rate 0.000120922
2017-09-28T16:31:53.476266: step 1336, loss 0.839876, acc 0.75, learning_rate 0.000120836
2017-09-28T16:31:53.558341: step 1337, loss 1.04297, acc 0.578125, learning_rate 0.000120751
2017-09-28T16:31:53.642625: step 1338, loss 0.915573, acc 0.5625, learning_rate 0.000120666
2017-09-28T16:31:53.726298: step 1339, loss 0.826517, acc 0.625, learning_rate 0.000120582
2017-09-28T16:31:53.812949: step 1340, loss 0.836844, acc 0.671875, learning_rate 0.000120498
2017-09-28T16:31:53.895060: step 1341, loss 0.966985, acc 0.578125, learning_rate 0.000120414
2017-09-28T16:31:53.980628: step 1342, loss 0.824503, acc 0.65625, learning_rate 0.000120331
2017-09-28T16:31:54.064070: step 1343, loss 0.847977, acc 0.65625, learning_rate 0.000120248
2017-09-28T16:31:54.147029: step 1344, loss 0.810243, acc 0.640625, learning_rate 0.000120165
2017-09-28T16:31:54.228112: step 1345, loss 0.854918, acc 0.671875, learning_rate 0.000120083
2017-09-28T16:31:54.309175: step 1346, loss 0.838674, acc 0.734375, learning_rate 0.000120001
2017-09-28T16:31:54.396025: step 1347, loss 0.790143, acc 0.75, learning_rate 0.00011992
2017-09-28T16:31:54.479176: step 1348, loss 1.07488, acc 0.625, learning_rate 0.000119838
2017-09-28T16:31:54.564974: step 1349, loss 0.643642, acc 0.78125, learning_rate 0.000119757
2017-09-28T16:31:54.648321: step 1350, loss 0.952034, acc 0.625, learning_rate 0.000119677
2017-09-28T16:31:54.732031: step 1351, loss 0.835798, acc 0.65625, learning_rate 0.000119596
2017-09-28T16:31:54.814274: step 1352, loss 0.816083, acc 0.703125, learning_rate 0.000119516
2017-09-28T16:31:54.899002: step 1353, loss 0.865805, acc 0.65625, learning_rate 0.000119437
2017-09-28T16:31:54.982988: step 1354, loss 0.810613, acc 0.703125, learning_rate 0.000119357
2017-09-28T16:31:55.067525: step 1355, loss 0.884413, acc 0.625, learning_rate 0.000119278
2017-09-28T16:31:55.150988: step 1356, loss 0.990162, acc 0.609375, learning_rate 0.0001192
2017-09-28T16:31:55.230737: step 1357, loss 0.783843, acc 0.703125, learning_rate 0.000119121
2017-09-28T16:31:55.311574: step 1358, loss 0.736975, acc 0.6875, learning_rate 0.000119043
2017-09-28T16:31:55.399507: step 1359, loss 0.935902, acc 0.609375, learning_rate 0.000118965
2017-09-28T16:31:55.482746: step 1360, loss 1.0648, acc 0.546875, learning_rate 0.000118888

Evaluation:
2017-09-28T16:31:55.763782: step 1360, loss 0.873721, acc 0.640288

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-1360

2017-09-28T16:31:56.261795: step 1361, loss 0.912503, acc 0.640625, learning_rate 0.000118811
2017-09-28T16:31:56.344764: step 1362, loss 0.847106, acc 0.71875, learning_rate 0.000118734
2017-09-28T16:31:56.427655: step 1363, loss 0.970649, acc 0.625, learning_rate 0.000118658
2017-09-28T16:31:56.510157: step 1364, loss 0.934322, acc 0.640625, learning_rate 0.000118582
2017-09-28T16:31:56.594883: step 1365, loss 0.941184, acc 0.625, learning_rate 0.000118506
2017-09-28T16:31:56.679980: step 1366, loss 0.928242, acc 0.59375, learning_rate 0.00011843
2017-09-28T16:31:56.761911: step 1367, loss 0.8009, acc 0.625, learning_rate 0.000118355
2017-09-28T16:31:56.845838: step 1368, loss 0.767149, acc 0.71875, learning_rate 0.00011828
2017-09-28T16:31:56.926792: step 1369, loss 1.14431, acc 0.515625, learning_rate 0.000118205
2017-09-28T16:31:57.010082: step 1370, loss 0.760523, acc 0.734375, learning_rate 0.000118131
2017-09-28T16:31:57.093048: step 1371, loss 0.679221, acc 0.71875, learning_rate 0.000118057
2017-09-28T16:31:57.158153: step 1372, loss 1.08498, acc 0.509804, learning_rate 0.000117983
2017-09-28T16:31:57.240383: step 1373, loss 1.09527, acc 0.578125, learning_rate 0.00011791
2017-09-28T16:31:57.326161: step 1374, loss 0.917074, acc 0.59375, learning_rate 0.000117837
2017-09-28T16:31:57.410205: step 1375, loss 1.0323, acc 0.625, learning_rate 0.000117764
2017-09-28T16:31:57.493825: step 1376, loss 0.827773, acc 0.625, learning_rate 0.000117692
2017-09-28T16:31:57.573767: step 1377, loss 0.769495, acc 0.6875, learning_rate 0.000117619
2017-09-28T16:31:57.657295: step 1378, loss 1.00161, acc 0.5625, learning_rate 0.000117547
2017-09-28T16:31:57.738601: step 1379, loss 0.782081, acc 0.71875, learning_rate 0.000117476
2017-09-28T16:31:57.823833: step 1380, loss 0.782403, acc 0.75, learning_rate 0.000117404
2017-09-28T16:31:57.905243: step 1381, loss 0.807714, acc 0.640625, learning_rate 0.000117333
2017-09-28T16:31:57.990196: step 1382, loss 0.794697, acc 0.703125, learning_rate 0.000117263
2017-09-28T16:31:58.076502: step 1383, loss 0.731374, acc 0.75, learning_rate 0.000117192
2017-09-28T16:31:58.161102: step 1384, loss 0.981624, acc 0.546875, learning_rate 0.000117122
2017-09-28T16:31:58.244484: step 1385, loss 0.796378, acc 0.671875, learning_rate 0.000117052
2017-09-28T16:31:58.329544: step 1386, loss 0.91051, acc 0.65625, learning_rate 0.000116983
2017-09-28T16:31:58.417059: step 1387, loss 0.856119, acc 0.640625, learning_rate 0.000116913
2017-09-28T16:31:58.499878: step 1388, loss 0.862397, acc 0.625, learning_rate 0.000116844
2017-09-28T16:31:58.581032: step 1389, loss 0.792336, acc 0.671875, learning_rate 0.000116775
2017-09-28T16:31:58.662740: step 1390, loss 0.880997, acc 0.671875, learning_rate 0.000116707
2017-09-28T16:31:58.748182: step 1391, loss 0.878406, acc 0.59375, learning_rate 0.000116639
2017-09-28T16:31:58.831849: step 1392, loss 0.728893, acc 0.765625, learning_rate 0.000116571
2017-09-28T16:31:58.912881: step 1393, loss 0.851907, acc 0.609375, learning_rate 0.000116503
2017-09-28T16:31:58.997166: step 1394, loss 0.948468, acc 0.53125, learning_rate 0.000116436
2017-09-28T16:31:59.079661: step 1395, loss 0.809832, acc 0.6875, learning_rate 0.000116369
2017-09-28T16:31:59.161306: step 1396, loss 0.789588, acc 0.71875, learning_rate 0.000116302
2017-09-28T16:31:59.244631: step 1397, loss 0.915795, acc 0.640625, learning_rate 0.000116235
2017-09-28T16:31:59.326534: step 1398, loss 0.883291, acc 0.640625, learning_rate 0.000116169
2017-09-28T16:31:59.409815: step 1399, loss 0.875463, acc 0.671875, learning_rate 0.000116103
2017-09-28T16:31:59.488974: step 1400, loss 0.889416, acc 0.578125, learning_rate 0.000116037

Evaluation:
2017-09-28T16:31:59.765111: step 1400, loss 0.871222, acc 0.653237

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-1400

2017-09-28T16:32:00.332405: step 1401, loss 1.13042, acc 0.5625, learning_rate 0.000115972
2017-09-28T16:32:00.416996: step 1402, loss 0.847535, acc 0.671875, learning_rate 0.000115907
2017-09-28T16:32:00.498953: step 1403, loss 0.718112, acc 0.71875, learning_rate 0.000115842
2017-09-28T16:32:00.580887: step 1404, loss 0.825535, acc 0.6875, learning_rate 0.000115777
2017-09-28T16:32:00.664888: step 1405, loss 0.763772, acc 0.6875, learning_rate 0.000115713
2017-09-28T16:32:00.747783: step 1406, loss 0.990745, acc 0.625, learning_rate 0.000115649
2017-09-28T16:32:00.830570: step 1407, loss 0.906109, acc 0.59375, learning_rate 0.000115585
2017-09-28T16:32:00.913417: step 1408, loss 0.789979, acc 0.71875, learning_rate 0.000115521
2017-09-28T16:32:00.998465: step 1409, loss 0.82209, acc 0.671875, learning_rate 0.000115458
2017-09-28T16:32:01.080171: step 1410, loss 0.781482, acc 0.65625, learning_rate 0.000115395
2017-09-28T16:32:01.162964: step 1411, loss 0.965496, acc 0.515625, learning_rate 0.000115332
2017-09-28T16:32:01.249010: step 1412, loss 0.968464, acc 0.609375, learning_rate 0.000115269
2017-09-28T16:32:01.328735: step 1413, loss 1.0429, acc 0.5, learning_rate 0.000115207
2017-09-28T16:32:01.412936: step 1414, loss 0.652304, acc 0.71875, learning_rate 0.000115145
2017-09-28T16:32:01.496775: step 1415, loss 0.967248, acc 0.625, learning_rate 0.000115083
2017-09-28T16:32:01.579261: step 1416, loss 1.02186, acc 0.59375, learning_rate 0.000115022
2017-09-28T16:32:01.665846: step 1417, loss 0.842815, acc 0.703125, learning_rate 0.00011496
2017-09-28T16:32:01.754828: step 1418, loss 0.938854, acc 0.5625, learning_rate 0.000114899
2017-09-28T16:32:01.838068: step 1419, loss 0.806213, acc 0.6875, learning_rate 0.000114838
2017-09-28T16:32:01.922677: step 1420, loss 0.840733, acc 0.6875, learning_rate 0.000114778
2017-09-28T16:32:02.007347: step 1421, loss 0.894695, acc 0.640625, learning_rate 0.000114717
2017-09-28T16:32:02.089221: step 1422, loss 0.922643, acc 0.640625, learning_rate 0.000114657
2017-09-28T16:32:02.172703: step 1423, loss 0.966188, acc 0.640625, learning_rate 0.000114598
2017-09-28T16:32:02.258179: step 1424, loss 0.855569, acc 0.65625, learning_rate 0.000114538
2017-09-28T16:32:02.340881: step 1425, loss 0.798065, acc 0.703125, learning_rate 0.000114479
2017-09-28T16:32:02.423210: step 1426, loss 0.703112, acc 0.71875, learning_rate 0.00011442
2017-09-28T16:32:02.506179: step 1427, loss 0.818479, acc 0.6875, learning_rate 0.000114361
2017-09-28T16:32:02.587885: step 1428, loss 0.627773, acc 0.734375, learning_rate 0.000114302
2017-09-28T16:32:02.673149: step 1429, loss 0.72787, acc 0.75, learning_rate 0.000114244
2017-09-28T16:32:02.757908: step 1430, loss 0.761804, acc 0.75, learning_rate 0.000114186
2017-09-28T16:32:02.841093: step 1431, loss 0.853005, acc 0.6875, learning_rate 0.000114128
2017-09-28T16:32:02.921294: step 1432, loss 1.03285, acc 0.578125, learning_rate 0.00011407
2017-09-28T16:32:03.003049: step 1433, loss 0.893834, acc 0.65625, learning_rate 0.000114013
2017-09-28T16:32:03.088368: step 1434, loss 0.902435, acc 0.625, learning_rate 0.000113955
2017-09-28T16:32:03.172125: step 1435, loss 0.997228, acc 0.578125, learning_rate 0.000113898
2017-09-28T16:32:03.256344: step 1436, loss 0.933794, acc 0.671875, learning_rate 0.000113842
2017-09-28T16:32:03.339432: step 1437, loss 0.839986, acc 0.671875, learning_rate 0.000113785
2017-09-28T16:32:03.421458: step 1438, loss 0.824795, acc 0.6875, learning_rate 0.000113729
2017-09-28T16:32:03.502976: step 1439, loss 0.843437, acc 0.65625, learning_rate 0.000113673
2017-09-28T16:32:03.586263: step 1440, loss 0.754434, acc 0.6875, learning_rate 0.000113617

Evaluation:
2017-09-28T16:32:03.866461: step 1440, loss 0.871417, acc 0.640288

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-1440

2017-09-28T16:32:04.436371: step 1441, loss 0.938967, acc 0.65625, learning_rate 0.000113561
2017-09-28T16:32:04.519880: step 1442, loss 0.885008, acc 0.640625, learning_rate 0.000113506
2017-09-28T16:32:04.601981: step 1443, loss 0.833628, acc 0.6875, learning_rate 0.000113451
2017-09-28T16:32:04.684393: step 1444, loss 0.666347, acc 0.875, learning_rate 0.000113396
2017-09-28T16:32:04.765667: step 1445, loss 0.837161, acc 0.6875, learning_rate 0.000113341
2017-09-28T16:32:04.846670: step 1446, loss 0.891644, acc 0.671875, learning_rate 0.000113287
2017-09-28T16:32:04.928779: step 1447, loss 0.847744, acc 0.640625, learning_rate 0.000113233
2017-09-28T16:32:05.012526: step 1448, loss 0.652304, acc 0.75, learning_rate 0.000113179
2017-09-28T16:32:05.096521: step 1449, loss 0.985029, acc 0.65625, learning_rate 0.000113125
2017-09-28T16:32:05.178695: step 1450, loss 0.741906, acc 0.703125, learning_rate 0.000113071
2017-09-28T16:32:05.262807: step 1451, loss 1.09057, acc 0.578125, learning_rate 0.000113018
2017-09-28T16:32:05.346065: step 1452, loss 0.777801, acc 0.703125, learning_rate 0.000112965
2017-09-28T16:32:05.430072: step 1453, loss 0.90133, acc 0.640625, learning_rate 0.000112912
2017-09-28T16:32:05.513975: step 1454, loss 0.807888, acc 0.6875, learning_rate 0.000112859
2017-09-28T16:32:05.598281: step 1455, loss 0.863129, acc 0.65625, learning_rate 0.000112807
2017-09-28T16:32:05.679866: step 1456, loss 0.79123, acc 0.625, learning_rate 0.000112754
2017-09-28T16:32:05.762817: step 1457, loss 0.746705, acc 0.671875, learning_rate 0.000112702
2017-09-28T16:32:05.846653: step 1458, loss 0.835038, acc 0.734375, learning_rate 0.000112651
2017-09-28T16:32:05.932148: step 1459, loss 0.822814, acc 0.71875, learning_rate 0.000112599
2017-09-28T16:32:06.016514: step 1460, loss 0.750803, acc 0.734375, learning_rate 0.000112547
2017-09-28T16:32:06.097627: step 1461, loss 0.894092, acc 0.671875, learning_rate 0.000112496
2017-09-28T16:32:06.180881: step 1462, loss 0.868586, acc 0.625, learning_rate 0.000112445
2017-09-28T16:32:06.259594: step 1463, loss 0.832581, acc 0.59375, learning_rate 0.000112394
2017-09-28T16:32:06.341576: step 1464, loss 0.880802, acc 0.6875, learning_rate 0.000112344
2017-09-28T16:32:06.426769: step 1465, loss 0.767871, acc 0.6875, learning_rate 0.000112293
2017-09-28T16:32:06.511086: step 1466, loss 0.799855, acc 0.734375, learning_rate 0.000112243
2017-09-28T16:32:06.591925: step 1467, loss 0.901983, acc 0.640625, learning_rate 0.000112193
2017-09-28T16:32:06.674058: step 1468, loss 0.727931, acc 0.71875, learning_rate 0.000112144
2017-09-28T16:32:06.762050: step 1469, loss 0.880482, acc 0.65625, learning_rate 0.000112094
2017-09-28T16:32:06.829269: step 1470, loss 0.748816, acc 0.686275, learning_rate 0.000112045
2017-09-28T16:32:06.911586: step 1471, loss 1.0084, acc 0.546875, learning_rate 0.000111995
2017-09-28T16:32:06.998424: step 1472, loss 0.919588, acc 0.625, learning_rate 0.000111946
2017-09-28T16:32:07.078716: step 1473, loss 0.928474, acc 0.6875, learning_rate 0.000111898
2017-09-28T16:32:07.163174: step 1474, loss 0.896307, acc 0.671875, learning_rate 0.000111849
2017-09-28T16:32:07.244313: step 1475, loss 0.748023, acc 0.671875, learning_rate 0.000111801
2017-09-28T16:32:07.328569: step 1476, loss 0.846981, acc 0.6875, learning_rate 0.000111753
2017-09-28T16:32:07.412104: step 1477, loss 0.797468, acc 0.71875, learning_rate 0.000111705
2017-09-28T16:32:07.494207: step 1478, loss 0.898718, acc 0.6875, learning_rate 0.000111657
2017-09-28T16:32:07.576138: step 1479, loss 0.664624, acc 0.765625, learning_rate 0.000111609
2017-09-28T16:32:07.657742: step 1480, loss 1.00538, acc 0.53125, learning_rate 0.000111562

Evaluation:
2017-09-28T16:32:07.937547: step 1480, loss 0.86824, acc 0.643165

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-1480

2017-09-28T16:32:08.636745: step 1481, loss 0.748595, acc 0.734375, learning_rate 0.000111515
2017-09-28T16:32:08.716422: step 1482, loss 0.865399, acc 0.65625, learning_rate 0.000111468
2017-09-28T16:32:08.799347: step 1483, loss 0.840897, acc 0.65625, learning_rate 0.000111421
2017-09-28T16:32:08.882777: step 1484, loss 0.777094, acc 0.71875, learning_rate 0.000111374
2017-09-28T16:32:08.967477: step 1485, loss 0.844425, acc 0.671875, learning_rate 0.000111328
2017-09-28T16:32:09.053197: step 1486, loss 0.779499, acc 0.734375, learning_rate 0.000111282
2017-09-28T16:32:09.134616: step 1487, loss 0.942011, acc 0.578125, learning_rate 0.000111236
2017-09-28T16:32:09.218998: step 1488, loss 0.85862, acc 0.71875, learning_rate 0.00011119
2017-09-28T16:32:09.303514: step 1489, loss 0.795321, acc 0.71875, learning_rate 0.000111144
2017-09-28T16:32:09.389808: step 1490, loss 0.979022, acc 0.65625, learning_rate 0.000111099
2017-09-28T16:32:09.471350: step 1491, loss 0.686214, acc 0.71875, learning_rate 0.000111053
2017-09-28T16:32:09.557854: step 1492, loss 0.886617, acc 0.625, learning_rate 0.000111008
2017-09-28T16:32:09.642720: step 1493, loss 0.836969, acc 0.6875, learning_rate 0.000110963
2017-09-28T16:32:09.725319: step 1494, loss 0.733731, acc 0.78125, learning_rate 0.000110918
2017-09-28T16:32:09.802688: step 1495, loss 0.871645, acc 0.65625, learning_rate 0.000110874
2017-09-28T16:32:09.889591: step 1496, loss 1.01116, acc 0.578125, learning_rate 0.00011083
2017-09-28T16:32:09.972436: step 1497, loss 0.85992, acc 0.59375, learning_rate 0.000110785
2017-09-28T16:32:10.055375: step 1498, loss 0.859109, acc 0.65625, learning_rate 0.000110741
2017-09-28T16:32:10.142301: step 1499, loss 0.809083, acc 0.671875, learning_rate 0.000110697
2017-09-28T16:32:10.226441: step 1500, loss 1.14485, acc 0.59375, learning_rate 0.000110654
2017-09-28T16:32:10.306995: step 1501, loss 0.923853, acc 0.59375, learning_rate 0.00011061
2017-09-28T16:32:10.395907: step 1502, loss 0.967963, acc 0.578125, learning_rate 0.000110567
2017-09-28T16:32:10.479740: step 1503, loss 0.789664, acc 0.671875, learning_rate 0.000110524
2017-09-28T16:32:10.560263: step 1504, loss 0.793018, acc 0.703125, learning_rate 0.000110481
2017-09-28T16:32:10.648165: step 1505, loss 0.829778, acc 0.640625, learning_rate 0.000110438
2017-09-28T16:32:10.738206: step 1506, loss 0.969128, acc 0.609375, learning_rate 0.000110396
2017-09-28T16:32:10.827724: step 1507, loss 0.811029, acc 0.65625, learning_rate 0.000110353
2017-09-28T16:32:10.917441: step 1508, loss 0.873814, acc 0.640625, learning_rate 0.000110311
2017-09-28T16:32:11.007644: step 1509, loss 1.0602, acc 0.578125, learning_rate 0.000110269
2017-09-28T16:32:11.096532: step 1510, loss 1.00265, acc 0.59375, learning_rate 0.000110227
2017-09-28T16:32:11.183973: step 1511, loss 0.741273, acc 0.6875, learning_rate 0.000110185
2017-09-28T16:32:11.270676: step 1512, loss 0.79573, acc 0.671875, learning_rate 0.000110144
2017-09-28T16:32:11.351375: step 1513, loss 0.860761, acc 0.65625, learning_rate 0.000110102
2017-09-28T16:32:11.436911: step 1514, loss 0.955803, acc 0.609375, learning_rate 0.000110061
2017-09-28T16:32:11.521257: step 1515, loss 0.730497, acc 0.78125, learning_rate 0.00011002
2017-09-28T16:32:11.605934: step 1516, loss 0.851609, acc 0.671875, learning_rate 0.000109979
2017-09-28T16:32:11.692114: step 1517, loss 0.943301, acc 0.671875, learning_rate 0.000109938
2017-09-28T16:32:11.784179: step 1518, loss 0.716627, acc 0.703125, learning_rate 0.000109898
2017-09-28T16:32:11.868817: step 1519, loss 0.752723, acc 0.703125, learning_rate 0.000109857
2017-09-28T16:32:11.951763: step 1520, loss 0.778098, acc 0.78125, learning_rate 0.000109817

Evaluation:
2017-09-28T16:32:12.239358: step 1520, loss 0.867912, acc 0.653237

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-1520

2017-09-28T16:32:12.879522: step 1521, loss 0.848054, acc 0.59375, learning_rate 0.000109777
2017-09-28T16:32:12.965362: step 1522, loss 0.990629, acc 0.65625, learning_rate 0.000109737
2017-09-28T16:32:13.047789: step 1523, loss 0.901407, acc 0.65625, learning_rate 0.000109697
2017-09-28T16:32:13.131546: step 1524, loss 0.699386, acc 0.671875, learning_rate 0.000109658
2017-09-28T16:32:13.216218: step 1525, loss 0.829119, acc 0.703125, learning_rate 0.000109618
2017-09-28T16:32:13.297796: step 1526, loss 0.919249, acc 0.59375, learning_rate 0.000109579
2017-09-28T16:32:13.380501: step 1527, loss 1.05221, acc 0.53125, learning_rate 0.00010954
2017-09-28T16:32:13.467636: step 1528, loss 0.878844, acc 0.640625, learning_rate 0.000109501
2017-09-28T16:32:13.551374: step 1529, loss 0.93265, acc 0.625, learning_rate 0.000109462
2017-09-28T16:32:13.639676: step 1530, loss 1.13199, acc 0.515625, learning_rate 0.000109424
2017-09-28T16:32:13.724566: step 1531, loss 0.905145, acc 0.609375, learning_rate 0.000109385
2017-09-28T16:32:13.812319: step 1532, loss 0.901132, acc 0.640625, learning_rate 0.000109347
2017-09-28T16:32:13.897581: step 1533, loss 0.776805, acc 0.6875, learning_rate 0.000109309
2017-09-28T16:32:13.980359: step 1534, loss 0.832914, acc 0.609375, learning_rate 0.000109271
2017-09-28T16:32:14.064227: step 1535, loss 0.752803, acc 0.703125, learning_rate 0.000109233
2017-09-28T16:32:14.148457: step 1536, loss 0.908875, acc 0.640625, learning_rate 0.000109195
2017-09-28T16:32:14.232850: step 1537, loss 0.829405, acc 0.625, learning_rate 0.000109158
2017-09-28T16:32:14.312175: step 1538, loss 0.854209, acc 0.6875, learning_rate 0.00010912
2017-09-28T16:32:14.395757: step 1539, loss 1.04325, acc 0.609375, learning_rate 0.000109083
2017-09-28T16:32:14.479970: step 1540, loss 1.095, acc 0.484375, learning_rate 0.000109046
2017-09-28T16:32:14.565185: step 1541, loss 0.963259, acc 0.5625, learning_rate 0.000109009
2017-09-28T16:32:14.647815: step 1542, loss 0.797542, acc 0.703125, learning_rate 0.000108972
2017-09-28T16:32:14.736809: step 1543, loss 0.941315, acc 0.671875, learning_rate 0.000108936
2017-09-28T16:32:14.827620: step 1544, loss 0.877743, acc 0.703125, learning_rate 0.000108899
2017-09-28T16:32:14.914021: step 1545, loss 0.930134, acc 0.640625, learning_rate 0.000108863
2017-09-28T16:32:14.997341: step 1546, loss 0.886809, acc 0.71875, learning_rate 0.000108827
2017-09-28T16:32:15.082500: step 1547, loss 0.770094, acc 0.65625, learning_rate 0.000108791
2017-09-28T16:32:15.166371: step 1548, loss 0.778976, acc 0.71875, learning_rate 0.000108755
2017-09-28T16:32:15.249303: step 1549, loss 0.802769, acc 0.734375, learning_rate 0.000108719
2017-09-28T16:32:15.331029: step 1550, loss 0.812225, acc 0.625, learning_rate 0.000108683
2017-09-28T16:32:15.414621: step 1551, loss 0.898371, acc 0.59375, learning_rate 0.000108648
2017-09-28T16:32:15.496111: step 1552, loss 0.845532, acc 0.625, learning_rate 0.000108613
2017-09-28T16:32:15.578984: step 1553, loss 1.01999, acc 0.59375, learning_rate 0.000108577
2017-09-28T16:32:15.667393: step 1554, loss 0.916021, acc 0.59375, learning_rate 0.000108542
2017-09-28T16:32:15.752789: step 1555, loss 0.734459, acc 0.71875, learning_rate 0.000108508
2017-09-28T16:32:15.840208: step 1556, loss 0.791417, acc 0.734375, learning_rate 0.000108473
2017-09-28T16:32:15.927701: step 1557, loss 0.765442, acc 0.6875, learning_rate 0.000108438
2017-09-28T16:32:16.010565: step 1558, loss 0.763768, acc 0.734375, learning_rate 0.000108404
2017-09-28T16:32:16.091147: step 1559, loss 0.790037, acc 0.75, learning_rate 0.00010837
2017-09-28T16:32:16.175060: step 1560, loss 0.866271, acc 0.65625, learning_rate 0.000108335

Evaluation:
2017-09-28T16:32:16.450725: step 1560, loss 0.867536, acc 0.653237

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-1560

2017-09-28T16:32:17.025919: step 1561, loss 0.768203, acc 0.6875, learning_rate 0.000108301
2017-09-28T16:32:17.119984: step 1562, loss 0.908786, acc 0.609375, learning_rate 0.000108267
2017-09-28T16:32:17.210634: step 1563, loss 0.833113, acc 0.640625, learning_rate 0.000108234
2017-09-28T16:32:17.304176: step 1564, loss 0.730308, acc 0.71875, learning_rate 0.0001082
2017-09-28T16:32:17.399233: step 1565, loss 0.707228, acc 0.71875, learning_rate 0.000108167
2017-09-28T16:32:17.489795: step 1566, loss 0.804769, acc 0.640625, learning_rate 0.000108133
2017-09-28T16:32:17.571010: step 1567, loss 0.996525, acc 0.65625, learning_rate 0.0001081
2017-09-28T16:32:17.637818: step 1568, loss 0.813325, acc 0.705882, learning_rate 0.000108067
2017-09-28T16:32:17.719382: step 1569, loss 1.00829, acc 0.625, learning_rate 0.000108034
2017-09-28T16:32:17.799260: step 1570, loss 0.71616, acc 0.6875, learning_rate 0.000108001
2017-09-28T16:32:17.881896: step 1571, loss 0.836949, acc 0.640625, learning_rate 0.000107969
2017-09-28T16:32:17.963356: step 1572, loss 0.865859, acc 0.59375, learning_rate 0.000107936
2017-09-28T16:32:18.046499: step 1573, loss 0.717085, acc 0.734375, learning_rate 0.000107904
2017-09-28T16:32:18.131525: step 1574, loss 0.908816, acc 0.65625, learning_rate 0.000107871
2017-09-28T16:32:18.224747: step 1575, loss 0.864624, acc 0.671875, learning_rate 0.000107839
2017-09-28T16:32:18.319041: step 1576, loss 0.905494, acc 0.640625, learning_rate 0.000107807
2017-09-28T16:32:18.417069: step 1577, loss 0.837002, acc 0.65625, learning_rate 0.000107775
2017-09-28T16:32:18.501987: step 1578, loss 0.823719, acc 0.625, learning_rate 0.000107744
2017-09-28T16:32:18.645707: step 1579, loss 0.880371, acc 0.609375, learning_rate 0.000107712
2017-09-28T16:32:18.732424: step 1580, loss 0.699354, acc 0.765625, learning_rate 0.000107681
2017-09-28T16:32:18.821704: step 1581, loss 0.860596, acc 0.625, learning_rate 0.000107649
2017-09-28T16:32:18.907747: step 1582, loss 0.622748, acc 0.78125, learning_rate 0.000107618
2017-09-28T16:32:18.995770: step 1583, loss 0.923436, acc 0.59375, learning_rate 0.000107587
2017-09-28T16:32:19.081341: step 1584, loss 0.940424, acc 0.578125, learning_rate 0.000107556
2017-09-28T16:32:19.169120: step 1585, loss 0.772997, acc 0.71875, learning_rate 0.000107525
2017-09-28T16:32:19.258998: step 1586, loss 0.584105, acc 0.8125, learning_rate 0.000107494
2017-09-28T16:32:19.342277: step 1587, loss 0.662066, acc 0.765625, learning_rate 0.000107464
2017-09-28T16:32:19.424750: step 1588, loss 0.962031, acc 0.59375, learning_rate 0.000107433
2017-09-28T16:32:19.507719: step 1589, loss 0.754089, acc 0.671875, learning_rate 0.000107403
2017-09-28T16:32:19.588645: step 1590, loss 1.00494, acc 0.59375, learning_rate 0.000107373
2017-09-28T16:32:19.670425: step 1591, loss 0.670604, acc 0.765625, learning_rate 0.000107343
2017-09-28T16:32:19.752484: step 1592, loss 0.96696, acc 0.578125, learning_rate 0.000107313
2017-09-28T16:32:19.834315: step 1593, loss 0.996035, acc 0.625, learning_rate 0.000107283
2017-09-28T16:32:19.915453: step 1594, loss 0.715976, acc 0.703125, learning_rate 0.000107253
2017-09-28T16:32:20.001719: step 1595, loss 0.683926, acc 0.734375, learning_rate 0.000107224
2017-09-28T16:32:20.081368: step 1596, loss 0.866618, acc 0.640625, learning_rate 0.000107194
2017-09-28T16:32:20.167162: step 1597, loss 0.849327, acc 0.65625, learning_rate 0.000107165
2017-09-28T16:32:20.247089: step 1598, loss 0.778656, acc 0.65625, learning_rate 0.000107136
2017-09-28T16:32:20.333682: step 1599, loss 0.880955, acc 0.609375, learning_rate 0.000107106
2017-09-28T16:32:20.423350: step 1600, loss 0.694087, acc 0.765625, learning_rate 0.000107077

Evaluation:
2017-09-28T16:32:20.717795: step 1600, loss 0.86593, acc 0.640288

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-1600

2017-09-28T16:32:21.328079: step 1601, loss 0.921385, acc 0.59375, learning_rate 0.000107048
2017-09-28T16:32:21.417955: step 1602, loss 0.811587, acc 0.71875, learning_rate 0.00010702
2017-09-28T16:32:21.502903: step 1603, loss 0.885577, acc 0.65625, learning_rate 0.000106991
2017-09-28T16:32:21.589359: step 1604, loss 0.779306, acc 0.625, learning_rate 0.000106963
2017-09-28T16:32:21.673892: step 1605, loss 0.870859, acc 0.609375, learning_rate 0.000106934
2017-09-28T16:32:21.762596: step 1606, loss 1.08687, acc 0.546875, learning_rate 0.000106906
2017-09-28T16:32:21.855847: step 1607, loss 0.720303, acc 0.671875, learning_rate 0.000106878
2017-09-28T16:32:21.939502: step 1608, loss 0.945841, acc 0.609375, learning_rate 0.00010685
2017-09-28T16:32:22.023136: step 1609, loss 0.948238, acc 0.59375, learning_rate 0.000106822
2017-09-28T16:32:22.109282: step 1610, loss 0.775684, acc 0.734375, learning_rate 0.000106794
2017-09-28T16:32:22.194218: step 1611, loss 0.906791, acc 0.65625, learning_rate 0.000106766
2017-09-28T16:32:22.280575: step 1612, loss 0.657282, acc 0.78125, learning_rate 0.000106738
2017-09-28T16:32:22.366098: step 1613, loss 0.946862, acc 0.578125, learning_rate 0.000106711
2017-09-28T16:32:22.451882: step 1614, loss 1.00072, acc 0.578125, learning_rate 0.000106684
2017-09-28T16:32:22.535407: step 1615, loss 0.919388, acc 0.609375, learning_rate 0.000106656
2017-09-28T16:32:22.624762: step 1616, loss 0.858284, acc 0.671875, learning_rate 0.000106629
2017-09-28T16:32:22.710238: step 1617, loss 0.868037, acc 0.65625, learning_rate 0.000106602
2017-09-28T16:32:22.792066: step 1618, loss 0.909516, acc 0.578125, learning_rate 0.000106575
2017-09-28T16:32:22.877727: step 1619, loss 1.01982, acc 0.546875, learning_rate 0.000106548
2017-09-28T16:32:22.968017: step 1620, loss 0.778447, acc 0.65625, learning_rate 0.000106521
2017-09-28T16:32:23.065873: step 1621, loss 0.701886, acc 0.71875, learning_rate 0.000106495
2017-09-28T16:32:23.152925: step 1622, loss 0.828383, acc 0.6875, learning_rate 0.000106468
2017-09-28T16:32:23.234638: step 1623, loss 0.888823, acc 0.65625, learning_rate 0.000106442
2017-09-28T16:32:23.318214: step 1624, loss 1.00067, acc 0.59375, learning_rate 0.000106416
2017-09-28T16:32:23.402792: step 1625, loss 0.742583, acc 0.71875, learning_rate 0.000106389
2017-09-28T16:32:23.485617: step 1626, loss 0.912884, acc 0.640625, learning_rate 0.000106363
2017-09-28T16:32:23.570388: step 1627, loss 0.992476, acc 0.609375, learning_rate 0.000106337
2017-09-28T16:32:23.657333: step 1628, loss 0.85426, acc 0.6875, learning_rate 0.000106312
2017-09-28T16:32:23.744395: step 1629, loss 0.686451, acc 0.75, learning_rate 0.000106286
2017-09-28T16:32:23.831669: step 1630, loss 0.675537, acc 0.734375, learning_rate 0.00010626
2017-09-28T16:32:23.913400: step 1631, loss 0.973856, acc 0.5625, learning_rate 0.000106235
2017-09-28T16:32:23.998735: step 1632, loss 0.738739, acc 0.71875, learning_rate 0.000106209
2017-09-28T16:32:24.082221: step 1633, loss 0.887652, acc 0.65625, learning_rate 0.000106184
2017-09-28T16:32:24.162848: step 1634, loss 0.811714, acc 0.6875, learning_rate 0.000106159
2017-09-28T16:32:24.247632: step 1635, loss 0.71766, acc 0.71875, learning_rate 0.000106133
2017-09-28T16:32:24.327857: step 1636, loss 0.95193, acc 0.65625, learning_rate 0.000106108
2017-09-28T16:32:24.410454: step 1637, loss 0.90437, acc 0.609375, learning_rate 0.000106083
2017-09-28T16:32:24.499628: step 1638, loss 1.00263, acc 0.578125, learning_rate 0.000106059
2017-09-28T16:32:24.586405: step 1639, loss 0.77009, acc 0.765625, learning_rate 0.000106034
2017-09-28T16:32:24.670373: step 1640, loss 0.858393, acc 0.640625, learning_rate 0.000106009

Evaluation:
2017-09-28T16:32:24.945274: step 1640, loss 0.864413, acc 0.654676

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-1640

2017-09-28T16:32:25.587413: step 1641, loss 0.972311, acc 0.625, learning_rate 0.000105985
2017-09-28T16:32:25.670640: step 1642, loss 0.895132, acc 0.609375, learning_rate 0.00010596
2017-09-28T16:32:25.757106: step 1643, loss 0.85844, acc 0.640625, learning_rate 0.000105936
2017-09-28T16:32:25.844160: step 1644, loss 1.00966, acc 0.59375, learning_rate 0.000105912
2017-09-28T16:32:25.932431: step 1645, loss 0.861568, acc 0.640625, learning_rate 0.000105888
2017-09-28T16:32:26.020584: step 1646, loss 0.931484, acc 0.640625, learning_rate 0.000105864
2017-09-28T16:32:26.109484: step 1647, loss 1.04762, acc 0.640625, learning_rate 0.00010584
2017-09-28T16:32:26.198920: step 1648, loss 0.655412, acc 0.75, learning_rate 0.000105816
2017-09-28T16:32:26.708170: step 1649, loss 1.01423, acc 0.65625, learning_rate 0.000105792
2017-09-28T16:32:26.797434: step 1650, loss 0.678632, acc 0.8125, learning_rate 0.000105768
2017-09-28T16:32:26.884688: step 1651, loss 1.02727, acc 0.515625, learning_rate 0.000105745
2017-09-28T16:32:26.967185: step 1652, loss 0.838218, acc 0.6875, learning_rate 0.000105721
2017-09-28T16:32:27.050122: step 1653, loss 0.876796, acc 0.6875, learning_rate 0.000105698
2017-09-28T16:32:27.133337: step 1654, loss 0.804911, acc 0.671875, learning_rate 0.000105675
2017-09-28T16:32:27.217917: step 1655, loss 0.68425, acc 0.734375, learning_rate 0.000105652
2017-09-28T16:32:27.302458: step 1656, loss 0.728243, acc 0.703125, learning_rate 0.000105629
2017-09-28T16:32:27.383566: step 1657, loss 0.704468, acc 0.671875, learning_rate 0.000105606
2017-09-28T16:32:27.465974: step 1658, loss 0.896852, acc 0.578125, learning_rate 0.000105583
2017-09-28T16:32:27.547916: step 1659, loss 0.794058, acc 0.640625, learning_rate 0.00010556
2017-09-28T16:32:27.626821: step 1660, loss 0.921105, acc 0.546875, learning_rate 0.000105537
2017-09-28T16:32:27.708803: step 1661, loss 0.694177, acc 0.734375, learning_rate 0.000105515
2017-09-28T16:32:27.790443: step 1662, loss 0.981562, acc 0.609375, learning_rate 0.000105492
2017-09-28T16:32:27.875776: step 1663, loss 0.865456, acc 0.609375, learning_rate 0.00010547
2017-09-28T16:32:27.958480: step 1664, loss 0.889055, acc 0.625, learning_rate 0.000105447
2017-09-28T16:32:28.042934: step 1665, loss 0.812009, acc 0.65625, learning_rate 0.000105425
2017-09-28T16:32:28.108812: step 1666, loss 0.808457, acc 0.666667, learning_rate 0.000105403
2017-09-28T16:32:28.191690: step 1667, loss 0.86465, acc 0.65625, learning_rate 0.000105381
2017-09-28T16:32:28.273716: step 1668, loss 0.797906, acc 0.6875, learning_rate 0.000105359
2017-09-28T16:32:28.356064: step 1669, loss 0.940494, acc 0.5625, learning_rate 0.000105337
2017-09-28T16:32:28.445287: step 1670, loss 0.856599, acc 0.671875, learning_rate 0.000105315
2017-09-28T16:32:28.530687: step 1671, loss 0.644043, acc 0.75, learning_rate 0.000105294
2017-09-28T16:32:28.612958: step 1672, loss 0.864379, acc 0.640625, learning_rate 0.000105272
2017-09-28T16:32:28.695887: step 1673, loss 0.777327, acc 0.6875, learning_rate 0.000105251
2017-09-28T16:32:28.777068: step 1674, loss 0.866318, acc 0.671875, learning_rate 0.000105229
2017-09-28T16:32:28.859119: step 1675, loss 0.949103, acc 0.6875, learning_rate 0.000105208
2017-09-28T16:32:28.941110: step 1676, loss 0.871196, acc 0.625, learning_rate 0.000105186
2017-09-28T16:32:29.022185: step 1677, loss 0.858094, acc 0.640625, learning_rate 0.000105165
2017-09-28T16:32:29.106045: step 1678, loss 0.996683, acc 0.5625, learning_rate 0.000105144
2017-09-28T16:32:29.188396: step 1679, loss 0.971813, acc 0.59375, learning_rate 0.000105123
2017-09-28T16:32:29.273045: step 1680, loss 0.786865, acc 0.75, learning_rate 0.000105102

Evaluation:
2017-09-28T16:32:29.556959: step 1680, loss 0.863847, acc 0.651799

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-1680

2017-09-28T16:32:30.499378: step 1681, loss 0.879368, acc 0.578125, learning_rate 0.000105081
2017-09-28T16:32:30.654729: step 1682, loss 0.820807, acc 0.671875, learning_rate 0.000105061
2017-09-28T16:32:30.739882: step 1683, loss 0.712701, acc 0.71875, learning_rate 0.00010504
2017-09-28T16:32:30.824215: step 1684, loss 0.844359, acc 0.671875, learning_rate 0.00010502
2017-09-28T16:32:30.906339: step 1685, loss 0.723646, acc 0.75, learning_rate 0.000104999
2017-09-28T16:32:30.989179: step 1686, loss 0.867011, acc 0.6875, learning_rate 0.000104979
2017-09-28T16:32:31.074344: step 1687, loss 0.846269, acc 0.65625, learning_rate 0.000104958
2017-09-28T16:32:31.154454: step 1688, loss 1.19024, acc 0.5, learning_rate 0.000104938
2017-09-28T16:32:31.233967: step 1689, loss 0.904702, acc 0.671875, learning_rate 0.000104918
2017-09-28T16:32:31.316631: step 1690, loss 1.05962, acc 0.546875, learning_rate 0.000104898
2017-09-28T16:32:31.400905: step 1691, loss 0.836519, acc 0.703125, learning_rate 0.000104878
2017-09-28T16:32:31.483740: step 1692, loss 0.881019, acc 0.640625, learning_rate 0.000104858
2017-09-28T16:32:31.564854: step 1693, loss 0.865347, acc 0.65625, learning_rate 0.000104838
2017-09-28T16:32:31.643907: step 1694, loss 0.825564, acc 0.671875, learning_rate 0.000104818
2017-09-28T16:32:31.727379: step 1695, loss 0.663853, acc 0.75, learning_rate 0.000104799
2017-09-28T16:32:31.810554: step 1696, loss 0.650591, acc 0.765625, learning_rate 0.000104779
2017-09-28T16:32:31.894852: step 1697, loss 0.658368, acc 0.796875, learning_rate 0.00010476
2017-09-28T16:32:31.977395: step 1698, loss 0.742604, acc 0.671875, learning_rate 0.00010474
2017-09-28T16:32:32.062388: step 1699, loss 0.86452, acc 0.671875, learning_rate 0.000104721
2017-09-28T16:32:32.146894: step 1700, loss 0.959944, acc 0.59375, learning_rate 0.000104702
2017-09-28T16:32:32.231055: step 1701, loss 0.848754, acc 0.609375, learning_rate 0.000104682
2017-09-28T16:32:32.316994: step 1702, loss 0.9309, acc 0.6875, learning_rate 0.000104663
2017-09-28T16:32:32.400568: step 1703, loss 0.863663, acc 0.625, learning_rate 0.000104644
2017-09-28T16:32:32.483035: step 1704, loss 0.614855, acc 0.78125, learning_rate 0.000104625
2017-09-28T16:32:32.566369: step 1705, loss 0.738906, acc 0.71875, learning_rate 0.000104606
2017-09-28T16:32:32.652982: step 1706, loss 1.0027, acc 0.578125, learning_rate 0.000104588
2017-09-28T16:32:32.737832: step 1707, loss 0.978335, acc 0.625, learning_rate 0.000104569
2017-09-28T16:32:32.821183: step 1708, loss 0.714885, acc 0.703125, learning_rate 0.00010455
2017-09-28T16:32:32.905933: step 1709, loss 1.09061, acc 0.515625, learning_rate 0.000104532
2017-09-28T16:32:32.990984: step 1710, loss 0.798334, acc 0.6875, learning_rate 0.000104513
2017-09-28T16:32:33.076329: step 1711, loss 0.664892, acc 0.671875, learning_rate 0.000104495
2017-09-28T16:32:33.157696: step 1712, loss 0.737041, acc 0.703125, learning_rate 0.000104476
2017-09-28T16:32:33.240357: step 1713, loss 0.82719, acc 0.6875, learning_rate 0.000104458
2017-09-28T16:32:33.322511: step 1714, loss 0.861243, acc 0.59375, learning_rate 0.00010444
2017-09-28T16:32:33.404862: step 1715, loss 0.918273, acc 0.640625, learning_rate 0.000104422
2017-09-28T16:32:33.488876: step 1716, loss 0.470759, acc 0.84375, learning_rate 0.000104404
2017-09-28T16:32:33.571479: step 1717, loss 0.875683, acc 0.6875, learning_rate 0.000104386
2017-09-28T16:32:33.656841: step 1718, loss 0.853205, acc 0.671875, learning_rate 0.000104368
2017-09-28T16:32:33.739343: step 1719, loss 0.98264, acc 0.578125, learning_rate 0.00010435
2017-09-28T16:32:33.823630: step 1720, loss 0.729117, acc 0.734375, learning_rate 0.000104332

Evaluation:
2017-09-28T16:32:34.107692: step 1720, loss 0.860493, acc 0.654676

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-1720

2017-09-28T16:32:34.676231: step 1721, loss 0.814307, acc 0.625, learning_rate 0.000104315
2017-09-28T16:32:34.759460: step 1722, loss 1.07931, acc 0.546875, learning_rate 0.000104297
2017-09-28T16:32:34.842442: step 1723, loss 0.912818, acc 0.609375, learning_rate 0.000104279
2017-09-28T16:32:34.925140: step 1724, loss 0.872551, acc 0.640625, learning_rate 0.000104262
2017-09-28T16:32:35.008302: step 1725, loss 0.969355, acc 0.609375, learning_rate 0.000104245
2017-09-28T16:32:35.089541: step 1726, loss 0.748139, acc 0.734375, learning_rate 0.000104227
2017-09-28T16:32:35.170720: step 1727, loss 0.961115, acc 0.59375, learning_rate 0.00010421
2017-09-28T16:32:35.249907: step 1728, loss 0.697525, acc 0.75, learning_rate 0.000104193
2017-09-28T16:32:35.331249: step 1729, loss 0.757291, acc 0.6875, learning_rate 0.000104176
2017-09-28T16:32:35.411449: step 1730, loss 0.863341, acc 0.671875, learning_rate 0.000104159
2017-09-28T16:32:35.492182: step 1731, loss 0.901098, acc 0.59375, learning_rate 0.000104142
2017-09-28T16:32:35.573722: step 1732, loss 0.764643, acc 0.75, learning_rate 0.000104125
2017-09-28T16:32:35.655728: step 1733, loss 0.878738, acc 0.65625, learning_rate 0.000104108
2017-09-28T16:32:35.737059: step 1734, loss 0.835958, acc 0.640625, learning_rate 0.000104091
2017-09-28T16:32:35.816259: step 1735, loss 0.833903, acc 0.625, learning_rate 0.000104074
2017-09-28T16:32:35.895917: step 1736, loss 0.975001, acc 0.609375, learning_rate 0.000104058
2017-09-28T16:32:35.977290: step 1737, loss 0.893415, acc 0.625, learning_rate 0.000104041
2017-09-28T16:32:36.058243: step 1738, loss 0.95691, acc 0.625, learning_rate 0.000104025
2017-09-28T16:32:36.138105: step 1739, loss 0.809366, acc 0.734375, learning_rate 0.000104008
2017-09-28T16:32:36.220759: step 1740, loss 0.983417, acc 0.609375, learning_rate 0.000103992
2017-09-28T16:32:36.304257: step 1741, loss 0.988347, acc 0.703125, learning_rate 0.000103976
2017-09-28T16:32:36.386471: step 1742, loss 0.950723, acc 0.578125, learning_rate 0.000103959
2017-09-28T16:32:36.470171: step 1743, loss 0.873051, acc 0.6875, learning_rate 0.000103943
2017-09-28T16:32:36.550401: step 1744, loss 0.769494, acc 0.625, learning_rate 0.000103927
2017-09-28T16:32:36.634202: step 1745, loss 0.813193, acc 0.59375, learning_rate 0.000103911
2017-09-28T16:32:36.716412: step 1746, loss 0.759997, acc 0.6875, learning_rate 0.000103895
2017-09-28T16:32:36.795085: step 1747, loss 0.741156, acc 0.71875, learning_rate 0.000103879
2017-09-28T16:32:36.882469: step 1748, loss 1.00994, acc 0.53125, learning_rate 0.000103863
2017-09-28T16:32:36.969305: step 1749, loss 0.774738, acc 0.6875, learning_rate 0.000103848
2017-09-28T16:32:37.049586: step 1750, loss 0.743691, acc 0.734375, learning_rate 0.000103832
2017-09-28T16:32:37.133705: step 1751, loss 0.907648, acc 0.65625, learning_rate 0.000103816
2017-09-28T16:32:37.214079: step 1752, loss 0.955642, acc 0.625, learning_rate 0.000103801
2017-09-28T16:32:37.293805: step 1753, loss 0.662642, acc 0.734375, learning_rate 0.000103785
2017-09-28T16:32:37.382582: step 1754, loss 0.840808, acc 0.609375, learning_rate 0.00010377
2017-09-28T16:32:37.471296: step 1755, loss 0.780678, acc 0.703125, learning_rate 0.000103754
2017-09-28T16:32:37.553655: step 1756, loss 0.82696, acc 0.625, learning_rate 0.000103739
2017-09-28T16:32:37.634342: step 1757, loss 0.836674, acc 0.6875, learning_rate 0.000103724
2017-09-28T16:32:37.714850: step 1758, loss 0.802877, acc 0.6875, learning_rate 0.000103709
2017-09-28T16:32:37.797889: step 1759, loss 0.890267, acc 0.609375, learning_rate 0.000103694
2017-09-28T16:32:37.878291: step 1760, loss 0.752546, acc 0.71875, learning_rate 0.000103678

Evaluation:
2017-09-28T16:32:38.159396: step 1760, loss 0.862283, acc 0.653237

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-1760

2017-09-28T16:32:38.717873: step 1761, loss 0.984195, acc 0.546875, learning_rate 0.000103663
2017-09-28T16:32:38.798864: step 1762, loss 0.844096, acc 0.65625, learning_rate 0.000103648
2017-09-28T16:32:38.880782: step 1763, loss 0.946984, acc 0.59375, learning_rate 0.000103634
2017-09-28T16:32:38.944593: step 1764, loss 0.604546, acc 0.764706, learning_rate 0.000103619
2017-09-28T16:32:39.027647: step 1765, loss 0.797151, acc 0.6875, learning_rate 0.000103604
2017-09-28T16:32:39.109114: step 1766, loss 0.878835, acc 0.65625, learning_rate 0.000103589
2017-09-28T16:32:39.192040: step 1767, loss 0.789835, acc 0.671875, learning_rate 0.000103575
2017-09-28T16:32:39.273115: step 1768, loss 0.901084, acc 0.671875, learning_rate 0.00010356
2017-09-28T16:32:39.353709: step 1769, loss 0.763323, acc 0.71875, learning_rate 0.000103545
2017-09-28T16:32:39.437579: step 1770, loss 0.779731, acc 0.703125, learning_rate 0.000103531
2017-09-28T16:32:39.518930: step 1771, loss 0.974909, acc 0.5625, learning_rate 0.000103517
2017-09-28T16:32:39.599775: step 1772, loss 0.826747, acc 0.6875, learning_rate 0.000103502
2017-09-28T16:32:39.680549: step 1773, loss 0.817364, acc 0.6875, learning_rate 0.000103488
2017-09-28T16:32:39.760058: step 1774, loss 0.82914, acc 0.703125, learning_rate 0.000103474
2017-09-28T16:32:39.841874: step 1775, loss 0.67131, acc 0.71875, learning_rate 0.00010346
2017-09-28T16:32:39.923351: step 1776, loss 0.930585, acc 0.625, learning_rate 0.000103445
2017-09-28T16:32:40.005681: step 1777, loss 1.06387, acc 0.546875, learning_rate 0.000103431
2017-09-28T16:32:40.089500: step 1778, loss 1.06747, acc 0.640625, learning_rate 0.000103417
2017-09-28T16:32:40.172358: step 1779, loss 1.0572, acc 0.5, learning_rate 0.000103403
2017-09-28T16:32:40.253390: step 1780, loss 0.655217, acc 0.828125, learning_rate 0.00010339
2017-09-28T16:32:40.334193: step 1781, loss 0.840961, acc 0.609375, learning_rate 0.000103376
2017-09-28T16:32:40.415793: step 1782, loss 0.820226, acc 0.640625, learning_rate 0.000103362
2017-09-28T16:32:40.497975: step 1783, loss 0.767441, acc 0.703125, learning_rate 0.000103348
2017-09-28T16:32:40.579360: step 1784, loss 0.663236, acc 0.703125, learning_rate 0.000103335
2017-09-28T16:32:40.661213: step 1785, loss 0.604094, acc 0.84375, learning_rate 0.000103321
2017-09-28T16:32:40.742802: step 1786, loss 0.725634, acc 0.71875, learning_rate 0.000103307
2017-09-28T16:32:40.822616: step 1787, loss 0.937214, acc 0.59375, learning_rate 0.000103294
2017-09-28T16:32:40.905547: step 1788, loss 0.90932, acc 0.625, learning_rate 0.00010328
2017-09-28T16:32:40.987988: step 1789, loss 0.857941, acc 0.625, learning_rate 0.000103267
2017-09-28T16:32:41.069748: step 1790, loss 0.895778, acc 0.671875, learning_rate 0.000103254
2017-09-28T16:32:41.150752: step 1791, loss 1.11236, acc 0.5625, learning_rate 0.00010324
2017-09-28T16:32:41.235733: step 1792, loss 1.12323, acc 0.625, learning_rate 0.000103227
2017-09-28T16:32:41.318503: step 1793, loss 0.974123, acc 0.609375, learning_rate 0.000103214
2017-09-28T16:32:41.401535: step 1794, loss 0.829409, acc 0.671875, learning_rate 0.000103201
2017-09-28T16:32:41.483296: step 1795, loss 0.787914, acc 0.734375, learning_rate 0.000103188
2017-09-28T16:32:41.565083: step 1796, loss 0.573307, acc 0.796875, learning_rate 0.000103175
2017-09-28T16:32:41.646848: step 1797, loss 0.737558, acc 0.703125, learning_rate 0.000103162
2017-09-28T16:32:41.731212: step 1798, loss 0.865386, acc 0.640625, learning_rate 0.000103149
2017-09-28T16:32:41.813324: step 1799, loss 0.799265, acc 0.65625, learning_rate 0.000103136
2017-09-28T16:32:41.892132: step 1800, loss 0.81847, acc 0.71875, learning_rate 0.000103123

Evaluation:
2017-09-28T16:32:42.173675: step 1800, loss 0.85781, acc 0.657554

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-1800

2017-09-28T16:32:42.800614: step 1801, loss 0.999565, acc 0.578125, learning_rate 0.000103111
2017-09-28T16:32:42.881448: step 1802, loss 0.736292, acc 0.65625, learning_rate 0.000103098
2017-09-28T16:32:42.964977: step 1803, loss 0.76859, acc 0.671875, learning_rate 0.000103085
2017-09-28T16:32:43.046656: step 1804, loss 0.658417, acc 0.765625, learning_rate 0.000103073
2017-09-28T16:32:43.129734: step 1805, loss 0.757771, acc 0.703125, learning_rate 0.00010306
2017-09-28T16:32:43.208873: step 1806, loss 0.827872, acc 0.65625, learning_rate 0.000103048
2017-09-28T16:32:43.291720: step 1807, loss 1.02093, acc 0.59375, learning_rate 0.000103035
2017-09-28T16:32:43.374282: step 1808, loss 0.686642, acc 0.734375, learning_rate 0.000103023
2017-09-28T16:32:43.457296: step 1809, loss 0.750185, acc 0.75, learning_rate 0.00010301
2017-09-28T16:32:43.540213: step 1810, loss 0.774364, acc 0.671875, learning_rate 0.000102998
2017-09-28T16:32:43.621004: step 1811, loss 0.785744, acc 0.65625, learning_rate 0.000102986
2017-09-28T16:32:43.701684: step 1812, loss 0.939898, acc 0.625, learning_rate 0.000102974
2017-09-28T16:32:43.789007: step 1813, loss 0.792233, acc 0.65625, learning_rate 0.000102962
2017-09-28T16:32:43.870200: step 1814, loss 0.841636, acc 0.640625, learning_rate 0.000102949
2017-09-28T16:32:43.953778: step 1815, loss 0.905658, acc 0.65625, learning_rate 0.000102937
2017-09-28T16:32:44.036797: step 1816, loss 0.746136, acc 0.65625, learning_rate 0.000102925
2017-09-28T16:32:44.123114: step 1817, loss 0.876779, acc 0.625, learning_rate 0.000102913
2017-09-28T16:32:44.206174: step 1818, loss 0.929322, acc 0.671875, learning_rate 0.000102902
2017-09-28T16:32:44.290290: step 1819, loss 0.63702, acc 0.8125, learning_rate 0.00010289
2017-09-28T16:32:44.373911: step 1820, loss 0.713046, acc 0.734375, learning_rate 0.000102878
2017-09-28T16:32:44.454121: step 1821, loss 0.828944, acc 0.6875, learning_rate 0.000102866
2017-09-28T16:32:44.532343: step 1822, loss 0.972612, acc 0.578125, learning_rate 0.000102855
2017-09-28T16:32:44.612159: step 1823, loss 1.02046, acc 0.578125, learning_rate 0.000102843
2017-09-28T16:32:44.691253: step 1824, loss 0.783072, acc 0.65625, learning_rate 0.000102831
2017-09-28T16:32:44.774090: step 1825, loss 0.834831, acc 0.640625, learning_rate 0.00010282
2017-09-28T16:32:44.856446: step 1826, loss 0.893672, acc 0.625, learning_rate 0.000102808
2017-09-28T16:32:44.936781: step 1827, loss 0.941452, acc 0.609375, learning_rate 0.000102797
2017-09-28T16:32:45.018672: step 1828, loss 0.927401, acc 0.625, learning_rate 0.000102785
2017-09-28T16:32:45.100415: step 1829, loss 0.81957, acc 0.6875, learning_rate 0.000102774
2017-09-28T16:32:45.179566: step 1830, loss 0.901424, acc 0.609375, learning_rate 0.000102763
2017-09-28T16:32:45.260941: step 1831, loss 0.855304, acc 0.640625, learning_rate 0.000102751
2017-09-28T16:32:45.343066: step 1832, loss 1.02765, acc 0.53125, learning_rate 0.00010274
2017-09-28T16:32:45.426191: step 1833, loss 0.900828, acc 0.625, learning_rate 0.000102729
2017-09-28T16:32:45.507820: step 1834, loss 0.837979, acc 0.640625, learning_rate 0.000102718
2017-09-28T16:32:45.590884: step 1835, loss 0.784754, acc 0.640625, learning_rate 0.000102707
2017-09-28T16:32:45.674809: step 1836, loss 0.727274, acc 0.703125, learning_rate 0.000102696
2017-09-28T16:32:45.756606: step 1837, loss 0.842225, acc 0.65625, learning_rate 0.000102685
2017-09-28T16:32:45.837336: step 1838, loss 0.756643, acc 0.65625, learning_rate 0.000102674
2017-09-28T16:32:45.916686: step 1839, loss 0.759747, acc 0.6875, learning_rate 0.000102663
2017-09-28T16:32:45.999955: step 1840, loss 0.822789, acc 0.671875, learning_rate 0.000102652

Evaluation:
2017-09-28T16:32:46.272605: step 1840, loss 0.85869, acc 0.653237

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-1840

2017-09-28T16:32:46.763347: step 1841, loss 0.758379, acc 0.6875, learning_rate 0.000102641
2017-09-28T16:32:46.842669: step 1842, loss 1.04177, acc 0.546875, learning_rate 0.00010263
2017-09-28T16:32:46.925950: step 1843, loss 0.887599, acc 0.59375, learning_rate 0.00010262
2017-09-28T16:32:47.010756: step 1844, loss 0.625629, acc 0.8125, learning_rate 0.000102609
2017-09-28T16:32:47.093979: step 1845, loss 0.804105, acc 0.671875, learning_rate 0.000102598
2017-09-28T16:32:47.177200: step 1846, loss 0.956657, acc 0.59375, learning_rate 0.000102588
2017-09-28T16:32:47.255600: step 1847, loss 0.812534, acc 0.640625, learning_rate 0.000102577
2017-09-28T16:32:47.338287: step 1848, loss 0.705312, acc 0.734375, learning_rate 0.000102567
2017-09-28T16:32:47.420143: step 1849, loss 0.973555, acc 0.578125, learning_rate 0.000102556
2017-09-28T16:32:47.501659: step 1850, loss 1.06962, acc 0.53125, learning_rate 0.000102546
2017-09-28T16:32:47.585046: step 1851, loss 0.874811, acc 0.640625, learning_rate 0.000102535
2017-09-28T16:32:47.667277: step 1852, loss 0.859308, acc 0.640625, learning_rate 0.000102525
2017-09-28T16:32:47.752478: step 1853, loss 0.797692, acc 0.65625, learning_rate 0.000102515
2017-09-28T16:32:47.834542: step 1854, loss 0.74817, acc 0.71875, learning_rate 0.000102504
2017-09-28T16:32:47.916453: step 1855, loss 0.741716, acc 0.640625, learning_rate 0.000102494
2017-09-28T16:32:47.997261: step 1856, loss 0.91081, acc 0.625, learning_rate 0.000102484
2017-09-28T16:32:48.078774: step 1857, loss 0.906819, acc 0.59375, learning_rate 0.000102474
2017-09-28T16:32:48.159108: step 1858, loss 0.970004, acc 0.546875, learning_rate 0.000102464
2017-09-28T16:32:48.239437: step 1859, loss 0.827513, acc 0.703125, learning_rate 0.000102454
2017-09-28T16:32:48.320057: step 1860, loss 0.689335, acc 0.71875, learning_rate 0.000102444
2017-09-28T16:32:48.404070: step 1861, loss 0.828154, acc 0.6875, learning_rate 0.000102434
2017-09-28T16:32:48.470217: step 1862, loss 0.849499, acc 0.647059, learning_rate 0.000102424
2017-09-28T16:32:48.551350: step 1863, loss 0.898091, acc 0.609375, learning_rate 0.000102414
2017-09-28T16:32:48.633645: step 1864, loss 0.779586, acc 0.703125, learning_rate 0.000102404
2017-09-28T16:32:48.714969: step 1865, loss 0.775793, acc 0.75, learning_rate 0.000102394
2017-09-28T16:32:48.798569: step 1866, loss 0.925325, acc 0.65625, learning_rate 0.000102384
2017-09-28T16:32:48.879954: step 1867, loss 0.953466, acc 0.640625, learning_rate 0.000102375
2017-09-28T16:32:48.960245: step 1868, loss 0.795, acc 0.65625, learning_rate 0.000102365
2017-09-28T16:32:49.039801: step 1869, loss 0.719416, acc 0.75, learning_rate 0.000102355
2017-09-28T16:32:49.124501: step 1870, loss 0.68419, acc 0.75, learning_rate 0.000102346
2017-09-28T16:32:49.208182: step 1871, loss 0.732324, acc 0.71875, learning_rate 0.000102336
2017-09-28T16:32:49.288560: step 1872, loss 0.982801, acc 0.625, learning_rate 0.000102327
2017-09-28T16:32:49.369123: step 1873, loss 0.806546, acc 0.71875, learning_rate 0.000102317
2017-09-28T16:32:49.450749: step 1874, loss 0.901773, acc 0.625, learning_rate 0.000102308
2017-09-28T16:32:49.530719: step 1875, loss 0.885547, acc 0.65625, learning_rate 0.000102298
2017-09-28T16:32:49.610234: step 1876, loss 0.890486, acc 0.6875, learning_rate 0.000102289
2017-09-28T16:32:49.691752: step 1877, loss 0.845484, acc 0.671875, learning_rate 0.000102279
2017-09-28T16:32:49.774953: step 1878, loss 0.879413, acc 0.609375, learning_rate 0.00010227
2017-09-28T16:32:49.856675: step 1879, loss 0.909076, acc 0.625, learning_rate 0.000102261
2017-09-28T16:32:49.936166: step 1880, loss 0.74662, acc 0.71875, learning_rate 0.000102252

Evaluation:
2017-09-28T16:32:50.209335: step 1880, loss 0.8608, acc 0.654676

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-1880

2017-09-28T16:32:50.769336: step 1881, loss 0.570445, acc 0.78125, learning_rate 0.000102242
2017-09-28T16:32:50.850270: step 1882, loss 0.901889, acc 0.609375, learning_rate 0.000102233
2017-09-28T16:32:50.930900: step 1883, loss 0.882388, acc 0.671875, learning_rate 0.000102224
2017-09-28T16:32:51.011278: step 1884, loss 0.957101, acc 0.65625, learning_rate 0.000102215
2017-09-28T16:32:51.092188: step 1885, loss 0.868051, acc 0.6875, learning_rate 0.000102206
2017-09-28T16:32:51.170721: step 1886, loss 0.970265, acc 0.71875, learning_rate 0.000102197
2017-09-28T16:32:51.255587: step 1887, loss 0.88579, acc 0.625, learning_rate 0.000102188
2017-09-28T16:32:51.337428: step 1888, loss 0.956559, acc 0.53125, learning_rate 0.000102179
2017-09-28T16:32:51.423202: step 1889, loss 1.07852, acc 0.578125, learning_rate 0.00010217
2017-09-28T16:32:51.506115: step 1890, loss 0.815059, acc 0.65625, learning_rate 0.000102161
2017-09-28T16:32:51.584846: step 1891, loss 0.756963, acc 0.640625, learning_rate 0.000102153
2017-09-28T16:32:51.666907: step 1892, loss 0.874747, acc 0.640625, learning_rate 0.000102144
2017-09-28T16:32:51.748307: step 1893, loss 0.925594, acc 0.625, learning_rate 0.000102135
2017-09-28T16:32:51.829320: step 1894, loss 0.731096, acc 0.734375, learning_rate 0.000102126
2017-09-28T16:32:51.912350: step 1895, loss 0.764725, acc 0.6875, learning_rate 0.000102118
2017-09-28T16:32:51.999999: step 1896, loss 0.821857, acc 0.671875, learning_rate 0.000102109
2017-09-28T16:32:52.085186: step 1897, loss 0.98762, acc 0.609375, learning_rate 0.0001021
2017-09-28T16:32:52.166666: step 1898, loss 0.657827, acc 0.75, learning_rate 0.000102092
2017-09-28T16:32:52.251721: step 1899, loss 0.753152, acc 0.71875, learning_rate 0.000102083
2017-09-28T16:32:52.331903: step 1900, loss 0.775374, acc 0.671875, learning_rate 0.000102075
2017-09-28T16:32:52.413528: step 1901, loss 0.786216, acc 0.734375, learning_rate 0.000102066
2017-09-28T16:32:52.493164: step 1902, loss 1.02589, acc 0.59375, learning_rate 0.000102058
2017-09-28T16:32:52.575489: step 1903, loss 1.02248, acc 0.640625, learning_rate 0.00010205
2017-09-28T16:32:52.659201: step 1904, loss 0.964847, acc 0.5625, learning_rate 0.000102041
2017-09-28T16:32:52.741301: step 1905, loss 0.856578, acc 0.671875, learning_rate 0.000102033
2017-09-28T16:32:52.825524: step 1906, loss 0.778355, acc 0.734375, learning_rate 0.000102025
2017-09-28T16:32:52.907552: step 1907, loss 0.649645, acc 0.734375, learning_rate 0.000102016
2017-09-28T16:32:52.989478: step 1908, loss 0.778962, acc 0.671875, learning_rate 0.000102008
2017-09-28T16:32:53.072370: step 1909, loss 0.720781, acc 0.703125, learning_rate 0.000102
2017-09-28T16:32:53.151785: step 1910, loss 0.799484, acc 0.703125, learning_rate 0.000101992
2017-09-28T16:32:53.233549: step 1911, loss 1.02103, acc 0.546875, learning_rate 0.000101984
2017-09-28T16:32:53.317512: step 1912, loss 0.85317, acc 0.640625, learning_rate 0.000101975
2017-09-28T16:32:53.401934: step 1913, loss 0.911469, acc 0.625, learning_rate 0.000101967
2017-09-28T16:32:53.485767: step 1914, loss 0.764055, acc 0.671875, learning_rate 0.000101959
2017-09-28T16:32:53.567466: step 1915, loss 0.734605, acc 0.703125, learning_rate 0.000101951
2017-09-28T16:32:53.655784: step 1916, loss 0.817254, acc 0.671875, learning_rate 0.000101943
2017-09-28T16:32:53.737158: step 1917, loss 0.66998, acc 0.71875, learning_rate 0.000101935
2017-09-28T16:32:53.817596: step 1918, loss 0.836564, acc 0.625, learning_rate 0.000101928
2017-09-28T16:32:53.901598: step 1919, loss 0.898741, acc 0.59375, learning_rate 0.00010192
2017-09-28T16:32:53.983589: step 1920, loss 0.853199, acc 0.609375, learning_rate 0.000101912

Evaluation:
2017-09-28T16:32:54.257711: step 1920, loss 0.855251, acc 0.658993

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-1920

2017-09-28T16:32:54.830249: step 1921, loss 1.00573, acc 0.59375, learning_rate 0.000101904
2017-09-28T16:32:54.913106: step 1922, loss 0.825336, acc 0.609375, learning_rate 0.000101896
2017-09-28T16:32:54.996403: step 1923, loss 0.717816, acc 0.75, learning_rate 0.000101889
2017-09-28T16:32:55.080560: step 1924, loss 0.775335, acc 0.640625, learning_rate 0.000101881
2017-09-28T16:32:55.165751: step 1925, loss 0.916911, acc 0.6875, learning_rate 0.000101873
2017-09-28T16:32:55.251079: step 1926, loss 0.724028, acc 0.671875, learning_rate 0.000101865
2017-09-28T16:32:55.334466: step 1927, loss 0.782408, acc 0.703125, learning_rate 0.000101858
2017-09-28T16:32:55.418449: step 1928, loss 0.817995, acc 0.71875, learning_rate 0.00010185
2017-09-28T16:32:55.503903: step 1929, loss 0.724475, acc 0.71875, learning_rate 0.000101843
2017-09-28T16:32:55.586869: step 1930, loss 0.934119, acc 0.625, learning_rate 0.000101835
2017-09-28T16:32:55.668371: step 1931, loss 0.86834, acc 0.625, learning_rate 0.000101828
2017-09-28T16:32:55.749537: step 1932, loss 0.777689, acc 0.671875, learning_rate 0.00010182
2017-09-28T16:32:55.832666: step 1933, loss 0.789971, acc 0.71875, learning_rate 0.000101813
2017-09-28T16:32:55.920294: step 1934, loss 0.816589, acc 0.671875, learning_rate 0.000101805
2017-09-28T16:32:56.006041: step 1935, loss 0.771568, acc 0.703125, learning_rate 0.000101798
2017-09-28T16:32:56.090079: step 1936, loss 0.795251, acc 0.703125, learning_rate 0.000101791
2017-09-28T16:32:56.172146: step 1937, loss 0.855795, acc 0.640625, learning_rate 0.000101783
2017-09-28T16:32:56.255854: step 1938, loss 0.827331, acc 0.625, learning_rate 0.000101776
2017-09-28T16:32:56.337600: step 1939, loss 0.890035, acc 0.671875, learning_rate 0.000101769
2017-09-28T16:32:56.423915: step 1940, loss 0.891581, acc 0.625, learning_rate 0.000101762
2017-09-28T16:32:56.515670: step 1941, loss 0.880719, acc 0.703125, learning_rate 0.000101754
2017-09-28T16:32:56.596181: step 1942, loss 0.80615, acc 0.671875, learning_rate 0.000101747
2017-09-28T16:32:56.680330: step 1943, loss 0.738336, acc 0.703125, learning_rate 0.00010174
2017-09-28T16:32:56.763634: step 1944, loss 0.693298, acc 0.71875, learning_rate 0.000101733
2017-09-28T16:32:56.846321: step 1945, loss 0.726117, acc 0.6875, learning_rate 0.000101726
2017-09-28T16:32:56.927488: step 1946, loss 0.826051, acc 0.671875, learning_rate 0.000101719
2017-09-28T16:32:57.015149: step 1947, loss 0.907317, acc 0.625, learning_rate 0.000101712
2017-09-28T16:32:57.105044: step 1948, loss 0.9957, acc 0.5625, learning_rate 0.000101705
2017-09-28T16:32:57.189077: step 1949, loss 1.09216, acc 0.515625, learning_rate 0.000101698
2017-09-28T16:32:57.271411: step 1950, loss 0.881148, acc 0.671875, learning_rate 0.000101691
2017-09-28T16:32:57.356248: step 1951, loss 0.85801, acc 0.640625, learning_rate 0.000101684
2017-09-28T16:32:57.440460: step 1952, loss 0.627806, acc 0.734375, learning_rate 0.000101677
2017-09-28T16:32:57.524878: step 1953, loss 0.752911, acc 0.703125, learning_rate 0.00010167
2017-09-28T16:32:57.606579: step 1954, loss 0.922163, acc 0.65625, learning_rate 0.000101664
2017-09-28T16:32:57.690091: step 1955, loss 0.782786, acc 0.65625, learning_rate 0.000101657
2017-09-28T16:32:57.772607: step 1956, loss 0.638344, acc 0.78125, learning_rate 0.00010165
2017-09-28T16:32:57.853147: step 1957, loss 0.922182, acc 0.609375, learning_rate 0.000101643
2017-09-28T16:32:57.934747: step 1958, loss 0.8635, acc 0.65625, learning_rate 0.000101637
2017-09-28T16:32:58.013939: step 1959, loss 1.13259, acc 0.5625, learning_rate 0.00010163
2017-09-28T16:32:58.080554: step 1960, loss 0.978894, acc 0.627451, learning_rate 0.000101623

Evaluation:
2017-09-28T16:32:58.353566: step 1960, loss 0.856503, acc 0.65036

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-1960

2017-09-28T16:32:58.984221: step 1961, loss 0.892806, acc 0.640625, learning_rate 0.000101617
2017-09-28T16:32:59.065972: step 1962, loss 0.733265, acc 0.71875, learning_rate 0.00010161
2017-09-28T16:32:59.146405: step 1963, loss 0.968567, acc 0.5625, learning_rate 0.000101604
2017-09-28T16:32:59.227444: step 1964, loss 0.866111, acc 0.578125, learning_rate 0.000101597
2017-09-28T16:32:59.309763: step 1965, loss 0.908329, acc 0.546875, learning_rate 0.00010159
2017-09-28T16:32:59.393472: step 1966, loss 0.819935, acc 0.640625, learning_rate 0.000101584
2017-09-28T16:32:59.475259: step 1967, loss 0.881472, acc 0.6875, learning_rate 0.000101577
2017-09-28T16:32:59.555693: step 1968, loss 0.808075, acc 0.671875, learning_rate 0.000101571
2017-09-28T16:32:59.638490: step 1969, loss 0.78063, acc 0.703125, learning_rate 0.000101565
2017-09-28T16:32:59.718416: step 1970, loss 0.76101, acc 0.734375, learning_rate 0.000101558
2017-09-28T16:32:59.803058: step 1971, loss 0.859919, acc 0.6875, learning_rate 0.000101552
2017-09-28T16:32:59.882758: step 1972, loss 0.893227, acc 0.609375, learning_rate 0.000101546
2017-09-28T16:32:59.964780: step 1973, loss 0.904234, acc 0.671875, learning_rate 0.000101539
2017-09-28T16:33:00.048232: step 1974, loss 0.887408, acc 0.703125, learning_rate 0.000101533
2017-09-28T16:33:00.131798: step 1975, loss 0.736667, acc 0.71875, learning_rate 0.000101527
2017-09-28T16:33:00.213479: step 1976, loss 0.806201, acc 0.734375, learning_rate 0.00010152
2017-09-28T16:33:00.299121: step 1977, loss 0.806385, acc 0.65625, learning_rate 0.000101514
2017-09-28T16:33:00.386208: step 1978, loss 0.998836, acc 0.546875, learning_rate 0.000101508
2017-09-28T16:33:00.472387: step 1979, loss 0.896899, acc 0.5625, learning_rate 0.000101502
2017-09-28T16:33:00.557436: step 1980, loss 0.952743, acc 0.65625, learning_rate 0.000101496
2017-09-28T16:33:00.639755: step 1981, loss 0.880646, acc 0.671875, learning_rate 0.00010149
2017-09-28T16:33:00.723476: step 1982, loss 0.720282, acc 0.75, learning_rate 0.000101484
2017-09-28T16:33:00.805930: step 1983, loss 0.756757, acc 0.6875, learning_rate 0.000101478
2017-09-28T16:33:00.888251: step 1984, loss 0.925699, acc 0.578125, learning_rate 0.000101472
2017-09-28T16:33:00.968192: step 1985, loss 0.928469, acc 0.703125, learning_rate 0.000101466
2017-09-28T16:33:01.053098: step 1986, loss 0.787976, acc 0.671875, learning_rate 0.00010146
2017-09-28T16:33:01.134476: step 1987, loss 0.958258, acc 0.59375, learning_rate 0.000101454
2017-09-28T16:33:01.214732: step 1988, loss 0.81222, acc 0.703125, learning_rate 0.000101448
2017-09-28T16:33:01.297360: step 1989, loss 0.918657, acc 0.640625, learning_rate 0.000101442
2017-09-28T16:33:01.381401: step 1990, loss 0.724716, acc 0.6875, learning_rate 0.000101436
2017-09-28T16:33:01.465313: step 1991, loss 0.807167, acc 0.6875, learning_rate 0.00010143
2017-09-28T16:33:01.547697: step 1992, loss 0.851302, acc 0.625, learning_rate 0.000101424
2017-09-28T16:33:01.628635: step 1993, loss 1.21379, acc 0.53125, learning_rate 0.000101418
2017-09-28T16:33:01.710090: step 1994, loss 0.794061, acc 0.703125, learning_rate 0.000101413
2017-09-28T16:33:01.790773: step 1995, loss 0.717976, acc 0.765625, learning_rate 0.000101407
2017-09-28T16:33:01.871741: step 1996, loss 0.880252, acc 0.625, learning_rate 0.000101401
2017-09-28T16:33:01.956330: step 1997, loss 0.857903, acc 0.6875, learning_rate 0.000101395
2017-09-28T16:33:02.045668: step 1998, loss 1.06043, acc 0.5, learning_rate 0.00010139
2017-09-28T16:33:02.134223: step 1999, loss 0.908961, acc 0.65625, learning_rate 0.000101384
2017-09-28T16:33:02.219522: step 2000, loss 0.738851, acc 0.65625, learning_rate 0.000101378

Evaluation:
2017-09-28T16:33:02.494655: step 2000, loss 0.853188, acc 0.654676

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-2000

2017-09-28T16:33:03.096830: step 2001, loss 0.677037, acc 0.734375, learning_rate 0.000101373
2017-09-28T16:33:03.180205: step 2002, loss 0.671387, acc 0.8125, learning_rate 0.000101367
2017-09-28T16:33:03.260977: step 2003, loss 0.758288, acc 0.6875, learning_rate 0.000101362
2017-09-28T16:33:03.343553: step 2004, loss 0.78115, acc 0.671875, learning_rate 0.000101356
2017-09-28T16:33:03.427490: step 2005, loss 0.686956, acc 0.703125, learning_rate 0.00010135
2017-09-28T16:33:03.508466: step 2006, loss 0.8853, acc 0.640625, learning_rate 0.000101345
2017-09-28T16:33:03.588195: step 2007, loss 0.715016, acc 0.71875, learning_rate 0.000101339
2017-09-28T16:33:03.669423: step 2008, loss 0.956505, acc 0.65625, learning_rate 0.000101334
2017-09-28T16:33:03.751604: step 2009, loss 0.657466, acc 0.71875, learning_rate 0.000101328
2017-09-28T16:33:03.833229: step 2010, loss 0.912045, acc 0.59375, learning_rate 0.000101323
2017-09-28T16:33:03.915677: step 2011, loss 0.654744, acc 0.796875, learning_rate 0.000101318
2017-09-28T16:33:03.994073: step 2012, loss 0.703842, acc 0.78125, learning_rate 0.000101312
2017-09-28T16:33:04.077324: step 2013, loss 0.976138, acc 0.515625, learning_rate 0.000101307
2017-09-28T16:33:04.158390: step 2014, loss 0.647255, acc 0.78125, learning_rate 0.000101302
2017-09-28T16:33:04.238661: step 2015, loss 0.843963, acc 0.703125, learning_rate 0.000101296
2017-09-28T16:33:04.318878: step 2016, loss 0.804254, acc 0.734375, learning_rate 0.000101291
2017-09-28T16:33:04.400201: step 2017, loss 0.905706, acc 0.59375, learning_rate 0.000101286
2017-09-28T16:33:04.484765: step 2018, loss 0.869217, acc 0.65625, learning_rate 0.00010128
2017-09-28T16:33:04.566662: step 2019, loss 0.947775, acc 0.578125, learning_rate 0.000101275
2017-09-28T16:33:04.649284: step 2020, loss 0.732907, acc 0.71875, learning_rate 0.00010127
2017-09-28T16:33:04.730789: step 2021, loss 0.97352, acc 0.578125, learning_rate 0.000101265
2017-09-28T16:33:04.813893: step 2022, loss 0.938679, acc 0.6875, learning_rate 0.00010126
2017-09-28T16:33:04.895717: step 2023, loss 1.09407, acc 0.546875, learning_rate 0.000101255
2017-09-28T16:33:04.980210: step 2024, loss 0.702789, acc 0.703125, learning_rate 0.000101249
2017-09-28T16:33:05.061839: step 2025, loss 0.769814, acc 0.71875, learning_rate 0.000101244
2017-09-28T16:33:05.146198: step 2026, loss 0.79866, acc 0.65625, learning_rate 0.000101239
2017-09-28T16:33:05.229612: step 2027, loss 0.835437, acc 0.609375, learning_rate 0.000101234
2017-09-28T16:33:05.314403: step 2028, loss 0.73857, acc 0.71875, learning_rate 0.000101229
2017-09-28T16:33:05.398541: step 2029, loss 0.820719, acc 0.671875, learning_rate 0.000101224
2017-09-28T16:33:05.478835: step 2030, loss 0.695493, acc 0.765625, learning_rate 0.000101219
2017-09-28T16:33:05.562581: step 2031, loss 0.864506, acc 0.625, learning_rate 0.000101214
2017-09-28T16:33:05.643759: step 2032, loss 0.867624, acc 0.6875, learning_rate 0.000101209
2017-09-28T16:33:05.727270: step 2033, loss 0.885145, acc 0.5625, learning_rate 0.000101204
2017-09-28T16:33:05.809036: step 2034, loss 0.713014, acc 0.734375, learning_rate 0.000101199
2017-09-28T16:33:05.889998: step 2035, loss 0.85095, acc 0.640625, learning_rate 0.000101194
2017-09-28T16:33:05.971730: step 2036, loss 0.942044, acc 0.59375, learning_rate 0.00010119
2017-09-28T16:33:06.051282: step 2037, loss 0.762506, acc 0.703125, learning_rate 0.000101185
2017-09-28T16:33:06.135116: step 2038, loss 0.771125, acc 0.625, learning_rate 0.00010118
2017-09-28T16:33:06.216415: step 2039, loss 0.77249, acc 0.6875, learning_rate 0.000101175
2017-09-28T16:33:06.300037: step 2040, loss 0.96196, acc 0.65625, learning_rate 0.00010117

Evaluation:
2017-09-28T16:33:06.568170: step 2040, loss 0.852956, acc 0.648921

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-2040

2017-09-28T16:33:07.125186: step 2041, loss 0.788363, acc 0.703125, learning_rate 0.000101166
2017-09-28T16:33:07.211423: step 2042, loss 0.847964, acc 0.625, learning_rate 0.000101161
2017-09-28T16:33:07.291546: step 2043, loss 0.769501, acc 0.703125, learning_rate 0.000101156
2017-09-28T16:33:07.371584: step 2044, loss 0.580045, acc 0.828125, learning_rate 0.000101151
2017-09-28T16:33:07.454735: step 2045, loss 0.890407, acc 0.609375, learning_rate 0.000101147
2017-09-28T16:33:07.533946: step 2046, loss 1.02812, acc 0.609375, learning_rate 0.000101142
2017-09-28T16:33:07.618055: step 2047, loss 0.897333, acc 0.59375, learning_rate 0.000101137
2017-09-28T16:33:07.700390: step 2048, loss 0.883364, acc 0.609375, learning_rate 0.000101133
2017-09-28T16:33:07.780621: step 2049, loss 0.739924, acc 0.703125, learning_rate 0.000101128
2017-09-28T16:33:07.863845: step 2050, loss 0.773869, acc 0.65625, learning_rate 0.000101123
2017-09-28T16:33:07.945125: step 2051, loss 0.861928, acc 0.609375, learning_rate 0.000101119
2017-09-28T16:33:08.024064: step 2052, loss 0.812291, acc 0.734375, learning_rate 0.000101114
2017-09-28T16:33:08.105496: step 2053, loss 0.760547, acc 0.6875, learning_rate 0.00010111
2017-09-28T16:33:08.186524: step 2054, loss 1.06588, acc 0.546875, learning_rate 0.000101105
2017-09-28T16:33:08.267468: step 2055, loss 0.824467, acc 0.703125, learning_rate 0.000101101
2017-09-28T16:33:08.348447: step 2056, loss 0.914842, acc 0.59375, learning_rate 0.000101096
2017-09-28T16:33:08.430536: step 2057, loss 0.900134, acc 0.640625, learning_rate 0.000101092
2017-09-28T16:33:08.497922: step 2058, loss 0.651074, acc 0.72549, learning_rate 0.000101087
2017-09-28T16:33:08.579725: step 2059, loss 0.725111, acc 0.734375, learning_rate 0.000101083
2017-09-28T16:33:08.660976: step 2060, loss 0.888801, acc 0.609375, learning_rate 0.000101078
2017-09-28T16:33:08.745047: step 2061, loss 0.803404, acc 0.71875, learning_rate 0.000101074
2017-09-28T16:33:08.828082: step 2062, loss 0.907561, acc 0.640625, learning_rate 0.00010107
2017-09-28T16:33:08.907115: step 2063, loss 0.814547, acc 0.640625, learning_rate 0.000101065
2017-09-28T16:33:08.988642: step 2064, loss 0.758264, acc 0.734375, learning_rate 0.000101061
2017-09-28T16:33:09.073270: step 2065, loss 0.996575, acc 0.625, learning_rate 0.000101057
2017-09-28T16:33:09.153163: step 2066, loss 0.790699, acc 0.75, learning_rate 0.000101052
2017-09-28T16:33:09.233747: step 2067, loss 0.965758, acc 0.59375, learning_rate 0.000101048
2017-09-28T16:33:09.315898: step 2068, loss 0.757801, acc 0.71875, learning_rate 0.000101044
2017-09-28T16:33:09.397601: step 2069, loss 0.670146, acc 0.796875, learning_rate 0.000101039
2017-09-28T16:33:09.478227: step 2070, loss 0.735855, acc 0.703125, learning_rate 0.000101035
2017-09-28T16:33:09.555959: step 2071, loss 0.662028, acc 0.734375, learning_rate 0.000101031
2017-09-28T16:33:09.634109: step 2072, loss 0.903145, acc 0.640625, learning_rate 0.000101027
2017-09-28T16:33:09.712990: step 2073, loss 0.860649, acc 0.609375, learning_rate 0.000101023
2017-09-28T16:33:09.794945: step 2074, loss 0.913612, acc 0.640625, learning_rate 0.000101018
2017-09-28T16:33:09.877475: step 2075, loss 0.780287, acc 0.6875, learning_rate 0.000101014
2017-09-28T16:33:09.958524: step 2076, loss 0.923099, acc 0.609375, learning_rate 0.00010101
2017-09-28T16:33:10.040981: step 2077, loss 1.08002, acc 0.515625, learning_rate 0.000101006
2017-09-28T16:33:10.123366: step 2078, loss 0.749301, acc 0.734375, learning_rate 0.000101002
2017-09-28T16:33:10.207838: step 2079, loss 0.73268, acc 0.6875, learning_rate 0.000100998
2017-09-28T16:33:10.289474: step 2080, loss 0.822867, acc 0.65625, learning_rate 0.000100994

Evaluation:
2017-09-28T16:33:10.563424: step 2080, loss 0.853352, acc 0.656115

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-2080

2017-09-28T16:33:11.119740: step 2081, loss 0.827151, acc 0.640625, learning_rate 0.00010099
2017-09-28T16:33:11.203958: step 2082, loss 0.618685, acc 0.8125, learning_rate 0.000100986
2017-09-28T16:33:11.285376: step 2083, loss 0.830252, acc 0.71875, learning_rate 0.000100982
2017-09-28T16:33:11.367060: step 2084, loss 0.865714, acc 0.671875, learning_rate 0.000100978
2017-09-28T16:33:11.451631: step 2085, loss 0.830352, acc 0.625, learning_rate 0.000100974
2017-09-28T16:33:11.539055: step 2086, loss 0.934346, acc 0.578125, learning_rate 0.00010097
2017-09-28T16:33:11.622802: step 2087, loss 0.930937, acc 0.59375, learning_rate 0.000100966
2017-09-28T16:33:11.709628: step 2088, loss 0.986999, acc 0.65625, learning_rate 0.000100962
2017-09-28T16:33:11.792009: step 2089, loss 0.884559, acc 0.625, learning_rate 0.000100958
2017-09-28T16:33:11.872842: step 2090, loss 0.774918, acc 0.71875, learning_rate 0.000100954
2017-09-28T16:33:11.954210: step 2091, loss 0.827393, acc 0.640625, learning_rate 0.00010095
2017-09-28T16:33:12.035836: step 2092, loss 0.800123, acc 0.65625, learning_rate 0.000100946
2017-09-28T16:33:12.122911: step 2093, loss 0.93278, acc 0.671875, learning_rate 0.000100942
2017-09-28T16:33:12.212748: step 2094, loss 0.640217, acc 0.765625, learning_rate 0.000100938
2017-09-28T16:33:12.292435: step 2095, loss 0.828802, acc 0.65625, learning_rate 0.000100935
2017-09-28T16:33:12.371838: step 2096, loss 0.850024, acc 0.640625, learning_rate 0.000100931
2017-09-28T16:33:12.455697: step 2097, loss 0.954508, acc 0.625, learning_rate 0.000100927
2017-09-28T16:33:12.538907: step 2098, loss 0.974758, acc 0.609375, learning_rate 0.000100923
2017-09-28T16:33:12.620154: step 2099, loss 0.836955, acc 0.671875, learning_rate 0.000100919
2017-09-28T16:33:12.704952: step 2100, loss 0.636175, acc 0.75, learning_rate 0.000100916
2017-09-28T16:33:12.788970: step 2101, loss 0.742432, acc 0.640625, learning_rate 0.000100912
2017-09-28T16:33:12.870107: step 2102, loss 0.748733, acc 0.71875, learning_rate 0.000100908
2017-09-28T16:33:12.951874: step 2103, loss 0.861762, acc 0.625, learning_rate 0.000100904
2017-09-28T16:33:13.033794: step 2104, loss 0.755965, acc 0.703125, learning_rate 0.000100901
2017-09-28T16:33:13.119080: step 2105, loss 0.754907, acc 0.71875, learning_rate 0.000100897
2017-09-28T16:33:13.202074: step 2106, loss 0.843398, acc 0.625, learning_rate 0.000100893
2017-09-28T16:33:13.283453: step 2107, loss 0.823845, acc 0.671875, learning_rate 0.00010089
2017-09-28T16:33:13.366563: step 2108, loss 1.0357, acc 0.59375, learning_rate 0.000100886
2017-09-28T16:33:13.449670: step 2109, loss 0.706498, acc 0.703125, learning_rate 0.000100883
2017-09-28T16:33:13.531623: step 2110, loss 0.932957, acc 0.625, learning_rate 0.000100879
2017-09-28T16:33:13.612726: step 2111, loss 0.661993, acc 0.8125, learning_rate 0.000100875
2017-09-28T16:33:13.693559: step 2112, loss 0.801233, acc 0.671875, learning_rate 0.000100872
2017-09-28T16:33:13.775712: step 2113, loss 0.808704, acc 0.671875, learning_rate 0.000100868
2017-09-28T16:33:13.857980: step 2114, loss 0.681162, acc 0.765625, learning_rate 0.000100865
2017-09-28T16:33:13.942247: step 2115, loss 0.939505, acc 0.59375, learning_rate 0.000100861
2017-09-28T16:33:14.023959: step 2116, loss 0.826109, acc 0.640625, learning_rate 0.000100858
2017-09-28T16:33:14.106052: step 2117, loss 0.767865, acc 0.6875, learning_rate 0.000100854
2017-09-28T16:33:14.185837: step 2118, loss 0.895329, acc 0.625, learning_rate 0.000100851
2017-09-28T16:33:14.267199: step 2119, loss 0.830473, acc 0.640625, learning_rate 0.000100847
2017-09-28T16:33:14.348882: step 2120, loss 0.763228, acc 0.640625, learning_rate 0.000100844

Evaluation:
2017-09-28T16:33:14.617194: step 2120, loss 0.852558, acc 0.656115

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-2120

2017-09-28T16:33:15.246628: step 2121, loss 0.720404, acc 0.703125, learning_rate 0.00010084
2017-09-28T16:33:15.328025: step 2122, loss 0.77675, acc 0.6875, learning_rate 0.000100837
2017-09-28T16:33:15.412230: step 2123, loss 0.754755, acc 0.671875, learning_rate 0.000100833
2017-09-28T16:33:15.490834: step 2124, loss 0.715341, acc 0.734375, learning_rate 0.00010083
2017-09-28T16:33:15.574188: step 2125, loss 0.981367, acc 0.59375, learning_rate 0.000100827
2017-09-28T16:33:15.655985: step 2126, loss 0.948062, acc 0.59375, learning_rate 0.000100823
2017-09-28T16:33:15.740612: step 2127, loss 1.08487, acc 0.609375, learning_rate 0.00010082
2017-09-28T16:33:15.820172: step 2128, loss 0.691844, acc 0.734375, learning_rate 0.000100817
2017-09-28T16:33:15.904850: step 2129, loss 0.747268, acc 0.6875, learning_rate 0.000100813
2017-09-28T16:33:15.984344: step 2130, loss 0.769934, acc 0.734375, learning_rate 0.00010081
2017-09-28T16:33:16.067352: step 2131, loss 0.880724, acc 0.625, learning_rate 0.000100807
2017-09-28T16:33:16.152381: step 2132, loss 0.780537, acc 0.671875, learning_rate 0.000100803
2017-09-28T16:33:16.232761: step 2133, loss 0.956773, acc 0.625, learning_rate 0.0001008
2017-09-28T16:33:16.313346: step 2134, loss 0.69105, acc 0.765625, learning_rate 0.000100797
2017-09-28T16:33:16.395108: step 2135, loss 0.922949, acc 0.640625, learning_rate 0.000100793
2017-09-28T16:33:16.474330: step 2136, loss 0.873003, acc 0.6875, learning_rate 0.00010079
2017-09-28T16:33:16.556358: step 2137, loss 0.739312, acc 0.6875, learning_rate 0.000100787
2017-09-28T16:33:16.637436: step 2138, loss 0.733134, acc 0.6875, learning_rate 0.000100784
2017-09-28T16:33:16.718548: step 2139, loss 0.875701, acc 0.5625, learning_rate 0.000100781
2017-09-28T16:33:16.802369: step 2140, loss 0.894259, acc 0.59375, learning_rate 0.000100777
2017-09-28T16:33:16.882585: step 2141, loss 0.95575, acc 0.625, learning_rate 0.000100774
2017-09-28T16:33:16.964870: step 2142, loss 0.953229, acc 0.546875, learning_rate 0.000100771
2017-09-28T16:33:17.046635: step 2143, loss 0.925611, acc 0.578125, learning_rate 0.000100768
2017-09-28T16:33:17.128883: step 2144, loss 0.800658, acc 0.65625, learning_rate 0.000100765
2017-09-28T16:33:17.210708: step 2145, loss 0.850914, acc 0.65625, learning_rate 0.000100762
2017-09-28T16:33:17.295383: step 2146, loss 0.957109, acc 0.65625, learning_rate 0.000100759
2017-09-28T16:33:17.374802: step 2147, loss 0.885646, acc 0.609375, learning_rate 0.000100755
2017-09-28T16:33:17.454647: step 2148, loss 0.910633, acc 0.578125, learning_rate 0.000100752
2017-09-28T16:33:17.536848: step 2149, loss 0.726241, acc 0.75, learning_rate 0.000100749
2017-09-28T16:33:17.621028: step 2150, loss 0.816247, acc 0.65625, learning_rate 0.000100746
2017-09-28T16:33:17.701927: step 2151, loss 0.640485, acc 0.734375, learning_rate 0.000100743
2017-09-28T16:33:17.782057: step 2152, loss 0.63495, acc 0.78125, learning_rate 0.00010074
2017-09-28T16:33:17.859837: step 2153, loss 1.00077, acc 0.625, learning_rate 0.000100737
2017-09-28T16:33:17.940902: step 2154, loss 0.873113, acc 0.671875, learning_rate 0.000100734
2017-09-28T16:33:18.020434: step 2155, loss 0.943744, acc 0.5625, learning_rate 0.000100731
2017-09-28T16:33:18.086089: step 2156, loss 0.695742, acc 0.72549, learning_rate 0.000100728
2017-09-28T16:33:18.168343: step 2157, loss 0.981974, acc 0.609375, learning_rate 0.000100725
2017-09-28T16:33:18.250688: step 2158, loss 0.789327, acc 0.671875, learning_rate 0.000100722
2017-09-28T16:33:18.332166: step 2159, loss 1.02872, acc 0.578125, learning_rate 0.000100719
2017-09-28T16:33:18.414194: step 2160, loss 0.873477, acc 0.703125, learning_rate 0.000100716

Evaluation:
2017-09-28T16:33:18.692233: step 2160, loss 0.850332, acc 0.657554

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-2160

2017-09-28T16:33:19.184079: step 2161, loss 0.868235, acc 0.609375, learning_rate 0.000100713
2017-09-28T16:33:19.266890: step 2162, loss 0.83278, acc 0.6875, learning_rate 0.000100711
2017-09-28T16:33:19.346042: step 2163, loss 0.840665, acc 0.65625, learning_rate 0.000100708
2017-09-28T16:33:19.426859: step 2164, loss 0.734009, acc 0.75, learning_rate 0.000100705
2017-09-28T16:33:19.508209: step 2165, loss 0.788026, acc 0.6875, learning_rate 0.000100702
2017-09-28T16:33:19.585714: step 2166, loss 0.928369, acc 0.640625, learning_rate 0.000100699
2017-09-28T16:33:19.669914: step 2167, loss 0.818493, acc 0.65625, learning_rate 0.000100696
2017-09-28T16:33:19.751557: step 2168, loss 0.813103, acc 0.703125, learning_rate 0.000100693
2017-09-28T16:33:19.831994: step 2169, loss 0.782005, acc 0.71875, learning_rate 0.00010069
2017-09-28T16:33:19.916446: step 2170, loss 0.819518, acc 0.640625, learning_rate 0.000100688
2017-09-28T16:33:19.996974: step 2171, loss 0.944347, acc 0.59375, learning_rate 0.000100685
2017-09-28T16:33:20.077778: step 2172, loss 0.630051, acc 0.78125, learning_rate 0.000100682
2017-09-28T16:33:20.159145: step 2173, loss 0.724266, acc 0.671875, learning_rate 0.000100679
2017-09-28T16:33:20.242835: step 2174, loss 1.03348, acc 0.546875, learning_rate 0.000100677
2017-09-28T16:33:20.325187: step 2175, loss 0.83019, acc 0.6875, learning_rate 0.000100674
2017-09-28T16:33:20.407439: step 2176, loss 0.761396, acc 0.703125, learning_rate 0.000100671
2017-09-28T16:33:20.489179: step 2177, loss 0.921839, acc 0.640625, learning_rate 0.000100668
2017-09-28T16:33:20.571715: step 2178, loss 0.874053, acc 0.65625, learning_rate 0.000100666
2017-09-28T16:33:20.652518: step 2179, loss 0.937569, acc 0.609375, learning_rate 0.000100663
2017-09-28T16:33:20.734514: step 2180, loss 0.74401, acc 0.65625, learning_rate 0.00010066
2017-09-28T16:33:20.814525: step 2181, loss 0.727998, acc 0.671875, learning_rate 0.000100657
2017-09-28T16:33:20.897608: step 2182, loss 0.941151, acc 0.625, learning_rate 0.000100655
2017-09-28T16:33:20.980984: step 2183, loss 0.737052, acc 0.703125, learning_rate 0.000100652
2017-09-28T16:33:21.065725: step 2184, loss 0.815404, acc 0.734375, learning_rate 0.000100649
2017-09-28T16:33:21.146567: step 2185, loss 0.956064, acc 0.609375, learning_rate 0.000100647
2017-09-28T16:33:21.228760: step 2186, loss 0.957432, acc 0.609375, learning_rate 0.000100644
2017-09-28T16:33:21.311061: step 2187, loss 0.735618, acc 0.6875, learning_rate 0.000100641
2017-09-28T16:33:21.391644: step 2188, loss 0.802332, acc 0.65625, learning_rate 0.000100639
2017-09-28T16:33:21.476094: step 2189, loss 0.965821, acc 0.578125, learning_rate 0.000100636
2017-09-28T16:33:21.557410: step 2190, loss 0.718221, acc 0.703125, learning_rate 0.000100634
2017-09-28T16:33:21.640868: step 2191, loss 0.902991, acc 0.625, learning_rate 0.000100631
2017-09-28T16:33:21.719219: step 2192, loss 0.860182, acc 0.640625, learning_rate 0.000100628
2017-09-28T16:33:21.797921: step 2193, loss 0.809781, acc 0.65625, learning_rate 0.000100626
2017-09-28T16:33:21.879791: step 2194, loss 0.902049, acc 0.671875, learning_rate 0.000100623
2017-09-28T16:33:21.961246: step 2195, loss 0.988454, acc 0.546875, learning_rate 0.000100621
2017-09-28T16:33:22.042961: step 2196, loss 0.853266, acc 0.703125, learning_rate 0.000100618
2017-09-28T16:33:22.122366: step 2197, loss 0.814027, acc 0.609375, learning_rate 0.000100616
2017-09-28T16:33:22.210369: step 2198, loss 0.955599, acc 0.625, learning_rate 0.000100613
2017-09-28T16:33:22.295634: step 2199, loss 0.765239, acc 0.765625, learning_rate 0.000100611
2017-09-28T16:33:22.376125: step 2200, loss 0.771298, acc 0.765625, learning_rate 0.000100608

Evaluation:
2017-09-28T16:33:22.651123: step 2200, loss 0.84821, acc 0.660432

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-2200

2017-09-28T16:33:23.208038: step 2201, loss 0.710837, acc 0.734375, learning_rate 0.000100606
2017-09-28T16:33:23.294827: step 2202, loss 0.907176, acc 0.59375, learning_rate 0.000100603
2017-09-28T16:33:23.372499: step 2203, loss 0.842554, acc 0.671875, learning_rate 0.000100601
2017-09-28T16:33:23.454696: step 2204, loss 0.803922, acc 0.6875, learning_rate 0.000100598
2017-09-28T16:33:23.534337: step 2205, loss 0.828039, acc 0.578125, learning_rate 0.000100596
2017-09-28T16:33:23.615721: step 2206, loss 0.713657, acc 0.703125, learning_rate 0.000100594
2017-09-28T16:33:23.696906: step 2207, loss 0.852442, acc 0.6875, learning_rate 0.000100591
2017-09-28T16:33:23.780371: step 2208, loss 0.751415, acc 0.6875, learning_rate 0.000100589
2017-09-28T16:33:23.859859: step 2209, loss 0.809324, acc 0.71875, learning_rate 0.000100586
2017-09-28T16:33:23.939670: step 2210, loss 0.851263, acc 0.625, learning_rate 0.000100584
2017-09-28T16:33:24.022147: step 2211, loss 0.886568, acc 0.59375, learning_rate 0.000100581
2017-09-28T16:33:24.102563: step 2212, loss 0.705693, acc 0.734375, learning_rate 0.000100579
2017-09-28T16:33:24.185985: step 2213, loss 0.884438, acc 0.65625, learning_rate 0.000100577
2017-09-28T16:33:24.266737: step 2214, loss 0.72285, acc 0.703125, learning_rate 0.000100574
2017-09-28T16:33:24.349834: step 2215, loss 0.662249, acc 0.71875, learning_rate 0.000100572
2017-09-28T16:33:24.433941: step 2216, loss 0.809846, acc 0.625, learning_rate 0.00010057
2017-09-28T16:33:24.516918: step 2217, loss 0.720232, acc 0.71875, learning_rate 0.000100567
2017-09-28T16:33:24.601591: step 2218, loss 0.94033, acc 0.59375, learning_rate 0.000100565
2017-09-28T16:33:24.682052: step 2219, loss 0.779048, acc 0.703125, learning_rate 0.000100563
2017-09-28T16:33:24.765692: step 2220, loss 0.830092, acc 0.625, learning_rate 0.00010056
2017-09-28T16:33:24.848084: step 2221, loss 0.881871, acc 0.625, learning_rate 0.000100558
2017-09-28T16:33:24.931044: step 2222, loss 0.912294, acc 0.625, learning_rate 0.000100556
2017-09-28T16:33:25.017714: step 2223, loss 0.840546, acc 0.640625, learning_rate 0.000100554
2017-09-28T16:33:25.100671: step 2224, loss 0.848103, acc 0.6875, learning_rate 0.000100551
2017-09-28T16:33:25.184256: step 2225, loss 0.900516, acc 0.609375, learning_rate 0.000100549
2017-09-28T16:33:25.264845: step 2226, loss 0.822856, acc 0.625, learning_rate 0.000100547
2017-09-28T16:33:25.345772: step 2227, loss 0.861756, acc 0.703125, learning_rate 0.000100545
2017-09-28T16:33:25.428353: step 2228, loss 0.718526, acc 0.6875, learning_rate 0.000100542
2017-09-28T16:33:25.507389: step 2229, loss 0.699977, acc 0.734375, learning_rate 0.00010054
2017-09-28T16:33:25.587305: step 2230, loss 0.901698, acc 0.609375, learning_rate 0.000100538
2017-09-28T16:33:25.667859: step 2231, loss 0.771562, acc 0.703125, learning_rate 0.000100536
2017-09-28T16:33:25.748278: step 2232, loss 0.845381, acc 0.6875, learning_rate 0.000100534
2017-09-28T16:33:25.829884: step 2233, loss 0.874408, acc 0.6875, learning_rate 0.000100531
2017-09-28T16:33:25.913546: step 2234, loss 0.95256, acc 0.671875, learning_rate 0.000100529
2017-09-28T16:33:25.997633: step 2235, loss 0.888469, acc 0.640625, learning_rate 0.000100527
2017-09-28T16:33:26.077927: step 2236, loss 0.854063, acc 0.671875, learning_rate 0.000100525
2017-09-28T16:33:26.160752: step 2237, loss 0.745862, acc 0.6875, learning_rate 0.000100523
2017-09-28T16:33:26.241975: step 2238, loss 0.879323, acc 0.671875, learning_rate 0.000100521
2017-09-28T16:33:26.321097: step 2239, loss 0.935629, acc 0.671875, learning_rate 0.000100519
2017-09-28T16:33:26.404096: step 2240, loss 0.89818, acc 0.640625, learning_rate 0.000100516

Evaluation:
2017-09-28T16:33:26.681875: step 2240, loss 0.84779, acc 0.660432

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-2240

2017-09-28T16:33:27.241677: step 2241, loss 0.885367, acc 0.609375, learning_rate 0.000100514
2017-09-28T16:33:27.325719: step 2242, loss 0.929445, acc 0.59375, learning_rate 0.000100512
2017-09-28T16:33:27.409693: step 2243, loss 0.895297, acc 0.609375, learning_rate 0.00010051
2017-09-28T16:33:27.491445: step 2244, loss 0.793971, acc 0.703125, learning_rate 0.000100508
2017-09-28T16:33:27.575033: step 2245, loss 0.65279, acc 0.796875, learning_rate 0.000100506
2017-09-28T16:33:27.655662: step 2246, loss 0.852612, acc 0.65625, learning_rate 0.000100504
2017-09-28T16:33:27.736739: step 2247, loss 0.933942, acc 0.625, learning_rate 0.000100502
2017-09-28T16:33:27.818694: step 2248, loss 0.591412, acc 0.8125, learning_rate 0.0001005
2017-09-28T16:33:27.897748: step 2249, loss 0.856878, acc 0.71875, learning_rate 0.000100498
2017-09-28T16:33:27.979062: step 2250, loss 0.743569, acc 0.734375, learning_rate 0.000100496
2017-09-28T16:33:28.060840: step 2251, loss 0.814964, acc 0.703125, learning_rate 0.000100494
2017-09-28T16:33:28.141672: step 2252, loss 0.738722, acc 0.71875, learning_rate 0.000100492
2017-09-28T16:33:28.222890: step 2253, loss 0.758483, acc 0.71875, learning_rate 0.00010049
2017-09-28T16:33:28.287154: step 2254, loss 0.687003, acc 0.705882, learning_rate 0.000100488
2017-09-28T16:33:28.370532: step 2255, loss 0.954655, acc 0.59375, learning_rate 0.000100486
2017-09-28T16:33:28.450971: step 2256, loss 0.868107, acc 0.6875, learning_rate 0.000100484
2017-09-28T16:33:28.532740: step 2257, loss 0.960575, acc 0.5625, learning_rate 0.000100482
2017-09-28T16:33:28.616118: step 2258, loss 0.787947, acc 0.734375, learning_rate 0.00010048
2017-09-28T16:33:28.696236: step 2259, loss 0.640876, acc 0.796875, learning_rate 0.000100478
2017-09-28T16:33:28.778309: step 2260, loss 0.721688, acc 0.734375, learning_rate 0.000100476
2017-09-28T16:33:28.860009: step 2261, loss 0.802773, acc 0.75, learning_rate 0.000100474
2017-09-28T16:33:28.940684: step 2262, loss 0.665832, acc 0.78125, learning_rate 0.000100472
2017-09-28T16:33:29.021394: step 2263, loss 0.813818, acc 0.734375, learning_rate 0.00010047
2017-09-28T16:33:29.103391: step 2264, loss 1.00021, acc 0.625, learning_rate 0.000100468
2017-09-28T16:33:29.185050: step 2265, loss 0.817603, acc 0.625, learning_rate 0.000100466
2017-09-28T16:33:29.264023: step 2266, loss 0.852343, acc 0.640625, learning_rate 0.000100464
2017-09-28T16:33:29.345936: step 2267, loss 0.681532, acc 0.703125, learning_rate 0.000100462
2017-09-28T16:33:29.429930: step 2268, loss 0.840982, acc 0.65625, learning_rate 0.000100461
2017-09-28T16:33:29.512503: step 2269, loss 0.763671, acc 0.71875, learning_rate 0.000100459
2017-09-28T16:33:29.592887: step 2270, loss 0.790205, acc 0.625, learning_rate 0.000100457
2017-09-28T16:33:29.673093: step 2271, loss 0.855253, acc 0.609375, learning_rate 0.000100455
2017-09-28T16:33:29.753722: step 2272, loss 0.860211, acc 0.65625, learning_rate 0.000100453
2017-09-28T16:33:29.835985: step 2273, loss 0.811969, acc 0.671875, learning_rate 0.000100451
2017-09-28T16:33:29.917880: step 2274, loss 0.7341, acc 0.75, learning_rate 0.000100449
2017-09-28T16:33:29.999726: step 2275, loss 0.690624, acc 0.765625, learning_rate 0.000100448
2017-09-28T16:33:30.081568: step 2276, loss 0.752465, acc 0.703125, learning_rate 0.000100446
2017-09-28T16:33:30.161807: step 2277, loss 1.0196, acc 0.578125, learning_rate 0.000100444
2017-09-28T16:33:30.243091: step 2278, loss 0.827284, acc 0.6875, learning_rate 0.000100442
2017-09-28T16:33:30.325325: step 2279, loss 0.974216, acc 0.59375, learning_rate 0.00010044
2017-09-28T16:33:30.408898: step 2280, loss 0.91013, acc 0.59375, learning_rate 0.000100439

Evaluation:
2017-09-28T16:33:30.685865: step 2280, loss 0.847322, acc 0.658993

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-2280

2017-09-28T16:33:31.322268: step 2281, loss 0.822027, acc 0.734375, learning_rate 0.000100437
2017-09-28T16:33:31.402688: step 2282, loss 0.851248, acc 0.65625, learning_rate 0.000100435
2017-09-28T16:33:31.482230: step 2283, loss 0.800882, acc 0.625, learning_rate 0.000100433
2017-09-28T16:33:31.566317: step 2284, loss 0.829195, acc 0.734375, learning_rate 0.000100431
2017-09-28T16:33:31.647510: step 2285, loss 0.762158, acc 0.765625, learning_rate 0.00010043
2017-09-28T16:33:31.730812: step 2286, loss 0.881814, acc 0.6875, learning_rate 0.000100428
2017-09-28T16:33:31.817255: step 2287, loss 0.805283, acc 0.609375, learning_rate 0.000100426
2017-09-28T16:33:31.900605: step 2288, loss 0.872432, acc 0.59375, learning_rate 0.000100424
2017-09-28T16:33:31.980734: step 2289, loss 0.89005, acc 0.609375, learning_rate 0.000100423
2017-09-28T16:33:32.062505: step 2290, loss 0.856874, acc 0.65625, learning_rate 0.000100421
2017-09-28T16:33:32.146691: step 2291, loss 0.870979, acc 0.59375, learning_rate 0.000100419
2017-09-28T16:33:32.230743: step 2292, loss 0.843354, acc 0.640625, learning_rate 0.000100418
2017-09-28T16:33:32.318166: step 2293, loss 0.768641, acc 0.703125, learning_rate 0.000100416
2017-09-28T16:33:32.406627: step 2294, loss 0.98838, acc 0.65625, learning_rate 0.000100414
2017-09-28T16:33:32.491349: step 2295, loss 0.866998, acc 0.65625, learning_rate 0.000100412
2017-09-28T16:33:32.574622: step 2296, loss 0.824153, acc 0.6875, learning_rate 0.000100411
2017-09-28T16:33:32.658024: step 2297, loss 0.65043, acc 0.734375, learning_rate 0.000100409
2017-09-28T16:33:32.742432: step 2298, loss 0.737843, acc 0.671875, learning_rate 0.000100407
2017-09-28T16:33:32.823016: step 2299, loss 0.900899, acc 0.625, learning_rate 0.000100406
2017-09-28T16:33:32.903555: step 2300, loss 0.773474, acc 0.703125, learning_rate 0.000100404
2017-09-28T16:33:32.982465: step 2301, loss 0.936894, acc 0.59375, learning_rate 0.000100402
2017-09-28T16:33:33.061988: step 2302, loss 0.746733, acc 0.71875, learning_rate 0.000100401
2017-09-28T16:33:33.143259: step 2303, loss 1.0314, acc 0.59375, learning_rate 0.000100399
2017-09-28T16:33:33.226277: step 2304, loss 0.914358, acc 0.625, learning_rate 0.000100398
2017-09-28T16:33:33.310342: step 2305, loss 0.909171, acc 0.65625, learning_rate 0.000100396
2017-09-28T16:33:33.391897: step 2306, loss 0.750581, acc 0.671875, learning_rate 0.000100394
2017-09-28T16:33:33.472071: step 2307, loss 0.770962, acc 0.6875, learning_rate 0.000100393
2017-09-28T16:33:33.553556: step 2308, loss 0.793715, acc 0.6875, learning_rate 0.000100391
2017-09-28T16:33:33.633727: step 2309, loss 0.92926, acc 0.59375, learning_rate 0.000100389
2017-09-28T16:33:33.717434: step 2310, loss 0.879159, acc 0.640625, learning_rate 0.000100388
2017-09-28T16:33:33.798119: step 2311, loss 0.817297, acc 0.671875, learning_rate 0.000100386
2017-09-28T16:33:33.879091: step 2312, loss 0.771699, acc 0.765625, learning_rate 0.000100385
2017-09-28T16:33:33.959346: step 2313, loss 0.682565, acc 0.75, learning_rate 0.000100383
2017-09-28T16:33:34.043725: step 2314, loss 0.874436, acc 0.6875, learning_rate 0.000100382
2017-09-28T16:33:34.126516: step 2315, loss 0.703666, acc 0.671875, learning_rate 0.00010038
2017-09-28T16:33:34.211031: step 2316, loss 0.707873, acc 0.765625, learning_rate 0.000100378
2017-09-28T16:33:34.290812: step 2317, loss 0.708367, acc 0.6875, learning_rate 0.000100377
2017-09-28T16:33:34.375865: step 2318, loss 0.647224, acc 0.78125, learning_rate 0.000100375
2017-09-28T16:33:34.460583: step 2319, loss 0.928631, acc 0.546875, learning_rate 0.000100374
2017-09-28T16:33:34.543133: step 2320, loss 0.963832, acc 0.5625, learning_rate 0.000100372

Evaluation:
2017-09-28T16:33:34.818953: step 2320, loss 0.847327, acc 0.653237

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-2320

2017-09-28T16:33:35.310190: step 2321, loss 0.890634, acc 0.671875, learning_rate 0.000100371
2017-09-28T16:33:35.392686: step 2322, loss 0.73858, acc 0.75, learning_rate 0.000100369
2017-09-28T16:33:35.477226: step 2323, loss 0.831738, acc 0.65625, learning_rate 0.000100368
2017-09-28T16:33:35.561102: step 2324, loss 0.769736, acc 0.703125, learning_rate 0.000100366
2017-09-28T16:33:35.642194: step 2325, loss 0.760986, acc 0.703125, learning_rate 0.000100365
2017-09-28T16:33:35.725296: step 2326, loss 0.861084, acc 0.625, learning_rate 0.000100363
2017-09-28T16:33:35.805519: step 2327, loss 0.798965, acc 0.703125, learning_rate 0.000100362
2017-09-28T16:33:35.886725: step 2328, loss 0.837346, acc 0.671875, learning_rate 0.00010036
2017-09-28T16:33:35.968529: step 2329, loss 0.825829, acc 0.640625, learning_rate 0.000100359
2017-09-28T16:33:36.051920: step 2330, loss 0.901761, acc 0.59375, learning_rate 0.000100357
2017-09-28T16:33:36.134204: step 2331, loss 0.87151, acc 0.640625, learning_rate 0.000100356
2017-09-28T16:33:36.218988: step 2332, loss 0.674133, acc 0.765625, learning_rate 0.000100354
2017-09-28T16:33:36.302050: step 2333, loss 0.814026, acc 0.59375, learning_rate 0.000100353
2017-09-28T16:33:36.386032: step 2334, loss 0.843919, acc 0.640625, learning_rate 0.000100352
2017-09-28T16:33:36.469108: step 2335, loss 0.934139, acc 0.578125, learning_rate 0.00010035
2017-09-28T16:33:36.551170: step 2336, loss 0.852814, acc 0.59375, learning_rate 0.000100349
2017-09-28T16:33:36.634395: step 2337, loss 0.865295, acc 0.640625, learning_rate 0.000100347
2017-09-28T16:33:36.717126: step 2338, loss 0.775177, acc 0.6875, learning_rate 0.000100346
2017-09-28T16:33:36.798284: step 2339, loss 0.86602, acc 0.6875, learning_rate 0.000100344
2017-09-28T16:33:36.878830: step 2340, loss 0.902999, acc 0.640625, learning_rate 0.000100343
2017-09-28T16:33:36.960353: step 2341, loss 0.71147, acc 0.734375, learning_rate 0.000100342
2017-09-28T16:33:37.041607: step 2342, loss 0.868544, acc 0.640625, learning_rate 0.00010034
2017-09-28T16:33:37.126125: step 2343, loss 0.736505, acc 0.6875, learning_rate 0.000100339
2017-09-28T16:33:37.208847: step 2344, loss 1.00226, acc 0.59375, learning_rate 0.000100338
2017-09-28T16:33:37.294580: step 2345, loss 0.589166, acc 0.796875, learning_rate 0.000100336
2017-09-28T16:33:37.376473: step 2346, loss 0.924325, acc 0.609375, learning_rate 0.000100335
2017-09-28T16:33:37.462651: step 2347, loss 0.905377, acc 0.625, learning_rate 0.000100333
2017-09-28T16:33:37.545106: step 2348, loss 1.01215, acc 0.53125, learning_rate 0.000100332
2017-09-28T16:33:37.628630: step 2349, loss 0.743497, acc 0.71875, learning_rate 0.000100331
2017-09-28T16:33:37.709192: step 2350, loss 0.726668, acc 0.671875, learning_rate 0.000100329
2017-09-28T16:33:37.793523: step 2351, loss 0.923232, acc 0.59375, learning_rate 0.000100328
2017-09-28T16:33:37.857852: step 2352, loss 0.783754, acc 0.745098, learning_rate 0.000100327
2017-09-28T16:33:37.941484: step 2353, loss 0.716891, acc 0.75, learning_rate 0.000100325
2017-09-28T16:33:38.025457: step 2354, loss 0.803245, acc 0.6875, learning_rate 0.000100324
2017-09-28T16:33:38.108796: step 2355, loss 0.824, acc 0.6875, learning_rate 0.000100323
2017-09-28T16:33:38.193026: step 2356, loss 0.881406, acc 0.609375, learning_rate 0.000100321
2017-09-28T16:33:38.279054: step 2357, loss 0.67934, acc 0.734375, learning_rate 0.00010032
2017-09-28T16:33:38.361782: step 2358, loss 0.961485, acc 0.578125, learning_rate 0.000100319
2017-09-28T16:33:38.444531: step 2359, loss 0.992539, acc 0.640625, learning_rate 0.000100317
2017-09-28T16:33:38.526011: step 2360, loss 0.73895, acc 0.6875, learning_rate 0.000100316

Evaluation:
2017-09-28T16:33:38.802931: step 2360, loss 0.844803, acc 0.658993

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-2360

2017-09-28T16:33:39.355037: step 2361, loss 0.8183, acc 0.578125, learning_rate 0.000100315
2017-09-28T16:33:39.438972: step 2362, loss 0.840964, acc 0.640625, learning_rate 0.000100314
2017-09-28T16:33:39.519026: step 2363, loss 0.751817, acc 0.734375, learning_rate 0.000100312
2017-09-28T16:33:39.598681: step 2364, loss 0.787564, acc 0.671875, learning_rate 0.000100311
2017-09-28T16:33:39.679878: step 2365, loss 0.864975, acc 0.734375, learning_rate 0.00010031
2017-09-28T16:33:39.762086: step 2366, loss 0.676883, acc 0.71875, learning_rate 0.000100308
2017-09-28T16:33:39.840644: step 2367, loss 0.719982, acc 0.640625, learning_rate 0.000100307
2017-09-28T16:33:39.923424: step 2368, loss 0.91815, acc 0.546875, learning_rate 0.000100306
2017-09-28T16:33:40.004886: step 2369, loss 0.712859, acc 0.71875, learning_rate 0.000100305
2017-09-28T16:33:40.085390: step 2370, loss 0.902823, acc 0.625, learning_rate 0.000100303
2017-09-28T16:33:40.165521: step 2371, loss 0.940254, acc 0.65625, learning_rate 0.000100302
2017-09-28T16:33:40.250174: step 2372, loss 0.974106, acc 0.609375, learning_rate 0.000100301
2017-09-28T16:33:40.334667: step 2373, loss 0.712974, acc 0.75, learning_rate 0.0001003
2017-09-28T16:33:40.417475: step 2374, loss 0.887881, acc 0.609375, learning_rate 0.000100299
2017-09-28T16:33:40.499069: step 2375, loss 0.732643, acc 0.6875, learning_rate 0.000100297
2017-09-28T16:33:40.580724: step 2376, loss 0.991845, acc 0.59375, learning_rate 0.000100296
2017-09-28T16:33:40.661156: step 2377, loss 0.718146, acc 0.703125, learning_rate 0.000100295
2017-09-28T16:33:40.743268: step 2378, loss 0.797301, acc 0.5625, learning_rate 0.000100294
2017-09-28T16:33:40.825921: step 2379, loss 0.682141, acc 0.75, learning_rate 0.000100292
2017-09-28T16:33:40.908634: step 2380, loss 0.627577, acc 0.78125, learning_rate 0.000100291
2017-09-28T16:33:40.988381: step 2381, loss 0.743351, acc 0.71875, learning_rate 0.00010029
2017-09-28T16:33:41.070387: step 2382, loss 0.785318, acc 0.671875, learning_rate 0.000100289
2017-09-28T16:33:41.151431: step 2383, loss 0.644308, acc 0.78125, learning_rate 0.000100288
2017-09-28T16:33:41.232230: step 2384, loss 0.880532, acc 0.625, learning_rate 0.000100287
2017-09-28T16:33:41.316264: step 2385, loss 0.996681, acc 0.59375, learning_rate 0.000100285
2017-09-28T16:33:41.396423: step 2386, loss 0.841478, acc 0.640625, learning_rate 0.000100284
2017-09-28T16:33:41.478825: step 2387, loss 0.78615, acc 0.671875, learning_rate 0.000100283
2017-09-28T16:33:41.559104: step 2388, loss 0.859879, acc 0.65625, learning_rate 0.000100282
2017-09-28T16:33:41.639676: step 2389, loss 0.876641, acc 0.625, learning_rate 0.000100281
2017-09-28T16:33:41.723381: step 2390, loss 0.91629, acc 0.640625, learning_rate 0.00010028
2017-09-28T16:33:41.803076: step 2391, loss 0.799787, acc 0.6875, learning_rate 0.000100278
2017-09-28T16:33:41.886074: step 2392, loss 0.834406, acc 0.65625, learning_rate 0.000100277
2017-09-28T16:33:41.966876: step 2393, loss 0.854076, acc 0.640625, learning_rate 0.000100276
2017-09-28T16:33:42.049650: step 2394, loss 0.876347, acc 0.625, learning_rate 0.000100275
2017-09-28T16:33:42.132583: step 2395, loss 0.749889, acc 0.703125, learning_rate 0.000100274
2017-09-28T16:33:42.214898: step 2396, loss 0.950887, acc 0.671875, learning_rate 0.000100273
2017-09-28T16:33:42.294540: step 2397, loss 0.753734, acc 0.71875, learning_rate 0.000100272
2017-09-28T16:33:42.379770: step 2398, loss 1.04135, acc 0.5625, learning_rate 0.000100271
2017-09-28T16:33:42.468368: step 2399, loss 0.869081, acc 0.71875, learning_rate 0.00010027
2017-09-28T16:33:42.552231: step 2400, loss 0.736867, acc 0.671875, learning_rate 0.000100268

Evaluation:
2017-09-28T16:33:42.822698: step 2400, loss 0.84324, acc 0.658993

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-2400

2017-09-28T16:33:43.391318: step 2401, loss 0.769677, acc 0.703125, learning_rate 0.000100267
2017-09-28T16:33:43.472717: step 2402, loss 0.886147, acc 0.609375, learning_rate 0.000100266
2017-09-28T16:33:43.551971: step 2403, loss 1.03814, acc 0.546875, learning_rate 0.000100265
2017-09-28T16:33:43.637214: step 2404, loss 0.681106, acc 0.78125, learning_rate 0.000100264
2017-09-28T16:33:43.720802: step 2405, loss 0.772403, acc 0.703125, learning_rate 0.000100263
2017-09-28T16:33:43.804043: step 2406, loss 0.896324, acc 0.640625, learning_rate 0.000100262
2017-09-28T16:33:43.886135: step 2407, loss 0.741952, acc 0.71875, learning_rate 0.000100261
2017-09-28T16:33:43.967158: step 2408, loss 0.84877, acc 0.640625, learning_rate 0.00010026
2017-09-28T16:33:44.049098: step 2409, loss 0.907134, acc 0.640625, learning_rate 0.000100259
2017-09-28T16:33:44.127952: step 2410, loss 0.707385, acc 0.703125, learning_rate 0.000100258
2017-09-28T16:33:44.211632: step 2411, loss 0.894237, acc 0.59375, learning_rate 0.000100257
2017-09-28T16:33:44.292208: step 2412, loss 0.757508, acc 0.734375, learning_rate 0.000100256
2017-09-28T16:33:44.374639: step 2413, loss 0.766944, acc 0.71875, learning_rate 0.000100255
2017-09-28T16:33:44.458185: step 2414, loss 0.822189, acc 0.671875, learning_rate 0.000100253
2017-09-28T16:33:44.542484: step 2415, loss 0.879895, acc 0.59375, learning_rate 0.000100252
2017-09-28T16:33:44.623394: step 2416, loss 0.96095, acc 0.59375, learning_rate 0.000100251
2017-09-28T16:33:44.706462: step 2417, loss 0.776091, acc 0.640625, learning_rate 0.00010025
2017-09-28T16:33:44.786616: step 2418, loss 0.672598, acc 0.796875, learning_rate 0.000100249
2017-09-28T16:33:44.869708: step 2419, loss 0.969978, acc 0.640625, learning_rate 0.000100248
2017-09-28T16:33:44.951548: step 2420, loss 0.890961, acc 0.625, learning_rate 0.000100247
2017-09-28T16:33:45.034424: step 2421, loss 0.815301, acc 0.609375, learning_rate 0.000100246
2017-09-28T16:33:45.117480: step 2422, loss 0.733723, acc 0.703125, learning_rate 0.000100245
2017-09-28T16:33:45.198757: step 2423, loss 0.873222, acc 0.640625, learning_rate 0.000100244
2017-09-28T16:33:45.281255: step 2424, loss 0.806739, acc 0.6875, learning_rate 0.000100243
2017-09-28T16:33:45.365650: step 2425, loss 0.894397, acc 0.6875, learning_rate 0.000100242
2017-09-28T16:33:45.447182: step 2426, loss 0.710321, acc 0.734375, learning_rate 0.000100241
2017-09-28T16:33:45.530030: step 2427, loss 0.784908, acc 0.703125, learning_rate 0.00010024
2017-09-28T16:33:45.615223: step 2428, loss 0.790919, acc 0.734375, learning_rate 0.000100239
2017-09-28T16:33:45.695089: step 2429, loss 0.652847, acc 0.78125, learning_rate 0.000100238
2017-09-28T16:33:45.774509: step 2430, loss 0.754408, acc 0.71875, learning_rate 0.000100237
2017-09-28T16:33:45.854510: step 2431, loss 0.770221, acc 0.734375, learning_rate 0.000100236
2017-09-28T16:33:45.935768: step 2432, loss 0.753011, acc 0.65625, learning_rate 0.000100235
2017-09-28T16:33:46.018406: step 2433, loss 0.665667, acc 0.71875, learning_rate 0.000100235
2017-09-28T16:33:46.100155: step 2434, loss 1.11694, acc 0.546875, learning_rate 0.000100234
2017-09-28T16:33:46.180339: step 2435, loss 0.809635, acc 0.703125, learning_rate 0.000100233
2017-09-28T16:33:46.261676: step 2436, loss 0.92537, acc 0.609375, learning_rate 0.000100232
2017-09-28T16:33:46.344146: step 2437, loss 0.867819, acc 0.640625, learning_rate 0.000100231
2017-09-28T16:33:46.425914: step 2438, loss 0.749285, acc 0.6875, learning_rate 0.00010023
2017-09-28T16:33:46.505583: step 2439, loss 0.965532, acc 0.59375, learning_rate 0.000100229
2017-09-28T16:33:46.587234: step 2440, loss 1.03118, acc 0.578125, learning_rate 0.000100228

Evaluation:
2017-09-28T16:33:46.859186: step 2440, loss 0.843313, acc 0.663309

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-2440

2017-09-28T16:33:47.492900: step 2441, loss 0.742981, acc 0.65625, learning_rate 0.000100227
2017-09-28T16:33:47.576491: step 2442, loss 0.828324, acc 0.671875, learning_rate 0.000100226
2017-09-28T16:33:47.656254: step 2443, loss 1.02033, acc 0.609375, learning_rate 0.000100225
2017-09-28T16:33:47.737462: step 2444, loss 0.805748, acc 0.65625, learning_rate 0.000100224
2017-09-28T16:33:47.819927: step 2445, loss 0.930643, acc 0.671875, learning_rate 0.000100223
2017-09-28T16:33:47.902522: step 2446, loss 0.765526, acc 0.703125, learning_rate 0.000100222
2017-09-28T16:33:47.982853: step 2447, loss 0.799596, acc 0.671875, learning_rate 0.000100221
2017-09-28T16:33:48.064303: step 2448, loss 0.753009, acc 0.71875, learning_rate 0.000100221
2017-09-28T16:33:48.148591: step 2449, loss 0.744953, acc 0.734375, learning_rate 0.00010022
2017-09-28T16:33:48.215130: step 2450, loss 0.757525, acc 0.627451, learning_rate 0.000100219
2017-09-28T16:33:48.294374: step 2451, loss 0.708152, acc 0.6875, learning_rate 0.000100218
2017-09-28T16:33:48.373651: step 2452, loss 0.741895, acc 0.703125, learning_rate 0.000100217
2017-09-28T16:33:48.453307: step 2453, loss 0.774266, acc 0.6875, learning_rate 0.000100216
2017-09-28T16:33:48.536032: step 2454, loss 0.800891, acc 0.734375, learning_rate 0.000100215
2017-09-28T16:33:48.618022: step 2455, loss 0.76129, acc 0.671875, learning_rate 0.000100214
2017-09-28T16:33:48.700622: step 2456, loss 0.871685, acc 0.578125, learning_rate 0.000100213
2017-09-28T16:33:48.779290: step 2457, loss 0.914672, acc 0.53125, learning_rate 0.000100213
2017-09-28T16:33:48.862199: step 2458, loss 0.706975, acc 0.734375, learning_rate 0.000100212
2017-09-28T16:33:48.941403: step 2459, loss 0.748436, acc 0.671875, learning_rate 0.000100211
2017-09-28T16:33:49.022360: step 2460, loss 0.711821, acc 0.703125, learning_rate 0.00010021
2017-09-28T16:33:49.105134: step 2461, loss 0.953177, acc 0.546875, learning_rate 0.000100209
2017-09-28T16:33:49.188055: step 2462, loss 0.878825, acc 0.6875, learning_rate 0.000100208
2017-09-28T16:33:49.271022: step 2463, loss 0.672603, acc 0.75, learning_rate 0.000100207
2017-09-28T16:33:49.351551: step 2464, loss 0.873901, acc 0.640625, learning_rate 0.000100207
2017-09-28T16:33:49.432292: step 2465, loss 0.754766, acc 0.671875, learning_rate 0.000100206
2017-09-28T16:33:49.512952: step 2466, loss 0.812381, acc 0.6875, learning_rate 0.000100205
2017-09-28T16:33:49.597187: step 2467, loss 1.1016, acc 0.609375, learning_rate 0.000100204
2017-09-28T16:33:49.679845: step 2468, loss 0.649887, acc 0.75, learning_rate 0.000100203
2017-09-28T16:33:49.764281: step 2469, loss 0.775096, acc 0.671875, learning_rate 0.000100202
2017-09-28T16:33:49.847619: step 2470, loss 0.803533, acc 0.6875, learning_rate 0.000100202
2017-09-28T16:33:49.928559: step 2471, loss 0.842858, acc 0.640625, learning_rate 0.000100201
2017-09-28T16:33:50.011657: step 2472, loss 0.686817, acc 0.75, learning_rate 0.0001002
2017-09-28T16:33:50.094371: step 2473, loss 0.797079, acc 0.6875, learning_rate 0.000100199
2017-09-28T16:33:50.175664: step 2474, loss 0.876948, acc 0.609375, learning_rate 0.000100198
2017-09-28T16:33:50.257664: step 2475, loss 1.12684, acc 0.625, learning_rate 0.000100198
2017-09-28T16:33:50.340889: step 2476, loss 0.706941, acc 0.703125, learning_rate 0.000100197
2017-09-28T16:33:50.425945: step 2477, loss 0.707184, acc 0.78125, learning_rate 0.000100196
2017-09-28T16:33:50.505978: step 2478, loss 0.967142, acc 0.59375, learning_rate 0.000100195
2017-09-28T16:33:50.587510: step 2479, loss 0.805384, acc 0.6875, learning_rate 0.000100194
2017-09-28T16:33:50.667514: step 2480, loss 0.745147, acc 0.703125, learning_rate 0.000100194

Evaluation:
2017-09-28T16:33:50.948694: step 2480, loss 0.842062, acc 0.660432

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-2480

2017-09-28T16:33:51.446151: step 2481, loss 0.779061, acc 0.65625, learning_rate 0.000100193
2017-09-28T16:33:51.530092: step 2482, loss 0.733385, acc 0.75, learning_rate 0.000100192
2017-09-28T16:33:51.613344: step 2483, loss 0.730879, acc 0.703125, learning_rate 0.000100191
2017-09-28T16:33:51.694727: step 2484, loss 0.911619, acc 0.71875, learning_rate 0.00010019
2017-09-28T16:33:51.775754: step 2485, loss 0.748916, acc 0.734375, learning_rate 0.00010019
2017-09-28T16:33:51.859017: step 2486, loss 0.814505, acc 0.703125, learning_rate 0.000100189
2017-09-28T16:33:51.940255: step 2487, loss 0.848745, acc 0.609375, learning_rate 0.000100188
2017-09-28T16:33:52.022844: step 2488, loss 0.824252, acc 0.625, learning_rate 0.000100187
2017-09-28T16:33:52.105894: step 2489, loss 0.634865, acc 0.765625, learning_rate 0.000100187
2017-09-28T16:33:52.190098: step 2490, loss 0.723125, acc 0.6875, learning_rate 0.000100186
2017-09-28T16:33:52.271043: step 2491, loss 0.735759, acc 0.71875, learning_rate 0.000100185
2017-09-28T16:33:52.356180: step 2492, loss 0.731449, acc 0.703125, learning_rate 0.000100184
2017-09-28T16:33:52.441527: step 2493, loss 0.785957, acc 0.671875, learning_rate 0.000100183
2017-09-28T16:33:52.531425: step 2494, loss 0.914798, acc 0.59375, learning_rate 0.000100183
2017-09-28T16:33:52.614980: step 2495, loss 0.954443, acc 0.609375, learning_rate 0.000100182
2017-09-28T16:33:52.701124: step 2496, loss 0.746883, acc 0.6875, learning_rate 0.000100181
2017-09-28T16:33:52.785242: step 2497, loss 0.861948, acc 0.65625, learning_rate 0.000100181
2017-09-28T16:33:52.871726: step 2498, loss 0.612773, acc 0.765625, learning_rate 0.00010018
2017-09-28T16:33:52.954915: step 2499, loss 0.821768, acc 0.65625, learning_rate 0.000100179
2017-09-28T16:33:53.038869: step 2500, loss 0.784115, acc 0.6875, learning_rate 0.000100178
2017-09-28T16:33:53.120614: step 2501, loss 0.838966, acc 0.703125, learning_rate 0.000100178
2017-09-28T16:33:53.201398: step 2502, loss 0.849411, acc 0.640625, learning_rate 0.000100177
2017-09-28T16:33:53.284428: step 2503, loss 0.770993, acc 0.703125, learning_rate 0.000100176
2017-09-28T16:33:53.366923: step 2504, loss 0.727677, acc 0.65625, learning_rate 0.000100175
2017-09-28T16:33:53.451913: step 2505, loss 0.830464, acc 0.671875, learning_rate 0.000100175
2017-09-28T16:33:53.534618: step 2506, loss 0.957434, acc 0.609375, learning_rate 0.000100174
2017-09-28T16:33:53.613609: step 2507, loss 0.816923, acc 0.75, learning_rate 0.000100173
2017-09-28T16:33:53.697127: step 2508, loss 1.0203, acc 0.578125, learning_rate 0.000100173
2017-09-28T16:33:53.778282: step 2509, loss 0.859684, acc 0.640625, learning_rate 0.000100172
2017-09-28T16:33:53.860670: step 2510, loss 0.752593, acc 0.6875, learning_rate 0.000100171
2017-09-28T16:33:53.945883: step 2511, loss 0.788536, acc 0.65625, learning_rate 0.00010017
2017-09-28T16:33:54.027657: step 2512, loss 0.832864, acc 0.640625, learning_rate 0.00010017
2017-09-28T16:33:54.111146: step 2513, loss 0.981546, acc 0.59375, learning_rate 0.000100169
2017-09-28T16:33:54.193878: step 2514, loss 0.699003, acc 0.71875, learning_rate 0.000100168
2017-09-28T16:33:54.276362: step 2515, loss 0.887893, acc 0.65625, learning_rate 0.000100168
2017-09-28T16:33:54.357575: step 2516, loss 0.857405, acc 0.59375, learning_rate 0.000100167
2017-09-28T16:33:54.437326: step 2517, loss 0.962853, acc 0.5625, learning_rate 0.000100166
2017-09-28T16:33:54.523161: step 2518, loss 0.89344, acc 0.65625, learning_rate 0.000100166
2017-09-28T16:33:54.603203: step 2519, loss 0.808756, acc 0.640625, learning_rate 0.000100165
2017-09-28T16:33:54.688038: step 2520, loss 0.744555, acc 0.75, learning_rate 0.000100164

Evaluation:
2017-09-28T16:33:54.972938: step 2520, loss 0.84069, acc 0.66187

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-2520

2017-09-28T16:33:55.545806: step 2521, loss 0.741125, acc 0.671875, learning_rate 0.000100164
2017-09-28T16:33:55.630666: step 2522, loss 0.865731, acc 0.59375, learning_rate 0.000100163
2017-09-28T16:33:55.716694: step 2523, loss 0.605609, acc 0.796875, learning_rate 0.000100162
2017-09-28T16:33:55.798413: step 2524, loss 0.823164, acc 0.6875, learning_rate 0.000100162
2017-09-28T16:33:55.876503: step 2525, loss 0.69663, acc 0.703125, learning_rate 0.000100161
2017-09-28T16:33:55.958389: step 2526, loss 0.96611, acc 0.609375, learning_rate 0.00010016
2017-09-28T16:33:56.036799: step 2527, loss 0.839285, acc 0.71875, learning_rate 0.00010016
2017-09-28T16:33:56.119858: step 2528, loss 0.747315, acc 0.765625, learning_rate 0.000100159
2017-09-28T16:33:56.203219: step 2529, loss 0.789335, acc 0.640625, learning_rate 0.000100158
2017-09-28T16:33:56.283932: step 2530, loss 0.776221, acc 0.671875, learning_rate 0.000100158
2017-09-28T16:33:56.364754: step 2531, loss 0.874617, acc 0.671875, learning_rate 0.000100157
2017-09-28T16:33:56.446979: step 2532, loss 0.834008, acc 0.65625, learning_rate 0.000100156
2017-09-28T16:33:56.529337: step 2533, loss 0.824185, acc 0.640625, learning_rate 0.000100156
2017-09-28T16:33:56.612293: step 2534, loss 0.94677, acc 0.640625, learning_rate 0.000100155
2017-09-28T16:33:56.694502: step 2535, loss 0.844439, acc 0.6875, learning_rate 0.000100155
2017-09-28T16:33:56.777406: step 2536, loss 0.90753, acc 0.65625, learning_rate 0.000100154
2017-09-28T16:33:56.857981: step 2537, loss 0.726, acc 0.671875, learning_rate 0.000100153
2017-09-28T16:33:56.939145: step 2538, loss 0.834423, acc 0.640625, learning_rate 0.000100153
2017-09-28T16:33:57.021581: step 2539, loss 0.949674, acc 0.578125, learning_rate 0.000100152
2017-09-28T16:33:57.103494: step 2540, loss 0.899552, acc 0.609375, learning_rate 0.000100151
2017-09-28T16:33:57.185795: step 2541, loss 0.952518, acc 0.625, learning_rate 0.000100151
2017-09-28T16:33:57.271539: step 2542, loss 0.985999, acc 0.578125, learning_rate 0.00010015
2017-09-28T16:33:57.356298: step 2543, loss 0.75647, acc 0.671875, learning_rate 0.00010015
2017-09-28T16:33:57.441143: step 2544, loss 1.10039, acc 0.59375, learning_rate 0.000100149
2017-09-28T16:33:57.524599: step 2545, loss 0.810298, acc 0.65625, learning_rate 0.000100148
2017-09-28T16:33:57.614137: step 2546, loss 1.0163, acc 0.515625, learning_rate 0.000100148
2017-09-28T16:33:57.695599: step 2547, loss 0.844012, acc 0.65625, learning_rate 0.000100147
2017-09-28T16:33:57.759867: step 2548, loss 0.777184, acc 0.705882, learning_rate 0.000100147
2017-09-28T16:33:57.841716: step 2549, loss 0.722878, acc 0.765625, learning_rate 0.000100146
2017-09-28T16:33:57.923196: step 2550, loss 0.715872, acc 0.703125, learning_rate 0.000100145
2017-09-28T16:33:58.008145: step 2551, loss 0.691314, acc 0.765625, learning_rate 0.000100145
2017-09-28T16:33:58.089109: step 2552, loss 0.841436, acc 0.640625, learning_rate 0.000100144
2017-09-28T16:33:58.171293: step 2553, loss 0.871433, acc 0.671875, learning_rate 0.000100144
2017-09-28T16:33:58.250487: step 2554, loss 0.891514, acc 0.703125, learning_rate 0.000100143
2017-09-28T16:33:58.334461: step 2555, loss 0.604982, acc 0.765625, learning_rate 0.000100142
2017-09-28T16:33:58.415161: step 2556, loss 0.751557, acc 0.734375, learning_rate 0.000100142
2017-09-28T16:33:58.494657: step 2557, loss 0.756036, acc 0.71875, learning_rate 0.000100141
2017-09-28T16:33:58.575749: step 2558, loss 0.790696, acc 0.703125, learning_rate 0.000100141
2017-09-28T16:33:58.659696: step 2559, loss 1.04999, acc 0.53125, learning_rate 0.00010014
2017-09-28T16:33:58.745299: step 2560, loss 0.843172, acc 0.671875, learning_rate 0.00010014

Evaluation:
2017-09-28T16:33:59.021216: step 2560, loss 0.840495, acc 0.657554

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-2560

2017-09-28T16:33:59.573261: step 2561, loss 0.796183, acc 0.65625, learning_rate 0.000100139
2017-09-28T16:33:59.655737: step 2562, loss 0.86842, acc 0.671875, learning_rate 0.000100138
2017-09-28T16:33:59.738213: step 2563, loss 0.865419, acc 0.65625, learning_rate 0.000100138
2017-09-28T16:33:59.821690: step 2564, loss 0.609446, acc 0.75, learning_rate 0.000100137
2017-09-28T16:33:59.902241: step 2565, loss 0.821764, acc 0.671875, learning_rate 0.000100137
2017-09-28T16:33:59.983505: step 2566, loss 0.848446, acc 0.6875, learning_rate 0.000100136
2017-09-28T16:34:00.067337: step 2567, loss 0.969353, acc 0.59375, learning_rate 0.000100136
2017-09-28T16:34:00.147555: step 2568, loss 0.902463, acc 0.671875, learning_rate 0.000100135
2017-09-28T16:34:00.230360: step 2569, loss 0.931753, acc 0.546875, learning_rate 0.000100134
2017-09-28T16:34:00.312404: step 2570, loss 0.734635, acc 0.65625, learning_rate 0.000100134
2017-09-28T16:34:00.396760: step 2571, loss 0.785961, acc 0.6875, learning_rate 0.000100133
2017-09-28T16:34:00.478181: step 2572, loss 0.629345, acc 0.703125, learning_rate 0.000100133
2017-09-28T16:34:00.558829: step 2573, loss 0.676627, acc 0.734375, learning_rate 0.000100132
2017-09-28T16:34:00.640261: step 2574, loss 0.72312, acc 0.734375, learning_rate 0.000100132
2017-09-28T16:34:00.719770: step 2575, loss 0.931296, acc 0.59375, learning_rate 0.000100131
2017-09-28T16:34:00.800439: step 2576, loss 0.735042, acc 0.703125, learning_rate 0.000100131
2017-09-28T16:34:00.880776: step 2577, loss 0.850341, acc 0.65625, learning_rate 0.00010013
2017-09-28T16:34:00.962938: step 2578, loss 0.820398, acc 0.671875, learning_rate 0.00010013
2017-09-28T16:34:01.044622: step 2579, loss 0.749623, acc 0.703125, learning_rate 0.000100129
2017-09-28T16:34:01.128215: step 2580, loss 0.83985, acc 0.640625, learning_rate 0.000100129
2017-09-28T16:34:01.208715: step 2581, loss 0.741012, acc 0.71875, learning_rate 0.000100128
2017-09-28T16:34:01.290639: step 2582, loss 0.897269, acc 0.6875, learning_rate 0.000100128
2017-09-28T16:34:01.371148: step 2583, loss 0.751107, acc 0.75, learning_rate 0.000100127
2017-09-28T16:34:01.454336: step 2584, loss 0.912629, acc 0.640625, learning_rate 0.000100126
2017-09-28T16:34:01.536657: step 2585, loss 0.784167, acc 0.703125, learning_rate 0.000100126
2017-09-28T16:34:01.617139: step 2586, loss 0.72704, acc 0.71875, learning_rate 0.000100125
2017-09-28T16:34:01.699573: step 2587, loss 0.752195, acc 0.734375, learning_rate 0.000100125
2017-09-28T16:34:01.779022: step 2588, loss 0.668341, acc 0.75, learning_rate 0.000100124
2017-09-28T16:34:01.859011: step 2589, loss 1.02688, acc 0.609375, learning_rate 0.000100124
2017-09-28T16:34:01.940102: step 2590, loss 0.87244, acc 0.671875, learning_rate 0.000100123
2017-09-28T16:34:02.019556: step 2591, loss 0.900006, acc 0.609375, learning_rate 0.000100123
2017-09-28T16:34:02.100042: step 2592, loss 0.787238, acc 0.671875, learning_rate 0.000100122
2017-09-28T16:34:02.184497: step 2593, loss 0.985609, acc 0.609375, learning_rate 0.000100122
2017-09-28T16:34:02.267101: step 2594, loss 0.937005, acc 0.640625, learning_rate 0.000100121
2017-09-28T16:34:02.345660: step 2595, loss 0.67072, acc 0.765625, learning_rate 0.000100121
2017-09-28T16:34:02.430628: step 2596, loss 0.862915, acc 0.625, learning_rate 0.00010012
2017-09-28T16:34:02.516625: step 2597, loss 0.776977, acc 0.671875, learning_rate 0.00010012
2017-09-28T16:34:02.603063: step 2598, loss 0.934385, acc 0.609375, learning_rate 0.000100119
2017-09-28T16:34:02.688115: step 2599, loss 0.909538, acc 0.609375, learning_rate 0.000100119
2017-09-28T16:34:02.769494: step 2600, loss 0.894835, acc 0.640625, learning_rate 0.000100118

Evaluation:
2017-09-28T16:34:03.046204: step 2600, loss 0.839518, acc 0.658993

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-2600

2017-09-28T16:34:03.682316: step 2601, loss 0.822114, acc 0.609375, learning_rate 0.000100118
2017-09-28T16:34:03.766077: step 2602, loss 0.899974, acc 0.640625, learning_rate 0.000100117
2017-09-28T16:34:03.851909: step 2603, loss 0.814454, acc 0.640625, learning_rate 0.000100117
2017-09-28T16:34:03.935571: step 2604, loss 0.793675, acc 0.671875, learning_rate 0.000100117
2017-09-28T16:34:04.016488: step 2605, loss 0.759795, acc 0.71875, learning_rate 0.000100116
2017-09-28T16:34:04.099372: step 2606, loss 0.700079, acc 0.71875, learning_rate 0.000100116
2017-09-28T16:34:04.180837: step 2607, loss 0.704508, acc 0.703125, learning_rate 0.000100115
2017-09-28T16:34:04.263202: step 2608, loss 0.626345, acc 0.71875, learning_rate 0.000100115
2017-09-28T16:34:04.342704: step 2609, loss 0.934611, acc 0.546875, learning_rate 0.000100114
2017-09-28T16:34:04.426459: step 2610, loss 0.80368, acc 0.6875, learning_rate 0.000100114
2017-09-28T16:34:04.515849: step 2611, loss 0.803583, acc 0.671875, learning_rate 0.000100113
2017-09-28T16:34:04.594723: step 2612, loss 0.620771, acc 0.734375, learning_rate 0.000100113
2017-09-28T16:34:04.676377: step 2613, loss 0.888328, acc 0.609375, learning_rate 0.000100112
2017-09-28T16:34:04.755667: step 2614, loss 0.919222, acc 0.5625, learning_rate 0.000100112
2017-09-28T16:34:04.835077: step 2615, loss 1.05788, acc 0.46875, learning_rate 0.000100111
2017-09-28T16:34:04.916536: step 2616, loss 0.852948, acc 0.640625, learning_rate 0.000100111
2017-09-28T16:34:04.998380: step 2617, loss 0.936844, acc 0.65625, learning_rate 0.000100111
2017-09-28T16:34:05.077830: step 2618, loss 0.77107, acc 0.65625, learning_rate 0.00010011
2017-09-28T16:34:05.157523: step 2619, loss 0.763674, acc 0.671875, learning_rate 0.00010011
2017-09-28T16:34:05.242393: step 2620, loss 0.780696, acc 0.640625, learning_rate 0.000100109
2017-09-28T16:34:05.322733: step 2621, loss 0.821772, acc 0.671875, learning_rate 0.000100109
2017-09-28T16:34:05.406098: step 2622, loss 0.924697, acc 0.65625, learning_rate 0.000100108
2017-09-28T16:34:05.485259: step 2623, loss 0.799359, acc 0.671875, learning_rate 0.000100108
2017-09-28T16:34:05.562905: step 2624, loss 0.883789, acc 0.640625, learning_rate 0.000100107
2017-09-28T16:34:05.643273: step 2625, loss 0.746609, acc 0.703125, learning_rate 0.000100107
2017-09-28T16:34:05.722050: step 2626, loss 0.728922, acc 0.703125, learning_rate 0.000100107
2017-09-28T16:34:05.803157: step 2627, loss 0.687006, acc 0.78125, learning_rate 0.000100106
2017-09-28T16:34:05.884007: step 2628, loss 0.881536, acc 0.65625, learning_rate 0.000100106
2017-09-28T16:34:05.965530: step 2629, loss 0.794052, acc 0.734375, learning_rate 0.000100105
2017-09-28T16:34:06.050593: step 2630, loss 0.787068, acc 0.65625, learning_rate 0.000100105
2017-09-28T16:34:06.128605: step 2631, loss 0.918818, acc 0.609375, learning_rate 0.000100104
2017-09-28T16:34:06.208764: step 2632, loss 0.793815, acc 0.6875, learning_rate 0.000100104
2017-09-28T16:34:06.291404: step 2633, loss 0.827882, acc 0.671875, learning_rate 0.000100104
2017-09-28T16:34:06.370927: step 2634, loss 0.83817, acc 0.671875, learning_rate 0.000100103
2017-09-28T16:34:06.454592: step 2635, loss 0.828782, acc 0.640625, learning_rate 0.000100103
2017-09-28T16:34:06.537329: step 2636, loss 0.792336, acc 0.65625, learning_rate 0.000100102
2017-09-28T16:34:06.618389: step 2637, loss 0.867372, acc 0.609375, learning_rate 0.000100102
2017-09-28T16:34:06.699898: step 2638, loss 0.736079, acc 0.734375, learning_rate 0.000100101
2017-09-28T16:34:06.781813: step 2639, loss 0.728383, acc 0.75, learning_rate 0.000100101
2017-09-28T16:34:06.864373: step 2640, loss 0.937866, acc 0.625, learning_rate 0.000100101

Evaluation:
2017-09-28T16:34:07.131203: step 2640, loss 0.836874, acc 0.663309

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-2640

2017-09-28T16:34:07.634045: step 2641, loss 0.820496, acc 0.671875, learning_rate 0.0001001
2017-09-28T16:34:07.716707: step 2642, loss 0.760416, acc 0.65625, learning_rate 0.0001001
2017-09-28T16:34:07.796364: step 2643, loss 0.97873, acc 0.609375, learning_rate 0.000100099
2017-09-28T16:34:07.879644: step 2644, loss 0.872528, acc 0.640625, learning_rate 0.000100099
2017-09-28T16:34:07.959559: step 2645, loss 0.860036, acc 0.609375, learning_rate 0.000100099
2017-09-28T16:34:08.024643: step 2646, loss 0.757222, acc 0.745098, learning_rate 0.000100098
2017-09-28T16:34:08.105773: step 2647, loss 0.924916, acc 0.59375, learning_rate 0.000100098
2017-09-28T16:34:08.187420: step 2648, loss 0.81522, acc 0.65625, learning_rate 0.000100097
2017-09-28T16:34:08.267673: step 2649, loss 0.933906, acc 0.65625, learning_rate 0.000100097
2017-09-28T16:34:08.351241: step 2650, loss 0.745007, acc 0.640625, learning_rate 0.000100097
2017-09-28T16:34:08.436190: step 2651, loss 0.808503, acc 0.640625, learning_rate 0.000100096
2017-09-28T16:34:08.521024: step 2652, loss 0.846363, acc 0.640625, learning_rate 0.000100096
2017-09-28T16:34:08.601110: step 2653, loss 0.720998, acc 0.703125, learning_rate 0.000100095
2017-09-28T16:34:08.680371: step 2654, loss 0.600441, acc 0.78125, learning_rate 0.000100095
2017-09-28T16:34:08.760233: step 2655, loss 0.899075, acc 0.65625, learning_rate 0.000100095
2017-09-28T16:34:08.841794: step 2656, loss 0.641281, acc 0.765625, learning_rate 0.000100094
2017-09-28T16:34:08.921108: step 2657, loss 0.776546, acc 0.625, learning_rate 0.000100094
2017-09-28T16:34:09.000581: step 2658, loss 0.706987, acc 0.734375, learning_rate 0.000100093
2017-09-28T16:34:09.081403: step 2659, loss 0.924109, acc 0.640625, learning_rate 0.000100093
2017-09-28T16:34:09.160299: step 2660, loss 0.775062, acc 0.65625, learning_rate 0.000100093
2017-09-28T16:34:09.242924: step 2661, loss 0.587959, acc 0.765625, learning_rate 0.000100092
2017-09-28T16:34:09.324548: step 2662, loss 0.919294, acc 0.640625, learning_rate 0.000100092
2017-09-28T16:34:09.404627: step 2663, loss 0.919549, acc 0.640625, learning_rate 0.000100092
2017-09-28T16:34:09.485449: step 2664, loss 0.905699, acc 0.703125, learning_rate 0.000100091
2017-09-28T16:34:09.565664: step 2665, loss 0.712368, acc 0.71875, learning_rate 0.000100091
2017-09-28T16:34:09.648025: step 2666, loss 0.737433, acc 0.703125, learning_rate 0.00010009
2017-09-28T16:34:09.729044: step 2667, loss 0.794806, acc 0.703125, learning_rate 0.00010009
2017-09-28T16:34:09.811025: step 2668, loss 0.888815, acc 0.625, learning_rate 0.00010009
2017-09-28T16:34:09.889423: step 2669, loss 0.976359, acc 0.53125, learning_rate 0.000100089
2017-09-28T16:34:09.972823: step 2670, loss 0.648829, acc 0.765625, learning_rate 0.000100089
2017-09-28T16:34:10.052732: step 2671, loss 0.858254, acc 0.609375, learning_rate 0.000100089
2017-09-28T16:34:10.136143: step 2672, loss 0.845544, acc 0.6875, learning_rate 0.000100088
2017-09-28T16:34:10.216217: step 2673, loss 0.697468, acc 0.734375, learning_rate 0.000100088
2017-09-28T16:34:10.299168: step 2674, loss 0.780999, acc 0.703125, learning_rate 0.000100088
2017-09-28T16:34:10.378755: step 2675, loss 0.87575, acc 0.609375, learning_rate 0.000100087
2017-09-28T16:34:10.461084: step 2676, loss 0.923747, acc 0.65625, learning_rate 0.000100087
2017-09-28T16:34:10.543797: step 2677, loss 0.958183, acc 0.609375, learning_rate 0.000100086
2017-09-28T16:34:10.623772: step 2678, loss 0.82141, acc 0.734375, learning_rate 0.000100086
2017-09-28T16:34:10.702725: step 2679, loss 0.790541, acc 0.625, learning_rate 0.000100086
2017-09-28T16:34:10.786223: step 2680, loss 0.786658, acc 0.703125, learning_rate 0.000100085

Evaluation:
2017-09-28T16:34:11.058256: step 2680, loss 0.837484, acc 0.660432

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-2680

2017-09-28T16:34:11.624936: step 2681, loss 0.761247, acc 0.703125, learning_rate 0.000100085
2017-09-28T16:34:11.706501: step 2682, loss 0.667831, acc 0.765625, learning_rate 0.000100085
2017-09-28T16:34:11.788742: step 2683, loss 0.660233, acc 0.734375, learning_rate 0.000100084
2017-09-28T16:34:11.870953: step 2684, loss 0.816239, acc 0.65625, learning_rate 0.000100084
2017-09-28T16:34:11.953183: step 2685, loss 0.748558, acc 0.703125, learning_rate 0.000100084
2017-09-28T16:34:12.035082: step 2686, loss 0.681322, acc 0.796875, learning_rate 0.000100083
2017-09-28T16:34:12.115428: step 2687, loss 0.744591, acc 0.71875, learning_rate 0.000100083
2017-09-28T16:34:12.197461: step 2688, loss 0.652789, acc 0.765625, learning_rate 0.000100083
2017-09-28T16:34:12.279835: step 2689, loss 0.83354, acc 0.71875, learning_rate 0.000100082
2017-09-28T16:34:12.357951: step 2690, loss 0.909321, acc 0.578125, learning_rate 0.000100082
2017-09-28T16:34:12.438361: step 2691, loss 0.760221, acc 0.671875, learning_rate 0.000100082
2017-09-28T16:34:12.524268: step 2692, loss 1.0125, acc 0.59375, learning_rate 0.000100081
2017-09-28T16:34:12.603015: step 2693, loss 0.65291, acc 0.75, learning_rate 0.000100081
2017-09-28T16:34:12.690120: step 2694, loss 0.782717, acc 0.703125, learning_rate 0.000100081
2017-09-28T16:34:12.776038: step 2695, loss 0.931036, acc 0.59375, learning_rate 0.00010008
2017-09-28T16:34:12.859375: step 2696, loss 0.735474, acc 0.765625, learning_rate 0.00010008
2017-09-28T16:34:12.938931: step 2697, loss 0.847993, acc 0.625, learning_rate 0.00010008
2017-09-28T16:34:13.019368: step 2698, loss 0.923613, acc 0.578125, learning_rate 0.000100079
2017-09-28T16:34:13.102574: step 2699, loss 0.679913, acc 0.71875, learning_rate 0.000100079
2017-09-28T16:34:13.182285: step 2700, loss 0.800423, acc 0.6875, learning_rate 0.000100079
2017-09-28T16:34:13.266570: step 2701, loss 0.895348, acc 0.671875, learning_rate 0.000100078
2017-09-28T16:34:13.350761: step 2702, loss 0.907571, acc 0.578125, learning_rate 0.000100078
2017-09-28T16:34:13.433355: step 2703, loss 0.798516, acc 0.640625, learning_rate 0.000100078
2017-09-28T16:34:13.517274: step 2704, loss 0.673185, acc 0.71875, learning_rate 0.000100077
2017-09-28T16:34:13.598144: step 2705, loss 0.841674, acc 0.609375, learning_rate 0.000100077
2017-09-28T16:34:13.678564: step 2706, loss 0.705258, acc 0.75, learning_rate 0.000100077
2017-09-28T16:34:13.759710: step 2707, loss 0.865249, acc 0.703125, learning_rate 0.000100076
2017-09-28T16:34:13.838067: step 2708, loss 0.886067, acc 0.6875, learning_rate 0.000100076
2017-09-28T16:34:13.916229: step 2709, loss 0.803655, acc 0.65625, learning_rate 0.000100076
2017-09-28T16:34:14.000939: step 2710, loss 0.802771, acc 0.75, learning_rate 0.000100076
2017-09-28T16:34:14.082998: step 2711, loss 0.852078, acc 0.734375, learning_rate 0.000100075
2017-09-28T16:34:14.164773: step 2712, loss 0.919068, acc 0.53125, learning_rate 0.000100075
2017-09-28T16:34:14.248267: step 2713, loss 0.967734, acc 0.640625, learning_rate 0.000100075
2017-09-28T16:34:14.327720: step 2714, loss 0.939717, acc 0.625, learning_rate 0.000100074
2017-09-28T16:34:14.413608: step 2715, loss 0.878021, acc 0.640625, learning_rate 0.000100074
2017-09-28T16:34:14.492708: step 2716, loss 0.66579, acc 0.78125, learning_rate 0.000100074
2017-09-28T16:34:14.576959: step 2717, loss 0.839944, acc 0.671875, learning_rate 0.000100073
2017-09-28T16:34:14.658380: step 2718, loss 0.741331, acc 0.75, learning_rate 0.000100073
2017-09-28T16:34:14.740890: step 2719, loss 0.736891, acc 0.703125, learning_rate 0.000100073
2017-09-28T16:34:14.822159: step 2720, loss 0.885212, acc 0.65625, learning_rate 0.000100073

Evaluation:
2017-09-28T16:34:15.090747: step 2720, loss 0.835777, acc 0.657554

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-2720

2017-09-28T16:34:15.648574: step 2721, loss 0.886829, acc 0.65625, learning_rate 0.000100072
2017-09-28T16:34:15.730775: step 2722, loss 0.831429, acc 0.671875, learning_rate 0.000100072
2017-09-28T16:34:15.813783: step 2723, loss 0.885812, acc 0.578125, learning_rate 0.000100072
2017-09-28T16:34:15.893743: step 2724, loss 0.693673, acc 0.75, learning_rate 0.000100071
2017-09-28T16:34:15.973316: step 2725, loss 0.675611, acc 0.6875, learning_rate 0.000100071
2017-09-28T16:34:16.053577: step 2726, loss 0.69539, acc 0.734375, learning_rate 0.000100071
2017-09-28T16:34:16.134717: step 2727, loss 0.929322, acc 0.671875, learning_rate 0.00010007
2017-09-28T16:34:16.218700: step 2728, loss 1.15044, acc 0.546875, learning_rate 0.00010007
2017-09-28T16:34:16.300052: step 2729, loss 0.83771, acc 0.609375, learning_rate 0.00010007
2017-09-28T16:34:16.383704: step 2730, loss 0.826471, acc 0.6875, learning_rate 0.00010007
2017-09-28T16:34:16.468123: step 2731, loss 0.731723, acc 0.71875, learning_rate 0.000100069
2017-09-28T16:34:16.548333: step 2732, loss 0.932492, acc 0.640625, learning_rate 0.000100069
2017-09-28T16:34:16.631036: step 2733, loss 0.853014, acc 0.5625, learning_rate 0.000100069
2017-09-28T16:34:16.712233: step 2734, loss 0.910333, acc 0.609375, learning_rate 0.000100068
2017-09-28T16:34:16.796144: step 2735, loss 0.958995, acc 0.65625, learning_rate 0.000100068
2017-09-28T16:34:16.878069: step 2736, loss 0.847329, acc 0.6875, learning_rate 0.000100068
2017-09-28T16:34:16.957991: step 2737, loss 0.85321, acc 0.6875, learning_rate 0.000100068
2017-09-28T16:34:17.040791: step 2738, loss 0.750705, acc 0.6875, learning_rate 0.000100067
2017-09-28T16:34:17.121050: step 2739, loss 0.841749, acc 0.65625, learning_rate 0.000100067
2017-09-28T16:34:17.202600: step 2740, loss 0.637142, acc 0.765625, learning_rate 0.000100067
2017-09-28T16:34:17.286646: step 2741, loss 0.772592, acc 0.6875, learning_rate 0.000100067
2017-09-28T16:34:17.365026: step 2742, loss 0.80766, acc 0.6875, learning_rate 0.000100066
2017-09-28T16:34:17.446568: step 2743, loss 0.721476, acc 0.703125, learning_rate 0.000100066
2017-09-28T16:34:17.511688: step 2744, loss 0.845445, acc 0.607843, learning_rate 0.000100066
2017-09-28T16:34:17.597251: step 2745, loss 0.817948, acc 0.6875, learning_rate 0.000100065
2017-09-28T16:34:17.678025: step 2746, loss 0.779167, acc 0.6875, learning_rate 0.000100065
2017-09-28T16:34:17.758477: step 2747, loss 0.79601, acc 0.71875, learning_rate 0.000100065
2017-09-28T16:34:17.838321: step 2748, loss 0.746838, acc 0.71875, learning_rate 0.000100065
2017-09-28T16:34:17.920938: step 2749, loss 0.719572, acc 0.75, learning_rate 0.000100064
2017-09-28T16:34:18.002103: step 2750, loss 0.767765, acc 0.703125, learning_rate 0.000100064
2017-09-28T16:34:18.083638: step 2751, loss 0.66838, acc 0.703125, learning_rate 0.000100064
2017-09-28T16:34:18.162177: step 2752, loss 0.939504, acc 0.625, learning_rate 0.000100064
2017-09-28T16:34:18.245263: step 2753, loss 0.718724, acc 0.703125, learning_rate 0.000100063
2017-09-28T16:34:18.329242: step 2754, loss 0.977844, acc 0.546875, learning_rate 0.000100063
2017-09-28T16:34:18.409620: step 2755, loss 0.824837, acc 0.640625, learning_rate 0.000100063
2017-09-28T16:34:18.489716: step 2756, loss 0.723664, acc 0.703125, learning_rate 0.000100063
2017-09-28T16:34:18.571248: step 2757, loss 0.89693, acc 0.59375, learning_rate 0.000100062
2017-09-28T16:34:18.649662: step 2758, loss 0.714719, acc 0.734375, learning_rate 0.000100062
2017-09-28T16:34:18.731633: step 2759, loss 0.866459, acc 0.640625, learning_rate 0.000100062
2017-09-28T16:34:18.814883: step 2760, loss 0.97784, acc 0.625, learning_rate 0.000100062

Evaluation:
2017-09-28T16:34:19.087702: step 2760, loss 0.834903, acc 0.660432

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-2760

2017-09-28T16:34:19.722884: step 2761, loss 0.712412, acc 0.75, learning_rate 0.000100061
2017-09-28T16:34:19.802238: step 2762, loss 0.774187, acc 0.65625, learning_rate 0.000100061
2017-09-28T16:34:19.885641: step 2763, loss 0.81732, acc 0.75, learning_rate 0.000100061
2017-09-28T16:34:19.966385: step 2764, loss 0.809437, acc 0.671875, learning_rate 0.000100061
2017-09-28T16:34:20.044404: step 2765, loss 0.895858, acc 0.546875, learning_rate 0.00010006
2017-09-28T16:34:20.123333: step 2766, loss 0.752569, acc 0.6875, learning_rate 0.00010006
2017-09-28T16:34:20.205843: step 2767, loss 0.847641, acc 0.65625, learning_rate 0.00010006
2017-09-28T16:34:20.288337: step 2768, loss 0.654272, acc 0.765625, learning_rate 0.00010006
2017-09-28T16:34:20.374703: step 2769, loss 0.790362, acc 0.6875, learning_rate 0.000100059
2017-09-28T16:34:20.458533: step 2770, loss 1.01156, acc 0.5625, learning_rate 0.000100059
2017-09-28T16:34:20.548167: step 2771, loss 0.66392, acc 0.71875, learning_rate 0.000100059
2017-09-28T16:34:20.631254: step 2772, loss 0.596383, acc 0.8125, learning_rate 0.000100059
2017-09-28T16:34:20.715024: step 2773, loss 0.968722, acc 0.625, learning_rate 0.000100058
2017-09-28T16:34:20.801964: step 2774, loss 0.9361, acc 0.625, learning_rate 0.000100058
2017-09-28T16:34:20.886590: step 2775, loss 0.935849, acc 0.609375, learning_rate 0.000100058
2017-09-28T16:34:20.969850: step 2776, loss 0.683096, acc 0.671875, learning_rate 0.000100058
2017-09-28T16:34:21.053386: step 2777, loss 0.801791, acc 0.671875, learning_rate 0.000100057
2017-09-28T16:34:21.137284: step 2778, loss 0.729755, acc 0.71875, learning_rate 0.000100057
2017-09-28T16:34:21.219360: step 2779, loss 0.853138, acc 0.640625, learning_rate 0.000100057
2017-09-28T16:34:21.300947: step 2780, loss 0.78245, acc 0.6875, learning_rate 0.000100057
2017-09-28T16:34:21.384434: step 2781, loss 0.716164, acc 0.71875, learning_rate 0.000100056
2017-09-28T16:34:21.469615: step 2782, loss 0.649979, acc 0.75, learning_rate 0.000100056
2017-09-28T16:34:21.550764: step 2783, loss 0.690357, acc 0.734375, learning_rate 0.000100056
2017-09-28T16:34:21.634069: step 2784, loss 0.883173, acc 0.6875, learning_rate 0.000100056
2017-09-28T16:34:21.718826: step 2785, loss 0.795028, acc 0.703125, learning_rate 0.000100056
2017-09-28T16:34:21.803285: step 2786, loss 0.663075, acc 0.75, learning_rate 0.000100055
2017-09-28T16:34:21.883360: step 2787, loss 0.887411, acc 0.640625, learning_rate 0.000100055
2017-09-28T16:34:21.967794: step 2788, loss 0.751924, acc 0.703125, learning_rate 0.000100055
2017-09-28T16:34:22.050966: step 2789, loss 0.799293, acc 0.65625, learning_rate 0.000100055
2017-09-28T16:34:22.134912: step 2790, loss 0.819623, acc 0.765625, learning_rate 0.000100054
2017-09-28T16:34:22.226818: step 2791, loss 0.70909, acc 0.703125, learning_rate 0.000100054
2017-09-28T16:34:22.311437: step 2792, loss 0.819739, acc 0.65625, learning_rate 0.000100054
2017-09-28T16:34:22.396582: step 2793, loss 0.889152, acc 0.640625, learning_rate 0.000100054
2017-09-28T16:34:22.478267: step 2794, loss 0.779769, acc 0.6875, learning_rate 0.000100054
2017-09-28T16:34:22.560955: step 2795, loss 0.918434, acc 0.609375, learning_rate 0.000100053
2017-09-28T16:34:22.651527: step 2796, loss 0.912324, acc 0.671875, learning_rate 0.000100053
2017-09-28T16:34:22.740911: step 2797, loss 0.758834, acc 0.6875, learning_rate 0.000100053
2017-09-28T16:34:22.826133: step 2798, loss 0.859793, acc 0.71875, learning_rate 0.000100053
2017-09-28T16:34:22.905007: step 2799, loss 0.866298, acc 0.6875, learning_rate 0.000100052
2017-09-28T16:34:22.990575: step 2800, loss 0.983545, acc 0.609375, learning_rate 0.000100052

Evaluation:
2017-09-28T16:34:23.272362: step 2800, loss 0.832947, acc 0.658993

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-2800

2017-09-28T16:34:23.778262: step 2801, loss 0.996458, acc 0.578125, learning_rate 0.000100052
2017-09-28T16:34:23.861653: step 2802, loss 0.688295, acc 0.671875, learning_rate 0.000100052
2017-09-28T16:34:23.945663: step 2803, loss 0.816937, acc 0.671875, learning_rate 0.000100052
2017-09-28T16:34:24.031827: step 2804, loss 0.847832, acc 0.671875, learning_rate 0.000100051
2017-09-28T16:34:24.118154: step 2805, loss 0.808917, acc 0.65625, learning_rate 0.000100051
2017-09-28T16:34:24.204054: step 2806, loss 0.830643, acc 0.65625, learning_rate 0.000100051
2017-09-28T16:34:24.290363: step 2807, loss 0.863162, acc 0.625, learning_rate 0.000100051
2017-09-28T16:34:24.375271: step 2808, loss 0.868283, acc 0.625, learning_rate 0.000100051
2017-09-28T16:34:24.459179: step 2809, loss 0.716319, acc 0.78125, learning_rate 0.00010005
2017-09-28T16:34:24.538978: step 2810, loss 0.793605, acc 0.65625, learning_rate 0.00010005
2017-09-28T16:34:24.622391: step 2811, loss 0.910468, acc 0.640625, learning_rate 0.00010005
2017-09-28T16:34:24.702855: step 2812, loss 0.977876, acc 0.578125, learning_rate 0.00010005
2017-09-28T16:34:24.784957: step 2813, loss 0.789195, acc 0.71875, learning_rate 0.00010005
2017-09-28T16:34:24.865948: step 2814, loss 1.04431, acc 0.578125, learning_rate 0.000100049
2017-09-28T16:34:24.947598: step 2815, loss 0.767347, acc 0.671875, learning_rate 0.000100049
2017-09-28T16:34:25.033673: step 2816, loss 0.687207, acc 0.765625, learning_rate 0.000100049
2017-09-28T16:34:25.117504: step 2817, loss 0.834719, acc 0.671875, learning_rate 0.000100049
2017-09-28T16:34:25.200591: step 2818, loss 0.669695, acc 0.734375, learning_rate 0.000100049
2017-09-28T16:34:25.284015: step 2819, loss 0.824595, acc 0.609375, learning_rate 0.000100048
2017-09-28T16:34:25.364964: step 2820, loss 0.757747, acc 0.6875, learning_rate 0.000100048
2017-09-28T16:34:25.444832: step 2821, loss 0.666041, acc 0.6875, learning_rate 0.000100048
2017-09-28T16:34:25.524998: step 2822, loss 0.70267, acc 0.765625, learning_rate 0.000100048
2017-09-28T16:34:25.604812: step 2823, loss 0.765426, acc 0.65625, learning_rate 0.000100048
2017-09-28T16:34:25.684297: step 2824, loss 0.863289, acc 0.609375, learning_rate 0.000100047
2017-09-28T16:34:25.765222: step 2825, loss 0.935719, acc 0.65625, learning_rate 0.000100047
2017-09-28T16:34:25.844252: step 2826, loss 0.862016, acc 0.65625, learning_rate 0.000100047
2017-09-28T16:34:25.925918: step 2827, loss 0.769551, acc 0.71875, learning_rate 0.000100047
2017-09-28T16:34:26.010676: step 2828, loss 0.947778, acc 0.625, learning_rate 0.000100047
2017-09-28T16:34:26.092838: step 2829, loss 0.791594, acc 0.640625, learning_rate 0.000100046
2017-09-28T16:34:26.169315: step 2830, loss 0.841962, acc 0.734375, learning_rate 0.000100046
2017-09-28T16:34:26.251491: step 2831, loss 0.872184, acc 0.6875, learning_rate 0.000100046
2017-09-28T16:34:26.335768: step 2832, loss 0.8911, acc 0.625, learning_rate 0.000100046
2017-09-28T16:34:26.419948: step 2833, loss 0.709979, acc 0.765625, learning_rate 0.000100046
2017-09-28T16:34:26.499721: step 2834, loss 0.968723, acc 0.546875, learning_rate 0.000100045
2017-09-28T16:34:26.581132: step 2835, loss 0.808439, acc 0.71875, learning_rate 0.000100045
2017-09-28T16:34:26.661361: step 2836, loss 0.735478, acc 0.71875, learning_rate 0.000100045
2017-09-28T16:34:26.745828: step 2837, loss 0.620241, acc 0.734375, learning_rate 0.000100045
2017-09-28T16:34:26.829108: step 2838, loss 0.707243, acc 0.75, learning_rate 0.000100045
2017-09-28T16:34:26.911252: step 2839, loss 0.801789, acc 0.703125, learning_rate 0.000100045
2017-09-28T16:34:26.995777: step 2840, loss 0.578604, acc 0.859375, learning_rate 0.000100044

Evaluation:
2017-09-28T16:34:27.278586: step 2840, loss 0.832822, acc 0.66187

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-2840

2017-09-28T16:34:28.201749: step 2841, loss 0.863642, acc 0.609375, learning_rate 0.000100044
2017-09-28T16:34:28.269033: step 2842, loss 0.703452, acc 0.705882, learning_rate 0.000100044
2017-09-28T16:34:28.350754: step 2843, loss 0.738048, acc 0.65625, learning_rate 0.000100044
2017-09-28T16:34:28.431769: step 2844, loss 0.894465, acc 0.671875, learning_rate 0.000100044
2017-09-28T16:34:28.516060: step 2845, loss 0.862947, acc 0.6875, learning_rate 0.000100043
2017-09-28T16:34:28.598237: step 2846, loss 1.12653, acc 0.578125, learning_rate 0.000100043
2017-09-28T16:34:28.683505: step 2847, loss 0.768221, acc 0.71875, learning_rate 0.000100043
2017-09-28T16:34:28.768795: step 2848, loss 0.819556, acc 0.703125, learning_rate 0.000100043
2017-09-28T16:34:28.852037: step 2849, loss 0.934072, acc 0.65625, learning_rate 0.000100043
2017-09-28T16:34:28.930326: step 2850, loss 0.718033, acc 0.734375, learning_rate 0.000100043
2017-09-28T16:34:29.014696: step 2851, loss 0.858311, acc 0.671875, learning_rate 0.000100042
2017-09-28T16:34:29.096875: step 2852, loss 0.965501, acc 0.578125, learning_rate 0.000100042
2017-09-28T16:34:29.179259: step 2853, loss 0.745243, acc 0.71875, learning_rate 0.000100042
2017-09-28T16:34:29.257127: step 2854, loss 0.820434, acc 0.71875, learning_rate 0.000100042
2017-09-28T16:34:29.337814: step 2855, loss 0.89076, acc 0.65625, learning_rate 0.000100042
2017-09-28T16:34:29.418771: step 2856, loss 0.693487, acc 0.734375, learning_rate 0.000100042
2017-09-28T16:34:29.496140: step 2857, loss 0.895156, acc 0.640625, learning_rate 0.000100041
2017-09-28T16:34:29.577197: step 2858, loss 0.844514, acc 0.6875, learning_rate 0.000100041
2017-09-28T16:34:29.660948: step 2859, loss 0.683673, acc 0.6875, learning_rate 0.000100041
2017-09-28T16:34:29.739892: step 2860, loss 0.700153, acc 0.75, learning_rate 0.000100041
2017-09-28T16:34:29.820163: step 2861, loss 0.851044, acc 0.6875, learning_rate 0.000100041
2017-09-28T16:34:29.901382: step 2862, loss 0.865476, acc 0.625, learning_rate 0.000100041
2017-09-28T16:34:29.978894: step 2863, loss 0.692878, acc 0.703125, learning_rate 0.00010004
2017-09-28T16:34:30.059765: step 2864, loss 0.9931, acc 0.609375, learning_rate 0.00010004
2017-09-28T16:34:30.142329: step 2865, loss 0.780787, acc 0.6875, learning_rate 0.00010004
2017-09-28T16:34:30.222849: step 2866, loss 0.848237, acc 0.65625, learning_rate 0.00010004
2017-09-28T16:34:30.307156: step 2867, loss 0.695108, acc 0.765625, learning_rate 0.00010004
2017-09-28T16:34:30.388720: step 2868, loss 0.749498, acc 0.71875, learning_rate 0.00010004
2017-09-28T16:34:30.470558: step 2869, loss 0.691538, acc 0.765625, learning_rate 0.000100039
2017-09-28T16:34:30.550122: step 2870, loss 0.689707, acc 0.703125, learning_rate 0.000100039
2017-09-28T16:34:30.630191: step 2871, loss 0.650347, acc 0.71875, learning_rate 0.000100039
2017-09-28T16:34:30.710273: step 2872, loss 0.799297, acc 0.6875, learning_rate 0.000100039
2017-09-28T16:34:30.791014: step 2873, loss 0.802808, acc 0.65625, learning_rate 0.000100039
2017-09-28T16:34:30.874305: step 2874, loss 0.744278, acc 0.75, learning_rate 0.000100039
2017-09-28T16:34:30.955906: step 2875, loss 0.927386, acc 0.671875, learning_rate 0.000100038
2017-09-28T16:34:31.034508: step 2876, loss 0.783635, acc 0.703125, learning_rate 0.000100038
2017-09-28T16:34:31.119116: step 2877, loss 0.768267, acc 0.6875, learning_rate 0.000100038
2017-09-28T16:34:31.200026: step 2878, loss 0.729112, acc 0.71875, learning_rate 0.000100038
2017-09-28T16:34:31.282607: step 2879, loss 0.760989, acc 0.6875, learning_rate 0.000100038
2017-09-28T16:34:31.364232: step 2880, loss 0.805163, acc 0.703125, learning_rate 0.000100038

Evaluation:
2017-09-28T16:34:31.637370: step 2880, loss 0.833579, acc 0.664748

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-2880

2017-09-28T16:34:32.188226: step 2881, loss 0.942393, acc 0.609375, learning_rate 0.000100038
2017-09-28T16:34:32.267771: step 2882, loss 0.902975, acc 0.59375, learning_rate 0.000100037
2017-09-28T16:34:32.349850: step 2883, loss 0.825725, acc 0.671875, learning_rate 0.000100037
2017-09-28T16:34:32.431877: step 2884, loss 0.889311, acc 0.671875, learning_rate 0.000100037
2017-09-28T16:34:32.512008: step 2885, loss 0.658677, acc 0.78125, learning_rate 0.000100037
2017-09-28T16:34:32.592600: step 2886, loss 0.71933, acc 0.71875, learning_rate 0.000100037
2017-09-28T16:34:32.678192: step 2887, loss 0.774617, acc 0.734375, learning_rate 0.000100037
2017-09-28T16:34:32.763874: step 2888, loss 0.881825, acc 0.59375, learning_rate 0.000100036
2017-09-28T16:34:32.846973: step 2889, loss 0.980698, acc 0.546875, learning_rate 0.000100036
2017-09-28T16:34:32.927470: step 2890, loss 0.758349, acc 0.734375, learning_rate 0.000100036
2017-09-28T16:34:33.008546: step 2891, loss 0.823867, acc 0.671875, learning_rate 0.000100036
2017-09-28T16:34:33.090111: step 2892, loss 0.605908, acc 0.765625, learning_rate 0.000100036
2017-09-28T16:34:33.168962: step 2893, loss 0.899312, acc 0.640625, learning_rate 0.000100036
2017-09-28T16:34:33.248510: step 2894, loss 0.694251, acc 0.671875, learning_rate 0.000100036
2017-09-28T16:34:33.331091: step 2895, loss 0.962549, acc 0.609375, learning_rate 0.000100035
2017-09-28T16:34:33.412411: step 2896, loss 0.925995, acc 0.671875, learning_rate 0.000100035
2017-09-28T16:34:33.495279: step 2897, loss 0.662333, acc 0.78125, learning_rate 0.000100035
2017-09-28T16:34:33.576505: step 2898, loss 0.785143, acc 0.71875, learning_rate 0.000100035
2017-09-28T16:34:33.659292: step 2899, loss 0.876934, acc 0.578125, learning_rate 0.000100035
2017-09-28T16:34:33.739388: step 2900, loss 0.906963, acc 0.59375, learning_rate 0.000100035
2017-09-28T16:34:33.819964: step 2901, loss 0.72868, acc 0.734375, learning_rate 0.000100035
2017-09-28T16:34:33.900310: step 2902, loss 0.86498, acc 0.609375, learning_rate 0.000100034
2017-09-28T16:34:33.983919: step 2903, loss 0.836734, acc 0.609375, learning_rate 0.000100034
2017-09-28T16:34:34.065418: step 2904, loss 0.968802, acc 0.5625, learning_rate 0.000100034
2017-09-28T16:34:34.148817: step 2905, loss 0.731402, acc 0.671875, learning_rate 0.000100034
2017-09-28T16:34:34.232115: step 2906, loss 0.730502, acc 0.703125, learning_rate 0.000100034
2017-09-28T16:34:34.313605: step 2907, loss 0.796657, acc 0.65625, learning_rate 0.000100034
2017-09-28T16:34:34.395919: step 2908, loss 0.845778, acc 0.609375, learning_rate 0.000100034
2017-09-28T16:34:34.479073: step 2909, loss 0.84985, acc 0.71875, learning_rate 0.000100033
2017-09-28T16:34:34.561422: step 2910, loss 0.683973, acc 0.78125, learning_rate 0.000100033
2017-09-28T16:34:34.642927: step 2911, loss 0.88848, acc 0.671875, learning_rate 0.000100033
2017-09-28T16:34:34.723707: step 2912, loss 0.705593, acc 0.71875, learning_rate 0.000100033
2017-09-28T16:34:34.807451: step 2913, loss 0.825616, acc 0.671875, learning_rate 0.000100033
2017-09-28T16:34:34.889144: step 2914, loss 0.746695, acc 0.71875, learning_rate 0.000100033
2017-09-28T16:34:34.969475: step 2915, loss 0.697422, acc 0.703125, learning_rate 0.000100033
2017-09-28T16:34:35.052879: step 2916, loss 0.863656, acc 0.640625, learning_rate 0.000100033
2017-09-28T16:34:35.134283: step 2917, loss 0.82403, acc 0.671875, learning_rate 0.000100032
2017-09-28T16:34:35.216413: step 2918, loss 0.582533, acc 0.796875, learning_rate 0.000100032
2017-09-28T16:34:35.297002: step 2919, loss 0.663547, acc 0.765625, learning_rate 0.000100032
2017-09-28T16:34:35.377462: step 2920, loss 0.820564, acc 0.640625, learning_rate 0.000100032

Evaluation:
2017-09-28T16:34:35.647293: step 2920, loss 0.831091, acc 0.663309

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-2920

2017-09-28T16:34:36.276577: step 2921, loss 0.806909, acc 0.703125, learning_rate 0.000100032
2017-09-28T16:34:36.358612: step 2922, loss 0.807413, acc 0.625, learning_rate 0.000100032
2017-09-28T16:34:36.446054: step 2923, loss 0.781133, acc 0.640625, learning_rate 0.000100032
2017-09-28T16:34:36.529555: step 2924, loss 0.748149, acc 0.6875, learning_rate 0.000100031
2017-09-28T16:34:36.608339: step 2925, loss 0.650299, acc 0.75, learning_rate 0.000100031
2017-09-28T16:34:36.687271: step 2926, loss 0.933813, acc 0.625, learning_rate 0.000100031
2017-09-28T16:34:36.768818: step 2927, loss 0.791335, acc 0.703125, learning_rate 0.000100031
2017-09-28T16:34:36.852705: step 2928, loss 0.735118, acc 0.703125, learning_rate 0.000100031
2017-09-28T16:34:36.932227: step 2929, loss 0.736189, acc 0.734375, learning_rate 0.000100031
2017-09-28T16:34:37.013715: step 2930, loss 0.962093, acc 0.65625, learning_rate 0.000100031
2017-09-28T16:34:37.095703: step 2931, loss 0.930345, acc 0.578125, learning_rate 0.000100031
2017-09-28T16:34:37.175572: step 2932, loss 0.756049, acc 0.640625, learning_rate 0.00010003
2017-09-28T16:34:37.257032: step 2933, loss 0.682316, acc 0.734375, learning_rate 0.00010003
2017-09-28T16:34:37.340135: step 2934, loss 0.828158, acc 0.65625, learning_rate 0.00010003
2017-09-28T16:34:37.422447: step 2935, loss 0.602818, acc 0.796875, learning_rate 0.00010003
2017-09-28T16:34:37.503079: step 2936, loss 0.855166, acc 0.59375, learning_rate 0.00010003
2017-09-28T16:34:37.583565: step 2937, loss 0.926848, acc 0.703125, learning_rate 0.00010003
2017-09-28T16:34:37.663628: step 2938, loss 0.647515, acc 0.734375, learning_rate 0.00010003
2017-09-28T16:34:37.747530: step 2939, loss 0.769924, acc 0.6875, learning_rate 0.00010003
2017-09-28T16:34:37.818713: step 2940, loss 0.74796, acc 0.647059, learning_rate 0.000100029
2017-09-28T16:34:37.901262: step 2941, loss 0.780531, acc 0.59375, learning_rate 0.000100029
2017-09-28T16:34:37.983098: step 2942, loss 0.60539, acc 0.765625, learning_rate 0.000100029
2017-09-28T16:34:38.066671: step 2943, loss 0.84942, acc 0.625, learning_rate 0.000100029
2017-09-28T16:34:38.147542: step 2944, loss 0.653304, acc 0.71875, learning_rate 0.000100029
2017-09-28T16:34:38.229993: step 2945, loss 0.761369, acc 0.734375, learning_rate 0.000100029
2017-09-28T16:34:38.309826: step 2946, loss 0.826754, acc 0.640625, learning_rate 0.000100029
2017-09-28T16:34:38.395420: step 2947, loss 0.917277, acc 0.625, learning_rate 0.000100029
2017-09-28T16:34:38.480236: step 2948, loss 0.932144, acc 0.6875, learning_rate 0.000100029
2017-09-28T16:34:38.561063: step 2949, loss 0.731383, acc 0.71875, learning_rate 0.000100028
2017-09-28T16:34:38.642290: step 2950, loss 0.882545, acc 0.640625, learning_rate 0.000100028
2017-09-28T16:34:38.724818: step 2951, loss 0.987516, acc 0.53125, learning_rate 0.000100028
2017-09-28T16:34:38.807239: step 2952, loss 0.744656, acc 0.703125, learning_rate 0.000100028
2017-09-28T16:34:38.887610: step 2953, loss 0.86412, acc 0.640625, learning_rate 0.000100028
2017-09-28T16:34:38.970609: step 2954, loss 0.859788, acc 0.640625, learning_rate 0.000100028
2017-09-28T16:34:39.049958: step 2955, loss 0.761913, acc 0.71875, learning_rate 0.000100028
2017-09-28T16:34:39.130790: step 2956, loss 0.696881, acc 0.6875, learning_rate 0.000100028
2017-09-28T16:34:39.212612: step 2957, loss 0.710494, acc 0.75, learning_rate 0.000100028
2017-09-28T16:34:39.296734: step 2958, loss 0.808097, acc 0.578125, learning_rate 0.000100027
2017-09-28T16:34:39.375450: step 2959, loss 0.926187, acc 0.609375, learning_rate 0.000100027
2017-09-28T16:34:39.457377: step 2960, loss 0.744506, acc 0.609375, learning_rate 0.000100027

Evaluation:
2017-09-28T16:34:39.720886: step 2960, loss 0.830412, acc 0.666187

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-2960

2017-09-28T16:34:40.207606: step 2961, loss 0.845045, acc 0.703125, learning_rate 0.000100027
2017-09-28T16:34:40.288313: step 2962, loss 0.902276, acc 0.6875, learning_rate 0.000100027
2017-09-28T16:34:40.366770: step 2963, loss 0.805172, acc 0.71875, learning_rate 0.000100027
2017-09-28T16:34:40.451092: step 2964, loss 0.822211, acc 0.703125, learning_rate 0.000100027
2017-09-28T16:34:40.532503: step 2965, loss 0.913634, acc 0.609375, learning_rate 0.000100027
2017-09-28T16:34:40.612548: step 2966, loss 0.654712, acc 0.734375, learning_rate 0.000100027
2017-09-28T16:34:40.693012: step 2967, loss 0.858024, acc 0.6875, learning_rate 0.000100026
2017-09-28T16:34:40.773094: step 2968, loss 0.749024, acc 0.6875, learning_rate 0.000100026
2017-09-28T16:34:40.854715: step 2969, loss 0.80968, acc 0.640625, learning_rate 0.000100026
2017-09-28T16:34:40.937877: step 2970, loss 0.744811, acc 0.71875, learning_rate 0.000100026
2017-09-28T16:34:41.021595: step 2971, loss 0.794792, acc 0.703125, learning_rate 0.000100026
2017-09-28T16:34:41.101315: step 2972, loss 0.807213, acc 0.703125, learning_rate 0.000100026
2017-09-28T16:34:41.181024: step 2973, loss 0.870058, acc 0.609375, learning_rate 0.000100026
2017-09-28T16:34:41.263751: step 2974, loss 0.73025, acc 0.78125, learning_rate 0.000100026
2017-09-28T16:34:41.346905: step 2975, loss 0.845086, acc 0.65625, learning_rate 0.000100026
2017-09-28T16:34:41.428128: step 2976, loss 0.818933, acc 0.703125, learning_rate 0.000100025
2017-09-28T16:34:41.507867: step 2977, loss 0.822481, acc 0.640625, learning_rate 0.000100025
2017-09-28T16:34:41.590806: step 2978, loss 0.79305, acc 0.71875, learning_rate 0.000100025
2017-09-28T16:34:41.672726: step 2979, loss 0.815697, acc 0.625, learning_rate 0.000100025
2017-09-28T16:34:41.753933: step 2980, loss 0.836412, acc 0.640625, learning_rate 0.000100025
2017-09-28T16:34:41.834712: step 2981, loss 0.738588, acc 0.6875, learning_rate 0.000100025
2017-09-28T16:34:41.915523: step 2982, loss 0.926477, acc 0.625, learning_rate 0.000100025
2017-09-28T16:34:41.996986: step 2983, loss 0.81573, acc 0.734375, learning_rate 0.000100025
2017-09-28T16:34:42.076132: step 2984, loss 0.681677, acc 0.765625, learning_rate 0.000100025
2017-09-28T16:34:42.163231: step 2985, loss 0.770525, acc 0.703125, learning_rate 0.000100025
2017-09-28T16:34:42.243699: step 2986, loss 0.86704, acc 0.65625, learning_rate 0.000100024
2017-09-28T16:34:42.325915: step 2987, loss 0.811815, acc 0.703125, learning_rate 0.000100024
2017-09-28T16:34:42.408158: step 2988, loss 0.579499, acc 0.78125, learning_rate 0.000100024
2017-09-28T16:34:42.487702: step 2989, loss 0.618313, acc 0.75, learning_rate 0.000100024
2017-09-28T16:34:42.570683: step 2990, loss 0.892866, acc 0.640625, learning_rate 0.000100024
2017-09-28T16:34:42.654395: step 2991, loss 0.771878, acc 0.71875, learning_rate 0.000100024
2017-09-28T16:34:42.736075: step 2992, loss 0.812115, acc 0.671875, learning_rate 0.000100024
2017-09-28T16:34:42.823158: step 2993, loss 0.806641, acc 0.625, learning_rate 0.000100024
2017-09-28T16:34:42.902784: step 2994, loss 0.842096, acc 0.625, learning_rate 0.000100024
2017-09-28T16:34:42.983859: step 2995, loss 0.74516, acc 0.6875, learning_rate 0.000100024
2017-09-28T16:34:43.064781: step 2996, loss 0.786944, acc 0.671875, learning_rate 0.000100023
2017-09-28T16:34:43.144893: step 2997, loss 0.848347, acc 0.671875, learning_rate 0.000100023
2017-09-28T16:34:43.225548: step 2998, loss 0.670526, acc 0.75, learning_rate 0.000100023
2017-09-28T16:34:43.305875: step 2999, loss 0.777212, acc 0.6875, learning_rate 0.000100023
2017-09-28T16:34:43.384982: step 3000, loss 0.722897, acc 0.71875, learning_rate 0.000100023

Evaluation:
2017-09-28T16:34:43.657693: step 3000, loss 0.828671, acc 0.66187

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-3000

2017-09-28T16:34:44.215095: step 3001, loss 0.813425, acc 0.671875, learning_rate 0.000100023
2017-09-28T16:34:44.294782: step 3002, loss 0.874755, acc 0.59375, learning_rate 0.000100023
2017-09-28T16:34:44.377674: step 3003, loss 0.811659, acc 0.71875, learning_rate 0.000100023
2017-09-28T16:34:44.461375: step 3004, loss 0.890716, acc 0.6875, learning_rate 0.000100023
2017-09-28T16:34:44.544855: step 3005, loss 0.751388, acc 0.6875, learning_rate 0.000100023
2017-09-28T16:34:44.626054: step 3006, loss 0.730058, acc 0.734375, learning_rate 0.000100023
2017-09-28T16:34:44.709164: step 3007, loss 0.876901, acc 0.625, learning_rate 0.000100022
2017-09-28T16:34:44.790555: step 3008, loss 0.921055, acc 0.703125, learning_rate 0.000100022
2017-09-28T16:34:44.874683: step 3009, loss 0.621409, acc 0.78125, learning_rate 0.000100022
2017-09-28T16:34:44.954408: step 3010, loss 0.581308, acc 0.84375, learning_rate 0.000100022
2017-09-28T16:34:45.037339: step 3011, loss 0.898297, acc 0.609375, learning_rate 0.000100022
2017-09-28T16:34:45.122208: step 3012, loss 0.945183, acc 0.65625, learning_rate 0.000100022
2017-09-28T16:34:45.201716: step 3013, loss 0.81744, acc 0.65625, learning_rate 0.000100022
2017-09-28T16:34:45.284744: step 3014, loss 0.676476, acc 0.75, learning_rate 0.000100022
2017-09-28T16:34:45.364608: step 3015, loss 0.848849, acc 0.640625, learning_rate 0.000100022
2017-09-28T16:34:45.447235: step 3016, loss 1.01986, acc 0.609375, learning_rate 0.000100022
2017-09-28T16:34:45.526469: step 3017, loss 0.736918, acc 0.703125, learning_rate 0.000100022
2017-09-28T16:34:45.607054: step 3018, loss 0.791835, acc 0.671875, learning_rate 0.000100021
2017-09-28T16:34:45.685433: step 3019, loss 1.03775, acc 0.515625, learning_rate 0.000100021
2017-09-28T16:34:45.767019: step 3020, loss 0.841097, acc 0.65625, learning_rate 0.000100021
2017-09-28T16:34:45.846304: step 3021, loss 0.623749, acc 0.8125, learning_rate 0.000100021
2017-09-28T16:34:45.928035: step 3022, loss 0.70594, acc 0.703125, learning_rate 0.000100021
2017-09-28T16:34:46.008230: step 3023, loss 0.669916, acc 0.796875, learning_rate 0.000100021
2017-09-28T16:34:46.092487: step 3024, loss 0.808597, acc 0.75, learning_rate 0.000100021
2017-09-28T16:34:46.174417: step 3025, loss 0.680107, acc 0.734375, learning_rate 0.000100021
2017-09-28T16:34:46.259128: step 3026, loss 0.898504, acc 0.578125, learning_rate 0.000100021
2017-09-28T16:34:46.346005: step 3027, loss 0.917742, acc 0.65625, learning_rate 0.000100021
2017-09-28T16:34:46.427826: step 3028, loss 0.808222, acc 0.609375, learning_rate 0.000100021
2017-09-28T16:34:46.510322: step 3029, loss 0.831187, acc 0.625, learning_rate 0.00010002
2017-09-28T16:34:46.590374: step 3030, loss 0.706697, acc 0.6875, learning_rate 0.00010002
2017-09-28T16:34:46.669805: step 3031, loss 0.827872, acc 0.640625, learning_rate 0.00010002
2017-09-28T16:34:46.746614: step 3032, loss 0.667059, acc 0.71875, learning_rate 0.00010002
2017-09-28T16:34:46.830400: step 3033, loss 0.75598, acc 0.703125, learning_rate 0.00010002
2017-09-28T16:34:46.910034: step 3034, loss 0.795633, acc 0.65625, learning_rate 0.00010002
2017-09-28T16:34:46.993057: step 3035, loss 0.747938, acc 0.703125, learning_rate 0.00010002
2017-09-28T16:34:47.074740: step 3036, loss 0.765928, acc 0.765625, learning_rate 0.00010002
2017-09-28T16:34:47.157422: step 3037, loss 0.722247, acc 0.65625, learning_rate 0.00010002
2017-09-28T16:34:47.220668: step 3038, loss 1.04032, acc 0.54902, learning_rate 0.00010002
2017-09-28T16:34:47.303869: step 3039, loss 0.766441, acc 0.703125, learning_rate 0.00010002
2017-09-28T16:34:47.387013: step 3040, loss 0.757608, acc 0.671875, learning_rate 0.00010002

Evaluation:
2017-09-28T16:34:47.666917: step 3040, loss 0.827806, acc 0.667626

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-3040

2017-09-28T16:34:48.228580: step 3041, loss 0.723972, acc 0.6875, learning_rate 0.00010002
2017-09-28T16:34:48.310269: step 3042, loss 0.971188, acc 0.5625, learning_rate 0.000100019
2017-09-28T16:34:48.391736: step 3043, loss 0.759814, acc 0.71875, learning_rate 0.000100019
2017-09-28T16:34:48.477586: step 3044, loss 0.693348, acc 0.75, learning_rate 0.000100019
2017-09-28T16:34:48.560862: step 3045, loss 0.804415, acc 0.640625, learning_rate 0.000100019
2017-09-28T16:34:48.640067: step 3046, loss 0.756392, acc 0.6875, learning_rate 0.000100019
2017-09-28T16:34:48.719996: step 3047, loss 0.603802, acc 0.75, learning_rate 0.000100019
2017-09-28T16:34:48.804717: step 3048, loss 0.548611, acc 0.78125, learning_rate 0.000100019
2017-09-28T16:34:48.883674: step 3049, loss 0.983683, acc 0.546875, learning_rate 0.000100019
2017-09-28T16:34:48.962640: step 3050, loss 0.89282, acc 0.640625, learning_rate 0.000100019
2017-09-28T16:34:49.046332: step 3051, loss 0.634707, acc 0.75, learning_rate 0.000100019
2017-09-28T16:34:49.125595: step 3052, loss 0.785783, acc 0.71875, learning_rate 0.000100019
2017-09-28T16:34:49.205170: step 3053, loss 0.783779, acc 0.734375, learning_rate 0.000100019
2017-09-28T16:34:49.285264: step 3054, loss 0.839399, acc 0.734375, learning_rate 0.000100018
2017-09-28T16:34:49.373723: step 3055, loss 0.714564, acc 0.75, learning_rate 0.000100018
2017-09-28T16:34:49.458122: step 3056, loss 0.807393, acc 0.71875, learning_rate 0.000100018
2017-09-28T16:34:49.542615: step 3057, loss 1.00097, acc 0.53125, learning_rate 0.000100018
2017-09-28T16:34:49.621038: step 3058, loss 0.695616, acc 0.703125, learning_rate 0.000100018
2017-09-28T16:34:49.700911: step 3059, loss 0.70792, acc 0.6875, learning_rate 0.000100018
2017-09-28T16:34:49.783686: step 3060, loss 1.06576, acc 0.515625, learning_rate 0.000100018
2017-09-28T16:34:49.864516: step 3061, loss 0.782042, acc 0.640625, learning_rate 0.000100018
2017-09-28T16:34:49.946035: step 3062, loss 0.922191, acc 0.65625, learning_rate 0.000100018
2017-09-28T16:34:50.027807: step 3063, loss 0.628277, acc 0.78125, learning_rate 0.000100018
2017-09-28T16:34:50.107914: step 3064, loss 0.683072, acc 0.703125, learning_rate 0.000100018
2017-09-28T16:34:50.191520: step 3065, loss 0.648733, acc 0.734375, learning_rate 0.000100018
2017-09-28T16:34:50.273266: step 3066, loss 0.784317, acc 0.640625, learning_rate 0.000100018
2017-09-28T16:34:50.356507: step 3067, loss 0.857415, acc 0.703125, learning_rate 0.000100018
2017-09-28T16:34:50.440075: step 3068, loss 0.941047, acc 0.640625, learning_rate 0.000100017
2017-09-28T16:34:50.522380: step 3069, loss 0.892066, acc 0.578125, learning_rate 0.000100017
2017-09-28T16:34:50.603124: step 3070, loss 0.817935, acc 0.640625, learning_rate 0.000100017
2017-09-28T16:34:50.685546: step 3071, loss 0.793324, acc 0.71875, learning_rate 0.000100017
2017-09-28T16:34:50.766871: step 3072, loss 0.879512, acc 0.671875, learning_rate 0.000100017
2017-09-28T16:34:50.848800: step 3073, loss 0.725461, acc 0.703125, learning_rate 0.000100017
2017-09-28T16:34:50.930494: step 3074, loss 0.820968, acc 0.71875, learning_rate 0.000100017
2017-09-28T16:34:51.013038: step 3075, loss 0.850151, acc 0.640625, learning_rate 0.000100017
2017-09-28T16:34:51.093129: step 3076, loss 0.890403, acc 0.671875, learning_rate 0.000100017
2017-09-28T16:34:51.172050: step 3077, loss 0.760653, acc 0.734375, learning_rate 0.000100017
2017-09-28T16:34:51.253383: step 3078, loss 0.721012, acc 0.71875, learning_rate 0.000100017
2017-09-28T16:34:51.336190: step 3079, loss 0.774291, acc 0.75, learning_rate 0.000100017
2017-09-28T16:34:51.417767: step 3080, loss 0.836461, acc 0.671875, learning_rate 0.000100017

Evaluation:
2017-09-28T16:34:51.686144: step 3080, loss 0.82641, acc 0.669065

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-3080

2017-09-28T16:34:52.313009: step 3081, loss 0.719624, acc 0.796875, learning_rate 0.000100017
2017-09-28T16:34:52.400416: step 3082, loss 0.80152, acc 0.65625, learning_rate 0.000100016
2017-09-28T16:34:52.482844: step 3083, loss 0.901021, acc 0.609375, learning_rate 0.000100016
2017-09-28T16:34:52.566267: step 3084, loss 0.897719, acc 0.625, learning_rate 0.000100016
2017-09-28T16:34:52.647218: step 3085, loss 0.72338, acc 0.703125, learning_rate 0.000100016
2017-09-28T16:34:52.727999: step 3086, loss 0.951936, acc 0.625, learning_rate 0.000100016
2017-09-28T16:34:52.813619: step 3087, loss 0.677534, acc 0.671875, learning_rate 0.000100016
2017-09-28T16:34:52.898563: step 3088, loss 0.887641, acc 0.65625, learning_rate 0.000100016
2017-09-28T16:34:52.978457: step 3089, loss 0.749621, acc 0.703125, learning_rate 0.000100016
2017-09-28T16:34:53.058574: step 3090, loss 0.673183, acc 0.75, learning_rate 0.000100016
2017-09-28T16:34:53.142662: step 3091, loss 0.682301, acc 0.796875, learning_rate 0.000100016
2017-09-28T16:34:53.221770: step 3092, loss 0.90903, acc 0.640625, learning_rate 0.000100016
2017-09-28T16:34:53.302367: step 3093, loss 0.623838, acc 0.71875, learning_rate 0.000100016
2017-09-28T16:34:53.383349: step 3094, loss 0.646454, acc 0.703125, learning_rate 0.000100016
2017-09-28T16:34:53.463704: step 3095, loss 0.779687, acc 0.6875, learning_rate 0.000100016
2017-09-28T16:34:53.543346: step 3096, loss 0.726887, acc 0.734375, learning_rate 0.000100016
2017-09-28T16:34:53.626671: step 3097, loss 0.819496, acc 0.734375, learning_rate 0.000100016
2017-09-28T16:34:53.707194: step 3098, loss 0.791045, acc 0.703125, learning_rate 0.000100015
2017-09-28T16:34:53.789510: step 3099, loss 0.949486, acc 0.5625, learning_rate 0.000100015
2017-09-28T16:34:53.870109: step 3100, loss 0.710923, acc 0.65625, learning_rate 0.000100015
2017-09-28T16:34:53.951859: step 3101, loss 0.915224, acc 0.625, learning_rate 0.000100015
2017-09-28T16:34:54.030811: step 3102, loss 0.930701, acc 0.6875, learning_rate 0.000100015
2017-09-28T16:34:54.113448: step 3103, loss 0.861415, acc 0.625, learning_rate 0.000100015
2017-09-28T16:34:54.198572: step 3104, loss 0.704716, acc 0.71875, learning_rate 0.000100015
2017-09-28T16:34:54.279935: step 3105, loss 0.837786, acc 0.640625, learning_rate 0.000100015
2017-09-28T16:34:54.360685: step 3106, loss 0.863423, acc 0.640625, learning_rate 0.000100015
2017-09-28T16:34:54.445970: step 3107, loss 0.986894, acc 0.578125, learning_rate 0.000100015
2017-09-28T16:34:54.527173: step 3108, loss 0.897672, acc 0.640625, learning_rate 0.000100015
2017-09-28T16:34:54.609262: step 3109, loss 0.720541, acc 0.75, learning_rate 0.000100015
2017-09-28T16:34:54.689839: step 3110, loss 0.706184, acc 0.765625, learning_rate 0.000100015
2017-09-28T16:34:54.769650: step 3111, loss 0.751636, acc 0.71875, learning_rate 0.000100015
2017-09-28T16:34:54.851298: step 3112, loss 0.894869, acc 0.6875, learning_rate 0.000100015
2017-09-28T16:34:54.935654: step 3113, loss 1.08916, acc 0.5625, learning_rate 0.000100015
2017-09-28T16:34:55.015661: step 3114, loss 0.693592, acc 0.6875, learning_rate 0.000100014
2017-09-28T16:34:55.100009: step 3115, loss 0.796942, acc 0.640625, learning_rate 0.000100014
2017-09-28T16:34:55.182110: step 3116, loss 0.630957, acc 0.75, learning_rate 0.000100014
2017-09-28T16:34:55.260630: step 3117, loss 0.809566, acc 0.71875, learning_rate 0.000100014
2017-09-28T16:34:55.342962: step 3118, loss 0.767799, acc 0.75, learning_rate 0.000100014
2017-09-28T16:34:55.425263: step 3119, loss 0.781172, acc 0.703125, learning_rate 0.000100014
2017-09-28T16:34:55.506219: step 3120, loss 0.664829, acc 0.78125, learning_rate 0.000100014

Evaluation:
2017-09-28T16:34:55.772028: step 3120, loss 0.826292, acc 0.667626

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-3120

2017-09-28T16:34:56.261847: step 3121, loss 0.884427, acc 0.65625, learning_rate 0.000100014
2017-09-28T16:34:56.345725: step 3122, loss 0.812117, acc 0.6875, learning_rate 0.000100014
2017-09-28T16:34:56.425651: step 3123, loss 0.715202, acc 0.703125, learning_rate 0.000100014
2017-09-28T16:34:56.506748: step 3124, loss 0.745522, acc 0.625, learning_rate 0.000100014
2017-09-28T16:34:56.587024: step 3125, loss 0.732903, acc 0.734375, learning_rate 0.000100014
2017-09-28T16:34:56.667353: step 3126, loss 0.965373, acc 0.640625, learning_rate 0.000100014
2017-09-28T16:34:56.747749: step 3127, loss 0.698472, acc 0.734375, learning_rate 0.000100014
2017-09-28T16:34:56.834946: step 3128, loss 0.845718, acc 0.671875, learning_rate 0.000100014
2017-09-28T16:34:56.919324: step 3129, loss 0.994691, acc 0.65625, learning_rate 0.000100014
2017-09-28T16:34:57.004080: step 3130, loss 0.829502, acc 0.734375, learning_rate 0.000100014
2017-09-28T16:34:57.085123: step 3131, loss 0.926799, acc 0.609375, learning_rate 0.000100014
2017-09-28T16:34:57.165842: step 3132, loss 0.712741, acc 0.765625, learning_rate 0.000100013
2017-09-28T16:34:57.246953: step 3133, loss 0.732856, acc 0.640625, learning_rate 0.000100013
2017-09-28T16:34:57.327041: step 3134, loss 0.787163, acc 0.703125, learning_rate 0.000100013
2017-09-28T16:34:57.411811: step 3135, loss 0.646578, acc 0.71875, learning_rate 0.000100013
2017-09-28T16:34:57.477832: step 3136, loss 0.608017, acc 0.823529, learning_rate 0.000100013
2017-09-28T16:34:57.559051: step 3137, loss 0.719888, acc 0.78125, learning_rate 0.000100013
2017-09-28T16:34:57.639925: step 3138, loss 0.828451, acc 0.640625, learning_rate 0.000100013
2017-09-28T16:34:57.721664: step 3139, loss 0.674186, acc 0.703125, learning_rate 0.000100013
2017-09-28T16:34:57.803176: step 3140, loss 0.814857, acc 0.578125, learning_rate 0.000100013
2017-09-28T16:34:57.890303: step 3141, loss 0.912541, acc 0.671875, learning_rate 0.000100013
2017-09-28T16:34:57.975399: step 3142, loss 1.03832, acc 0.53125, learning_rate 0.000100013
2017-09-28T16:34:58.061053: step 3143, loss 0.821962, acc 0.65625, learning_rate 0.000100013
2017-09-28T16:34:58.167531: step 3144, loss 0.803881, acc 0.640625, learning_rate 0.000100013
2017-09-28T16:34:58.252360: step 3145, loss 0.804156, acc 0.6875, learning_rate 0.000100013
2017-09-28T16:34:58.337737: step 3146, loss 0.78535, acc 0.65625, learning_rate 0.000100013
2017-09-28T16:34:58.420118: step 3147, loss 0.763622, acc 0.71875, learning_rate 0.000100013
2017-09-28T16:34:58.502381: step 3148, loss 0.78171, acc 0.75, learning_rate 0.000100013
2017-09-28T16:34:58.583727: step 3149, loss 0.807049, acc 0.609375, learning_rate 0.000100013
2017-09-28T16:34:58.663728: step 3150, loss 0.746041, acc 0.671875, learning_rate 0.000100012
2017-09-28T16:34:58.743132: step 3151, loss 0.6514, acc 0.734375, learning_rate 0.000100012
2017-09-28T16:34:58.825825: step 3152, loss 0.832641, acc 0.671875, learning_rate 0.000100012
2017-09-28T16:34:58.906193: step 3153, loss 0.742238, acc 0.75, learning_rate 0.000100012
2017-09-28T16:34:58.991457: step 3154, loss 0.838298, acc 0.6875, learning_rate 0.000100012
2017-09-28T16:34:59.069894: step 3155, loss 0.563672, acc 0.828125, learning_rate 0.000100012
2017-09-28T16:34:59.151850: step 3156, loss 0.888859, acc 0.671875, learning_rate 0.000100012
2017-09-28T16:34:59.234031: step 3157, loss 0.833851, acc 0.65625, learning_rate 0.000100012
2017-09-28T16:34:59.316556: step 3158, loss 0.886501, acc 0.6875, learning_rate 0.000100012
2017-09-28T16:34:59.397609: step 3159, loss 0.854093, acc 0.6875, learning_rate 0.000100012
2017-09-28T16:34:59.477907: step 3160, loss 0.970341, acc 0.59375, learning_rate 0.000100012

Evaluation:
2017-09-28T16:34:59.746336: step 3160, loss 0.825428, acc 0.667626

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-3160

2017-09-28T16:35:00.297711: step 3161, loss 0.809401, acc 0.671875, learning_rate 0.000100012
2017-09-28T16:35:00.379773: step 3162, loss 0.818067, acc 0.65625, learning_rate 0.000100012
2017-09-28T16:35:00.461965: step 3163, loss 0.69007, acc 0.75, learning_rate 0.000100012
2017-09-28T16:35:00.543370: step 3164, loss 0.794168, acc 0.640625, learning_rate 0.000100012
2017-09-28T16:35:00.623995: step 3165, loss 0.7763, acc 0.78125, learning_rate 0.000100012
2017-09-28T16:35:00.705220: step 3166, loss 0.758759, acc 0.6875, learning_rate 0.000100012
2017-09-28T16:35:00.788527: step 3167, loss 0.797285, acc 0.671875, learning_rate 0.000100012
2017-09-28T16:35:00.867744: step 3168, loss 0.689924, acc 0.734375, learning_rate 0.000100012
2017-09-28T16:35:00.948944: step 3169, loss 0.81801, acc 0.65625, learning_rate 0.000100012
2017-09-28T16:35:01.030528: step 3170, loss 0.74138, acc 0.734375, learning_rate 0.000100012
2017-09-28T16:35:01.114874: step 3171, loss 0.626056, acc 0.765625, learning_rate 0.000100011
2017-09-28T16:35:01.195704: step 3172, loss 0.858498, acc 0.609375, learning_rate 0.000100011
2017-09-28T16:35:01.282802: step 3173, loss 0.567937, acc 0.828125, learning_rate 0.000100011
2017-09-28T16:35:01.368561: step 3174, loss 0.702248, acc 0.75, learning_rate 0.000100011
2017-09-28T16:35:01.451259: step 3175, loss 0.856788, acc 0.640625, learning_rate 0.000100011
2017-09-28T16:35:01.528965: step 3176, loss 0.842534, acc 0.640625, learning_rate 0.000100011
2017-09-28T16:35:01.610340: step 3177, loss 0.875934, acc 0.6875, learning_rate 0.000100011
2017-09-28T16:35:01.688318: step 3178, loss 0.775136, acc 0.625, learning_rate 0.000100011
2017-09-28T16:35:01.768998: step 3179, loss 0.785013, acc 0.703125, learning_rate 0.000100011
2017-09-28T16:35:01.849465: step 3180, loss 0.833895, acc 0.671875, learning_rate 0.000100011
2017-09-28T16:35:01.931646: step 3181, loss 0.901894, acc 0.65625, learning_rate 0.000100011
2017-09-28T16:35:02.011888: step 3182, loss 0.918228, acc 0.65625, learning_rate 0.000100011
2017-09-28T16:35:02.096258: step 3183, loss 0.848763, acc 0.59375, learning_rate 0.000100011
2017-09-28T16:35:02.175984: step 3184, loss 0.752717, acc 0.6875, learning_rate 0.000100011
2017-09-28T16:35:02.260769: step 3185, loss 0.812092, acc 0.625, learning_rate 0.000100011
2017-09-28T16:35:02.340505: step 3186, loss 0.765953, acc 0.65625, learning_rate 0.000100011
2017-09-28T16:35:02.425662: step 3187, loss 0.734401, acc 0.6875, learning_rate 0.000100011
2017-09-28T16:35:02.503585: step 3188, loss 0.643428, acc 0.78125, learning_rate 0.000100011
2017-09-28T16:35:02.584265: step 3189, loss 0.985302, acc 0.578125, learning_rate 0.000100011
2017-09-28T16:35:02.663718: step 3190, loss 0.829374, acc 0.65625, learning_rate 0.000100011
2017-09-28T16:35:02.747442: step 3191, loss 0.77405, acc 0.703125, learning_rate 0.000100011
2017-09-28T16:35:02.827957: step 3192, loss 0.888958, acc 0.625, learning_rate 0.000100011
2017-09-28T16:35:02.919072: step 3193, loss 0.77769, acc 0.75, learning_rate 0.00010001
2017-09-28T16:35:03.001597: step 3194, loss 0.752204, acc 0.734375, learning_rate 0.00010001
2017-09-28T16:35:03.079299: step 3195, loss 0.725734, acc 0.671875, learning_rate 0.00010001
2017-09-28T16:35:03.161213: step 3196, loss 0.690857, acc 0.71875, learning_rate 0.00010001
2017-09-28T16:35:03.243874: step 3197, loss 0.834258, acc 0.625, learning_rate 0.00010001
2017-09-28T16:35:03.323724: step 3198, loss 0.756306, acc 0.703125, learning_rate 0.00010001
2017-09-28T16:35:03.406344: step 3199, loss 0.787599, acc 0.703125, learning_rate 0.00010001
2017-09-28T16:35:03.488459: step 3200, loss 0.827526, acc 0.671875, learning_rate 0.00010001

Evaluation:
2017-09-28T16:35:03.761636: step 3200, loss 0.827201, acc 0.669065

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-3200

2017-09-28T16:35:04.314352: step 3201, loss 0.760792, acc 0.734375, learning_rate 0.00010001
2017-09-28T16:35:04.395544: step 3202, loss 0.747025, acc 0.6875, learning_rate 0.00010001
2017-09-28T16:35:04.477013: step 3203, loss 0.811981, acc 0.625, learning_rate 0.00010001
2017-09-28T16:35:04.560755: step 3204, loss 0.818187, acc 0.671875, learning_rate 0.00010001
2017-09-28T16:35:04.643944: step 3205, loss 0.89716, acc 0.703125, learning_rate 0.00010001
2017-09-28T16:35:04.723078: step 3206, loss 0.695861, acc 0.703125, learning_rate 0.00010001
2017-09-28T16:35:04.803561: step 3207, loss 0.792509, acc 0.734375, learning_rate 0.00010001
2017-09-28T16:35:04.884624: step 3208, loss 0.81143, acc 0.6875, learning_rate 0.00010001
2017-09-28T16:35:04.967245: step 3209, loss 0.883645, acc 0.65625, learning_rate 0.00010001
2017-09-28T16:35:05.044742: step 3210, loss 0.729935, acc 0.671875, learning_rate 0.00010001
2017-09-28T16:35:05.123796: step 3211, loss 0.838272, acc 0.65625, learning_rate 0.00010001
2017-09-28T16:35:05.203125: step 3212, loss 0.861605, acc 0.625, learning_rate 0.00010001
2017-09-28T16:35:05.284092: step 3213, loss 0.725983, acc 0.75, learning_rate 0.00010001
2017-09-28T16:35:05.366806: step 3214, loss 0.881644, acc 0.53125, learning_rate 0.00010001
2017-09-28T16:35:05.452973: step 3215, loss 0.829971, acc 0.65625, learning_rate 0.00010001
2017-09-28T16:35:05.531344: step 3216, loss 0.744903, acc 0.703125, learning_rate 0.00010001
2017-09-28T16:35:05.611050: step 3217, loss 0.662868, acc 0.75, learning_rate 0.000100009
2017-09-28T16:35:05.692145: step 3218, loss 0.628687, acc 0.71875, learning_rate 0.000100009
2017-09-28T16:35:05.772623: step 3219, loss 0.83199, acc 0.703125, learning_rate 0.000100009
2017-09-28T16:35:05.857027: step 3220, loss 0.899693, acc 0.703125, learning_rate 0.000100009
2017-09-28T16:35:05.939474: step 3221, loss 0.673576, acc 0.796875, learning_rate 0.000100009
2017-09-28T16:35:06.021372: step 3222, loss 0.596368, acc 0.734375, learning_rate 0.000100009
2017-09-28T16:35:06.102018: step 3223, loss 0.764862, acc 0.65625, learning_rate 0.000100009
2017-09-28T16:35:06.187265: step 3224, loss 0.725183, acc 0.75, learning_rate 0.000100009
2017-09-28T16:35:06.267025: step 3225, loss 0.773738, acc 0.703125, learning_rate 0.000100009
2017-09-28T16:35:06.347112: step 3226, loss 0.851377, acc 0.671875, learning_rate 0.000100009
2017-09-28T16:35:06.426360: step 3227, loss 1.00713, acc 0.59375, learning_rate 0.000100009
2017-09-28T16:35:06.510657: step 3228, loss 0.812685, acc 0.734375, learning_rate 0.000100009
2017-09-28T16:35:06.590437: step 3229, loss 0.859403, acc 0.640625, learning_rate 0.000100009
2017-09-28T16:35:06.672137: step 3230, loss 0.822289, acc 0.65625, learning_rate 0.000100009
2017-09-28T16:35:06.754090: step 3231, loss 0.907372, acc 0.71875, learning_rate 0.000100009
2017-09-28T16:35:06.835102: step 3232, loss 0.842606, acc 0.609375, learning_rate 0.000100009
2017-09-28T16:35:06.917901: step 3233, loss 0.717014, acc 0.671875, learning_rate 0.000100009
2017-09-28T16:35:06.980221: step 3234, loss 0.822003, acc 0.686275, learning_rate 0.000100009
2017-09-28T16:35:07.061837: step 3235, loss 0.761105, acc 0.703125, learning_rate 0.000100009
2017-09-28T16:35:07.144141: step 3236, loss 0.696848, acc 0.71875, learning_rate 0.000100009
2017-09-28T16:35:07.222513: step 3237, loss 0.799044, acc 0.65625, learning_rate 0.000100009
2017-09-28T16:35:07.301439: step 3238, loss 0.832444, acc 0.671875, learning_rate 0.000100009
2017-09-28T16:35:07.382202: step 3239, loss 0.620753, acc 0.734375, learning_rate 0.000100009
2017-09-28T16:35:07.466439: step 3240, loss 0.647842, acc 0.765625, learning_rate 0.000100009

Evaluation:
2017-09-28T16:35:07.736252: step 3240, loss 0.824171, acc 0.664748

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-3240

2017-09-28T16:35:08.372839: step 3241, loss 0.73243, acc 0.71875, learning_rate 0.000100009
2017-09-28T16:35:08.453978: step 3242, loss 0.775199, acc 0.734375, learning_rate 0.000100009
2017-09-28T16:35:08.534716: step 3243, loss 0.771021, acc 0.671875, learning_rate 0.000100009
2017-09-28T16:35:08.617718: step 3244, loss 0.894184, acc 0.59375, learning_rate 0.000100009
2017-09-28T16:35:08.698062: step 3245, loss 0.693376, acc 0.671875, learning_rate 0.000100008
2017-09-28T16:35:08.777552: step 3246, loss 0.849477, acc 0.703125, learning_rate 0.000100008
2017-09-28T16:35:08.859242: step 3247, loss 0.714312, acc 0.75, learning_rate 0.000100008
2017-09-28T16:35:08.937225: step 3248, loss 0.761002, acc 0.75, learning_rate 0.000100008
2017-09-28T16:35:09.018577: step 3249, loss 0.789579, acc 0.71875, learning_rate 0.000100008
2017-09-28T16:35:09.100484: step 3250, loss 0.98081, acc 0.640625, learning_rate 0.000100008
2017-09-28T16:35:09.179964: step 3251, loss 0.841203, acc 0.609375, learning_rate 0.000100008
2017-09-28T16:35:09.262359: step 3252, loss 0.732182, acc 0.671875, learning_rate 0.000100008
2017-09-28T16:35:09.344289: step 3253, loss 0.686534, acc 0.6875, learning_rate 0.000100008
2017-09-28T16:35:09.429316: step 3254, loss 0.715297, acc 0.734375, learning_rate 0.000100008
2017-09-28T16:35:09.508760: step 3255, loss 0.775321, acc 0.671875, learning_rate 0.000100008
2017-09-28T16:35:09.589833: step 3256, loss 0.834414, acc 0.625, learning_rate 0.000100008
2017-09-28T16:35:09.669807: step 3257, loss 0.821597, acc 0.71875, learning_rate 0.000100008
2017-09-28T16:35:09.749650: step 3258, loss 0.681789, acc 0.78125, learning_rate 0.000100008
2017-09-28T16:35:09.832348: step 3259, loss 0.825719, acc 0.75, learning_rate 0.000100008
2017-09-28T16:35:09.914608: step 3260, loss 0.817125, acc 0.59375, learning_rate 0.000100008
2017-09-28T16:35:09.994917: step 3261, loss 0.744979, acc 0.6875, learning_rate 0.000100008
2017-09-28T16:35:10.072296: step 3262, loss 0.59587, acc 0.765625, learning_rate 0.000100008
2017-09-28T16:35:10.152221: step 3263, loss 0.824015, acc 0.65625, learning_rate 0.000100008
2017-09-28T16:35:10.233828: step 3264, loss 0.823908, acc 0.640625, learning_rate 0.000100008
2017-09-28T16:35:10.316385: step 3265, loss 0.801322, acc 0.71875, learning_rate 0.000100008
2017-09-28T16:35:10.400222: step 3266, loss 0.88267, acc 0.609375, learning_rate 0.000100008
2017-09-28T16:35:10.478628: step 3267, loss 0.786911, acc 0.6875, learning_rate 0.000100008
2017-09-28T16:35:10.559438: step 3268, loss 0.6917, acc 0.75, learning_rate 0.000100008
2017-09-28T16:35:10.640558: step 3269, loss 0.638356, acc 0.765625, learning_rate 0.000100008
2017-09-28T16:35:10.720641: step 3270, loss 0.860644, acc 0.625, learning_rate 0.000100008
2017-09-28T16:35:10.801462: step 3271, loss 0.867107, acc 0.6875, learning_rate 0.000100008
2017-09-28T16:35:10.883146: step 3272, loss 0.74313, acc 0.75, learning_rate 0.000100008
2017-09-28T16:35:10.963225: step 3273, loss 0.858801, acc 0.65625, learning_rate 0.000100008
2017-09-28T16:35:11.045786: step 3274, loss 0.801599, acc 0.640625, learning_rate 0.000100008
2017-09-28T16:35:11.127018: step 3275, loss 0.637928, acc 0.796875, learning_rate 0.000100007
2017-09-28T16:35:11.205742: step 3276, loss 0.740232, acc 0.671875, learning_rate 0.000100007
2017-09-28T16:35:11.287393: step 3277, loss 0.70153, acc 0.78125, learning_rate 0.000100007
2017-09-28T16:35:11.368904: step 3278, loss 1.05544, acc 0.546875, learning_rate 0.000100007
2017-09-28T16:35:11.454567: step 3279, loss 0.657495, acc 0.75, learning_rate 0.000100007
2017-09-28T16:35:11.536351: step 3280, loss 0.776496, acc 0.71875, learning_rate 0.000100007

Evaluation:
2017-09-28T16:35:11.812423: step 3280, loss 0.824336, acc 0.666187

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-3280

2017-09-28T16:35:12.305307: step 3281, loss 0.91202, acc 0.640625, learning_rate 0.000100007
2017-09-28T16:35:12.385761: step 3282, loss 0.906081, acc 0.59375, learning_rate 0.000100007
2017-09-28T16:35:12.469007: step 3283, loss 0.86414, acc 0.65625, learning_rate 0.000100007
2017-09-28T16:35:12.554491: step 3284, loss 0.761925, acc 0.65625, learning_rate 0.000100007
2017-09-28T16:35:12.641508: step 3285, loss 0.700871, acc 0.734375, learning_rate 0.000100007
2017-09-28T16:35:12.726694: step 3286, loss 0.662051, acc 0.796875, learning_rate 0.000100007
2017-09-28T16:35:12.811730: step 3287, loss 0.760743, acc 0.65625, learning_rate 0.000100007
2017-09-28T16:35:12.893088: step 3288, loss 0.856377, acc 0.640625, learning_rate 0.000100007
2017-09-28T16:35:12.979431: step 3289, loss 0.624693, acc 0.71875, learning_rate 0.000100007
2017-09-28T16:35:13.066446: step 3290, loss 0.596617, acc 0.8125, learning_rate 0.000100007
2017-09-28T16:35:13.149437: step 3291, loss 0.876154, acc 0.65625, learning_rate 0.000100007
2017-09-28T16:35:13.229649: step 3292, loss 0.704554, acc 0.71875, learning_rate 0.000100007
2017-09-28T16:35:13.310712: step 3293, loss 1.042, acc 0.546875, learning_rate 0.000100007
2017-09-28T16:35:13.396116: step 3294, loss 0.8752, acc 0.65625, learning_rate 0.000100007
2017-09-28T16:35:13.479884: step 3295, loss 0.682268, acc 0.8125, learning_rate 0.000100007
2017-09-28T16:35:13.564358: step 3296, loss 0.926472, acc 0.640625, learning_rate 0.000100007
2017-09-28T16:35:13.642408: step 3297, loss 0.717146, acc 0.703125, learning_rate 0.000100007
2017-09-28T16:35:13.721682: step 3298, loss 0.696118, acc 0.6875, learning_rate 0.000100007
2017-09-28T16:35:13.802341: step 3299, loss 0.982097, acc 0.59375, learning_rate 0.000100007
2017-09-28T16:35:13.888884: step 3300, loss 0.888842, acc 0.671875, learning_rate 0.000100007
2017-09-28T16:35:13.970780: step 3301, loss 0.807562, acc 0.6875, learning_rate 0.000100007
2017-09-28T16:35:14.050507: step 3302, loss 0.937237, acc 0.625, learning_rate 0.000100007
2017-09-28T16:35:14.136334: step 3303, loss 0.874905, acc 0.6875, learning_rate 0.000100007
2017-09-28T16:35:14.216198: step 3304, loss 0.609496, acc 0.765625, learning_rate 0.000100007
2017-09-28T16:35:14.295928: step 3305, loss 0.602819, acc 0.75, learning_rate 0.000100007
2017-09-28T16:35:14.380511: step 3306, loss 0.857839, acc 0.65625, learning_rate 0.000100007
2017-09-28T16:35:14.463651: step 3307, loss 0.591281, acc 0.75, learning_rate 0.000100007
2017-09-28T16:35:14.545404: step 3308, loss 0.772351, acc 0.734375, learning_rate 0.000100007
2017-09-28T16:35:14.626479: step 3309, loss 0.720685, acc 0.765625, learning_rate 0.000100007
2017-09-28T16:35:14.707030: step 3310, loss 0.836048, acc 0.671875, learning_rate 0.000100006
2017-09-28T16:35:14.787499: step 3311, loss 0.734604, acc 0.671875, learning_rate 0.000100006
2017-09-28T16:35:14.868687: step 3312, loss 0.649395, acc 0.703125, learning_rate 0.000100006
2017-09-28T16:35:14.951998: step 3313, loss 0.889997, acc 0.59375, learning_rate 0.000100006
2017-09-28T16:35:15.031795: step 3314, loss 0.845012, acc 0.734375, learning_rate 0.000100006
2017-09-28T16:35:15.115546: step 3315, loss 0.773411, acc 0.75, learning_rate 0.000100006
2017-09-28T16:35:15.194434: step 3316, loss 0.83926, acc 0.625, learning_rate 0.000100006
2017-09-28T16:35:15.275568: step 3317, loss 0.706075, acc 0.671875, learning_rate 0.000100006
2017-09-28T16:35:15.355578: step 3318, loss 0.92164, acc 0.625, learning_rate 0.000100006
2017-09-28T16:35:15.438076: step 3319, loss 0.985948, acc 0.671875, learning_rate 0.000100006
2017-09-28T16:35:15.515654: step 3320, loss 0.763595, acc 0.703125, learning_rate 0.000100006

Evaluation:
2017-09-28T16:35:15.788986: step 3320, loss 0.819802, acc 0.670504

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-3320

2017-09-28T16:35:16.346059: step 3321, loss 0.897719, acc 0.671875, learning_rate 0.000100006
2017-09-28T16:35:16.427820: step 3322, loss 0.730137, acc 0.703125, learning_rate 0.000100006
2017-09-28T16:35:16.510110: step 3323, loss 0.776755, acc 0.65625, learning_rate 0.000100006
2017-09-28T16:35:16.590975: step 3324, loss 0.823627, acc 0.625, learning_rate 0.000100006
2017-09-28T16:35:16.671456: step 3325, loss 0.597693, acc 0.8125, learning_rate 0.000100006
2017-09-28T16:35:16.751897: step 3326, loss 0.799926, acc 0.6875, learning_rate 0.000100006
2017-09-28T16:35:16.833964: step 3327, loss 0.699074, acc 0.75, learning_rate 0.000100006
2017-09-28T16:35:16.916723: step 3328, loss 0.767771, acc 0.6875, learning_rate 0.000100006
2017-09-28T16:35:16.998416: step 3329, loss 1.09853, acc 0.53125, learning_rate 0.000100006
2017-09-28T16:35:17.077373: step 3330, loss 0.937009, acc 0.625, learning_rate 0.000100006
2017-09-28T16:35:17.159283: step 3331, loss 0.705315, acc 0.765625, learning_rate 0.000100006
2017-09-28T16:35:17.223670: step 3332, loss 0.696981, acc 0.764706, learning_rate 0.000100006
2017-09-28T16:35:17.306951: step 3333, loss 0.746696, acc 0.65625, learning_rate 0.000100006
2017-09-28T16:35:17.386669: step 3334, loss 0.754482, acc 0.703125, learning_rate 0.000100006
2017-09-28T16:35:17.466980: step 3335, loss 0.653689, acc 0.765625, learning_rate 0.000100006
2017-09-28T16:35:17.546958: step 3336, loss 0.77635, acc 0.734375, learning_rate 0.000100006
2017-09-28T16:35:17.627129: step 3337, loss 0.67319, acc 0.734375, learning_rate 0.000100006
2017-09-28T16:35:17.706920: step 3338, loss 0.817611, acc 0.703125, learning_rate 0.000100006
2017-09-28T16:35:17.787243: step 3339, loss 0.749787, acc 0.6875, learning_rate 0.000100006
2017-09-28T16:35:17.867829: step 3340, loss 0.788824, acc 0.671875, learning_rate 0.000100006
2017-09-28T16:35:17.949382: step 3341, loss 0.803007, acc 0.640625, learning_rate 0.000100006
2017-09-28T16:35:18.037789: step 3342, loss 0.842992, acc 0.71875, learning_rate 0.000100006
2017-09-28T16:35:18.121682: step 3343, loss 0.758092, acc 0.703125, learning_rate 0.000100006
2017-09-28T16:35:18.203438: step 3344, loss 0.851404, acc 0.625, learning_rate 0.000100006
2017-09-28T16:35:18.282177: step 3345, loss 0.93569, acc 0.625, learning_rate 0.000100006
2017-09-28T16:35:18.363148: step 3346, loss 0.730134, acc 0.65625, learning_rate 0.000100006
2017-09-28T16:35:18.445569: step 3347, loss 0.713507, acc 0.71875, learning_rate 0.000100006
2017-09-28T16:35:18.528817: step 3348, loss 0.784843, acc 0.71875, learning_rate 0.000100006
2017-09-28T16:35:18.610874: step 3349, loss 0.798924, acc 0.71875, learning_rate 0.000100006
2017-09-28T16:35:18.694297: step 3350, loss 0.958073, acc 0.671875, learning_rate 0.000100006
2017-09-28T16:35:18.775984: step 3351, loss 0.657674, acc 0.703125, learning_rate 0.000100005
2017-09-28T16:35:18.858388: step 3352, loss 0.844962, acc 0.640625, learning_rate 0.000100005
2017-09-28T16:35:18.940102: step 3353, loss 0.644374, acc 0.71875, learning_rate 0.000100005
2017-09-28T16:35:19.021831: step 3354, loss 0.839885, acc 0.640625, learning_rate 0.000100005
2017-09-28T16:35:19.104133: step 3355, loss 0.810276, acc 0.625, learning_rate 0.000100005
2017-09-28T16:35:19.185377: step 3356, loss 0.765571, acc 0.625, learning_rate 0.000100005
2017-09-28T16:35:19.268220: step 3357, loss 0.763385, acc 0.703125, learning_rate 0.000100005
2017-09-28T16:35:19.350077: step 3358, loss 0.801657, acc 0.59375, learning_rate 0.000100005
2017-09-28T16:35:19.432564: step 3359, loss 0.619137, acc 0.78125, learning_rate 0.000100005
2017-09-28T16:35:19.509490: step 3360, loss 0.610977, acc 0.765625, learning_rate 0.000100005

Evaluation:
2017-09-28T16:35:19.776477: step 3360, loss 0.820786, acc 0.669065

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-3360

2017-09-28T16:35:20.334075: step 3361, loss 0.851712, acc 0.71875, learning_rate 0.000100005
2017-09-28T16:35:20.419597: step 3362, loss 0.831434, acc 0.609375, learning_rate 0.000100005
2017-09-28T16:35:20.500613: step 3363, loss 0.695661, acc 0.75, learning_rate 0.000100005
2017-09-28T16:35:20.582661: step 3364, loss 0.730559, acc 0.703125, learning_rate 0.000100005
2017-09-28T16:35:20.663768: step 3365, loss 0.796346, acc 0.671875, learning_rate 0.000100005
2017-09-28T16:35:20.746018: step 3366, loss 0.778295, acc 0.703125, learning_rate 0.000100005
2017-09-28T16:35:20.827184: step 3367, loss 0.737561, acc 0.703125, learning_rate 0.000100005
2017-09-28T16:35:20.908646: step 3368, loss 0.675184, acc 0.78125, learning_rate 0.000100005
2017-09-28T16:35:20.989470: step 3369, loss 0.78552, acc 0.703125, learning_rate 0.000100005
2017-09-28T16:35:21.070439: step 3370, loss 0.554639, acc 0.796875, learning_rate 0.000100005
2017-09-28T16:35:21.151343: step 3371, loss 0.681386, acc 0.734375, learning_rate 0.000100005
2017-09-28T16:35:21.233342: step 3372, loss 0.985708, acc 0.671875, learning_rate 0.000100005
2017-09-28T16:35:21.314066: step 3373, loss 0.750011, acc 0.734375, learning_rate 0.000100005
2017-09-28T16:35:21.396483: step 3374, loss 0.797921, acc 0.625, learning_rate 0.000100005
2017-09-28T16:35:21.476087: step 3375, loss 0.71906, acc 0.734375, learning_rate 0.000100005
2017-09-28T16:35:21.556709: step 3376, loss 0.69298, acc 0.734375, learning_rate 0.000100005
2017-09-28T16:35:21.641075: step 3377, loss 0.629303, acc 0.8125, learning_rate 0.000100005
2017-09-28T16:35:21.724178: step 3378, loss 0.73454, acc 0.71875, learning_rate 0.000100005
2017-09-28T16:35:21.808925: step 3379, loss 0.890374, acc 0.59375, learning_rate 0.000100005
2017-09-28T16:35:21.890202: step 3380, loss 0.728679, acc 0.703125, learning_rate 0.000100005
2017-09-28T16:35:21.971636: step 3381, loss 0.654537, acc 0.75, learning_rate 0.000100005
2017-09-28T16:35:22.052099: step 3382, loss 0.787109, acc 0.71875, learning_rate 0.000100005
2017-09-28T16:35:22.134516: step 3383, loss 0.752303, acc 0.71875, learning_rate 0.000100005
2017-09-28T16:35:22.216109: step 3384, loss 0.993165, acc 0.640625, learning_rate 0.000100005
2017-09-28T16:35:22.298265: step 3385, loss 0.760341, acc 0.6875, learning_rate 0.000100005
2017-09-28T16:35:22.381941: step 3386, loss 0.664452, acc 0.75, learning_rate 0.000100005
2017-09-28T16:35:22.466047: step 3387, loss 0.752521, acc 0.671875, learning_rate 0.000100005
2017-09-28T16:35:22.546363: step 3388, loss 0.850509, acc 0.65625, learning_rate 0.000100005
2017-09-28T16:35:22.628268: step 3389, loss 0.779233, acc 0.640625, learning_rate 0.000100005
2017-09-28T16:35:22.712118: step 3390, loss 0.951717, acc 0.609375, learning_rate 0.000100005
2017-09-28T16:35:22.794591: step 3391, loss 0.814174, acc 0.640625, learning_rate 0.000100005
2017-09-28T16:35:22.878603: step 3392, loss 0.75946, acc 0.734375, learning_rate 0.000100005
2017-09-28T16:35:22.961984: step 3393, loss 0.83803, acc 0.65625, learning_rate 0.000100005
2017-09-28T16:35:23.045821: step 3394, loss 0.860678, acc 0.703125, learning_rate 0.000100005
2017-09-28T16:35:23.131574: step 3395, loss 0.740948, acc 0.6875, learning_rate 0.000100005
2017-09-28T16:35:23.212787: step 3396, loss 0.721968, acc 0.734375, learning_rate 0.000100005
2017-09-28T16:35:23.294101: step 3397, loss 0.687098, acc 0.71875, learning_rate 0.000100005
2017-09-28T16:35:23.378973: step 3398, loss 0.792883, acc 0.65625, learning_rate 0.000100005
2017-09-28T16:35:23.458496: step 3399, loss 0.800388, acc 0.734375, learning_rate 0.000100005
2017-09-28T16:35:23.540262: step 3400, loss 0.806732, acc 0.703125, learning_rate 0.000100004

Evaluation:
2017-09-28T16:35:23.804239: step 3400, loss 0.818621, acc 0.669065

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-3400

2017-09-28T16:35:24.429494: step 3401, loss 0.715619, acc 0.6875, learning_rate 0.000100004
2017-09-28T16:35:24.511820: step 3402, loss 0.69537, acc 0.75, learning_rate 0.000100004
2017-09-28T16:35:24.591548: step 3403, loss 0.886542, acc 0.671875, learning_rate 0.000100004
2017-09-28T16:35:24.675671: step 3404, loss 0.869949, acc 0.609375, learning_rate 0.000100004
2017-09-28T16:35:24.757984: step 3405, loss 0.835375, acc 0.671875, learning_rate 0.000100004
2017-09-28T16:35:24.841646: step 3406, loss 0.902384, acc 0.671875, learning_rate 0.000100004
2017-09-28T16:35:24.918234: step 3407, loss 0.954588, acc 0.59375, learning_rate 0.000100004
2017-09-28T16:35:24.998464: step 3408, loss 0.732259, acc 0.671875, learning_rate 0.000100004
2017-09-28T16:35:25.082078: step 3409, loss 0.779527, acc 0.6875, learning_rate 0.000100004
2017-09-28T16:35:25.163610: step 3410, loss 0.809932, acc 0.625, learning_rate 0.000100004
2017-09-28T16:35:25.251453: step 3411, loss 0.892401, acc 0.6875, learning_rate 0.000100004
2017-09-28T16:35:25.330351: step 3412, loss 0.773122, acc 0.640625, learning_rate 0.000100004
2017-09-28T16:35:25.418489: step 3413, loss 0.857566, acc 0.65625, learning_rate 0.000100004
2017-09-28T16:35:25.497865: step 3414, loss 0.719091, acc 0.796875, learning_rate 0.000100004
2017-09-28T16:35:25.584026: step 3415, loss 0.66638, acc 0.78125, learning_rate 0.000100004
2017-09-28T16:35:25.668103: step 3416, loss 0.954812, acc 0.59375, learning_rate 0.000100004
2017-09-28T16:35:25.750225: step 3417, loss 0.797284, acc 0.671875, learning_rate 0.000100004
2017-09-28T16:35:25.834213: step 3418, loss 0.658832, acc 0.734375, learning_rate 0.000100004
2017-09-28T16:35:25.918502: step 3419, loss 0.676221, acc 0.765625, learning_rate 0.000100004
2017-09-28T16:35:25.999382: step 3420, loss 0.724763, acc 0.6875, learning_rate 0.000100004
2017-09-28T16:35:26.083094: step 3421, loss 0.919275, acc 0.59375, learning_rate 0.000100004
2017-09-28T16:35:26.168343: step 3422, loss 0.865582, acc 0.65625, learning_rate 0.000100004
2017-09-28T16:35:26.251851: step 3423, loss 0.777488, acc 0.671875, learning_rate 0.000100004
2017-09-28T16:35:26.334279: step 3424, loss 0.797471, acc 0.640625, learning_rate 0.000100004
2017-09-28T16:35:26.418609: step 3425, loss 0.737939, acc 0.71875, learning_rate 0.000100004
2017-09-28T16:35:26.500487: step 3426, loss 0.626706, acc 0.796875, learning_rate 0.000100004
2017-09-28T16:35:26.581880: step 3427, loss 0.892972, acc 0.609375, learning_rate 0.000100004
2017-09-28T16:35:26.662947: step 3428, loss 0.863195, acc 0.65625, learning_rate 0.000100004
2017-09-28T16:35:26.746444: step 3429, loss 0.727316, acc 0.71875, learning_rate 0.000100004
2017-09-28T16:35:26.810614: step 3430, loss 0.836588, acc 0.72549, learning_rate 0.000100004
2017-09-28T16:35:26.891290: step 3431, loss 0.900051, acc 0.5625, learning_rate 0.000100004
2017-09-28T16:35:26.973558: step 3432, loss 0.783659, acc 0.78125, learning_rate 0.000100004
2017-09-28T16:35:27.054988: step 3433, loss 0.826315, acc 0.6875, learning_rate 0.000100004
2017-09-28T16:35:27.140015: step 3434, loss 0.816017, acc 0.65625, learning_rate 0.000100004
2017-09-28T16:35:27.223118: step 3435, loss 0.783013, acc 0.65625, learning_rate 0.000100004
2017-09-28T16:35:27.306319: step 3436, loss 0.663736, acc 0.75, learning_rate 0.000100004
2017-09-28T16:35:27.391639: step 3437, loss 0.87036, acc 0.625, learning_rate 0.000100004
2017-09-28T16:35:27.473046: step 3438, loss 0.732104, acc 0.65625, learning_rate 0.000100004
2017-09-28T16:35:27.552861: step 3439, loss 0.886375, acc 0.65625, learning_rate 0.000100004
2017-09-28T16:35:27.633405: step 3440, loss 0.664883, acc 0.734375, learning_rate 0.000100004

Evaluation:
2017-09-28T16:35:27.896025: step 3440, loss 0.818595, acc 0.667626

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-3440

2017-09-28T16:35:28.395714: step 3441, loss 0.684764, acc 0.734375, learning_rate 0.000100004
2017-09-28T16:35:28.478250: step 3442, loss 0.774818, acc 0.65625, learning_rate 0.000100004
2017-09-28T16:35:28.559632: step 3443, loss 0.76833, acc 0.703125, learning_rate 0.000100004
2017-09-28T16:35:28.642482: step 3444, loss 0.85964, acc 0.65625, learning_rate 0.000100004
2017-09-28T16:35:28.722136: step 3445, loss 0.74103, acc 0.71875, learning_rate 0.000100004
2017-09-28T16:35:28.803893: step 3446, loss 0.647057, acc 0.703125, learning_rate 0.000100004
2017-09-28T16:35:28.885061: step 3447, loss 0.715663, acc 0.765625, learning_rate 0.000100004
2017-09-28T16:35:28.967619: step 3448, loss 0.754444, acc 0.671875, learning_rate 0.000100004
2017-09-28T16:35:29.047563: step 3449, loss 0.810767, acc 0.671875, learning_rate 0.000100004
2017-09-28T16:35:29.130528: step 3450, loss 0.683829, acc 0.671875, learning_rate 0.000100004
2017-09-28T16:35:29.209469: step 3451, loss 0.794578, acc 0.703125, learning_rate 0.000100004
2017-09-28T16:35:29.289877: step 3452, loss 0.762638, acc 0.71875, learning_rate 0.000100004
2017-09-28T16:35:29.372773: step 3453, loss 0.777276, acc 0.6875, learning_rate 0.000100004
2017-09-28T16:35:29.458544: step 3454, loss 0.653471, acc 0.75, learning_rate 0.000100004
2017-09-28T16:35:29.542319: step 3455, loss 0.873074, acc 0.640625, learning_rate 0.000100004
2017-09-28T16:35:29.626956: step 3456, loss 0.799691, acc 0.65625, learning_rate 0.000100004
2017-09-28T16:35:29.710109: step 3457, loss 0.806852, acc 0.640625, learning_rate 0.000100004
2017-09-28T16:35:29.791426: step 3458, loss 0.593281, acc 0.765625, learning_rate 0.000100004
2017-09-28T16:35:29.875481: step 3459, loss 0.730866, acc 0.6875, learning_rate 0.000100004
2017-09-28T16:35:29.952745: step 3460, loss 0.901104, acc 0.578125, learning_rate 0.000100004
2017-09-28T16:35:30.035498: step 3461, loss 0.955281, acc 0.703125, learning_rate 0.000100004
2017-09-28T16:35:30.114271: step 3462, loss 0.725573, acc 0.703125, learning_rate 0.000100003
2017-09-28T16:35:30.196823: step 3463, loss 0.87325, acc 0.625, learning_rate 0.000100003
2017-09-28T16:35:30.276220: step 3464, loss 0.689586, acc 0.703125, learning_rate 0.000100003
2017-09-28T16:35:30.359070: step 3465, loss 0.756083, acc 0.65625, learning_rate 0.000100003
2017-09-28T16:35:30.443716: step 3466, loss 0.664401, acc 0.6875, learning_rate 0.000100003
2017-09-28T16:35:30.525934: step 3467, loss 0.672472, acc 0.75, learning_rate 0.000100003
2017-09-28T16:35:30.612363: step 3468, loss 0.891997, acc 0.671875, learning_rate 0.000100003
2017-09-28T16:35:30.693570: step 3469, loss 0.810755, acc 0.71875, learning_rate 0.000100003
2017-09-28T16:35:30.773483: step 3470, loss 0.892163, acc 0.59375, learning_rate 0.000100003
2017-09-28T16:35:30.855936: step 3471, loss 0.728333, acc 0.65625, learning_rate 0.000100003
2017-09-28T16:35:30.938384: step 3472, loss 0.955493, acc 0.625, learning_rate 0.000100003
2017-09-28T16:35:31.016221: step 3473, loss 0.972884, acc 0.59375, learning_rate 0.000100003
2017-09-28T16:35:31.102361: step 3474, loss 0.649119, acc 0.796875, learning_rate 0.000100003
2017-09-28T16:35:31.183295: step 3475, loss 0.768823, acc 0.6875, learning_rate 0.000100003
2017-09-28T16:35:31.262722: step 3476, loss 0.731422, acc 0.671875, learning_rate 0.000100003
2017-09-28T16:35:31.343339: step 3477, loss 0.747688, acc 0.6875, learning_rate 0.000100003
2017-09-28T16:35:31.425853: step 3478, loss 0.607031, acc 0.78125, learning_rate 0.000100003
2017-09-28T16:35:31.507519: step 3479, loss 0.761461, acc 0.6875, learning_rate 0.000100003
2017-09-28T16:35:31.590362: step 3480, loss 0.759629, acc 0.671875, learning_rate 0.000100003

Evaluation:
2017-09-28T16:35:31.868519: step 3480, loss 0.817161, acc 0.669065

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-3480

2017-09-28T16:35:32.446335: step 3481, loss 0.767723, acc 0.640625, learning_rate 0.000100003
2017-09-28T16:35:32.535567: step 3482, loss 0.740434, acc 0.671875, learning_rate 0.000100003
2017-09-28T16:35:32.624763: step 3483, loss 0.814548, acc 0.734375, learning_rate 0.000100003
2017-09-28T16:35:32.711051: step 3484, loss 0.732633, acc 0.734375, learning_rate 0.000100003
2017-09-28T16:35:32.800095: step 3485, loss 0.73131, acc 0.6875, learning_rate 0.000100003
2017-09-28T16:35:32.891279: step 3486, loss 0.82451, acc 0.703125, learning_rate 0.000100003
2017-09-28T16:35:32.977099: step 3487, loss 0.798884, acc 0.65625, learning_rate 0.000100003
2017-09-28T16:35:33.062107: step 3488, loss 0.95098, acc 0.578125, learning_rate 0.000100003
2017-09-28T16:35:33.152662: step 3489, loss 0.773817, acc 0.671875, learning_rate 0.000100003
2017-09-28T16:35:33.241810: step 3490, loss 0.814939, acc 0.71875, learning_rate 0.000100003
2017-09-28T16:35:33.329059: step 3491, loss 0.815449, acc 0.671875, learning_rate 0.000100003
2017-09-28T16:35:33.416814: step 3492, loss 0.879312, acc 0.65625, learning_rate 0.000100003
2017-09-28T16:35:33.501772: step 3493, loss 0.70624, acc 0.734375, learning_rate 0.000100003
2017-09-28T16:35:33.590431: step 3494, loss 0.723023, acc 0.6875, learning_rate 0.000100003
2017-09-28T16:35:33.680521: step 3495, loss 0.957257, acc 0.625, learning_rate 0.000100003
2017-09-28T16:35:33.766629: step 3496, loss 0.722936, acc 0.703125, learning_rate 0.000100003
2017-09-28T16:35:33.862245: step 3497, loss 0.74294, acc 0.703125, learning_rate 0.000100003
2017-09-28T16:35:33.949466: step 3498, loss 0.783508, acc 0.703125, learning_rate 0.000100003
2017-09-28T16:35:34.036325: step 3499, loss 0.945212, acc 0.609375, learning_rate 0.000100003
2017-09-28T16:35:34.126982: step 3500, loss 0.744892, acc 0.671875, learning_rate 0.000100003
2017-09-28T16:35:34.212816: step 3501, loss 0.577972, acc 0.8125, learning_rate 0.000100003
2017-09-28T16:35:34.293881: step 3502, loss 0.729304, acc 0.65625, learning_rate 0.000100003
2017-09-28T16:35:34.373119: step 3503, loss 0.942356, acc 0.59375, learning_rate 0.000100003
2017-09-28T16:35:34.458104: step 3504, loss 0.661902, acc 0.71875, learning_rate 0.000100003
2017-09-28T16:35:34.559411: step 3505, loss 0.713771, acc 0.703125, learning_rate 0.000100003
2017-09-28T16:35:34.661782: step 3506, loss 0.657537, acc 0.78125, learning_rate 0.000100003
2017-09-28T16:35:34.754255: step 3507, loss 0.6979, acc 0.734375, learning_rate 0.000100003
2017-09-28T16:35:34.852637: step 3508, loss 0.891462, acc 0.625, learning_rate 0.000100003
2017-09-28T16:35:34.961036: step 3509, loss 0.708163, acc 0.734375, learning_rate 0.000100003
2017-09-28T16:35:35.053489: step 3510, loss 0.732996, acc 0.671875, learning_rate 0.000100003
2017-09-28T16:35:35.139226: step 3511, loss 0.612425, acc 0.75, learning_rate 0.000100003
2017-09-28T16:35:35.225978: step 3512, loss 0.864247, acc 0.625, learning_rate 0.000100003
2017-09-28T16:35:35.309794: step 3513, loss 0.832747, acc 0.703125, learning_rate 0.000100003
2017-09-28T16:35:35.397890: step 3514, loss 0.684087, acc 0.734375, learning_rate 0.000100003
2017-09-28T16:35:35.480799: step 3515, loss 0.786721, acc 0.6875, learning_rate 0.000100003
2017-09-28T16:35:35.565908: step 3516, loss 0.635434, acc 0.75, learning_rate 0.000100003
2017-09-28T16:35:35.652180: step 3517, loss 0.835286, acc 0.640625, learning_rate 0.000100003
2017-09-28T16:35:35.734032: step 3518, loss 0.780489, acc 0.71875, learning_rate 0.000100003
2017-09-28T16:35:35.813983: step 3519, loss 0.740904, acc 0.703125, learning_rate 0.000100003
2017-09-28T16:35:35.893306: step 3520, loss 0.851142, acc 0.6875, learning_rate 0.000100003

Evaluation:
2017-09-28T16:35:36.171784: step 3520, loss 0.818197, acc 0.673381

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-3520

2017-09-28T16:35:36.769870: step 3521, loss 0.717072, acc 0.75, learning_rate 0.000100003
2017-09-28T16:35:36.879443: step 3522, loss 0.868616, acc 0.609375, learning_rate 0.000100003
2017-09-28T16:35:36.977733: step 3523, loss 0.691486, acc 0.71875, learning_rate 0.000100003
2017-09-28T16:35:37.073162: step 3524, loss 0.893281, acc 0.5625, learning_rate 0.000100003
2017-09-28T16:35:37.155906: step 3525, loss 0.946408, acc 0.578125, learning_rate 0.000100003
2017-09-28T16:35:37.243157: step 3526, loss 0.854852, acc 0.65625, learning_rate 0.000100003
2017-09-28T16:35:37.329705: step 3527, loss 0.670873, acc 0.765625, learning_rate 0.000100003
2017-09-28T16:35:37.397727: step 3528, loss 0.667615, acc 0.745098, learning_rate 0.000100003
2017-09-28T16:35:37.479750: step 3529, loss 0.790111, acc 0.671875, learning_rate 0.000100003
2017-09-28T16:35:37.565528: step 3530, loss 0.634409, acc 0.703125, learning_rate 0.000100003
2017-09-28T16:35:37.648947: step 3531, loss 0.837903, acc 0.671875, learning_rate 0.000100003
2017-09-28T16:35:37.731826: step 3532, loss 0.826612, acc 0.671875, learning_rate 0.000100003
2017-09-28T16:35:37.814468: step 3533, loss 0.765981, acc 0.65625, learning_rate 0.000100003
2017-09-28T16:35:37.898099: step 3534, loss 0.741723, acc 0.734375, learning_rate 0.000100003
2017-09-28T16:35:37.975636: step 3535, loss 0.623165, acc 0.75, learning_rate 0.000100003
2017-09-28T16:35:38.057339: step 3536, loss 0.798852, acc 0.703125, learning_rate 0.000100003
2017-09-28T16:35:38.145176: step 3537, loss 0.822696, acc 0.65625, learning_rate 0.000100003
2017-09-28T16:35:38.231330: step 3538, loss 0.958615, acc 0.625, learning_rate 0.000100003
2017-09-28T16:35:38.315888: step 3539, loss 0.936848, acc 0.578125, learning_rate 0.000100003
2017-09-28T16:35:38.399726: step 3540, loss 0.604524, acc 0.734375, learning_rate 0.000100003
2017-09-28T16:35:38.481165: step 3541, loss 0.835463, acc 0.703125, learning_rate 0.000100003
2017-09-28T16:35:38.563870: step 3542, loss 0.865461, acc 0.5625, learning_rate 0.000100003
2017-09-28T16:35:38.642965: step 3543, loss 0.866157, acc 0.6875, learning_rate 0.000100003
2017-09-28T16:35:38.726919: step 3544, loss 0.786591, acc 0.703125, learning_rate 0.000100002
2017-09-28T16:35:38.819408: step 3545, loss 0.792665, acc 0.703125, learning_rate 0.000100002
2017-09-28T16:35:38.902780: step 3546, loss 0.691388, acc 0.71875, learning_rate 0.000100002
2017-09-28T16:35:38.993256: step 3547, loss 0.857624, acc 0.6875, learning_rate 0.000100002
2017-09-28T16:35:39.077876: step 3548, loss 0.738821, acc 0.6875, learning_rate 0.000100002
2017-09-28T16:35:39.161640: step 3549, loss 0.811756, acc 0.6875, learning_rate 0.000100002
2017-09-28T16:35:39.248336: step 3550, loss 0.758901, acc 0.65625, learning_rate 0.000100002
2017-09-28T16:35:39.332635: step 3551, loss 0.838919, acc 0.703125, learning_rate 0.000100002
2017-09-28T16:35:39.413103: step 3552, loss 0.83132, acc 0.6875, learning_rate 0.000100002
2017-09-28T16:35:39.497238: step 3553, loss 0.604205, acc 0.75, learning_rate 0.000100002
2017-09-28T16:35:39.582894: step 3554, loss 0.916048, acc 0.578125, learning_rate 0.000100002
2017-09-28T16:35:39.663681: step 3555, loss 0.828681, acc 0.65625, learning_rate 0.000100002
2017-09-28T16:35:39.754611: step 3556, loss 0.783709, acc 0.671875, learning_rate 0.000100002
2017-09-28T16:35:39.845710: step 3557, loss 0.728276, acc 0.6875, learning_rate 0.000100002
2017-09-28T16:35:39.930821: step 3558, loss 0.797141, acc 0.6875, learning_rate 0.000100002
2017-09-28T16:35:40.017276: step 3559, loss 0.672269, acc 0.71875, learning_rate 0.000100002
2017-09-28T16:35:40.100584: step 3560, loss 0.875924, acc 0.65625, learning_rate 0.000100002

Evaluation:
2017-09-28T16:35:40.364200: step 3560, loss 0.815606, acc 0.669065

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-3560

2017-09-28T16:35:41.000807: step 3561, loss 0.729668, acc 0.71875, learning_rate 0.000100002
2017-09-28T16:35:41.086551: step 3562, loss 0.91703, acc 0.59375, learning_rate 0.000100002
2017-09-28T16:35:41.166260: step 3563, loss 0.79277, acc 0.734375, learning_rate 0.000100002
2017-09-28T16:35:41.247676: step 3564, loss 0.677718, acc 0.765625, learning_rate 0.000100002
2017-09-28T16:35:41.334383: step 3565, loss 0.710921, acc 0.734375, learning_rate 0.000100002
2017-09-28T16:35:41.416455: step 3566, loss 0.873429, acc 0.671875, learning_rate 0.000100002
2017-09-28T16:35:41.504926: step 3567, loss 0.928267, acc 0.609375, learning_rate 0.000100002
2017-09-28T16:35:41.593064: step 3568, loss 0.623605, acc 0.78125, learning_rate 0.000100002
2017-09-28T16:35:41.684326: step 3569, loss 0.670727, acc 0.71875, learning_rate 0.000100002
2017-09-28T16:35:41.770894: step 3570, loss 0.751076, acc 0.65625, learning_rate 0.000100002
2017-09-28T16:35:41.861753: step 3571, loss 0.95801, acc 0.578125, learning_rate 0.000100002
2017-09-28T16:35:41.954468: step 3572, loss 0.725551, acc 0.671875, learning_rate 0.000100002
2017-09-28T16:35:42.032687: step 3573, loss 0.624103, acc 0.765625, learning_rate 0.000100002
2017-09-28T16:35:42.130240: step 3574, loss 0.852661, acc 0.6875, learning_rate 0.000100002
2017-09-28T16:35:42.227542: step 3575, loss 0.722322, acc 0.625, learning_rate 0.000100002
2017-09-28T16:35:42.319884: step 3576, loss 0.63591, acc 0.734375, learning_rate 0.000100002
2017-09-28T16:35:42.410791: step 3577, loss 0.677217, acc 0.6875, learning_rate 0.000100002
2017-09-28T16:35:42.512782: step 3578, loss 0.817566, acc 0.65625, learning_rate 0.000100002
2017-09-28T16:35:42.613275: step 3579, loss 0.824477, acc 0.65625, learning_rate 0.000100002
2017-09-28T16:35:42.716315: step 3580, loss 0.821565, acc 0.640625, learning_rate 0.000100002
2017-09-28T16:35:42.821736: step 3581, loss 0.629123, acc 0.765625, learning_rate 0.000100002
2017-09-28T16:35:42.923079: step 3582, loss 0.634421, acc 0.796875, learning_rate 0.000100002
2017-09-28T16:35:43.016054: step 3583, loss 0.844887, acc 0.6875, learning_rate 0.000100002
2017-09-28T16:35:43.109173: step 3584, loss 0.85936, acc 0.609375, learning_rate 0.000100002
2017-09-28T16:35:43.212216: step 3585, loss 0.63092, acc 0.78125, learning_rate 0.000100002
2017-09-28T16:35:43.320490: step 3586, loss 0.945897, acc 0.6875, learning_rate 0.000100002
2017-09-28T16:35:43.417698: step 3587, loss 0.719079, acc 0.6875, learning_rate 0.000100002
2017-09-28T16:35:43.514641: step 3588, loss 0.705827, acc 0.703125, learning_rate 0.000100002
2017-09-28T16:35:43.610916: step 3589, loss 0.673004, acc 0.71875, learning_rate 0.000100002
2017-09-28T16:35:43.725899: step 3590, loss 0.919742, acc 0.625, learning_rate 0.000100002
2017-09-28T16:35:43.816364: step 3591, loss 0.617517, acc 0.75, learning_rate 0.000100002
2017-09-28T16:35:43.905301: step 3592, loss 0.966623, acc 0.625, learning_rate 0.000100002
2017-09-28T16:35:43.996604: step 3593, loss 0.66616, acc 0.6875, learning_rate 0.000100002
2017-09-28T16:35:44.087906: step 3594, loss 0.70482, acc 0.75, learning_rate 0.000100002
2017-09-28T16:35:44.174558: step 3595, loss 0.801597, acc 0.6875, learning_rate 0.000100002
2017-09-28T16:35:44.265266: step 3596, loss 0.667456, acc 0.734375, learning_rate 0.000100002
2017-09-28T16:35:44.367406: step 3597, loss 0.870914, acc 0.53125, learning_rate 0.000100002
2017-09-28T16:35:44.456181: step 3598, loss 0.795753, acc 0.671875, learning_rate 0.000100002
2017-09-28T16:35:44.539879: step 3599, loss 0.835805, acc 0.65625, learning_rate 0.000100002
2017-09-28T16:35:44.619355: step 3600, loss 0.630684, acc 0.765625, learning_rate 0.000100002

Evaluation:
2017-09-28T16:35:44.901325: step 3600, loss 0.815279, acc 0.669065

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-3600

2017-09-28T16:35:45.427114: step 3601, loss 0.947679, acc 0.65625, learning_rate 0.000100002
2017-09-28T16:35:45.509433: step 3602, loss 0.796759, acc 0.65625, learning_rate 0.000100002
2017-09-28T16:35:45.589949: step 3603, loss 0.892675, acc 0.65625, learning_rate 0.000100002
2017-09-28T16:35:45.673462: step 3604, loss 0.72741, acc 0.625, learning_rate 0.000100002
2017-09-28T16:35:45.760967: step 3605, loss 0.949495, acc 0.59375, learning_rate 0.000100002
2017-09-28T16:35:45.844360: step 3606, loss 0.980223, acc 0.609375, learning_rate 0.000100002
2017-09-28T16:35:45.932162: step 3607, loss 0.709808, acc 0.75, learning_rate 0.000100002
2017-09-28T16:35:46.012826: step 3608, loss 0.778949, acc 0.640625, learning_rate 0.000100002
2017-09-28T16:35:46.096559: step 3609, loss 0.865773, acc 0.625, learning_rate 0.000100002
2017-09-28T16:35:46.179247: step 3610, loss 0.816932, acc 0.703125, learning_rate 0.000100002
2017-09-28T16:35:46.263451: step 3611, loss 0.617538, acc 0.796875, learning_rate 0.000100002
2017-09-28T16:35:46.344507: step 3612, loss 0.72218, acc 0.6875, learning_rate 0.000100002
2017-09-28T16:35:46.427749: step 3613, loss 0.872602, acc 0.609375, learning_rate 0.000100002
2017-09-28T16:35:46.510414: step 3614, loss 0.968446, acc 0.609375, learning_rate 0.000100002
2017-09-28T16:35:46.590268: step 3615, loss 0.86272, acc 0.671875, learning_rate 0.000100002
2017-09-28T16:35:46.672076: step 3616, loss 0.723142, acc 0.6875, learning_rate 0.000100002
2017-09-28T16:35:46.754776: step 3617, loss 0.784367, acc 0.625, learning_rate 0.000100002
2017-09-28T16:35:46.840545: step 3618, loss 0.67584, acc 0.703125, learning_rate 0.000100002
2017-09-28T16:35:46.928238: step 3619, loss 0.60547, acc 0.765625, learning_rate 0.000100002
2017-09-28T16:35:47.011703: step 3620, loss 0.690787, acc 0.65625, learning_rate 0.000100002
2017-09-28T16:35:47.097853: step 3621, loss 0.695911, acc 0.71875, learning_rate 0.000100002
2017-09-28T16:35:47.181043: step 3622, loss 0.896751, acc 0.609375, learning_rate 0.000100002
2017-09-28T16:35:47.263633: step 3623, loss 0.680784, acc 0.734375, learning_rate 0.000100002
2017-09-28T16:35:47.347019: step 3624, loss 0.780816, acc 0.75, learning_rate 0.000100002
2017-09-28T16:35:47.429796: step 3625, loss 0.645434, acc 0.765625, learning_rate 0.000100002
2017-09-28T16:35:47.498042: step 3626, loss 0.70902, acc 0.72549, learning_rate 0.000100002
2017-09-28T16:35:47.584696: step 3627, loss 0.901052, acc 0.640625, learning_rate 0.000100002
2017-09-28T16:35:47.668577: step 3628, loss 1.05308, acc 0.640625, learning_rate 0.000100002
2017-09-28T16:35:47.755038: step 3629, loss 0.848343, acc 0.6875, learning_rate 0.000100002
2017-09-28T16:35:47.835478: step 3630, loss 0.707517, acc 0.671875, learning_rate 0.000100002
2017-09-28T16:35:47.917133: step 3631, loss 0.824009, acc 0.71875, learning_rate 0.000100002
2017-09-28T16:35:47.997825: step 3632, loss 0.678694, acc 0.796875, learning_rate 0.000100002
2017-09-28T16:35:48.081474: step 3633, loss 0.761467, acc 0.703125, learning_rate 0.000100002
2017-09-28T16:35:48.161379: step 3634, loss 0.85402, acc 0.640625, learning_rate 0.000100002
2017-09-28T16:35:48.254685: step 3635, loss 0.840568, acc 0.65625, learning_rate 0.000100002
2017-09-28T16:35:48.341415: step 3636, loss 0.767132, acc 0.671875, learning_rate 0.000100002
2017-09-28T16:35:48.428243: step 3637, loss 0.820392, acc 0.6875, learning_rate 0.000100002
2017-09-28T16:35:48.511153: step 3638, loss 0.70228, acc 0.734375, learning_rate 0.000100002
2017-09-28T16:35:48.591794: step 3639, loss 0.883343, acc 0.640625, learning_rate 0.000100002
2017-09-28T16:35:48.674623: step 3640, loss 0.825779, acc 0.734375, learning_rate 0.000100002

Evaluation:
2017-09-28T16:35:48.941175: step 3640, loss 0.814455, acc 0.670504

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-3640

2017-09-28T16:35:49.559019: step 3641, loss 0.845238, acc 0.640625, learning_rate 0.000100002
2017-09-28T16:35:49.654234: step 3642, loss 0.72031, acc 0.765625, learning_rate 0.000100002
2017-09-28T16:35:49.742639: step 3643, loss 0.724131, acc 0.734375, learning_rate 0.000100002
2017-09-28T16:35:49.834660: step 3644, loss 0.758798, acc 0.71875, learning_rate 0.000100002
2017-09-28T16:35:49.917998: step 3645, loss 0.757508, acc 0.65625, learning_rate 0.000100002
2017-09-28T16:35:49.998701: step 3646, loss 0.954159, acc 0.5625, learning_rate 0.000100002
2017-09-28T16:35:50.079545: step 3647, loss 0.801748, acc 0.6875, learning_rate 0.000100002
2017-09-28T16:35:50.165165: step 3648, loss 0.954443, acc 0.578125, learning_rate 0.000100002
2017-09-28T16:35:50.246838: step 3649, loss 0.91988, acc 0.6875, learning_rate 0.000100002
2017-09-28T16:35:50.335375: step 3650, loss 0.767087, acc 0.734375, learning_rate 0.000100002
2017-09-28T16:35:50.420358: step 3651, loss 0.960787, acc 0.59375, learning_rate 0.000100002
2017-09-28T16:35:50.507653: step 3652, loss 0.773986, acc 0.6875, learning_rate 0.000100002
2017-09-28T16:35:50.595331: step 3653, loss 0.666319, acc 0.71875, learning_rate 0.000100002
2017-09-28T16:35:50.679497: step 3654, loss 0.995961, acc 0.609375, learning_rate 0.000100002
2017-09-28T16:35:50.765928: step 3655, loss 0.755052, acc 0.640625, learning_rate 0.000100002
2017-09-28T16:35:50.849198: step 3656, loss 0.631798, acc 0.703125, learning_rate 0.000100002
2017-09-28T16:35:50.936359: step 3657, loss 0.734805, acc 0.734375, learning_rate 0.000100002
2017-09-28T16:35:51.023699: step 3658, loss 0.814617, acc 0.671875, learning_rate 0.000100002
2017-09-28T16:35:51.111002: step 3659, loss 0.938587, acc 0.625, learning_rate 0.000100002
2017-09-28T16:35:51.194211: step 3660, loss 0.615874, acc 0.796875, learning_rate 0.000100002
2017-09-28T16:35:51.278726: step 3661, loss 0.781692, acc 0.671875, learning_rate 0.000100002
2017-09-28T16:35:51.365535: step 3662, loss 0.640387, acc 0.765625, learning_rate 0.000100002
2017-09-28T16:35:51.458815: step 3663, loss 0.837617, acc 0.703125, learning_rate 0.000100002
2017-09-28T16:35:51.547246: step 3664, loss 0.690544, acc 0.78125, learning_rate 0.000100002
2017-09-28T16:35:51.630979: step 3665, loss 0.692176, acc 0.6875, learning_rate 0.000100002
2017-09-28T16:35:51.716277: step 3666, loss 0.71573, acc 0.734375, learning_rate 0.000100002
2017-09-28T16:35:51.809354: step 3667, loss 0.727965, acc 0.71875, learning_rate 0.000100002
2017-09-28T16:35:51.899233: step 3668, loss 0.647074, acc 0.75, learning_rate 0.000100002
2017-09-28T16:35:51.985013: step 3669, loss 0.705269, acc 0.78125, learning_rate 0.000100001
2017-09-28T16:35:52.068209: step 3670, loss 0.613275, acc 0.765625, learning_rate 0.000100001
2017-09-28T16:35:52.154381: step 3671, loss 1.00112, acc 0.5625, learning_rate 0.000100001
2017-09-28T16:35:52.242303: step 3672, loss 0.999812, acc 0.5625, learning_rate 0.000100001
2017-09-28T16:35:52.329223: step 3673, loss 0.676852, acc 0.8125, learning_rate 0.000100001
2017-09-28T16:35:52.424859: step 3674, loss 0.907759, acc 0.59375, learning_rate 0.000100001
2017-09-28T16:35:52.513719: step 3675, loss 0.848286, acc 0.703125, learning_rate 0.000100001
2017-09-28T16:35:52.598986: step 3676, loss 0.769962, acc 0.6875, learning_rate 0.000100001
2017-09-28T16:35:52.681424: step 3677, loss 0.613999, acc 0.828125, learning_rate 0.000100001
2017-09-28T16:35:52.769779: step 3678, loss 0.785058, acc 0.59375, learning_rate 0.000100001
2017-09-28T16:35:52.852753: step 3679, loss 0.601279, acc 0.75, learning_rate 0.000100001
2017-09-28T16:35:52.942953: step 3680, loss 0.895814, acc 0.671875, learning_rate 0.000100001

Evaluation:
2017-09-28T16:35:53.218066: step 3680, loss 0.816043, acc 0.670504

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-3680

2017-09-28T16:35:53.797497: step 3681, loss 0.732844, acc 0.6875, learning_rate 0.000100001
2017-09-28T16:35:53.881007: step 3682, loss 0.884447, acc 0.578125, learning_rate 0.000100001
2017-09-28T16:35:53.966071: step 3683, loss 0.638569, acc 0.796875, learning_rate 0.000100001
2017-09-28T16:35:54.054690: step 3684, loss 0.666194, acc 0.765625, learning_rate 0.000100001
2017-09-28T16:35:54.136038: step 3685, loss 0.719329, acc 0.640625, learning_rate 0.000100001
2017-09-28T16:35:54.220118: step 3686, loss 0.604443, acc 0.78125, learning_rate 0.000100001
2017-09-28T16:35:54.303784: step 3687, loss 0.721118, acc 0.671875, learning_rate 0.000100001
2017-09-28T16:35:54.386371: step 3688, loss 0.748369, acc 0.65625, learning_rate 0.000100001
2017-09-28T16:35:54.468836: step 3689, loss 0.794897, acc 0.640625, learning_rate 0.000100001
2017-09-28T16:35:54.552528: step 3690, loss 0.79196, acc 0.6875, learning_rate 0.000100001
2017-09-28T16:35:54.633361: step 3691, loss 0.720911, acc 0.703125, learning_rate 0.000100001
2017-09-28T16:35:54.717833: step 3692, loss 0.734713, acc 0.640625, learning_rate 0.000100001
2017-09-28T16:35:54.802357: step 3693, loss 0.818296, acc 0.609375, learning_rate 0.000100001
2017-09-28T16:35:54.887162: step 3694, loss 0.722271, acc 0.75, learning_rate 0.000100001
2017-09-28T16:35:54.970371: step 3695, loss 0.690605, acc 0.734375, learning_rate 0.000100001
2017-09-28T16:35:55.050279: step 3696, loss 0.791677, acc 0.6875, learning_rate 0.000100001
2017-09-28T16:35:55.130309: step 3697, loss 0.559278, acc 0.765625, learning_rate 0.000100001
2017-09-28T16:35:55.217460: step 3698, loss 0.760285, acc 0.703125, learning_rate 0.000100001
2017-09-28T16:35:55.300259: step 3699, loss 0.636972, acc 0.734375, learning_rate 0.000100001
2017-09-28T16:35:55.381447: step 3700, loss 0.656455, acc 0.703125, learning_rate 0.000100001
2017-09-28T16:35:55.462995: step 3701, loss 0.819609, acc 0.609375, learning_rate 0.000100001
2017-09-28T16:35:55.545756: step 3702, loss 0.908081, acc 0.609375, learning_rate 0.000100001
2017-09-28T16:35:55.627771: step 3703, loss 0.812197, acc 0.703125, learning_rate 0.000100001
2017-09-28T16:35:55.710371: step 3704, loss 0.829738, acc 0.671875, learning_rate 0.000100001
2017-09-28T16:35:55.799851: step 3705, loss 0.869838, acc 0.59375, learning_rate 0.000100001
2017-09-28T16:35:55.881988: step 3706, loss 0.710198, acc 0.6875, learning_rate 0.000100001
2017-09-28T16:35:55.963467: step 3707, loss 0.710641, acc 0.703125, learning_rate 0.000100001
2017-09-28T16:35:56.048949: step 3708, loss 0.886069, acc 0.640625, learning_rate 0.000100001
2017-09-28T16:35:56.128951: step 3709, loss 0.793541, acc 0.671875, learning_rate 0.000100001
2017-09-28T16:35:56.208553: step 3710, loss 0.871715, acc 0.6875, learning_rate 0.000100001
2017-09-28T16:35:56.290293: step 3711, loss 0.697297, acc 0.71875, learning_rate 0.000100001
2017-09-28T16:35:56.370523: step 3712, loss 0.698744, acc 0.703125, learning_rate 0.000100001
2017-09-28T16:35:56.453225: step 3713, loss 0.749225, acc 0.65625, learning_rate 0.000100001
2017-09-28T16:35:56.542714: step 3714, loss 0.753093, acc 0.671875, learning_rate 0.000100001
2017-09-28T16:35:56.630555: step 3715, loss 0.741225, acc 0.671875, learning_rate 0.000100001
2017-09-28T16:35:56.715068: step 3716, loss 0.579914, acc 0.796875, learning_rate 0.000100001
2017-09-28T16:35:56.800143: step 3717, loss 0.750412, acc 0.703125, learning_rate 0.000100001
2017-09-28T16:35:56.885283: step 3718, loss 0.819115, acc 0.671875, learning_rate 0.000100001
2017-09-28T16:35:56.969340: step 3719, loss 0.811702, acc 0.65625, learning_rate 0.000100001
2017-09-28T16:35:57.053159: step 3720, loss 0.713181, acc 0.71875, learning_rate 0.000100001

Evaluation:
2017-09-28T16:35:57.321452: step 3720, loss 0.811211, acc 0.671942

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-3720

2017-09-28T16:35:57.951547: step 3721, loss 0.685484, acc 0.75, learning_rate 0.000100001
2017-09-28T16:35:58.031574: step 3722, loss 0.684149, acc 0.71875, learning_rate 0.000100001
2017-09-28T16:35:58.110603: step 3723, loss 0.985315, acc 0.59375, learning_rate 0.000100001
2017-09-28T16:35:58.178082: step 3724, loss 0.637565, acc 0.764706, learning_rate 0.000100001
2017-09-28T16:35:58.263185: step 3725, loss 0.850273, acc 0.71875, learning_rate 0.000100001
2017-09-28T16:35:58.345144: step 3726, loss 0.544815, acc 0.78125, learning_rate 0.000100001
2017-09-28T16:35:58.427598: step 3727, loss 0.88325, acc 0.671875, learning_rate 0.000100001
2017-09-28T16:35:58.508215: step 3728, loss 0.86859, acc 0.671875, learning_rate 0.000100001
2017-09-28T16:35:58.590181: step 3729, loss 0.714431, acc 0.703125, learning_rate 0.000100001
2017-09-28T16:35:58.671858: step 3730, loss 0.751363, acc 0.75, learning_rate 0.000100001
2017-09-28T16:35:58.759866: step 3731, loss 0.843003, acc 0.6875, learning_rate 0.000100001
2017-09-28T16:35:58.843350: step 3732, loss 0.658064, acc 0.703125, learning_rate 0.000100001
2017-09-28T16:35:58.924070: step 3733, loss 0.624905, acc 0.75, learning_rate 0.000100001
2017-09-28T16:35:59.005830: step 3734, loss 0.709255, acc 0.75, learning_rate 0.000100001
2017-09-28T16:35:59.088178: step 3735, loss 0.821002, acc 0.640625, learning_rate 0.000100001
2017-09-28T16:35:59.169331: step 3736, loss 0.579263, acc 0.796875, learning_rate 0.000100001
2017-09-28T16:35:59.255905: step 3737, loss 0.659964, acc 0.75, learning_rate 0.000100001
2017-09-28T16:35:59.339054: step 3738, loss 0.761667, acc 0.703125, learning_rate 0.000100001
2017-09-28T16:35:59.425456: step 3739, loss 0.833764, acc 0.625, learning_rate 0.000100001
2017-09-28T16:35:59.510345: step 3740, loss 0.576082, acc 0.796875, learning_rate 0.000100001
2017-09-28T16:35:59.592946: step 3741, loss 0.938656, acc 0.625, learning_rate 0.000100001
2017-09-28T16:35:59.676546: step 3742, loss 0.610605, acc 0.75, learning_rate 0.000100001
2017-09-28T16:35:59.757322: step 3743, loss 1.04897, acc 0.625, learning_rate 0.000100001
2017-09-28T16:35:59.840766: step 3744, loss 0.626809, acc 0.796875, learning_rate 0.000100001
2017-09-28T16:35:59.922882: step 3745, loss 0.598958, acc 0.765625, learning_rate 0.000100001
2017-09-28T16:36:00.004958: step 3746, loss 0.830458, acc 0.75, learning_rate 0.000100001
2017-09-28T16:36:00.089372: step 3747, loss 0.669679, acc 0.75, learning_rate 0.000100001
2017-09-28T16:36:00.172351: step 3748, loss 0.764405, acc 0.703125, learning_rate 0.000100001
2017-09-28T16:36:00.254522: step 3749, loss 0.737954, acc 0.71875, learning_rate 0.000100001
2017-09-28T16:36:00.337613: step 3750, loss 0.757458, acc 0.6875, learning_rate 0.000100001
2017-09-28T16:36:00.425863: step 3751, loss 0.963703, acc 0.625, learning_rate 0.000100001
2017-09-28T16:36:00.510494: step 3752, loss 1.00172, acc 0.640625, learning_rate 0.000100001
2017-09-28T16:36:00.596518: step 3753, loss 0.838163, acc 0.640625, learning_rate 0.000100001
2017-09-28T16:36:00.681861: step 3754, loss 0.763718, acc 0.78125, learning_rate 0.000100001
2017-09-28T16:36:00.774266: step 3755, loss 0.839411, acc 0.65625, learning_rate 0.000100001
2017-09-28T16:36:00.859460: step 3756, loss 0.79336, acc 0.625, learning_rate 0.000100001
2017-09-28T16:36:00.941812: step 3757, loss 0.65892, acc 0.78125, learning_rate 0.000100001
2017-09-28T16:36:01.025716: step 3758, loss 0.806898, acc 0.65625, learning_rate 0.000100001
2017-09-28T16:36:01.111132: step 3759, loss 0.786787, acc 0.71875, learning_rate 0.000100001
2017-09-28T16:36:01.194749: step 3760, loss 0.674634, acc 0.765625, learning_rate 0.000100001

Evaluation:
2017-09-28T16:36:01.479492: step 3760, loss 0.810877, acc 0.670504

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-3760

2017-09-28T16:36:01.982826: step 3761, loss 0.728226, acc 0.609375, learning_rate 0.000100001
2017-09-28T16:36:02.064713: step 3762, loss 0.884402, acc 0.625, learning_rate 0.000100001
2017-09-28T16:36:02.147366: step 3763, loss 0.956685, acc 0.703125, learning_rate 0.000100001
2017-09-28T16:36:02.229034: step 3764, loss 0.712768, acc 0.671875, learning_rate 0.000100001
2017-09-28T16:36:02.309803: step 3765, loss 0.643722, acc 0.75, learning_rate 0.000100001
2017-09-28T16:36:02.392920: step 3766, loss 0.674317, acc 0.75, learning_rate 0.000100001
2017-09-28T16:36:02.472905: step 3767, loss 0.806991, acc 0.640625, learning_rate 0.000100001
2017-09-28T16:36:02.555808: step 3768, loss 0.628219, acc 0.78125, learning_rate 0.000100001
2017-09-28T16:36:02.637788: step 3769, loss 0.654502, acc 0.75, learning_rate 0.000100001
2017-09-28T16:36:02.720476: step 3770, loss 0.62085, acc 0.75, learning_rate 0.000100001
2017-09-28T16:36:02.804161: step 3771, loss 0.816758, acc 0.65625, learning_rate 0.000100001
2017-09-28T16:36:02.888684: step 3772, loss 0.865514, acc 0.625, learning_rate 0.000100001
2017-09-28T16:36:02.972999: step 3773, loss 0.659575, acc 0.71875, learning_rate 0.000100001
2017-09-28T16:36:03.055588: step 3774, loss 0.896667, acc 0.609375, learning_rate 0.000100001
2017-09-28T16:36:03.139204: step 3775, loss 0.480723, acc 0.84375, learning_rate 0.000100001
2017-09-28T16:36:03.220902: step 3776, loss 0.640829, acc 0.703125, learning_rate 0.000100001
2017-09-28T16:36:03.311407: step 3777, loss 0.786812, acc 0.671875, learning_rate 0.000100001
2017-09-28T16:36:03.397161: step 3778, loss 0.759255, acc 0.703125, learning_rate 0.000100001
2017-09-28T16:36:03.480915: step 3779, loss 1.02548, acc 0.625, learning_rate 0.000100001
2017-09-28T16:36:03.563121: step 3780, loss 0.928401, acc 0.65625, learning_rate 0.000100001
2017-09-28T16:36:03.645635: step 3781, loss 0.732137, acc 0.640625, learning_rate 0.000100001
2017-09-28T16:36:03.725703: step 3782, loss 0.822496, acc 0.671875, learning_rate 0.000100001
2017-09-28T16:36:03.807268: step 3783, loss 0.787497, acc 0.734375, learning_rate 0.000100001
2017-09-28T16:36:03.887987: step 3784, loss 0.71748, acc 0.65625, learning_rate 0.000100001
2017-09-28T16:36:03.971223: step 3785, loss 0.763125, acc 0.734375, learning_rate 0.000100001
2017-09-28T16:36:04.050536: step 3786, loss 0.706209, acc 0.671875, learning_rate 0.000100001
2017-09-28T16:36:04.133180: step 3787, loss 0.744747, acc 0.6875, learning_rate 0.000100001
2017-09-28T16:36:04.211934: step 3788, loss 0.687047, acc 0.703125, learning_rate 0.000100001
2017-09-28T16:36:04.289435: step 3789, loss 0.715607, acc 0.671875, learning_rate 0.000100001
2017-09-28T16:36:04.371181: step 3790, loss 0.822748, acc 0.625, learning_rate 0.000100001
2017-09-28T16:36:04.453480: step 3791, loss 0.820127, acc 0.59375, learning_rate 0.000100001
2017-09-28T16:36:04.535793: step 3792, loss 0.624128, acc 0.765625, learning_rate 0.000100001
2017-09-28T16:36:04.620035: step 3793, loss 0.637528, acc 0.75, learning_rate 0.000100001
2017-09-28T16:36:04.700205: step 3794, loss 0.656298, acc 0.75, learning_rate 0.000100001
2017-09-28T16:36:04.781768: step 3795, loss 0.988888, acc 0.671875, learning_rate 0.000100001
2017-09-28T16:36:04.862778: step 3796, loss 0.74697, acc 0.78125, learning_rate 0.000100001
2017-09-28T16:36:04.945451: step 3797, loss 0.950805, acc 0.59375, learning_rate 0.000100001
2017-09-28T16:36:05.027939: step 3798, loss 0.887109, acc 0.625, learning_rate 0.000100001
2017-09-28T16:36:05.108928: step 3799, loss 0.958647, acc 0.609375, learning_rate 0.000100001
2017-09-28T16:36:05.189666: step 3800, loss 0.74868, acc 0.71875, learning_rate 0.000100001

Evaluation:
2017-09-28T16:36:05.462056: step 3800, loss 0.81259, acc 0.67482

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-3800

2017-09-28T16:36:06.013804: step 3801, loss 0.934296, acc 0.640625, learning_rate 0.000100001
2017-09-28T16:36:06.096368: step 3802, loss 0.752366, acc 0.75, learning_rate 0.000100001
2017-09-28T16:36:06.173446: step 3803, loss 0.791623, acc 0.671875, learning_rate 0.000100001
2017-09-28T16:36:06.254092: step 3804, loss 0.764279, acc 0.65625, learning_rate 0.000100001
2017-09-28T16:36:06.332699: step 3805, loss 0.9295, acc 0.609375, learning_rate 0.000100001
2017-09-28T16:36:06.416611: step 3806, loss 0.62243, acc 0.828125, learning_rate 0.000100001
2017-09-28T16:36:06.497752: step 3807, loss 0.842295, acc 0.65625, learning_rate 0.000100001
2017-09-28T16:36:06.576780: step 3808, loss 0.821307, acc 0.71875, learning_rate 0.000100001
2017-09-28T16:36:06.657607: step 3809, loss 0.707596, acc 0.703125, learning_rate 0.000100001
2017-09-28T16:36:06.740116: step 3810, loss 0.632865, acc 0.765625, learning_rate 0.000100001
2017-09-28T16:36:06.821339: step 3811, loss 0.653288, acc 0.734375, learning_rate 0.000100001
2017-09-28T16:36:06.899785: step 3812, loss 0.697841, acc 0.6875, learning_rate 0.000100001
2017-09-28T16:36:06.984233: step 3813, loss 0.950364, acc 0.59375, learning_rate 0.000100001
2017-09-28T16:36:07.064415: step 3814, loss 0.759878, acc 0.6875, learning_rate 0.000100001
2017-09-28T16:36:07.148003: step 3815, loss 0.673918, acc 0.75, learning_rate 0.000100001
2017-09-28T16:36:07.229692: step 3816, loss 0.908568, acc 0.640625, learning_rate 0.000100001
2017-09-28T16:36:07.311696: step 3817, loss 0.735572, acc 0.75, learning_rate 0.000100001
2017-09-28T16:36:07.390641: step 3818, loss 0.779971, acc 0.6875, learning_rate 0.000100001
2017-09-28T16:36:07.471594: step 3819, loss 0.766438, acc 0.78125, learning_rate 0.000100001
2017-09-28T16:36:07.553098: step 3820, loss 0.766654, acc 0.703125, learning_rate 0.000100001
2017-09-28T16:36:07.630896: step 3821, loss 0.756313, acc 0.6875, learning_rate 0.000100001
2017-09-28T16:36:07.697113: step 3822, loss 0.749283, acc 0.666667, learning_rate 0.000100001
2017-09-28T16:36:07.777837: step 3823, loss 0.634535, acc 0.71875, learning_rate 0.000100001
2017-09-28T16:36:07.859973: step 3824, loss 0.851089, acc 0.609375, learning_rate 0.000100001
2017-09-28T16:36:07.944106: step 3825, loss 0.672662, acc 0.75, learning_rate 0.000100001
2017-09-28T16:36:08.025764: step 3826, loss 0.719052, acc 0.671875, learning_rate 0.000100001
2017-09-28T16:36:08.106200: step 3827, loss 0.719904, acc 0.703125, learning_rate 0.000100001
2017-09-28T16:36:08.185689: step 3828, loss 0.732397, acc 0.78125, learning_rate 0.000100001
2017-09-28T16:36:08.267614: step 3829, loss 0.800162, acc 0.703125, learning_rate 0.000100001
2017-09-28T16:36:08.351869: step 3830, loss 0.783402, acc 0.6875, learning_rate 0.000100001
2017-09-28T16:36:08.441234: step 3831, loss 0.779519, acc 0.71875, learning_rate 0.000100001
2017-09-28T16:36:08.520601: step 3832, loss 0.585294, acc 0.78125, learning_rate 0.000100001
2017-09-28T16:36:08.603159: step 3833, loss 0.717264, acc 0.71875, learning_rate 0.000100001
2017-09-28T16:36:08.680264: step 3834, loss 0.804616, acc 0.640625, learning_rate 0.000100001
2017-09-28T16:36:08.761197: step 3835, loss 1.03273, acc 0.578125, learning_rate 0.000100001
2017-09-28T16:36:08.839956: step 3836, loss 0.886887, acc 0.671875, learning_rate 0.000100001
2017-09-28T16:36:08.920547: step 3837, loss 0.747343, acc 0.765625, learning_rate 0.000100001
2017-09-28T16:36:08.998342: step 3838, loss 0.775563, acc 0.71875, learning_rate 0.000100001
2017-09-28T16:36:09.078117: step 3839, loss 0.716343, acc 0.671875, learning_rate 0.000100001
2017-09-28T16:36:09.159645: step 3840, loss 0.802956, acc 0.703125, learning_rate 0.000100001

Evaluation:
2017-09-28T16:36:09.425502: step 3840, loss 0.810888, acc 0.67482

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-3840

2017-09-28T16:36:09.977928: step 3841, loss 0.640946, acc 0.78125, learning_rate 0.000100001
2017-09-28T16:36:10.061263: step 3842, loss 0.872625, acc 0.640625, learning_rate 0.000100001
2017-09-28T16:36:10.141917: step 3843, loss 0.734142, acc 0.671875, learning_rate 0.000100001
2017-09-28T16:36:10.221632: step 3844, loss 0.701321, acc 0.703125, learning_rate 0.000100001
2017-09-28T16:36:10.299801: step 3845, loss 0.90369, acc 0.671875, learning_rate 0.000100001
2017-09-28T16:36:10.383215: step 3846, loss 0.684113, acc 0.6875, learning_rate 0.000100001
2017-09-28T16:36:10.464757: step 3847, loss 0.814398, acc 0.703125, learning_rate 0.000100001
2017-09-28T16:36:10.545245: step 3848, loss 0.739764, acc 0.65625, learning_rate 0.000100001
2017-09-28T16:36:10.626218: step 3849, loss 0.751681, acc 0.671875, learning_rate 0.000100001
2017-09-28T16:36:10.710297: step 3850, loss 0.78693, acc 0.625, learning_rate 0.000100001
2017-09-28T16:36:10.797356: step 3851, loss 0.834455, acc 0.703125, learning_rate 0.000100001
2017-09-28T16:36:10.878494: step 3852, loss 0.746401, acc 0.6875, learning_rate 0.000100001
2017-09-28T16:36:10.960892: step 3853, loss 0.862734, acc 0.640625, learning_rate 0.000100001
2017-09-28T16:36:11.042977: step 3854, loss 0.562931, acc 0.84375, learning_rate 0.000100001
2017-09-28T16:36:11.124868: step 3855, loss 0.701474, acc 0.75, learning_rate 0.000100001
2017-09-28T16:36:11.206999: step 3856, loss 0.689404, acc 0.6875, learning_rate 0.000100001
2017-09-28T16:36:11.288085: step 3857, loss 0.803768, acc 0.65625, learning_rate 0.000100001
2017-09-28T16:36:11.368733: step 3858, loss 0.831866, acc 0.578125, learning_rate 0.000100001
2017-09-28T16:36:11.449383: step 3859, loss 0.744684, acc 0.71875, learning_rate 0.000100001
2017-09-28T16:36:11.533397: step 3860, loss 0.802155, acc 0.75, learning_rate 0.000100001
2017-09-28T16:36:11.614609: step 3861, loss 0.761343, acc 0.703125, learning_rate 0.000100001
2017-09-28T16:36:11.698055: step 3862, loss 0.799159, acc 0.6875, learning_rate 0.000100001
2017-09-28T16:36:11.776603: step 3863, loss 0.887283, acc 0.625, learning_rate 0.000100001
2017-09-28T16:36:11.859405: step 3864, loss 1.01271, acc 0.5625, learning_rate 0.000100001
2017-09-28T16:36:11.938993: step 3865, loss 0.757212, acc 0.703125, learning_rate 0.000100001
2017-09-28T16:36:12.023634: step 3866, loss 0.724287, acc 0.765625, learning_rate 0.000100001
2017-09-28T16:36:12.105907: step 3867, loss 0.718091, acc 0.734375, learning_rate 0.000100001
2017-09-28T16:36:12.183775: step 3868, loss 0.619494, acc 0.734375, learning_rate 0.000100001
2017-09-28T16:36:12.266318: step 3869, loss 0.806147, acc 0.671875, learning_rate 0.000100001
2017-09-28T16:36:12.348292: step 3870, loss 0.715588, acc 0.734375, learning_rate 0.000100001
2017-09-28T16:36:12.428403: step 3871, loss 0.87558, acc 0.6875, learning_rate 0.000100001
2017-09-28T16:36:12.505881: step 3872, loss 0.75188, acc 0.8125, learning_rate 0.000100001
2017-09-28T16:36:12.587720: step 3873, loss 0.628485, acc 0.796875, learning_rate 0.000100001
2017-09-28T16:36:12.669034: step 3874, loss 0.911111, acc 0.6875, learning_rate 0.000100001
2017-09-28T16:36:12.751344: step 3875, loss 0.780725, acc 0.765625, learning_rate 0.000100001
2017-09-28T16:36:12.837450: step 3876, loss 0.598308, acc 0.75, learning_rate 0.000100001
2017-09-28T16:36:12.919966: step 3877, loss 0.835637, acc 0.65625, learning_rate 0.000100001
2017-09-28T16:36:13.003248: step 3878, loss 0.768987, acc 0.625, learning_rate 0.000100001
2017-09-28T16:36:13.083383: step 3879, loss 0.949198, acc 0.609375, learning_rate 0.000100001
2017-09-28T16:36:13.166502: step 3880, loss 0.720251, acc 0.703125, learning_rate 0.000100001

Evaluation:
2017-09-28T16:36:13.436268: step 3880, loss 0.80884, acc 0.673381

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-3880

2017-09-28T16:36:14.080596: step 3881, loss 0.620462, acc 0.765625, learning_rate 0.000100001
2017-09-28T16:36:14.166215: step 3882, loss 0.919579, acc 0.65625, learning_rate 0.000100001
2017-09-28T16:36:14.244574: step 3883, loss 0.798704, acc 0.671875, learning_rate 0.000100001
2017-09-28T16:36:14.328359: step 3884, loss 0.641358, acc 0.75, learning_rate 0.000100001
2017-09-28T16:36:14.412328: step 3885, loss 0.561361, acc 0.875, learning_rate 0.000100001
2017-09-28T16:36:14.498585: step 3886, loss 0.73933, acc 0.6875, learning_rate 0.000100001
2017-09-28T16:36:14.579019: step 3887, loss 0.753248, acc 0.6875, learning_rate 0.000100001
2017-09-28T16:36:14.661178: step 3888, loss 0.822976, acc 0.703125, learning_rate 0.000100001
2017-09-28T16:36:14.742457: step 3889, loss 0.681691, acc 0.765625, learning_rate 0.000100001
2017-09-28T16:36:14.824581: step 3890, loss 0.615297, acc 0.765625, learning_rate 0.000100001
2017-09-28T16:36:14.903133: step 3891, loss 0.614644, acc 0.71875, learning_rate 0.000100001
2017-09-28T16:36:14.987067: step 3892, loss 0.743599, acc 0.6875, learning_rate 0.000100001
2017-09-28T16:36:15.066839: step 3893, loss 0.734727, acc 0.671875, learning_rate 0.000100001
2017-09-28T16:36:15.146655: step 3894, loss 0.66845, acc 0.703125, learning_rate 0.000100001
2017-09-28T16:36:15.227987: step 3895, loss 0.818949, acc 0.734375, learning_rate 0.000100001
2017-09-28T16:36:15.309673: step 3896, loss 0.799375, acc 0.671875, learning_rate 0.000100001
2017-09-28T16:36:15.389090: step 3897, loss 0.802109, acc 0.6875, learning_rate 0.000100001
2017-09-28T16:36:15.472998: step 3898, loss 0.633875, acc 0.78125, learning_rate 0.000100001
2017-09-28T16:36:15.552868: step 3899, loss 0.687461, acc 0.734375, learning_rate 0.000100001
2017-09-28T16:36:15.634229: step 3900, loss 0.864799, acc 0.609375, learning_rate 0.000100001
2017-09-28T16:36:15.714776: step 3901, loss 0.705903, acc 0.75, learning_rate 0.000100001
2017-09-28T16:36:15.799630: step 3902, loss 0.60693, acc 0.796875, learning_rate 0.000100001
2017-09-28T16:36:15.879606: step 3903, loss 0.606801, acc 0.78125, learning_rate 0.000100001
2017-09-28T16:36:15.959257: step 3904, loss 0.913168, acc 0.609375, learning_rate 0.000100001
2017-09-28T16:36:16.040456: step 3905, loss 0.779406, acc 0.625, learning_rate 0.000100001
2017-09-28T16:36:16.125787: step 3906, loss 0.827852, acc 0.640625, learning_rate 0.000100001
2017-09-28T16:36:16.206035: step 3907, loss 0.818477, acc 0.59375, learning_rate 0.000100001
2017-09-28T16:36:16.288577: step 3908, loss 0.588121, acc 0.796875, learning_rate 0.000100001
2017-09-28T16:36:16.368391: step 3909, loss 0.715556, acc 0.703125, learning_rate 0.000100001
2017-09-28T16:36:16.446847: step 3910, loss 0.658947, acc 0.734375, learning_rate 0.000100001
2017-09-28T16:36:16.527751: step 3911, loss 0.739034, acc 0.640625, learning_rate 0.000100001
2017-09-28T16:36:16.607430: step 3912, loss 0.835266, acc 0.640625, learning_rate 0.000100001
2017-09-28T16:36:16.685806: step 3913, loss 0.844676, acc 0.6875, learning_rate 0.000100001
2017-09-28T16:36:16.768297: step 3914, loss 0.827741, acc 0.65625, learning_rate 0.000100001
2017-09-28T16:36:16.846454: step 3915, loss 0.700614, acc 0.75, learning_rate 0.000100001
2017-09-28T16:36:16.926176: step 3916, loss 0.8456, acc 0.6875, learning_rate 0.000100001
2017-09-28T16:36:17.012217: step 3917, loss 0.799024, acc 0.671875, learning_rate 0.000100001
2017-09-28T16:36:17.093183: step 3918, loss 0.796304, acc 0.65625, learning_rate 0.000100001
2017-09-28T16:36:17.173606: step 3919, loss 0.922713, acc 0.609375, learning_rate 0.000100001
2017-09-28T16:36:17.238556: step 3920, loss 0.78984, acc 0.647059, learning_rate 0.000100001

Evaluation:
2017-09-28T16:36:17.511038: step 3920, loss 0.806971, acc 0.671942

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-3920

2017-09-28T16:36:17.999701: step 3921, loss 0.79171, acc 0.6875, learning_rate 0.000100001
2017-09-28T16:36:18.080022: step 3922, loss 0.817623, acc 0.65625, learning_rate 0.000100001
2017-09-28T16:36:18.157493: step 3923, loss 0.750629, acc 0.65625, learning_rate 0.000100001
2017-09-28T16:36:18.240478: step 3924, loss 0.787337, acc 0.6875, learning_rate 0.000100001
2017-09-28T16:36:18.319690: step 3925, loss 0.864965, acc 0.734375, learning_rate 0.000100001
2017-09-28T16:36:18.401789: step 3926, loss 0.807272, acc 0.640625, learning_rate 0.000100001
2017-09-28T16:36:18.491916: step 3927, loss 0.842458, acc 0.640625, learning_rate 0.000100001
2017-09-28T16:36:18.576216: step 3928, loss 0.733333, acc 0.71875, learning_rate 0.000100001
2017-09-28T16:36:18.657046: step 3929, loss 0.662202, acc 0.78125, learning_rate 0.000100001
2017-09-28T16:36:18.738643: step 3930, loss 0.665331, acc 0.75, learning_rate 0.000100001
2017-09-28T16:36:18.817392: step 3931, loss 0.865347, acc 0.625, learning_rate 0.000100001
2017-09-28T16:36:18.898088: step 3932, loss 0.573416, acc 0.78125, learning_rate 0.000100001
2017-09-28T16:36:18.979219: step 3933, loss 0.77669, acc 0.65625, learning_rate 0.000100001
2017-09-28T16:36:19.061026: step 3934, loss 0.907724, acc 0.5625, learning_rate 0.000100001
2017-09-28T16:36:19.144266: step 3935, loss 0.845379, acc 0.640625, learning_rate 0.000100001
2017-09-28T16:36:19.225550: step 3936, loss 0.911277, acc 0.625, learning_rate 0.000100001
2017-09-28T16:36:19.307191: step 3937, loss 0.59922, acc 0.78125, learning_rate 0.0001
2017-09-28T16:36:19.389866: step 3938, loss 0.72778, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:19.468947: step 3939, loss 0.765939, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:19.549023: step 3940, loss 0.652282, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:19.630621: step 3941, loss 0.826625, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:19.709239: step 3942, loss 0.74032, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:19.793347: step 3943, loss 0.787359, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:19.874411: step 3944, loss 0.746004, acc 0.78125, learning_rate 0.0001
2017-09-28T16:36:19.956178: step 3945, loss 0.724145, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:20.035908: step 3946, loss 0.90371, acc 0.640625, learning_rate 0.0001
2017-09-28T16:36:20.117109: step 3947, loss 0.895311, acc 0.5625, learning_rate 0.0001
2017-09-28T16:36:20.198749: step 3948, loss 0.632779, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:20.277544: step 3949, loss 0.876465, acc 0.578125, learning_rate 0.0001
2017-09-28T16:36:20.364927: step 3950, loss 0.713957, acc 0.75, learning_rate 0.0001
2017-09-28T16:36:20.446176: step 3951, loss 0.750092, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:20.528574: step 3952, loss 0.8522, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:20.609287: step 3953, loss 0.820067, acc 0.65625, learning_rate 0.0001
2017-09-28T16:36:20.688592: step 3954, loss 0.673656, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:20.769176: step 3955, loss 0.746029, acc 0.65625, learning_rate 0.0001
2017-09-28T16:36:20.849009: step 3956, loss 0.846032, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:20.929780: step 3957, loss 0.825872, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:21.012389: step 3958, loss 0.792694, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:21.094007: step 3959, loss 0.654825, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:21.176208: step 3960, loss 0.715621, acc 0.734375, learning_rate 0.0001

Evaluation:
2017-09-28T16:36:21.441506: step 3960, loss 0.808684, acc 0.677698

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-3960

2017-09-28T16:36:21.995796: step 3961, loss 0.769586, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:22.078560: step 3962, loss 0.700114, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:22.160492: step 3963, loss 0.667103, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:22.240225: step 3964, loss 0.873991, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:22.322815: step 3965, loss 0.688758, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:22.404284: step 3966, loss 0.805202, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:22.485355: step 3967, loss 0.874381, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:22.573569: step 3968, loss 0.694881, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:22.653609: step 3969, loss 0.883751, acc 0.65625, learning_rate 0.0001
2017-09-28T16:36:22.736052: step 3970, loss 0.664153, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:22.817687: step 3971, loss 0.738131, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:22.900642: step 3972, loss 0.826289, acc 0.640625, learning_rate 0.0001
2017-09-28T16:36:22.982870: step 3973, loss 0.759561, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:23.062962: step 3974, loss 0.908938, acc 0.625, learning_rate 0.0001
2017-09-28T16:36:23.145302: step 3975, loss 0.76129, acc 0.625, learning_rate 0.0001
2017-09-28T16:36:23.227578: step 3976, loss 0.628312, acc 0.75, learning_rate 0.0001
2017-09-28T16:36:23.306500: step 3977, loss 0.694585, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:23.387596: step 3978, loss 0.777675, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:23.474982: step 3979, loss 0.961184, acc 0.59375, learning_rate 0.0001
2017-09-28T16:36:23.562919: step 3980, loss 0.74401, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:23.643923: step 3981, loss 0.566756, acc 0.78125, learning_rate 0.0001
2017-09-28T16:36:23.725068: step 3982, loss 0.821698, acc 0.546875, learning_rate 0.0001
2017-09-28T16:36:23.806818: step 3983, loss 0.976642, acc 0.65625, learning_rate 0.0001
2017-09-28T16:36:23.885810: step 3984, loss 0.585004, acc 0.84375, learning_rate 0.0001
2017-09-28T16:36:23.968884: step 3985, loss 0.737085, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:24.050160: step 3986, loss 0.788378, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:24.131539: step 3987, loss 0.689469, acc 0.75, learning_rate 0.0001
2017-09-28T16:36:24.208754: step 3988, loss 0.780734, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:24.289785: step 3989, loss 0.765978, acc 0.75, learning_rate 0.0001
2017-09-28T16:36:24.373098: step 3990, loss 0.799027, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:24.455207: step 3991, loss 0.6302, acc 0.765625, learning_rate 0.0001
2017-09-28T16:36:24.538855: step 3992, loss 0.63232, acc 0.75, learning_rate 0.0001
2017-09-28T16:36:24.620496: step 3993, loss 0.816534, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:24.700151: step 3994, loss 0.605993, acc 0.796875, learning_rate 0.0001
2017-09-28T16:36:24.781806: step 3995, loss 0.696406, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:24.865840: step 3996, loss 0.804657, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:24.947978: step 3997, loss 0.777855, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:25.028614: step 3998, loss 0.770029, acc 0.640625, learning_rate 0.0001
2017-09-28T16:36:25.115595: step 3999, loss 0.828117, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:25.194596: step 4000, loss 0.692237, acc 0.734375, learning_rate 0.0001

Evaluation:
2017-09-28T16:36:25.460924: step 4000, loss 0.806061, acc 0.67482

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-4000

2017-09-28T16:36:26.011816: step 4001, loss 0.712863, acc 0.65625, learning_rate 0.0001
2017-09-28T16:36:26.091695: step 4002, loss 0.676545, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:26.172512: step 4003, loss 0.715244, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:26.251137: step 4004, loss 0.666465, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:26.333477: step 4005, loss 0.58522, acc 0.796875, learning_rate 0.0001
2017-09-28T16:36:26.417697: step 4006, loss 0.633002, acc 0.78125, learning_rate 0.0001
2017-09-28T16:36:26.499288: step 4007, loss 0.880951, acc 0.625, learning_rate 0.0001
2017-09-28T16:36:26.580415: step 4008, loss 0.656051, acc 0.75, learning_rate 0.0001
2017-09-28T16:36:26.659737: step 4009, loss 0.906466, acc 0.609375, learning_rate 0.0001
2017-09-28T16:36:26.742949: step 4010, loss 0.881827, acc 0.5625, learning_rate 0.0001
2017-09-28T16:36:26.825280: step 4011, loss 0.82588, acc 0.640625, learning_rate 0.0001
2017-09-28T16:36:26.905335: step 4012, loss 0.802454, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:26.984438: step 4013, loss 0.787529, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:27.065138: step 4014, loss 0.821958, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:27.147107: step 4015, loss 0.788985, acc 0.640625, learning_rate 0.0001
2017-09-28T16:36:27.228783: step 4016, loss 0.755803, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:27.309604: step 4017, loss 0.753442, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:27.373764: step 4018, loss 0.866345, acc 0.666667, learning_rate 0.0001
2017-09-28T16:36:27.457048: step 4019, loss 0.793118, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:27.538365: step 4020, loss 0.783055, acc 0.625, learning_rate 0.0001
2017-09-28T16:36:27.621174: step 4021, loss 0.684004, acc 0.75, learning_rate 0.0001
2017-09-28T16:36:27.703224: step 4022, loss 0.62578, acc 0.796875, learning_rate 0.0001
2017-09-28T16:36:27.784235: step 4023, loss 0.743965, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:27.864875: step 4024, loss 0.708447, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:27.946730: step 4025, loss 0.681581, acc 0.765625, learning_rate 0.0001
2017-09-28T16:36:28.025147: step 4026, loss 0.842935, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:28.111520: step 4027, loss 0.691323, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:28.193382: step 4028, loss 0.647032, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:28.275432: step 4029, loss 0.804481, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:28.354855: step 4030, loss 0.873165, acc 0.59375, learning_rate 0.0001
2017-09-28T16:36:28.440512: step 4031, loss 0.895422, acc 0.625, learning_rate 0.0001
2017-09-28T16:36:28.525544: step 4032, loss 0.729856, acc 0.765625, learning_rate 0.0001
2017-09-28T16:36:28.612363: step 4033, loss 0.670239, acc 0.78125, learning_rate 0.0001
2017-09-28T16:36:28.694244: step 4034, loss 0.875437, acc 0.65625, learning_rate 0.0001
2017-09-28T16:36:28.774593: step 4035, loss 0.851541, acc 0.65625, learning_rate 0.0001
2017-09-28T16:36:28.852576: step 4036, loss 0.665347, acc 0.78125, learning_rate 0.0001
2017-09-28T16:36:28.943089: step 4037, loss 0.642019, acc 0.765625, learning_rate 0.0001
2017-09-28T16:36:29.029652: step 4038, loss 0.81359, acc 0.578125, learning_rate 0.0001
2017-09-28T16:36:29.116007: step 4039, loss 0.746268, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:29.205383: step 4040, loss 0.716978, acc 0.75, learning_rate 0.0001

Evaluation:
2017-09-28T16:36:29.487200: step 4040, loss 0.805976, acc 0.67482

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-4040

2017-09-28T16:36:30.140159: step 4041, loss 0.763865, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:30.228525: step 4042, loss 0.681739, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:30.316857: step 4043, loss 0.839648, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:30.401860: step 4044, loss 0.594749, acc 0.765625, learning_rate 0.0001
2017-09-28T16:36:30.491546: step 4045, loss 0.831141, acc 0.640625, learning_rate 0.0001
2017-09-28T16:36:30.574477: step 4046, loss 0.851458, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:30.655443: step 4047, loss 0.826936, acc 0.65625, learning_rate 0.0001
2017-09-28T16:36:30.739369: step 4048, loss 0.725523, acc 0.75, learning_rate 0.0001
2017-09-28T16:36:30.820920: step 4049, loss 0.678278, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:30.905745: step 4050, loss 0.725682, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:30.988430: step 4051, loss 0.810713, acc 0.65625, learning_rate 0.0001
2017-09-28T16:36:31.069940: step 4052, loss 0.962508, acc 0.609375, learning_rate 0.0001
2017-09-28T16:36:31.152258: step 4053, loss 0.788999, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:31.235238: step 4054, loss 0.711124, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:31.318344: step 4055, loss 0.639871, acc 0.75, learning_rate 0.0001
2017-09-28T16:36:31.405685: step 4056, loss 0.790664, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:31.489815: step 4057, loss 0.756949, acc 0.65625, learning_rate 0.0001
2017-09-28T16:36:31.574055: step 4058, loss 0.812109, acc 0.625, learning_rate 0.0001
2017-09-28T16:36:31.661385: step 4059, loss 0.780565, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:31.745129: step 4060, loss 0.723098, acc 0.640625, learning_rate 0.0001
2017-09-28T16:36:31.827068: step 4061, loss 0.778559, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:31.909325: step 4062, loss 0.739379, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:31.996755: step 4063, loss 0.711088, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:32.079970: step 4064, loss 0.824244, acc 0.75, learning_rate 0.0001
2017-09-28T16:36:32.163186: step 4065, loss 0.807855, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:32.247787: step 4066, loss 0.684009, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:32.341769: step 4067, loss 0.835267, acc 0.65625, learning_rate 0.0001
2017-09-28T16:36:32.437108: step 4068, loss 0.926821, acc 0.640625, learning_rate 0.0001
2017-09-28T16:36:32.524804: step 4069, loss 0.690265, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:32.613276: step 4070, loss 0.944805, acc 0.546875, learning_rate 0.0001
2017-09-28T16:36:32.697871: step 4071, loss 0.835146, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:32.778115: step 4072, loss 0.722146, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:32.862173: step 4073, loss 0.827831, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:32.945197: step 4074, loss 0.792726, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:33.028322: step 4075, loss 0.701158, acc 0.75, learning_rate 0.0001
2017-09-28T16:36:33.109486: step 4076, loss 0.651451, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:33.193187: step 4077, loss 0.653348, acc 0.796875, learning_rate 0.0001
2017-09-28T16:36:33.273932: step 4078, loss 0.66833, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:33.355581: step 4079, loss 0.858293, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:33.437516: step 4080, loss 0.819447, acc 0.734375, learning_rate 0.0001

Evaluation:
2017-09-28T16:36:33.724658: step 4080, loss 0.805264, acc 0.677698

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-4080

2017-09-28T16:36:34.231836: step 4081, loss 0.58388, acc 0.78125, learning_rate 0.0001
2017-09-28T16:36:34.319865: step 4082, loss 0.72227, acc 0.765625, learning_rate 0.0001
2017-09-28T16:36:34.401976: step 4083, loss 0.807252, acc 0.65625, learning_rate 0.0001
2017-09-28T16:36:34.485982: step 4084, loss 0.755651, acc 0.65625, learning_rate 0.0001
2017-09-28T16:36:34.569703: step 4085, loss 0.680078, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:34.654327: step 4086, loss 0.733717, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:34.738144: step 4087, loss 0.786625, acc 0.625, learning_rate 0.0001
2017-09-28T16:36:34.829497: step 4088, loss 0.666245, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:34.909419: step 4089, loss 0.932158, acc 0.59375, learning_rate 0.0001
2017-09-28T16:36:34.989253: step 4090, loss 0.824849, acc 0.59375, learning_rate 0.0001
2017-09-28T16:36:35.070803: step 4091, loss 0.725415, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:35.158591: step 4092, loss 0.91301, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:35.240595: step 4093, loss 0.870128, acc 0.5625, learning_rate 0.0001
2017-09-28T16:36:35.321298: step 4094, loss 0.671583, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:35.403085: step 4095, loss 0.902437, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:35.486488: step 4096, loss 0.667482, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:35.570887: step 4097, loss 0.685372, acc 0.78125, learning_rate 0.0001
2017-09-28T16:36:35.659896: step 4098, loss 0.659473, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:35.750946: step 4099, loss 0.813771, acc 0.59375, learning_rate 0.0001
2017-09-28T16:36:35.834131: step 4100, loss 0.70701, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:35.918870: step 4101, loss 0.842032, acc 0.625, learning_rate 0.0001
2017-09-28T16:36:36.002836: step 4102, loss 0.774615, acc 0.65625, learning_rate 0.0001
2017-09-28T16:36:36.082916: step 4103, loss 0.742156, acc 0.75, learning_rate 0.0001
2017-09-28T16:36:36.165839: step 4104, loss 0.528888, acc 0.828125, learning_rate 0.0001
2017-09-28T16:36:36.257348: step 4105, loss 0.804692, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:36.337812: step 4106, loss 0.93546, acc 0.578125, learning_rate 0.0001
2017-09-28T16:36:36.420271: step 4107, loss 0.615509, acc 0.75, learning_rate 0.0001
2017-09-28T16:36:36.504443: step 4108, loss 0.731287, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:36.594815: step 4109, loss 0.977057, acc 0.625, learning_rate 0.0001
2017-09-28T16:36:36.680364: step 4110, loss 0.778942, acc 0.65625, learning_rate 0.0001
2017-09-28T16:36:36.769364: step 4111, loss 0.717094, acc 0.625, learning_rate 0.0001
2017-09-28T16:36:36.851381: step 4112, loss 0.686035, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:36.934730: step 4113, loss 0.71119, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:37.022828: step 4114, loss 0.843982, acc 0.609375, learning_rate 0.0001
2017-09-28T16:36:37.110826: step 4115, loss 0.661548, acc 0.765625, learning_rate 0.0001
2017-09-28T16:36:37.181301: step 4116, loss 0.774302, acc 0.745098, learning_rate 0.0001
2017-09-28T16:36:37.263661: step 4117, loss 0.644548, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:37.346875: step 4118, loss 0.819122, acc 0.640625, learning_rate 0.0001
2017-09-28T16:36:37.428596: step 4119, loss 0.884585, acc 0.625, learning_rate 0.0001
2017-09-28T16:36:37.514619: step 4120, loss 0.679021, acc 0.765625, learning_rate 0.0001

Evaluation:
2017-09-28T16:36:37.792689: step 4120, loss 0.803071, acc 0.677698

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-4120

2017-09-28T16:36:38.362349: step 4121, loss 0.665512, acc 0.796875, learning_rate 0.0001
2017-09-28T16:36:38.444206: step 4122, loss 0.970307, acc 0.65625, learning_rate 0.0001
2017-09-28T16:36:38.528449: step 4123, loss 0.782235, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:38.612392: step 4124, loss 0.633835, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:38.695399: step 4125, loss 0.923214, acc 0.640625, learning_rate 0.0001
2017-09-28T16:36:38.783703: step 4126, loss 0.771799, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:38.869097: step 4127, loss 0.900305, acc 0.640625, learning_rate 0.0001
2017-09-28T16:36:38.952070: step 4128, loss 0.857631, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:39.036938: step 4129, loss 0.660561, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:39.120046: step 4130, loss 0.826745, acc 0.65625, learning_rate 0.0001
2017-09-28T16:36:39.202907: step 4131, loss 0.544494, acc 0.796875, learning_rate 0.0001
2017-09-28T16:36:39.296437: step 4132, loss 0.791112, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:39.386211: step 4133, loss 0.561621, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:39.476592: step 4134, loss 0.86132, acc 0.625, learning_rate 0.0001
2017-09-28T16:36:39.559660: step 4135, loss 0.856803, acc 0.609375, learning_rate 0.0001
2017-09-28T16:36:39.648796: step 4136, loss 0.714176, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:39.735278: step 4137, loss 0.815355, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:39.817566: step 4138, loss 0.810284, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:39.900846: step 4139, loss 0.92089, acc 0.546875, learning_rate 0.0001
2017-09-28T16:36:39.984328: step 4140, loss 0.703156, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:40.064287: step 4141, loss 0.78459, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:40.147123: step 4142, loss 0.699486, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:40.229095: step 4143, loss 0.746756, acc 0.75, learning_rate 0.0001
2017-09-28T16:36:40.313155: step 4144, loss 0.779745, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:40.395030: step 4145, loss 0.886587, acc 0.640625, learning_rate 0.0001
2017-09-28T16:36:40.477998: step 4146, loss 0.675039, acc 0.78125, learning_rate 0.0001
2017-09-28T16:36:40.557106: step 4147, loss 0.704847, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:40.640003: step 4148, loss 0.739025, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:40.720636: step 4149, loss 0.641832, acc 0.828125, learning_rate 0.0001
2017-09-28T16:36:40.801996: step 4150, loss 0.616212, acc 0.75, learning_rate 0.0001
2017-09-28T16:36:40.883736: step 4151, loss 0.62189, acc 0.796875, learning_rate 0.0001
2017-09-28T16:36:40.966001: step 4152, loss 0.985037, acc 0.59375, learning_rate 0.0001
2017-09-28T16:36:41.047953: step 4153, loss 0.815483, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:41.126032: step 4154, loss 0.887293, acc 0.65625, learning_rate 0.0001
2017-09-28T16:36:41.207981: step 4155, loss 0.719356, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:41.291012: step 4156, loss 0.602958, acc 0.796875, learning_rate 0.0001
2017-09-28T16:36:41.373045: step 4157, loss 0.801168, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:41.455803: step 4158, loss 0.776521, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:41.535447: step 4159, loss 0.778494, acc 0.640625, learning_rate 0.0001
2017-09-28T16:36:41.616587: step 4160, loss 0.672884, acc 0.71875, learning_rate 0.0001

Evaluation:
2017-09-28T16:36:41.884057: step 4160, loss 0.802878, acc 0.679137

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-4160

2017-09-28T16:36:42.433529: step 4161, loss 0.669256, acc 0.75, learning_rate 0.0001
2017-09-28T16:36:42.512275: step 4162, loss 0.61154, acc 0.78125, learning_rate 0.0001
2017-09-28T16:36:42.594449: step 4163, loss 0.745303, acc 0.625, learning_rate 0.0001
2017-09-28T16:36:42.678347: step 4164, loss 0.89553, acc 0.65625, learning_rate 0.0001
2017-09-28T16:36:42.760279: step 4165, loss 0.729558, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:42.843095: step 4166, loss 0.700027, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:42.924643: step 4167, loss 0.744567, acc 0.65625, learning_rate 0.0001
2017-09-28T16:36:43.006725: step 4168, loss 0.719495, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:43.092959: step 4169, loss 0.713788, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:43.179276: step 4170, loss 0.880764, acc 0.59375, learning_rate 0.0001
2017-09-28T16:36:43.261723: step 4171, loss 0.650701, acc 0.75, learning_rate 0.0001
2017-09-28T16:36:43.345072: step 4172, loss 0.668925, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:43.425983: step 4173, loss 0.905353, acc 0.59375, learning_rate 0.0001
2017-09-28T16:36:43.509613: step 4174, loss 0.641575, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:43.593352: step 4175, loss 0.879736, acc 0.625, learning_rate 0.0001
2017-09-28T16:36:43.679023: step 4176, loss 0.705586, acc 0.765625, learning_rate 0.0001
2017-09-28T16:36:43.763197: step 4177, loss 0.765786, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:43.845900: step 4178, loss 0.710907, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:43.930244: step 4179, loss 0.75278, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:44.015565: step 4180, loss 0.697525, acc 0.765625, learning_rate 0.0001
2017-09-28T16:36:44.094503: step 4181, loss 0.753598, acc 0.765625, learning_rate 0.0001
2017-09-28T16:36:44.175169: step 4182, loss 0.773088, acc 0.65625, learning_rate 0.0001
2017-09-28T16:36:44.253829: step 4183, loss 0.802086, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:44.336343: step 4184, loss 0.824195, acc 0.65625, learning_rate 0.0001
2017-09-28T16:36:44.422864: step 4185, loss 0.829485, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:44.505218: step 4186, loss 0.806319, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:44.585882: step 4187, loss 0.692697, acc 0.75, learning_rate 0.0001
2017-09-28T16:36:44.666899: step 4188, loss 0.809392, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:44.746905: step 4189, loss 0.827555, acc 0.609375, learning_rate 0.0001
2017-09-28T16:36:44.827714: step 4190, loss 0.879329, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:44.910220: step 4191, loss 0.760723, acc 0.640625, learning_rate 0.0001
2017-09-28T16:36:44.991249: step 4192, loss 0.745607, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:45.079615: step 4193, loss 0.759528, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:45.166300: step 4194, loss 0.675576, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:45.248132: step 4195, loss 0.803071, acc 0.65625, learning_rate 0.0001
2017-09-28T16:36:45.330761: step 4196, loss 0.666938, acc 0.75, learning_rate 0.0001
2017-09-28T16:36:45.410416: step 4197, loss 0.706121, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:45.490614: step 4198, loss 0.670273, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:45.572267: step 4199, loss 0.616777, acc 0.75, learning_rate 0.0001
2017-09-28T16:36:45.653678: step 4200, loss 0.752598, acc 0.703125, learning_rate 0.0001

Evaluation:
2017-09-28T16:36:45.916767: step 4200, loss 0.80334, acc 0.677698

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-4200

2017-09-28T16:36:46.545487: step 4201, loss 0.917903, acc 0.625, learning_rate 0.0001
2017-09-28T16:36:46.626706: step 4202, loss 0.647431, acc 0.78125, learning_rate 0.0001
2017-09-28T16:36:46.703888: step 4203, loss 0.525504, acc 0.796875, learning_rate 0.0001
2017-09-28T16:36:46.783332: step 4204, loss 0.618952, acc 0.796875, learning_rate 0.0001
2017-09-28T16:36:46.864480: step 4205, loss 0.748522, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:46.946161: step 4206, loss 0.831515, acc 0.640625, learning_rate 0.0001
2017-09-28T16:36:47.027252: step 4207, loss 0.615144, acc 0.75, learning_rate 0.0001
2017-09-28T16:36:47.106194: step 4208, loss 0.707658, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:47.188386: step 4209, loss 0.714615, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:47.267576: step 4210, loss 0.768737, acc 0.75, learning_rate 0.0001
2017-09-28T16:36:47.347640: step 4211, loss 0.80499, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:47.429720: step 4212, loss 0.602365, acc 0.78125, learning_rate 0.0001
2017-09-28T16:36:47.512347: step 4213, loss 0.706957, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:47.577544: step 4214, loss 0.806894, acc 0.764706, learning_rate 0.0001
2017-09-28T16:36:47.657018: step 4215, loss 0.616991, acc 0.78125, learning_rate 0.0001
2017-09-28T16:36:47.737669: step 4216, loss 0.775861, acc 0.65625, learning_rate 0.0001
2017-09-28T16:36:47.819417: step 4217, loss 0.76496, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:47.900357: step 4218, loss 0.642273, acc 0.78125, learning_rate 0.0001
2017-09-28T16:36:47.983451: step 4219, loss 0.639464, acc 0.765625, learning_rate 0.0001
2017-09-28T16:36:48.062653: step 4220, loss 0.729239, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:48.143845: step 4221, loss 0.858605, acc 0.640625, learning_rate 0.0001
2017-09-28T16:36:48.226415: step 4222, loss 0.734554, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:48.311754: step 4223, loss 0.760481, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:48.393227: step 4224, loss 0.821461, acc 0.59375, learning_rate 0.0001
2017-09-28T16:36:48.475248: step 4225, loss 0.666121, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:48.556453: step 4226, loss 0.814399, acc 0.609375, learning_rate 0.0001
2017-09-28T16:36:48.638110: step 4227, loss 0.721996, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:48.724359: step 4228, loss 0.70817, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:48.809103: step 4229, loss 0.788737, acc 0.640625, learning_rate 0.0001
2017-09-28T16:36:48.892977: step 4230, loss 0.648389, acc 0.78125, learning_rate 0.0001
2017-09-28T16:36:48.975382: step 4231, loss 0.824577, acc 0.640625, learning_rate 0.0001
2017-09-28T16:36:49.054993: step 4232, loss 0.652244, acc 0.796875, learning_rate 0.0001
2017-09-28T16:36:49.137186: step 4233, loss 0.751793, acc 0.625, learning_rate 0.0001
2017-09-28T16:36:49.219841: step 4234, loss 0.611403, acc 0.78125, learning_rate 0.0001
2017-09-28T16:36:49.300103: step 4235, loss 0.587163, acc 0.796875, learning_rate 0.0001
2017-09-28T16:36:49.380874: step 4236, loss 0.777217, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:49.459724: step 4237, loss 0.622755, acc 0.75, learning_rate 0.0001
2017-09-28T16:36:49.542884: step 4238, loss 0.748251, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:49.626786: step 4239, loss 0.724812, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:49.706722: step 4240, loss 0.833998, acc 0.671875, learning_rate 0.0001

Evaluation:
2017-09-28T16:36:49.965071: step 4240, loss 0.80201, acc 0.677698

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-4240

2017-09-28T16:36:50.451260: step 4241, loss 0.853803, acc 0.625, learning_rate 0.0001
2017-09-28T16:36:50.530365: step 4242, loss 0.702421, acc 0.640625, learning_rate 0.0001
2017-09-28T16:36:50.612181: step 4243, loss 0.774923, acc 0.65625, learning_rate 0.0001
2017-09-28T16:36:50.696347: step 4244, loss 0.898738, acc 0.625, learning_rate 0.0001
2017-09-28T16:36:50.779447: step 4245, loss 0.61685, acc 0.859375, learning_rate 0.0001
2017-09-28T16:36:50.861073: step 4246, loss 0.581591, acc 0.765625, learning_rate 0.0001
2017-09-28T16:36:50.942446: step 4247, loss 0.730454, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:51.023162: step 4248, loss 0.713152, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:51.102984: step 4249, loss 0.794207, acc 0.609375, learning_rate 0.0001
2017-09-28T16:36:51.183145: step 4250, loss 0.651686, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:51.263435: step 4251, loss 1.01838, acc 0.578125, learning_rate 0.0001
2017-09-28T16:36:51.348226: step 4252, loss 0.716935, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:51.432079: step 4253, loss 0.778273, acc 0.75, learning_rate 0.0001
2017-09-28T16:36:51.513310: step 4254, loss 0.699474, acc 0.78125, learning_rate 0.0001
2017-09-28T16:36:51.594760: step 4255, loss 0.871494, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:51.673148: step 4256, loss 0.772293, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:51.752649: step 4257, loss 0.918978, acc 0.640625, learning_rate 0.0001
2017-09-28T16:36:51.836119: step 4258, loss 0.744944, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:51.917547: step 4259, loss 0.809741, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:51.999551: step 4260, loss 0.714248, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:52.082256: step 4261, loss 0.564754, acc 0.84375, learning_rate 0.0001
2017-09-28T16:36:52.162932: step 4262, loss 0.765847, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:52.247740: step 4263, loss 0.610216, acc 0.796875, learning_rate 0.0001
2017-09-28T16:36:52.329823: step 4264, loss 0.761638, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:52.413093: step 4265, loss 0.557303, acc 0.796875, learning_rate 0.0001
2017-09-28T16:36:52.493090: step 4266, loss 0.649149, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:52.575444: step 4267, loss 0.850008, acc 0.640625, learning_rate 0.0001
2017-09-28T16:36:52.657165: step 4268, loss 0.59227, acc 0.8125, learning_rate 0.0001
2017-09-28T16:36:52.737549: step 4269, loss 0.638277, acc 0.75, learning_rate 0.0001
2017-09-28T16:36:52.817241: step 4270, loss 0.838817, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:52.898063: step 4271, loss 0.958111, acc 0.640625, learning_rate 0.0001
2017-09-28T16:36:52.980822: step 4272, loss 0.831126, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:53.063862: step 4273, loss 0.940455, acc 0.5625, learning_rate 0.0001
2017-09-28T16:36:53.145352: step 4274, loss 0.825449, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:53.224303: step 4275, loss 0.764434, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:53.305617: step 4276, loss 0.742145, acc 0.765625, learning_rate 0.0001
2017-09-28T16:36:53.384774: step 4277, loss 0.683881, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:53.467486: step 4278, loss 0.763037, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:53.548082: step 4279, loss 0.812673, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:53.630437: step 4280, loss 0.879101, acc 0.59375, learning_rate 0.0001

Evaluation:
2017-09-28T16:36:53.898795: step 4280, loss 0.800704, acc 0.677698

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-4280

2017-09-28T16:36:54.453008: step 4281, loss 0.861113, acc 0.640625, learning_rate 0.0001
2017-09-28T16:36:54.535388: step 4282, loss 0.688722, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:54.614909: step 4283, loss 0.724347, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:54.692551: step 4284, loss 0.727079, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:54.773471: step 4285, loss 0.838223, acc 0.625, learning_rate 0.0001
2017-09-28T16:36:54.855383: step 4286, loss 0.913222, acc 0.578125, learning_rate 0.0001
2017-09-28T16:36:54.937687: step 4287, loss 0.835951, acc 0.640625, learning_rate 0.0001
2017-09-28T16:36:55.017041: step 4288, loss 0.876024, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:55.096569: step 4289, loss 0.804629, acc 0.625, learning_rate 0.0001
2017-09-28T16:36:55.180970: step 4290, loss 0.964519, acc 0.59375, learning_rate 0.0001
2017-09-28T16:36:55.261563: step 4291, loss 0.722371, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:55.342948: step 4292, loss 0.663705, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:55.424005: step 4293, loss 0.751907, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:55.508433: step 4294, loss 1.07468, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:55.590245: step 4295, loss 0.757439, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:55.667488: step 4296, loss 0.80653, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:55.747711: step 4297, loss 0.67559, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:55.829946: step 4298, loss 0.683043, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:55.910261: step 4299, loss 0.66047, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:55.990361: step 4300, loss 0.798089, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:56.069062: step 4301, loss 0.701969, acc 0.75, learning_rate 0.0001
2017-09-28T16:36:56.151545: step 4302, loss 0.738273, acc 0.765625, learning_rate 0.0001
2017-09-28T16:36:56.231592: step 4303, loss 0.871286, acc 0.65625, learning_rate 0.0001
2017-09-28T16:36:56.310343: step 4304, loss 0.638195, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:56.395130: step 4305, loss 0.809566, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:56.477026: step 4306, loss 0.674854, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:56.561195: step 4307, loss 0.637608, acc 0.734375, learning_rate 0.0001
2017-09-28T16:36:56.642129: step 4308, loss 0.665481, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:56.720357: step 4309, loss 0.791278, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:56.799953: step 4310, loss 0.819693, acc 0.640625, learning_rate 0.0001
2017-09-28T16:36:56.881078: step 4311, loss 0.759283, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:56.947763: step 4312, loss 0.633129, acc 0.764706, learning_rate 0.0001
2017-09-28T16:36:57.029796: step 4313, loss 0.632704, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:57.109568: step 4314, loss 0.873389, acc 0.640625, learning_rate 0.0001
2017-09-28T16:36:57.190177: step 4315, loss 0.719991, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:57.270328: step 4316, loss 0.784261, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:57.351017: step 4317, loss 0.675568, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:57.433330: step 4318, loss 0.919597, acc 0.625, learning_rate 0.0001
2017-09-28T16:36:57.511743: step 4319, loss 0.652871, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:57.590510: step 4320, loss 0.723169, acc 0.703125, learning_rate 0.0001

Evaluation:
2017-09-28T16:36:57.849403: step 4320, loss 0.79925, acc 0.680576

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-4320

2017-09-28T16:36:58.405876: step 4321, loss 0.970157, acc 0.578125, learning_rate 0.0001
2017-09-28T16:36:58.485522: step 4322, loss 0.848196, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:58.567953: step 4323, loss 0.711334, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:58.650146: step 4324, loss 0.859752, acc 0.609375, learning_rate 0.0001
2017-09-28T16:36:58.731163: step 4325, loss 0.839762, acc 0.625, learning_rate 0.0001
2017-09-28T16:36:58.818235: step 4326, loss 0.836477, acc 0.609375, learning_rate 0.0001
2017-09-28T16:36:58.900562: step 4327, loss 0.762581, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:58.982313: step 4328, loss 0.510813, acc 0.78125, learning_rate 0.0001
2017-09-28T16:36:59.061800: step 4329, loss 0.800814, acc 0.65625, learning_rate 0.0001
2017-09-28T16:36:59.142392: step 4330, loss 0.728813, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:59.221613: step 4331, loss 0.70811, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:59.302764: step 4332, loss 0.799799, acc 0.640625, learning_rate 0.0001
2017-09-28T16:36:59.385775: step 4333, loss 0.778272, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:59.468291: step 4334, loss 0.697002, acc 0.765625, learning_rate 0.0001
2017-09-28T16:36:59.548963: step 4335, loss 0.687437, acc 0.71875, learning_rate 0.0001
2017-09-28T16:36:59.630410: step 4336, loss 0.858094, acc 0.625, learning_rate 0.0001
2017-09-28T16:36:59.710410: step 4337, loss 0.710323, acc 0.6875, learning_rate 0.0001
2017-09-28T16:36:59.790338: step 4338, loss 0.766866, acc 0.703125, learning_rate 0.0001
2017-09-28T16:36:59.872207: step 4339, loss 0.849301, acc 0.671875, learning_rate 0.0001
2017-09-28T16:36:59.953814: step 4340, loss 0.770509, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:00.035482: step 4341, loss 0.629671, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:00.116839: step 4342, loss 0.989212, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:00.198008: step 4343, loss 0.685955, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:00.277998: step 4344, loss 0.9116, acc 0.609375, learning_rate 0.0001
2017-09-28T16:37:00.358101: step 4345, loss 0.738899, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:00.439276: step 4346, loss 0.970801, acc 0.625, learning_rate 0.0001
2017-09-28T16:37:00.517464: step 4347, loss 0.644551, acc 0.796875, learning_rate 0.0001
2017-09-28T16:37:00.597249: step 4348, loss 0.599493, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:00.678654: step 4349, loss 0.635084, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:00.760852: step 4350, loss 0.996993, acc 0.609375, learning_rate 0.0001
2017-09-28T16:37:00.841619: step 4351, loss 0.750513, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:00.923940: step 4352, loss 0.613934, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:01.003952: step 4353, loss 0.718663, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:01.082174: step 4354, loss 0.721967, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:01.165563: step 4355, loss 0.744129, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:01.244524: step 4356, loss 0.609045, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:01.327987: step 4357, loss 0.754997, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:01.410228: step 4358, loss 0.633203, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:01.489507: step 4359, loss 0.616463, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:01.571985: step 4360, loss 0.735529, acc 0.765625, learning_rate 0.0001

Evaluation:
2017-09-28T16:37:01.836760: step 4360, loss 0.800331, acc 0.677698

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-4360

2017-09-28T16:37:02.462975: step 4361, loss 0.750857, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:02.539880: step 4362, loss 0.768836, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:02.623950: step 4363, loss 0.611547, acc 0.78125, learning_rate 0.0001
2017-09-28T16:37:02.703799: step 4364, loss 0.828092, acc 0.59375, learning_rate 0.0001
2017-09-28T16:37:02.784608: step 4365, loss 0.73573, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:02.864694: step 4366, loss 0.811916, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:02.942599: step 4367, loss 0.777088, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:03.023974: step 4368, loss 0.783586, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:03.106567: step 4369, loss 0.72946, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:03.188473: step 4370, loss 0.706346, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:03.268576: step 4371, loss 0.671728, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:03.347995: step 4372, loss 0.758778, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:03.432147: step 4373, loss 0.968228, acc 0.59375, learning_rate 0.0001
2017-09-28T16:37:03.510716: step 4374, loss 0.920757, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:03.590067: step 4375, loss 0.625021, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:03.670842: step 4376, loss 0.915347, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:03.750699: step 4377, loss 0.787667, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:03.832602: step 4378, loss 0.729896, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:03.915205: step 4379, loss 0.81953, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:03.998201: step 4380, loss 0.846572, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:04.079230: step 4381, loss 0.755103, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:04.161323: step 4382, loss 0.815671, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:04.244484: step 4383, loss 0.737423, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:04.323824: step 4384, loss 0.813145, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:04.404060: step 4385, loss 0.67373, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:04.489041: step 4386, loss 0.785686, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:04.571290: step 4387, loss 0.802912, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:04.654448: step 4388, loss 0.783217, acc 0.625, learning_rate 0.0001
2017-09-28T16:37:04.733014: step 4389, loss 0.75545, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:04.814594: step 4390, loss 0.761459, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:04.898250: step 4391, loss 0.818998, acc 0.625, learning_rate 0.0001
2017-09-28T16:37:04.979094: step 4392, loss 0.709692, acc 0.78125, learning_rate 0.0001
2017-09-28T16:37:05.060311: step 4393, loss 0.694163, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:05.142315: step 4394, loss 0.65751, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:05.224770: step 4395, loss 0.699157, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:05.305403: step 4396, loss 0.751945, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:05.387742: step 4397, loss 0.595558, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:05.467778: step 4398, loss 0.934913, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:05.551995: step 4399, loss 0.774864, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:05.635535: step 4400, loss 0.564661, acc 0.796875, learning_rate 0.0001

Evaluation:
2017-09-28T16:37:05.905216: step 4400, loss 0.796734, acc 0.679137

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-4400

2017-09-28T16:37:06.393919: step 4401, loss 0.613353, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:06.472927: step 4402, loss 0.732181, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:06.554729: step 4403, loss 0.877957, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:06.636651: step 4404, loss 0.853028, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:06.715324: step 4405, loss 0.787971, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:06.795377: step 4406, loss 0.603308, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:06.878729: step 4407, loss 0.721661, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:06.959489: step 4408, loss 0.733187, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:07.041311: step 4409, loss 0.680963, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:07.104418: step 4410, loss 0.628366, acc 0.745098, learning_rate 0.0001
2017-09-28T16:37:07.184652: step 4411, loss 0.775807, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:07.263906: step 4412, loss 0.513408, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:07.343326: step 4413, loss 0.6721, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:07.426961: step 4414, loss 0.813346, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:07.510417: step 4415, loss 0.632506, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:07.589843: step 4416, loss 0.744937, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:07.669498: step 4417, loss 0.707958, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:07.747376: step 4418, loss 0.832705, acc 0.625, learning_rate 0.0001
2017-09-28T16:37:07.830651: step 4419, loss 0.585667, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:07.911155: step 4420, loss 0.735016, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:07.993915: step 4421, loss 0.561469, acc 0.796875, learning_rate 0.0001
2017-09-28T16:37:08.072137: step 4422, loss 0.711884, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:08.151479: step 4423, loss 0.765205, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:08.231873: step 4424, loss 0.613873, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:08.313062: step 4425, loss 0.898565, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:08.393508: step 4426, loss 0.835888, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:08.474372: step 4427, loss 0.780496, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:08.555203: step 4428, loss 0.699015, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:08.636808: step 4429, loss 0.620112, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:08.718127: step 4430, loss 0.834653, acc 0.609375, learning_rate 0.0001
2017-09-28T16:37:08.798841: step 4431, loss 0.641217, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:08.884132: step 4432, loss 0.786845, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:08.965653: step 4433, loss 0.600902, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:09.053654: step 4434, loss 0.60743, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:09.132717: step 4435, loss 0.707972, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:09.214320: step 4436, loss 0.641634, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:09.299182: step 4437, loss 0.760989, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:09.382055: step 4438, loss 0.746041, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:09.465564: step 4439, loss 0.75379, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:09.546278: step 4440, loss 0.705691, acc 0.65625, learning_rate 0.0001

Evaluation:
2017-09-28T16:37:09.813520: step 4440, loss 0.796946, acc 0.677698

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-4440

2017-09-28T16:37:10.362471: step 4441, loss 0.759738, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:10.443463: step 4442, loss 0.748388, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:10.522464: step 4443, loss 0.815571, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:10.603845: step 4444, loss 0.623974, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:10.686246: step 4445, loss 0.68867, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:10.768749: step 4446, loss 0.857172, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:10.849777: step 4447, loss 0.789592, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:10.931022: step 4448, loss 0.716239, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:11.013916: step 4449, loss 0.813853, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:11.094566: step 4450, loss 0.767251, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:11.174073: step 4451, loss 0.479375, acc 0.828125, learning_rate 0.0001
2017-09-28T16:37:11.257345: step 4452, loss 0.859712, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:11.340730: step 4453, loss 0.672112, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:11.422277: step 4454, loss 0.684909, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:11.502405: step 4455, loss 0.57415, acc 0.8125, learning_rate 0.0001
2017-09-28T16:37:11.584780: step 4456, loss 0.733394, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:11.665455: step 4457, loss 0.663455, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:11.744422: step 4458, loss 0.857413, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:11.826398: step 4459, loss 0.721791, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:11.907002: step 4460, loss 0.972963, acc 0.578125, learning_rate 0.0001
2017-09-28T16:37:11.987533: step 4461, loss 0.75636, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:12.067685: step 4462, loss 0.854879, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:12.150356: step 4463, loss 0.845236, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:12.233165: step 4464, loss 0.781228, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:12.312169: step 4465, loss 0.680699, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:12.391434: step 4466, loss 0.726244, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:12.472504: step 4467, loss 0.663471, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:12.552006: step 4468, loss 0.59135, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:12.633145: step 4469, loss 0.757348, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:12.713168: step 4470, loss 0.75161, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:12.791996: step 4471, loss 0.862425, acc 0.625, learning_rate 0.0001
2017-09-28T16:37:12.871935: step 4472, loss 0.739206, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:12.955276: step 4473, loss 0.556203, acc 0.859375, learning_rate 0.0001
2017-09-28T16:37:13.035918: step 4474, loss 0.816465, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:13.116114: step 4475, loss 0.850153, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:13.198031: step 4476, loss 0.689878, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:13.280981: step 4477, loss 0.820909, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:13.361677: step 4478, loss 0.934667, acc 0.609375, learning_rate 0.0001
2017-09-28T16:37:13.441203: step 4479, loss 0.797648, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:13.524531: step 4480, loss 0.815878, acc 0.640625, learning_rate 0.0001

Evaluation:
2017-09-28T16:37:13.789078: step 4480, loss 0.797025, acc 0.680576

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-4480

2017-09-28T16:37:14.348111: step 4481, loss 0.652199, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:14.432614: step 4482, loss 0.736063, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:14.514519: step 4483, loss 0.672305, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:14.599657: step 4484, loss 0.831171, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:14.681341: step 4485, loss 0.817784, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:14.762985: step 4486, loss 0.810523, acc 0.59375, learning_rate 0.0001
2017-09-28T16:37:14.840033: step 4487, loss 0.873822, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:14.918920: step 4488, loss 0.696734, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:15.001273: step 4489, loss 0.676551, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:15.080249: step 4490, loss 0.697637, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:15.158758: step 4491, loss 0.885295, acc 0.625, learning_rate 0.0001
2017-09-28T16:37:15.239593: step 4492, loss 0.938425, acc 0.5625, learning_rate 0.0001
2017-09-28T16:37:15.320940: step 4493, loss 0.682433, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:15.403074: step 4494, loss 0.860134, acc 0.609375, learning_rate 0.0001
2017-09-28T16:37:15.482885: step 4495, loss 0.754832, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:15.562850: step 4496, loss 0.641548, acc 0.78125, learning_rate 0.0001
2017-09-28T16:37:15.646007: step 4497, loss 0.860637, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:15.727247: step 4498, loss 0.69812, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:15.805703: step 4499, loss 0.541522, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:15.883970: step 4500, loss 0.767728, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:15.960955: step 4501, loss 0.758118, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:16.040574: step 4502, loss 0.733721, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:16.121363: step 4503, loss 0.787957, acc 0.625, learning_rate 0.0001
2017-09-28T16:37:16.201873: step 4504, loss 0.704381, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:16.283727: step 4505, loss 0.9907, acc 0.578125, learning_rate 0.0001
2017-09-28T16:37:16.363853: step 4506, loss 0.726829, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:16.446966: step 4507, loss 0.653741, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:16.513846: step 4508, loss 0.93437, acc 0.607843, learning_rate 0.0001
2017-09-28T16:37:16.596246: step 4509, loss 0.792415, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:16.678831: step 4510, loss 0.693365, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:16.758345: step 4511, loss 0.690336, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:16.839862: step 4512, loss 0.787496, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:16.920224: step 4513, loss 0.559109, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:16.999798: step 4514, loss 0.737464, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:17.083854: step 4515, loss 0.757551, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:17.163864: step 4516, loss 0.616187, acc 0.78125, learning_rate 0.0001
2017-09-28T16:37:17.246868: step 4517, loss 0.58861, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:17.329106: step 4518, loss 0.562533, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:17.409991: step 4519, loss 0.742636, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:17.490265: step 4520, loss 0.78914, acc 0.65625, learning_rate 0.0001

Evaluation:
2017-09-28T16:37:17.756645: step 4520, loss 0.796285, acc 0.677698

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-4520

2017-09-28T16:37:18.379629: step 4521, loss 0.638187, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:18.460670: step 4522, loss 0.846437, acc 0.625, learning_rate 0.0001
2017-09-28T16:37:18.541940: step 4523, loss 0.736488, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:18.625320: step 4524, loss 0.631541, acc 0.78125, learning_rate 0.0001
2017-09-28T16:37:18.705499: step 4525, loss 0.826045, acc 0.609375, learning_rate 0.0001
2017-09-28T16:37:18.784468: step 4526, loss 0.610357, acc 0.8125, learning_rate 0.0001
2017-09-28T16:37:18.866062: step 4527, loss 0.85098, acc 0.625, learning_rate 0.0001
2017-09-28T16:37:18.951803: step 4528, loss 0.926827, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:19.032199: step 4529, loss 0.821229, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:19.117565: step 4530, loss 0.778442, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:19.197937: step 4531, loss 0.702198, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:19.279184: step 4532, loss 0.762611, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:19.358930: step 4533, loss 0.757809, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:19.442873: step 4534, loss 0.817453, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:19.524176: step 4535, loss 0.774299, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:19.606132: step 4536, loss 0.741316, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:19.687231: step 4537, loss 0.803701, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:19.766527: step 4538, loss 0.791678, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:19.847990: step 4539, loss 0.631558, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:19.926592: step 4540, loss 0.871932, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:20.008447: step 4541, loss 0.849157, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:20.090492: step 4542, loss 0.746266, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:20.170634: step 4543, loss 0.545241, acc 0.78125, learning_rate 0.0001
2017-09-28T16:37:20.251223: step 4544, loss 0.699091, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:20.333012: step 4545, loss 0.699678, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:20.414776: step 4546, loss 0.690676, acc 0.796875, learning_rate 0.0001
2017-09-28T16:37:20.495344: step 4547, loss 0.828146, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:20.575732: step 4548, loss 0.795497, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:20.653400: step 4549, loss 0.664757, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:20.735397: step 4550, loss 0.794851, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:20.813675: step 4551, loss 0.701392, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:20.895595: step 4552, loss 0.783103, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:20.977162: step 4553, loss 0.789711, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:21.056391: step 4554, loss 0.651939, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:21.140483: step 4555, loss 0.800074, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:21.220946: step 4556, loss 0.634787, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:21.304861: step 4557, loss 0.781138, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:21.385618: step 4558, loss 0.897247, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:21.469897: step 4559, loss 0.650961, acc 0.78125, learning_rate 0.0001
2017-09-28T16:37:21.549972: step 4560, loss 0.748435, acc 0.75, learning_rate 0.0001

Evaluation:
2017-09-28T16:37:21.819216: step 4560, loss 0.795931, acc 0.677698

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-4560

2017-09-28T16:37:22.303823: step 4561, loss 0.573497, acc 0.796875, learning_rate 0.0001
2017-09-28T16:37:22.381668: step 4562, loss 0.619062, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:22.464330: step 4563, loss 0.649003, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:22.544426: step 4564, loss 0.574859, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:22.623943: step 4565, loss 0.675047, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:22.706970: step 4566, loss 0.835785, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:22.787195: step 4567, loss 0.708279, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:22.867017: step 4568, loss 0.7793, acc 0.625, learning_rate 0.0001
2017-09-28T16:37:22.949628: step 4569, loss 0.840118, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:23.027427: step 4570, loss 0.788242, acc 0.796875, learning_rate 0.0001
2017-09-28T16:37:23.109630: step 4571, loss 0.834208, acc 0.625, learning_rate 0.0001
2017-09-28T16:37:23.190181: step 4572, loss 0.647774, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:23.269948: step 4573, loss 0.45777, acc 0.84375, learning_rate 0.0001
2017-09-28T16:37:23.353614: step 4574, loss 0.803221, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:23.433619: step 4575, loss 0.851511, acc 0.609375, learning_rate 0.0001
2017-09-28T16:37:23.514107: step 4576, loss 0.731461, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:23.597812: step 4577, loss 0.805482, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:23.678910: step 4578, loss 0.659463, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:23.763279: step 4579, loss 0.757131, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:23.842541: step 4580, loss 0.755749, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:23.921266: step 4581, loss 0.792075, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:24.007859: step 4582, loss 0.756553, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:24.094409: step 4583, loss 0.770124, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:24.178831: step 4584, loss 0.646667, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:24.259381: step 4585, loss 0.79022, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:24.341575: step 4586, loss 0.824363, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:24.423220: step 4587, loss 0.570641, acc 0.796875, learning_rate 0.0001
2017-09-28T16:37:24.504623: step 4588, loss 0.759898, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:24.583141: step 4589, loss 0.797631, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:24.662268: step 4590, loss 0.791943, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:24.742650: step 4591, loss 0.693762, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:24.822863: step 4592, loss 0.786148, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:24.905558: step 4593, loss 0.793788, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:24.985919: step 4594, loss 0.733092, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:25.068053: step 4595, loss 0.912197, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:25.147917: step 4596, loss 0.596626, acc 0.796875, learning_rate 0.0001
2017-09-28T16:37:25.231356: step 4597, loss 0.796759, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:25.311701: step 4598, loss 0.820821, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:25.392747: step 4599, loss 0.639781, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:25.473608: step 4600, loss 0.755389, acc 0.6875, learning_rate 0.0001

Evaluation:
2017-09-28T16:37:25.752331: step 4600, loss 0.794856, acc 0.680576

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-4600

2017-09-28T16:37:26.316812: step 4601, loss 0.854931, acc 0.625, learning_rate 0.0001
2017-09-28T16:37:26.399669: step 4602, loss 0.997232, acc 0.625, learning_rate 0.0001
2017-09-28T16:37:26.480143: step 4603, loss 0.72892, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:26.564540: step 4604, loss 0.868116, acc 0.625, learning_rate 0.0001
2017-09-28T16:37:26.646585: step 4605, loss 0.637761, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:26.710890: step 4606, loss 0.526452, acc 0.862745, learning_rate 0.0001
2017-09-28T16:37:26.792422: step 4607, loss 0.637135, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:26.875330: step 4608, loss 0.881855, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:26.958240: step 4609, loss 0.656416, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:27.038013: step 4610, loss 0.762124, acc 0.625, learning_rate 0.0001
2017-09-28T16:37:27.118771: step 4611, loss 0.866998, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:27.198671: step 4612, loss 0.537565, acc 0.8125, learning_rate 0.0001
2017-09-28T16:37:27.278534: step 4613, loss 0.832396, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:27.358680: step 4614, loss 0.69718, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:27.441664: step 4615, loss 0.722873, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:27.521340: step 4616, loss 0.691626, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:27.601181: step 4617, loss 0.600112, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:27.684512: step 4618, loss 0.766152, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:27.764213: step 4619, loss 0.735607, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:27.843229: step 4620, loss 0.585676, acc 0.78125, learning_rate 0.0001
2017-09-28T16:37:27.923014: step 4621, loss 0.793683, acc 0.625, learning_rate 0.0001
2017-09-28T16:37:28.004290: step 4622, loss 0.681369, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:28.087532: step 4623, loss 0.803346, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:28.167390: step 4624, loss 0.634449, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:28.247239: step 4625, loss 0.740125, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:28.329801: step 4626, loss 0.94538, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:28.411905: step 4627, loss 0.733733, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:28.491819: step 4628, loss 0.821887, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:28.571443: step 4629, loss 0.69711, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:28.655673: step 4630, loss 0.826352, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:28.736947: step 4631, loss 0.712044, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:28.817490: step 4632, loss 0.678614, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:28.895642: step 4633, loss 0.790688, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:28.974461: step 4634, loss 0.827804, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:29.057959: step 4635, loss 0.774537, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:29.140536: step 4636, loss 0.642665, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:29.219920: step 4637, loss 0.57302, acc 0.796875, learning_rate 0.0001
2017-09-28T16:37:29.300094: step 4638, loss 0.80709, acc 0.59375, learning_rate 0.0001
2017-09-28T16:37:29.383376: step 4639, loss 0.802914, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:29.464034: step 4640, loss 0.736002, acc 0.6875, learning_rate 0.0001

Evaluation:
2017-09-28T16:37:29.742383: step 4640, loss 0.792678, acc 0.676259

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-4640

2017-09-28T16:37:30.291511: step 4641, loss 0.668245, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:30.372947: step 4642, loss 0.636155, acc 0.78125, learning_rate 0.0001
2017-09-28T16:37:30.454696: step 4643, loss 0.792888, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:30.536788: step 4644, loss 0.971123, acc 0.609375, learning_rate 0.0001
2017-09-28T16:37:30.618235: step 4645, loss 0.740382, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:30.698587: step 4646, loss 0.831082, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:30.778976: step 4647, loss 0.706982, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:30.860769: step 4648, loss 0.671392, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:30.940690: step 4649, loss 0.600444, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:31.024486: step 4650, loss 0.758286, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:31.105616: step 4651, loss 0.786167, acc 0.59375, learning_rate 0.0001
2017-09-28T16:37:31.186980: step 4652, loss 0.695592, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:31.271030: step 4653, loss 0.681077, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:31.352317: step 4654, loss 0.79186, acc 0.609375, learning_rate 0.0001
2017-09-28T16:37:31.431371: step 4655, loss 0.78859, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:31.513206: step 4656, loss 0.669129, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:31.596005: step 4657, loss 0.844886, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:31.678255: step 4658, loss 0.724158, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:31.759608: step 4659, loss 0.712605, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:31.840806: step 4660, loss 0.724961, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:31.921156: step 4661, loss 0.810243, acc 0.609375, learning_rate 0.0001
2017-09-28T16:37:32.002391: step 4662, loss 0.647554, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:32.085177: step 4663, loss 0.768694, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:32.169119: step 4664, loss 0.753643, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:32.252029: step 4665, loss 0.787618, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:32.332423: step 4666, loss 0.954434, acc 0.609375, learning_rate 0.0001
2017-09-28T16:37:32.419456: step 4667, loss 0.933071, acc 0.5625, learning_rate 0.0001
2017-09-28T16:37:32.500367: step 4668, loss 0.851157, acc 0.59375, learning_rate 0.0001
2017-09-28T16:37:32.583257: step 4669, loss 0.660406, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:32.661192: step 4670, loss 0.676815, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:32.741100: step 4671, loss 0.712658, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:32.821553: step 4672, loss 0.639569, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:32.904373: step 4673, loss 0.629962, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:32.985642: step 4674, loss 0.657725, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:33.066974: step 4675, loss 0.681409, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:33.146907: step 4676, loss 0.643995, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:33.229766: step 4677, loss 0.728453, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:33.311015: step 4678, loss 0.834179, acc 0.609375, learning_rate 0.0001
2017-09-28T16:37:33.392685: step 4679, loss 0.710011, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:33.474314: step 4680, loss 0.752551, acc 0.71875, learning_rate 0.0001

Evaluation:
2017-09-28T16:37:33.747466: step 4680, loss 0.794233, acc 0.680576

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-4680

2017-09-28T16:37:34.381303: step 4681, loss 0.711267, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:34.462128: step 4682, loss 0.6908, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:34.544977: step 4683, loss 0.836463, acc 0.609375, learning_rate 0.0001
2017-09-28T16:37:34.629020: step 4684, loss 0.761908, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:34.711061: step 4685, loss 0.691855, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:34.791460: step 4686, loss 0.854748, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:34.875100: step 4687, loss 0.826604, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:34.961421: step 4688, loss 0.803735, acc 0.625, learning_rate 0.0001
2017-09-28T16:37:35.048134: step 4689, loss 0.756348, acc 0.625, learning_rate 0.0001
2017-09-28T16:37:35.141454: step 4690, loss 0.667756, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:35.220459: step 4691, loss 0.74313, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:35.305305: step 4692, loss 0.535359, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:35.386687: step 4693, loss 0.72141, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:35.467992: step 4694, loss 0.83021, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:35.548683: step 4695, loss 0.558558, acc 0.8125, learning_rate 0.0001
2017-09-28T16:37:35.628092: step 4696, loss 0.699246, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:35.712195: step 4697, loss 0.72937, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:35.794031: step 4698, loss 0.704517, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:35.874585: step 4699, loss 0.694347, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:35.955564: step 4700, loss 0.679365, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:36.041258: step 4701, loss 0.581856, acc 0.78125, learning_rate 0.0001
2017-09-28T16:37:36.124282: step 4702, loss 0.742054, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:36.205340: step 4703, loss 0.747995, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:36.269537: step 4704, loss 0.739178, acc 0.686275, learning_rate 0.0001
2017-09-28T16:37:36.351708: step 4705, loss 0.752038, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:36.435043: step 4706, loss 0.733317, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:36.516561: step 4707, loss 0.743912, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:36.596107: step 4708, loss 0.694751, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:36.675638: step 4709, loss 0.748796, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:36.758444: step 4710, loss 0.829537, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:36.840529: step 4711, loss 0.673574, acc 0.796875, learning_rate 0.0001
2017-09-28T16:37:36.922257: step 4712, loss 0.799647, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:37.008135: step 4713, loss 0.776659, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:37.088316: step 4714, loss 0.597755, acc 0.78125, learning_rate 0.0001
2017-09-28T16:37:37.169844: step 4715, loss 0.745389, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:37.250381: step 4716, loss 0.682352, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:37.328020: step 4717, loss 0.707988, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:37.412217: step 4718, loss 0.78463, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:37.490976: step 4719, loss 0.658716, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:37.570848: step 4720, loss 0.66272, acc 0.734375, learning_rate 0.0001

Evaluation:
2017-09-28T16:37:37.845880: step 4720, loss 0.791797, acc 0.680576

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-4720

2017-09-28T16:37:38.336221: step 4721, loss 0.652279, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:38.421474: step 4722, loss 0.690485, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:38.507492: step 4723, loss 0.730394, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:38.587804: step 4724, loss 0.641578, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:38.668358: step 4725, loss 0.721228, acc 0.78125, learning_rate 0.0001
2017-09-28T16:37:38.749983: step 4726, loss 0.71252, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:38.831181: step 4727, loss 0.732216, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:38.915080: step 4728, loss 0.693337, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:38.994398: step 4729, loss 0.804345, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:39.077288: step 4730, loss 0.748668, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:39.163239: step 4731, loss 0.740366, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:39.246055: step 4732, loss 0.833517, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:39.332134: step 4733, loss 0.613325, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:39.412066: step 4734, loss 0.994148, acc 0.609375, learning_rate 0.0001
2017-09-28T16:37:39.491368: step 4735, loss 0.743499, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:39.577201: step 4736, loss 0.673974, acc 0.78125, learning_rate 0.0001
2017-09-28T16:37:39.659494: step 4737, loss 0.816147, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:39.742122: step 4738, loss 0.695838, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:39.822425: step 4739, loss 0.604704, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:39.906311: step 4740, loss 0.837991, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:39.990315: step 4741, loss 0.670097, acc 0.78125, learning_rate 0.0001
2017-09-28T16:37:40.070872: step 4742, loss 0.886365, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:40.153879: step 4743, loss 0.623825, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:40.233238: step 4744, loss 0.620422, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:40.315502: step 4745, loss 0.677969, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:40.397475: step 4746, loss 0.614696, acc 0.8125, learning_rate 0.0001
2017-09-28T16:37:40.477702: step 4747, loss 0.736318, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:40.561377: step 4748, loss 0.780979, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:40.641499: step 4749, loss 0.634521, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:40.723952: step 4750, loss 0.793449, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:40.806526: step 4751, loss 0.74547, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:40.888242: step 4752, loss 0.810326, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:40.968570: step 4753, loss 0.668521, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:41.051463: step 4754, loss 0.551819, acc 0.796875, learning_rate 0.0001
2017-09-28T16:37:41.133888: step 4755, loss 0.736417, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:41.215403: step 4756, loss 0.847613, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:41.294070: step 4757, loss 0.852244, acc 0.625, learning_rate 0.0001
2017-09-28T16:37:41.374283: step 4758, loss 0.704231, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:41.457153: step 4759, loss 0.640649, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:41.538346: step 4760, loss 0.712597, acc 0.671875, learning_rate 0.0001

Evaluation:
2017-09-28T16:37:41.809048: step 4760, loss 0.789764, acc 0.684892

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-4760

2017-09-28T16:37:42.363416: step 4761, loss 0.813208, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:42.444577: step 4762, loss 0.703114, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:42.527177: step 4763, loss 0.749153, acc 0.625, learning_rate 0.0001
2017-09-28T16:37:42.610118: step 4764, loss 0.550337, acc 0.84375, learning_rate 0.0001
2017-09-28T16:37:42.693813: step 4765, loss 0.540598, acc 0.796875, learning_rate 0.0001
2017-09-28T16:37:42.775936: step 4766, loss 0.823511, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:42.860027: step 4767, loss 0.711184, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:42.939548: step 4768, loss 0.741589, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:43.021730: step 4769, loss 0.68457, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:43.103569: step 4770, loss 0.711666, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:43.189006: step 4771, loss 0.647099, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:43.270257: step 4772, loss 0.845062, acc 0.59375, learning_rate 0.0001
2017-09-28T16:37:43.351904: step 4773, loss 0.607077, acc 0.796875, learning_rate 0.0001
2017-09-28T16:37:43.433069: step 4774, loss 0.92873, acc 0.625, learning_rate 0.0001
2017-09-28T16:37:43.515589: step 4775, loss 0.740769, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:43.596498: step 4776, loss 0.775148, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:43.676888: step 4777, loss 0.667394, acc 0.78125, learning_rate 0.0001
2017-09-28T16:37:43.759499: step 4778, loss 0.78554, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:43.840794: step 4779, loss 0.868146, acc 0.609375, learning_rate 0.0001
2017-09-28T16:37:43.919139: step 4780, loss 0.828031, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:44.000475: step 4781, loss 0.805558, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:44.080864: step 4782, loss 0.65339, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:44.167496: step 4783, loss 0.668683, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:44.248532: step 4784, loss 0.979613, acc 0.578125, learning_rate 0.0001
2017-09-28T16:37:44.332984: step 4785, loss 0.769975, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:44.416448: step 4786, loss 0.736323, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:44.498673: step 4787, loss 0.644311, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:44.579084: step 4788, loss 0.733792, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:44.661174: step 4789, loss 0.773172, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:44.744240: step 4790, loss 0.740147, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:44.828055: step 4791, loss 0.789301, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:44.913911: step 4792, loss 0.849864, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:44.999543: step 4793, loss 0.78257, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:45.083848: step 4794, loss 0.76141, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:45.166578: step 4795, loss 0.591737, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:45.253126: step 4796, loss 0.778978, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:45.339952: step 4797, loss 0.678035, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:45.424713: step 4798, loss 0.834013, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:45.510357: step 4799, loss 0.716662, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:45.592337: step 4800, loss 0.702768, acc 0.71875, learning_rate 0.0001

Evaluation:
2017-09-28T16:37:45.874009: step 4800, loss 0.79254, acc 0.684892

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-4800

2017-09-28T16:37:46.452210: step 4801, loss 0.742273, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:46.520340: step 4802, loss 0.560071, acc 0.784314, learning_rate 0.0001
2017-09-28T16:37:46.601491: step 4803, loss 0.735988, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:46.681208: step 4804, loss 0.623001, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:46.764093: step 4805, loss 0.71733, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:46.847092: step 4806, loss 0.845643, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:46.930886: step 4807, loss 0.742523, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:47.010914: step 4808, loss 0.666972, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:47.090867: step 4809, loss 0.676, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:47.170386: step 4810, loss 0.8868, acc 0.59375, learning_rate 0.0001
2017-09-28T16:37:47.250243: step 4811, loss 0.540246, acc 0.78125, learning_rate 0.0001
2017-09-28T16:37:47.328511: step 4812, loss 0.669452, acc 0.78125, learning_rate 0.0001
2017-09-28T16:37:47.413171: step 4813, loss 0.750282, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:47.494241: step 4814, loss 0.761434, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:47.576702: step 4815, loss 0.56138, acc 0.78125, learning_rate 0.0001
2017-09-28T16:37:47.657040: step 4816, loss 0.546139, acc 0.8125, learning_rate 0.0001
2017-09-28T16:37:47.740441: step 4817, loss 0.984898, acc 0.578125, learning_rate 0.0001
2017-09-28T16:37:47.827556: step 4818, loss 0.767251, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:47.910190: step 4819, loss 0.743389, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:47.994925: step 4820, loss 0.721189, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:48.075134: step 4821, loss 0.819951, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:48.155702: step 4822, loss 0.664811, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:48.236871: step 4823, loss 0.751343, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:48.319055: step 4824, loss 0.695268, acc 0.78125, learning_rate 0.0001
2017-09-28T16:37:48.399890: step 4825, loss 0.493181, acc 0.84375, learning_rate 0.0001
2017-09-28T16:37:48.478979: step 4826, loss 0.75332, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:48.560009: step 4827, loss 0.80214, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:48.643477: step 4828, loss 0.789185, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:48.719951: step 4829, loss 0.795619, acc 0.625, learning_rate 0.0001
2017-09-28T16:37:48.801103: step 4830, loss 0.69487, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:48.880805: step 4831, loss 0.811065, acc 0.609375, learning_rate 0.0001
2017-09-28T16:37:48.964085: step 4832, loss 0.674906, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:49.044785: step 4833, loss 0.952243, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:49.126006: step 4834, loss 0.740419, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:49.209051: step 4835, loss 0.558837, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:49.293249: step 4836, loss 0.776927, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:49.375284: step 4837, loss 0.593058, acc 0.796875, learning_rate 0.0001
2017-09-28T16:37:49.457534: step 4838, loss 0.582369, acc 0.796875, learning_rate 0.0001
2017-09-28T16:37:49.539103: step 4839, loss 0.892241, acc 0.625, learning_rate 0.0001
2017-09-28T16:37:49.621377: step 4840, loss 0.642129, acc 0.75, learning_rate 0.0001

Evaluation:
2017-09-28T16:37:49.893808: step 4840, loss 0.793069, acc 0.680576

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-4840

2017-09-28T16:37:50.523192: step 4841, loss 0.782227, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:50.605714: step 4842, loss 0.696932, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:50.684927: step 4843, loss 0.782792, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:50.764615: step 4844, loss 0.639571, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:50.847830: step 4845, loss 0.912229, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:50.932025: step 4846, loss 0.69717, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:51.013554: step 4847, loss 0.858502, acc 0.59375, learning_rate 0.0001
2017-09-28T16:37:51.096037: step 4848, loss 0.72322, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:51.178286: step 4849, loss 0.667689, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:51.257569: step 4850, loss 0.733139, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:51.338915: step 4851, loss 0.853367, acc 0.609375, learning_rate 0.0001
2017-09-28T16:37:51.420112: step 4852, loss 0.702046, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:51.500409: step 4853, loss 0.718832, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:51.580081: step 4854, loss 0.678054, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:51.661692: step 4855, loss 0.763778, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:51.743682: step 4856, loss 0.763262, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:51.823460: step 4857, loss 0.638774, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:51.906246: step 4858, loss 0.808571, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:51.992594: step 4859, loss 0.822141, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:52.074335: step 4860, loss 0.702365, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:52.154071: step 4861, loss 0.840574, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:52.237641: step 4862, loss 0.805235, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:52.317970: step 4863, loss 0.682819, acc 0.78125, learning_rate 0.0001
2017-09-28T16:37:52.402464: step 4864, loss 0.655927, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:52.483789: step 4865, loss 0.734468, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:52.563936: step 4866, loss 0.689829, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:52.647148: step 4867, loss 0.814002, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:52.728647: step 4868, loss 0.926598, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:52.806017: step 4869, loss 0.759422, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:52.883924: step 4870, loss 0.809254, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:52.967041: step 4871, loss 0.660766, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:53.048355: step 4872, loss 0.712632, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:53.131005: step 4873, loss 0.622375, acc 0.828125, learning_rate 0.0001
2017-09-28T16:37:53.211860: step 4874, loss 0.809984, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:53.292765: step 4875, loss 0.820923, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:53.374154: step 4876, loss 0.708174, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:53.456561: step 4877, loss 0.461609, acc 0.84375, learning_rate 0.0001
2017-09-28T16:37:53.539359: step 4878, loss 0.793963, acc 0.59375, learning_rate 0.0001
2017-09-28T16:37:53.619697: step 4879, loss 0.682607, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:53.700839: step 4880, loss 0.609447, acc 0.765625, learning_rate 0.0001

Evaluation:
2017-09-28T16:37:53.976048: step 4880, loss 0.790191, acc 0.689209

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-4880

2017-09-28T16:37:54.473986: step 4881, loss 0.521481, acc 0.828125, learning_rate 0.0001
2017-09-28T16:37:54.558296: step 4882, loss 0.86402, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:54.645494: step 4883, loss 0.667805, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:54.728641: step 4884, loss 0.722015, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:54.811803: step 4885, loss 0.622167, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:54.896620: step 4886, loss 0.672613, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:54.980754: step 4887, loss 0.709207, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:55.064699: step 4888, loss 0.560091, acc 0.78125, learning_rate 0.0001
2017-09-28T16:37:55.149748: step 4889, loss 0.805621, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:55.233001: step 4890, loss 0.77382, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:55.319466: step 4891, loss 0.661604, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:55.405578: step 4892, loss 0.870241, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:55.487658: step 4893, loss 0.652084, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:55.572212: step 4894, loss 0.783587, acc 0.640625, learning_rate 0.0001
2017-09-28T16:37:55.651847: step 4895, loss 0.685983, acc 0.78125, learning_rate 0.0001
2017-09-28T16:37:55.732212: step 4896, loss 0.749344, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:55.814263: step 4897, loss 0.717727, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:55.896341: step 4898, loss 0.610618, acc 0.78125, learning_rate 0.0001
2017-09-28T16:37:55.976188: step 4899, loss 0.836475, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:56.042561: step 4900, loss 0.900471, acc 0.666667, learning_rate 0.0001
2017-09-28T16:37:56.125440: step 4901, loss 0.716799, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:56.210149: step 4902, loss 0.643368, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:56.293175: step 4903, loss 0.718241, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:56.372501: step 4904, loss 0.641102, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:56.459028: step 4905, loss 0.725754, acc 0.671875, learning_rate 0.0001
2017-09-28T16:37:56.538360: step 4906, loss 0.685774, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:56.620575: step 4907, loss 0.7466, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:56.702284: step 4908, loss 0.798845, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:56.784029: step 4909, loss 0.693897, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:56.862934: step 4910, loss 0.811571, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:56.945774: step 4911, loss 0.744739, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:57.024716: step 4912, loss 0.652566, acc 0.828125, learning_rate 0.0001
2017-09-28T16:37:57.106046: step 4913, loss 0.663169, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:57.187228: step 4914, loss 0.644341, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:57.269559: step 4915, loss 0.744289, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:57.351127: step 4916, loss 0.613357, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:57.431692: step 4917, loss 0.721365, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:57.513076: step 4918, loss 0.746514, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:57.592735: step 4919, loss 0.675994, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:57.672557: step 4920, loss 0.735539, acc 0.71875, learning_rate 0.0001

Evaluation:
2017-09-28T16:37:57.944540: step 4920, loss 0.785647, acc 0.684892

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-4920

2017-09-28T16:37:58.499989: step 4921, loss 0.791556, acc 0.609375, learning_rate 0.0001
2017-09-28T16:37:58.578522: step 4922, loss 0.639242, acc 0.75, learning_rate 0.0001
2017-09-28T16:37:58.661005: step 4923, loss 0.530469, acc 0.84375, learning_rate 0.0001
2017-09-28T16:37:58.742177: step 4924, loss 0.812418, acc 0.625, learning_rate 0.0001
2017-09-28T16:37:58.824746: step 4925, loss 0.800878, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:58.910080: step 4926, loss 0.49905, acc 0.859375, learning_rate 0.0001
2017-09-28T16:37:58.987543: step 4927, loss 0.637949, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:59.071382: step 4928, loss 0.793417, acc 0.6875, learning_rate 0.0001
2017-09-28T16:37:59.153611: step 4929, loss 0.655728, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:59.236083: step 4930, loss 0.720738, acc 0.65625, learning_rate 0.0001
2017-09-28T16:37:59.317788: step 4931, loss 0.62655, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:59.402494: step 4932, loss 0.73817, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:59.483526: step 4933, loss 0.685665, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:59.564488: step 4934, loss 0.7691, acc 0.71875, learning_rate 0.0001
2017-09-28T16:37:59.645608: step 4935, loss 0.740306, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:59.727244: step 4936, loss 0.649546, acc 0.765625, learning_rate 0.0001
2017-09-28T16:37:59.808719: step 4937, loss 0.707466, acc 0.703125, learning_rate 0.0001
2017-09-28T16:37:59.890566: step 4938, loss 0.675511, acc 0.734375, learning_rate 0.0001
2017-09-28T16:37:59.974378: step 4939, loss 0.879795, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:00.058113: step 4940, loss 0.732367, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:00.140115: step 4941, loss 0.765089, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:00.223155: step 4942, loss 0.872152, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:00.304333: step 4943, loss 0.917833, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:00.386498: step 4944, loss 0.678789, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:00.468304: step 4945, loss 0.819997, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:00.549727: step 4946, loss 0.943454, acc 0.578125, learning_rate 0.0001
2017-09-28T16:38:00.634268: step 4947, loss 0.63, acc 0.78125, learning_rate 0.0001
2017-09-28T16:38:00.719268: step 4948, loss 0.653972, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:00.800687: step 4949, loss 0.579601, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:00.883132: step 4950, loss 0.549048, acc 0.796875, learning_rate 0.0001
2017-09-28T16:38:00.964911: step 4951, loss 0.750654, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:01.052720: step 4952, loss 0.734291, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:01.131513: step 4953, loss 0.840068, acc 0.625, learning_rate 0.0001
2017-09-28T16:38:01.210397: step 4954, loss 0.788871, acc 0.609375, learning_rate 0.0001
2017-09-28T16:38:01.289992: step 4955, loss 0.757327, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:01.373439: step 4956, loss 0.739653, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:01.457819: step 4957, loss 0.587083, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:01.537623: step 4958, loss 0.914552, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:01.620042: step 4959, loss 0.73268, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:01.698654: step 4960, loss 0.767521, acc 0.703125, learning_rate 0.0001

Evaluation:
2017-09-28T16:38:01.966002: step 4960, loss 0.787409, acc 0.68777

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-4960

2017-09-28T16:38:02.538015: step 4961, loss 0.709553, acc 0.78125, learning_rate 0.0001
2017-09-28T16:38:02.624664: step 4962, loss 0.78616, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:02.708964: step 4963, loss 0.781576, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:02.796756: step 4964, loss 0.626686, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:02.880758: step 4965, loss 0.848281, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:02.962824: step 4966, loss 0.697816, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:03.045445: step 4967, loss 0.740997, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:03.127436: step 4968, loss 0.660657, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:03.208378: step 4969, loss 0.720271, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:03.292338: step 4970, loss 0.850859, acc 0.625, learning_rate 0.0001
2017-09-28T16:38:03.376491: step 4971, loss 0.72363, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:03.460623: step 4972, loss 0.744014, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:03.540992: step 4973, loss 0.822036, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:03.624530: step 4974, loss 0.718228, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:03.706499: step 4975, loss 0.704297, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:03.789938: step 4976, loss 0.740029, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:03.875028: step 4977, loss 0.608008, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:03.955458: step 4978, loss 0.769882, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:04.035972: step 4979, loss 0.666021, acc 0.78125, learning_rate 0.0001
2017-09-28T16:38:04.117589: step 4980, loss 0.530466, acc 0.84375, learning_rate 0.0001
2017-09-28T16:38:04.203214: step 4981, loss 0.739574, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:04.289117: step 4982, loss 0.575455, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:04.370736: step 4983, loss 0.629111, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:04.454650: step 4984, loss 0.771384, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:04.535956: step 4985, loss 0.768308, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:04.614165: step 4986, loss 0.727067, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:04.695967: step 4987, loss 0.690696, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:04.776104: step 4988, loss 0.851798, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:04.856803: step 4989, loss 0.802678, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:04.938841: step 4990, loss 0.636874, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:05.019329: step 4991, loss 0.816227, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:05.101642: step 4992, loss 0.672633, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:05.184056: step 4993, loss 0.77162, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:05.262943: step 4994, loss 0.704306, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:05.345122: step 4995, loss 0.671088, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:05.425730: step 4996, loss 0.581521, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:05.511077: step 4997, loss 0.755288, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:05.580127: step 4998, loss 0.682696, acc 0.803922, learning_rate 0.0001
2017-09-28T16:38:05.664392: step 4999, loss 0.592144, acc 0.78125, learning_rate 0.0001
2017-09-28T16:38:05.747086: step 5000, loss 0.656412, acc 0.75, learning_rate 0.0001

Evaluation:
2017-09-28T16:38:06.015847: step 5000, loss 0.787781, acc 0.686331

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-5000

2017-09-28T16:38:06.654456: step 5001, loss 0.754934, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:06.736861: step 5002, loss 0.698191, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:06.816671: step 5003, loss 0.692369, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:06.898337: step 5004, loss 0.707298, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:06.981338: step 5005, loss 0.710396, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:07.064015: step 5006, loss 0.774468, acc 0.625, learning_rate 0.0001
2017-09-28T16:38:07.146431: step 5007, loss 0.870495, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:07.227771: step 5008, loss 1.0617, acc 0.609375, learning_rate 0.0001
2017-09-28T16:38:07.307353: step 5009, loss 0.700011, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:07.389850: step 5010, loss 0.697373, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:07.470023: step 5011, loss 0.821433, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:07.551976: step 5012, loss 0.812469, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:07.632666: step 5013, loss 0.70328, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:07.713401: step 5014, loss 0.666184, acc 0.78125, learning_rate 0.0001
2017-09-28T16:38:07.794071: step 5015, loss 0.644467, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:07.877934: step 5016, loss 0.725484, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:07.960684: step 5017, loss 0.7184, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:08.039861: step 5018, loss 0.75792, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:08.121071: step 5019, loss 0.850875, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:08.200657: step 5020, loss 0.697628, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:08.279863: step 5021, loss 0.735876, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:08.363201: step 5022, loss 0.719903, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:08.442000: step 5023, loss 0.764549, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:08.523172: step 5024, loss 0.802892, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:08.603332: step 5025, loss 0.585154, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:08.682290: step 5026, loss 0.943434, acc 0.578125, learning_rate 0.0001
2017-09-28T16:38:08.763317: step 5027, loss 0.649575, acc 0.8125, learning_rate 0.0001
2017-09-28T16:38:08.844997: step 5028, loss 0.903536, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:08.926445: step 5029, loss 0.782503, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:09.012136: step 5030, loss 0.510008, acc 0.8125, learning_rate 0.0001
2017-09-28T16:38:09.093467: step 5031, loss 0.761934, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:09.173057: step 5032, loss 0.905716, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:09.262012: step 5033, loss 0.715088, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:09.347635: step 5034, loss 0.540865, acc 0.828125, learning_rate 0.0001
2017-09-28T16:38:09.426008: step 5035, loss 0.813873, acc 0.609375, learning_rate 0.0001
2017-09-28T16:38:09.507103: step 5036, loss 0.891964, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:09.587771: step 5037, loss 0.867078, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:09.668269: step 5038, loss 0.600007, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:09.750856: step 5039, loss 0.945452, acc 0.578125, learning_rate 0.0001
2017-09-28T16:38:09.831954: step 5040, loss 0.582417, acc 0.8125, learning_rate 0.0001

Evaluation:
2017-09-28T16:38:10.102197: step 5040, loss 0.787139, acc 0.684892

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-5040

2017-09-28T16:38:10.601572: step 5041, loss 0.855009, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:10.686447: step 5042, loss 0.691108, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:10.770084: step 5043, loss 0.657616, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:10.852147: step 5044, loss 0.653266, acc 0.78125, learning_rate 0.0001
2017-09-28T16:38:10.932710: step 5045, loss 0.727126, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:11.014730: step 5046, loss 0.588574, acc 0.8125, learning_rate 0.0001
2017-09-28T16:38:11.098855: step 5047, loss 0.814203, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:11.182081: step 5048, loss 0.853383, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:11.261734: step 5049, loss 0.708017, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:11.340643: step 5050, loss 0.711824, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:11.422674: step 5051, loss 0.616575, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:11.503788: step 5052, loss 0.59546, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:11.585465: step 5053, loss 0.911909, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:11.667931: step 5054, loss 0.637747, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:11.746659: step 5055, loss 0.738486, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:11.826839: step 5056, loss 0.821163, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:11.907070: step 5057, loss 0.676499, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:11.987383: step 5058, loss 0.673644, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:12.068581: step 5059, loss 0.682746, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:12.149499: step 5060, loss 0.585126, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:12.232296: step 5061, loss 0.720259, acc 0.8125, learning_rate 0.0001
2017-09-28T16:38:12.314348: step 5062, loss 0.713563, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:12.396789: step 5063, loss 0.607294, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:12.476502: step 5064, loss 0.661415, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:12.556924: step 5065, loss 0.781964, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:12.640045: step 5066, loss 0.771479, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:12.719378: step 5067, loss 0.578856, acc 0.8125, learning_rate 0.0001
2017-09-28T16:38:12.800782: step 5068, loss 0.760046, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:12.882996: step 5069, loss 0.611924, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:12.963568: step 5070, loss 0.487097, acc 0.828125, learning_rate 0.0001
2017-09-28T16:38:13.046109: step 5071, loss 0.917383, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:13.127378: step 5072, loss 0.534397, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:13.209070: step 5073, loss 0.653881, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:13.287938: step 5074, loss 0.656926, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:13.367783: step 5075, loss 0.650915, acc 0.78125, learning_rate 0.0001
2017-09-28T16:38:13.448281: step 5076, loss 0.79063, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:13.531492: step 5077, loss 0.724607, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:13.611953: step 5078, loss 0.833665, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:13.693537: step 5079, loss 0.771714, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:13.774610: step 5080, loss 0.810636, acc 0.671875, learning_rate 0.0001

Evaluation:
2017-09-28T16:38:14.045744: step 5080, loss 0.784672, acc 0.686331

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-5080

2017-09-28T16:38:14.612813: step 5081, loss 0.774036, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:14.696321: step 5082, loss 0.551908, acc 0.796875, learning_rate 0.0001
2017-09-28T16:38:14.778622: step 5083, loss 0.646272, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:14.863250: step 5084, loss 0.842573, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:14.941611: step 5085, loss 0.735314, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:15.025592: step 5086, loss 0.881788, acc 0.625, learning_rate 0.0001
2017-09-28T16:38:15.106276: step 5087, loss 0.76589, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:15.186741: step 5088, loss 0.719872, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:15.270178: step 5089, loss 0.681616, acc 0.8125, learning_rate 0.0001
2017-09-28T16:38:15.350281: step 5090, loss 0.627465, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:15.430370: step 5091, loss 0.805322, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:15.512772: step 5092, loss 0.803934, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:15.594356: step 5093, loss 0.57843, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:15.673240: step 5094, loss 0.619919, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:15.753965: step 5095, loss 0.63887, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:15.819070: step 5096, loss 0.661671, acc 0.764706, learning_rate 0.0001
2017-09-28T16:38:15.901700: step 5097, loss 0.648917, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:15.983086: step 5098, loss 0.741145, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:16.065554: step 5099, loss 0.628879, acc 0.78125, learning_rate 0.0001
2017-09-28T16:38:16.149237: step 5100, loss 0.699848, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:16.230075: step 5101, loss 0.822247, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:16.310113: step 5102, loss 0.575748, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:16.389869: step 5103, loss 0.896171, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:16.473135: step 5104, loss 0.46831, acc 0.796875, learning_rate 0.0001
2017-09-28T16:38:16.552858: step 5105, loss 0.633955, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:16.635020: step 5106, loss 0.707217, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:16.715349: step 5107, loss 0.566306, acc 0.78125, learning_rate 0.0001
2017-09-28T16:38:16.798828: step 5108, loss 0.653709, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:16.878974: step 5109, loss 0.752779, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:16.963687: step 5110, loss 0.746893, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:17.045309: step 5111, loss 0.829442, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:17.127606: step 5112, loss 0.690413, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:17.208088: step 5113, loss 0.833382, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:17.288838: step 5114, loss 0.658371, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:17.372520: step 5115, loss 0.771086, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:17.450332: step 5116, loss 0.66131, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:17.531268: step 5117, loss 0.799397, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:17.611922: step 5118, loss 0.665944, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:17.694797: step 5119, loss 0.921436, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:17.775644: step 5120, loss 0.691079, acc 0.703125, learning_rate 0.0001

Evaluation:
2017-09-28T16:38:18.051096: step 5120, loss 0.78438, acc 0.684892

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-5120

2017-09-28T16:38:18.603229: step 5121, loss 0.795538, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:18.685638: step 5122, loss 0.739979, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:18.767705: step 5123, loss 0.833653, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:18.850822: step 5124, loss 0.764518, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:18.931103: step 5125, loss 0.654075, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:19.010403: step 5126, loss 0.738686, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:19.090770: step 5127, loss 0.719317, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:19.171804: step 5128, loss 0.664695, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:19.251716: step 5129, loss 0.773859, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:19.339456: step 5130, loss 0.702461, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:19.424746: step 5131, loss 0.696815, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:19.508621: step 5132, loss 0.723039, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:19.589568: step 5133, loss 0.775728, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:19.671069: step 5134, loss 0.800814, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:19.753522: step 5135, loss 0.75844, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:19.835784: step 5136, loss 0.502919, acc 0.859375, learning_rate 0.0001
2017-09-28T16:38:19.920879: step 5137, loss 0.829033, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:20.005463: step 5138, loss 0.722388, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:20.086508: step 5139, loss 0.816443, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:20.167302: step 5140, loss 0.774444, acc 0.625, learning_rate 0.0001
2017-09-28T16:38:20.247732: step 5141, loss 0.721697, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:20.328454: step 5142, loss 0.699147, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:20.412612: step 5143, loss 0.669586, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:20.495101: step 5144, loss 0.704561, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:20.576177: step 5145, loss 0.58532, acc 0.828125, learning_rate 0.0001
2017-09-28T16:38:20.660735: step 5146, loss 0.814039, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:20.740430: step 5147, loss 0.577804, acc 0.8125, learning_rate 0.0001
2017-09-28T16:38:20.825122: step 5148, loss 0.690031, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:20.908286: step 5149, loss 0.611234, acc 0.875, learning_rate 0.0001
2017-09-28T16:38:20.990274: step 5150, loss 0.786039, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:21.075015: step 5151, loss 0.653456, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:21.157490: step 5152, loss 0.839927, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:21.239973: step 5153, loss 0.608296, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:21.322019: step 5154, loss 0.76552, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:21.401639: step 5155, loss 0.848391, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:21.481167: step 5156, loss 0.632365, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:21.563587: step 5157, loss 0.777814, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:21.648704: step 5158, loss 0.660065, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:21.731299: step 5159, loss 0.843821, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:21.812337: step 5160, loss 0.690116, acc 0.71875, learning_rate 0.0001

Evaluation:
2017-09-28T16:38:22.081642: step 5160, loss 0.784477, acc 0.68777

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-5160

2017-09-28T16:38:22.710504: step 5161, loss 0.717195, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:22.787803: step 5162, loss 0.861189, acc 0.625, learning_rate 0.0001
2017-09-28T16:38:22.870195: step 5163, loss 0.771487, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:22.952407: step 5164, loss 0.684761, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:23.031633: step 5165, loss 0.576686, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:23.114573: step 5166, loss 0.710894, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:23.194565: step 5167, loss 0.656066, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:23.277431: step 5168, loss 0.635183, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:23.362215: step 5169, loss 0.892887, acc 0.5625, learning_rate 0.0001
2017-09-28T16:38:23.442369: step 5170, loss 0.61818, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:23.522685: step 5171, loss 0.706358, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:23.603872: step 5172, loss 0.741242, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:23.683275: step 5173, loss 0.773545, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:23.763432: step 5174, loss 0.863011, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:23.845257: step 5175, loss 0.585615, acc 0.796875, learning_rate 0.0001
2017-09-28T16:38:23.924636: step 5176, loss 0.602345, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:24.005636: step 5177, loss 0.738907, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:24.088306: step 5178, loss 0.810491, acc 0.625, learning_rate 0.0001
2017-09-28T16:38:24.170985: step 5179, loss 0.88591, acc 0.625, learning_rate 0.0001
2017-09-28T16:38:24.253768: step 5180, loss 0.554044, acc 0.78125, learning_rate 0.0001
2017-09-28T16:38:24.335604: step 5181, loss 0.716935, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:24.416467: step 5182, loss 0.648659, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:24.495130: step 5183, loss 0.788864, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:24.580858: step 5184, loss 0.726748, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:24.660542: step 5185, loss 0.862121, acc 0.625, learning_rate 0.0001
2017-09-28T16:38:24.740749: step 5186, loss 0.661036, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:24.819722: step 5187, loss 0.682418, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:24.900248: step 5188, loss 0.772891, acc 0.625, learning_rate 0.0001
2017-09-28T16:38:24.982654: step 5189, loss 0.620112, acc 0.78125, learning_rate 0.0001
2017-09-28T16:38:25.062893: step 5190, loss 0.62311, acc 0.78125, learning_rate 0.0001
2017-09-28T16:38:25.143815: step 5191, loss 0.736276, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:25.226133: step 5192, loss 0.764568, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:25.307464: step 5193, loss 0.856717, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:25.374748: step 5194, loss 0.720339, acc 0.705882, learning_rate 0.0001
2017-09-28T16:38:25.458484: step 5195, loss 0.59699, acc 0.84375, learning_rate 0.0001
2017-09-28T16:38:25.540886: step 5196, loss 0.860492, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:25.618958: step 5197, loss 0.589476, acc 0.8125, learning_rate 0.0001
2017-09-28T16:38:25.699164: step 5198, loss 0.627742, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:25.783050: step 5199, loss 0.659348, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:25.863883: step 5200, loss 0.754212, acc 0.71875, learning_rate 0.0001

Evaluation:
2017-09-28T16:38:26.130164: step 5200, loss 0.782782, acc 0.689209

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-5200

2017-09-28T16:38:26.622849: step 5201, loss 0.811561, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:26.706682: step 5202, loss 0.744688, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:26.785464: step 5203, loss 0.458902, acc 0.78125, learning_rate 0.0001
2017-09-28T16:38:26.867230: step 5204, loss 0.599207, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:26.947016: step 5205, loss 0.800988, acc 0.625, learning_rate 0.0001
2017-09-28T16:38:27.029789: step 5206, loss 0.60099, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:27.111392: step 5207, loss 0.804287, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:27.195116: step 5208, loss 0.873715, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:27.275402: step 5209, loss 0.613847, acc 0.78125, learning_rate 0.0001
2017-09-28T16:38:27.353737: step 5210, loss 0.702976, acc 0.796875, learning_rate 0.0001
2017-09-28T16:38:27.434534: step 5211, loss 0.785136, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:27.517406: step 5212, loss 0.698422, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:27.597941: step 5213, loss 0.461198, acc 0.859375, learning_rate 0.0001
2017-09-28T16:38:27.677666: step 5214, loss 0.65942, acc 0.796875, learning_rate 0.0001
2017-09-28T16:38:27.756941: step 5215, loss 0.648579, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:27.839765: step 5216, loss 0.685648, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:27.921114: step 5217, loss 0.762303, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:28.004135: step 5218, loss 0.701778, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:28.083837: step 5219, loss 0.568347, acc 0.828125, learning_rate 0.0001
2017-09-28T16:38:28.166408: step 5220, loss 0.608024, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:28.248360: step 5221, loss 0.772964, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:28.327890: step 5222, loss 0.624192, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:28.413275: step 5223, loss 0.741479, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:28.495756: step 5224, loss 0.835611, acc 0.609375, learning_rate 0.0001
2017-09-28T16:38:28.580379: step 5225, loss 0.79374, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:28.660270: step 5226, loss 0.604005, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:28.738562: step 5227, loss 0.72548, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:28.820643: step 5228, loss 0.67, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:28.900837: step 5229, loss 0.6772, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:28.983912: step 5230, loss 0.802791, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:29.067408: step 5231, loss 0.661862, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:29.147604: step 5232, loss 0.664453, acc 0.8125, learning_rate 0.0001
2017-09-28T16:38:29.227633: step 5233, loss 0.773886, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:29.307547: step 5234, loss 0.814975, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:29.398045: step 5235, loss 0.546292, acc 0.78125, learning_rate 0.0001
2017-09-28T16:38:29.481802: step 5236, loss 0.686094, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:29.566436: step 5237, loss 0.713936, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:29.645909: step 5238, loss 0.856388, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:29.727983: step 5239, loss 0.864137, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:29.808873: step 5240, loss 0.59851, acc 0.734375, learning_rate 0.0001

Evaluation:
2017-09-28T16:38:30.082848: step 5240, loss 0.78231, acc 0.68777

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-5240

2017-09-28T16:38:30.644693: step 5241, loss 0.727224, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:30.724277: step 5242, loss 0.772558, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:30.804493: step 5243, loss 0.63344, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:30.886917: step 5244, loss 0.662083, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:30.965692: step 5245, loss 0.677031, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:31.047464: step 5246, loss 0.823897, acc 0.625, learning_rate 0.0001
2017-09-28T16:38:31.129197: step 5247, loss 0.785869, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:31.209968: step 5248, loss 0.57909, acc 0.796875, learning_rate 0.0001
2017-09-28T16:38:31.292324: step 5249, loss 0.703151, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:31.371859: step 5250, loss 0.8479, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:31.453412: step 5251, loss 0.867957, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:31.536877: step 5252, loss 0.664239, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:31.616070: step 5253, loss 0.689646, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:31.701589: step 5254, loss 0.738276, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:31.781822: step 5255, loss 0.692723, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:31.862940: step 5256, loss 0.740749, acc 0.78125, learning_rate 0.0001
2017-09-28T16:38:31.945513: step 5257, loss 0.782448, acc 0.625, learning_rate 0.0001
2017-09-28T16:38:32.028001: step 5258, loss 0.701448, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:32.110147: step 5259, loss 0.815391, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:32.199408: step 5260, loss 0.771664, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:32.282852: step 5261, loss 0.750598, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:32.363134: step 5262, loss 0.696817, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:32.446228: step 5263, loss 0.728363, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:32.530141: step 5264, loss 0.657819, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:32.613766: step 5265, loss 0.765559, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:32.696847: step 5266, loss 0.698402, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:32.778795: step 5267, loss 0.627038, acc 0.796875, learning_rate 0.0001
2017-09-28T16:38:32.859463: step 5268, loss 0.693852, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:32.945789: step 5269, loss 0.642382, acc 0.796875, learning_rate 0.0001
2017-09-28T16:38:33.029837: step 5270, loss 0.709185, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:33.112603: step 5271, loss 0.941194, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:33.197550: step 5272, loss 0.639668, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:33.281063: step 5273, loss 0.535677, acc 0.8125, learning_rate 0.0001
2017-09-28T16:38:33.364072: step 5274, loss 0.934513, acc 0.625, learning_rate 0.0001
2017-09-28T16:38:33.448680: step 5275, loss 0.832117, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:33.533514: step 5276, loss 0.783756, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:33.615402: step 5277, loss 0.771041, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:33.704238: step 5278, loss 0.636552, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:33.788087: step 5279, loss 0.62689, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:33.869577: step 5280, loss 0.712873, acc 0.71875, learning_rate 0.0001

Evaluation:
2017-09-28T16:38:34.142392: step 5280, loss 0.780809, acc 0.692086

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-5280

2017-09-28T16:38:34.711440: step 5281, loss 0.733291, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:34.793710: step 5282, loss 0.717587, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:34.872991: step 5283, loss 0.635124, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:34.958315: step 5284, loss 0.838584, acc 0.578125, learning_rate 0.0001
2017-09-28T16:38:35.038734: step 5285, loss 0.856248, acc 0.609375, learning_rate 0.0001
2017-09-28T16:38:35.119077: step 5286, loss 0.636575, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:35.198519: step 5287, loss 0.809277, acc 0.609375, learning_rate 0.0001
2017-09-28T16:38:35.282577: step 5288, loss 0.582397, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:35.361581: step 5289, loss 0.796363, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:35.444428: step 5290, loss 0.694151, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:35.529877: step 5291, loss 0.76779, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:35.595118: step 5292, loss 0.608357, acc 0.764706, learning_rate 0.0001
2017-09-28T16:38:35.675857: step 5293, loss 0.647688, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:35.762753: step 5294, loss 0.834122, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:35.845217: step 5295, loss 0.771263, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:35.927877: step 5296, loss 0.552862, acc 0.8125, learning_rate 0.0001
2017-09-28T16:38:36.009709: step 5297, loss 0.681369, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:36.089698: step 5298, loss 0.554818, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:36.174988: step 5299, loss 0.615329, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:36.258945: step 5300, loss 0.800375, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:36.340187: step 5301, loss 0.801827, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:36.421684: step 5302, loss 0.481372, acc 0.8125, learning_rate 0.0001
2017-09-28T16:38:36.503769: step 5303, loss 0.88373, acc 0.59375, learning_rate 0.0001
2017-09-28T16:38:36.585988: step 5304, loss 0.694201, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:36.666260: step 5305, loss 0.727338, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:36.746947: step 5306, loss 0.928761, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:36.828172: step 5307, loss 0.681251, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:36.913424: step 5308, loss 0.904536, acc 0.59375, learning_rate 0.0001
2017-09-28T16:38:36.995487: step 5309, loss 0.85973, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:37.078838: step 5310, loss 0.617712, acc 0.828125, learning_rate 0.0001
2017-09-28T16:38:37.159354: step 5311, loss 0.563276, acc 0.78125, learning_rate 0.0001
2017-09-28T16:38:37.239518: step 5312, loss 0.636205, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:37.329420: step 5313, loss 0.721495, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:37.417929: step 5314, loss 0.833624, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:37.500072: step 5315, loss 0.786419, acc 0.625, learning_rate 0.0001
2017-09-28T16:38:37.582163: step 5316, loss 0.73371, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:37.666285: step 5317, loss 0.69396, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:37.747438: step 5318, loss 0.799169, acc 0.625, learning_rate 0.0001
2017-09-28T16:38:37.828525: step 5319, loss 0.707401, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:37.909873: step 5320, loss 0.795583, acc 0.71875, learning_rate 0.0001

Evaluation:
2017-09-28T16:38:38.179374: step 5320, loss 0.778962, acc 0.689209

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-5320

2017-09-28T16:38:38.814729: step 5321, loss 0.607868, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:38.896505: step 5322, loss 0.707516, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:38.980194: step 5323, loss 0.563491, acc 0.8125, learning_rate 0.0001
2017-09-28T16:38:39.061688: step 5324, loss 0.720931, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:39.142906: step 5325, loss 0.672223, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:39.226875: step 5326, loss 0.628617, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:39.308488: step 5327, loss 0.672521, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:39.390122: step 5328, loss 0.617851, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:39.474364: step 5329, loss 0.588689, acc 0.828125, learning_rate 0.0001
2017-09-28T16:38:39.555456: step 5330, loss 0.624112, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:39.637610: step 5331, loss 0.811903, acc 0.609375, learning_rate 0.0001
2017-09-28T16:38:39.720601: step 5332, loss 0.62792, acc 0.796875, learning_rate 0.0001
2017-09-28T16:38:39.802863: step 5333, loss 0.616989, acc 0.796875, learning_rate 0.0001
2017-09-28T16:38:39.882338: step 5334, loss 0.802069, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:39.962073: step 5335, loss 0.644718, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:40.044725: step 5336, loss 0.711043, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:40.124105: step 5337, loss 0.621098, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:40.206923: step 5338, loss 0.773743, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:40.291857: step 5339, loss 0.576907, acc 0.78125, learning_rate 0.0001
2017-09-28T16:38:40.374158: step 5340, loss 0.586628, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:40.457235: step 5341, loss 0.770856, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:40.538504: step 5342, loss 0.676764, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:40.624846: step 5343, loss 0.733074, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:40.705992: step 5344, loss 0.590985, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:40.786986: step 5345, loss 0.620162, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:40.868755: step 5346, loss 0.614986, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:40.950209: step 5347, loss 0.849494, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:41.028801: step 5348, loss 0.8013, acc 0.625, learning_rate 0.0001
2017-09-28T16:38:41.111642: step 5349, loss 0.743077, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:41.193848: step 5350, loss 0.649125, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:41.275207: step 5351, loss 0.618424, acc 0.78125, learning_rate 0.0001
2017-09-28T16:38:41.355256: step 5352, loss 0.666713, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:41.438928: step 5353, loss 0.725896, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:41.520300: step 5354, loss 0.703805, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:41.600312: step 5355, loss 0.585577, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:41.682902: step 5356, loss 0.771877, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:41.763961: step 5357, loss 0.589115, acc 0.796875, learning_rate 0.0001
2017-09-28T16:38:41.842760: step 5358, loss 0.647261, acc 0.796875, learning_rate 0.0001
2017-09-28T16:38:41.921737: step 5359, loss 0.814026, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:42.002762: step 5360, loss 0.75334, acc 0.65625, learning_rate 0.0001

Evaluation:
2017-09-28T16:38:42.273243: step 5360, loss 0.779676, acc 0.68777

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-5360

2017-09-28T16:38:42.766109: step 5361, loss 0.629404, acc 0.8125, learning_rate 0.0001
2017-09-28T16:38:42.851433: step 5362, loss 0.771053, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:42.932926: step 5363, loss 0.781896, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:43.015674: step 5364, loss 0.815658, acc 0.609375, learning_rate 0.0001
2017-09-28T16:38:43.100636: step 5365, loss 0.615904, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:43.182224: step 5366, loss 0.996322, acc 0.53125, learning_rate 0.0001
2017-09-28T16:38:43.263269: step 5367, loss 0.86615, acc 0.625, learning_rate 0.0001
2017-09-28T16:38:43.344104: step 5368, loss 0.730338, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:43.429193: step 5369, loss 0.712123, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:43.512462: step 5370, loss 0.619519, acc 0.78125, learning_rate 0.0001
2017-09-28T16:38:43.591862: step 5371, loss 0.730553, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:43.678278: step 5372, loss 0.632799, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:43.758746: step 5373, loss 0.665525, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:43.842432: step 5374, loss 0.547802, acc 0.78125, learning_rate 0.0001
2017-09-28T16:38:43.922837: step 5375, loss 0.903094, acc 0.59375, learning_rate 0.0001
2017-09-28T16:38:44.004799: step 5376, loss 0.734433, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:44.084576: step 5377, loss 0.784477, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:44.166716: step 5378, loss 0.751873, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:44.247116: step 5379, loss 0.784325, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:44.326820: step 5380, loss 0.84026, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:44.410033: step 5381, loss 0.705217, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:44.499729: step 5382, loss 0.633088, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:44.585453: step 5383, loss 0.56218, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:44.666105: step 5384, loss 0.827186, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:44.751490: step 5385, loss 0.911444, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:44.835426: step 5386, loss 0.808189, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:44.918189: step 5387, loss 0.716321, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:44.999898: step 5388, loss 0.649661, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:45.083569: step 5389, loss 0.545517, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:45.149187: step 5390, loss 0.702084, acc 0.686275, learning_rate 0.0001
2017-09-28T16:38:45.233344: step 5391, loss 0.623435, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:45.314666: step 5392, loss 0.701315, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:45.395747: step 5393, loss 0.790845, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:45.474499: step 5394, loss 0.502716, acc 0.78125, learning_rate 0.0001
2017-09-28T16:38:45.556244: step 5395, loss 0.786558, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:45.635561: step 5396, loss 0.616447, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:45.720825: step 5397, loss 0.657176, acc 0.78125, learning_rate 0.0001
2017-09-28T16:38:45.802032: step 5398, loss 0.701572, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:45.884308: step 5399, loss 0.651538, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:45.967518: step 5400, loss 0.791795, acc 0.703125, learning_rate 0.0001

Evaluation:
2017-09-28T16:38:46.228471: step 5400, loss 0.782039, acc 0.689209

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-5400

2017-09-28T16:38:46.786957: step 5401, loss 0.774959, acc 0.609375, learning_rate 0.0001
2017-09-28T16:38:46.866769: step 5402, loss 0.777795, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:46.952892: step 5403, loss 0.755615, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:47.034225: step 5404, loss 0.725548, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:47.115800: step 5405, loss 0.677068, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:47.195171: step 5406, loss 0.882597, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:47.278758: step 5407, loss 0.593615, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:47.359044: step 5408, loss 0.841857, acc 0.625, learning_rate 0.0001
2017-09-28T16:38:47.447943: step 5409, loss 0.751681, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:47.530645: step 5410, loss 0.870752, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:47.613841: step 5411, loss 0.56066, acc 0.828125, learning_rate 0.0001
2017-09-28T16:38:47.695779: step 5412, loss 0.757984, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:47.776749: step 5413, loss 0.66232, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:47.861902: step 5414, loss 0.64571, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:47.941734: step 5415, loss 0.856232, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:48.022176: step 5416, loss 0.632147, acc 0.796875, learning_rate 0.0001
2017-09-28T16:38:48.102491: step 5417, loss 0.884113, acc 0.5625, learning_rate 0.0001
2017-09-28T16:38:48.183972: step 5418, loss 0.650386, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:48.267857: step 5419, loss 0.606156, acc 0.828125, learning_rate 0.0001
2017-09-28T16:38:48.352911: step 5420, loss 0.581229, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:48.437345: step 5421, loss 0.738045, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:48.520286: step 5422, loss 0.857514, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:48.603085: step 5423, loss 0.765116, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:48.686620: step 5424, loss 0.681472, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:48.768800: step 5425, loss 0.709835, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:48.850793: step 5426, loss 0.693296, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:48.930842: step 5427, loss 0.869747, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:49.012998: step 5428, loss 0.672412, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:49.091938: step 5429, loss 0.664686, acc 0.8125, learning_rate 0.0001
2017-09-28T16:38:49.175352: step 5430, loss 0.802612, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:49.258644: step 5431, loss 0.520954, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:49.340796: step 5432, loss 0.649354, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:49.424784: step 5433, loss 0.700771, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:49.511669: step 5434, loss 0.673252, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:49.591417: step 5435, loss 0.712652, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:49.673317: step 5436, loss 0.764071, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:49.753454: step 5437, loss 0.881648, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:49.834876: step 5438, loss 0.528208, acc 0.796875, learning_rate 0.0001
2017-09-28T16:38:49.917970: step 5439, loss 0.78833, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:49.998157: step 5440, loss 0.768268, acc 0.65625, learning_rate 0.0001

Evaluation:
2017-09-28T16:38:50.271820: step 5440, loss 0.779735, acc 0.684892

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-5440

2017-09-28T16:38:50.837044: step 5441, loss 0.720327, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:50.917847: step 5442, loss 0.764108, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:51.002040: step 5443, loss 0.820437, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:51.083592: step 5444, loss 0.93262, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:51.167245: step 5445, loss 0.605896, acc 0.828125, learning_rate 0.0001
2017-09-28T16:38:51.250756: step 5446, loss 0.549105, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:51.331475: step 5447, loss 0.766087, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:51.410396: step 5448, loss 0.80337, acc 0.625, learning_rate 0.0001
2017-09-28T16:38:51.494751: step 5449, loss 0.706228, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:51.578303: step 5450, loss 0.793106, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:51.661792: step 5451, loss 0.613021, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:51.744302: step 5452, loss 0.638621, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:51.827599: step 5453, loss 0.628614, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:51.909095: step 5454, loss 0.640888, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:51.992396: step 5455, loss 0.75073, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:52.077701: step 5456, loss 0.672806, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:52.160909: step 5457, loss 0.770751, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:52.241852: step 5458, loss 0.753688, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:52.326260: step 5459, loss 0.790714, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:52.408242: step 5460, loss 0.61968, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:52.490419: step 5461, loss 0.647081, acc 0.828125, learning_rate 0.0001
2017-09-28T16:38:52.570900: step 5462, loss 0.495144, acc 0.90625, learning_rate 0.0001
2017-09-28T16:38:52.652793: step 5463, loss 0.815254, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:52.733510: step 5464, loss 0.72041, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:52.816068: step 5465, loss 0.70768, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:52.897690: step 5466, loss 0.706974, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:52.975772: step 5467, loss 0.670259, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:53.055882: step 5468, loss 0.763262, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:53.138575: step 5469, loss 0.677879, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:53.217463: step 5470, loss 0.695113, acc 0.734375, learning_rate 0.0001
2017-09-28T16:38:53.297332: step 5471, loss 0.690322, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:53.379599: step 5472, loss 0.507962, acc 0.859375, learning_rate 0.0001
2017-09-28T16:38:53.462359: step 5473, loss 0.71117, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:53.547224: step 5474, loss 0.659878, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:53.628451: step 5475, loss 0.817128, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:53.711942: step 5476, loss 0.7309, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:53.795111: step 5477, loss 0.807015, acc 0.625, learning_rate 0.0001
2017-09-28T16:38:53.880673: step 5478, loss 0.540619, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:53.963036: step 5479, loss 0.568058, acc 0.828125, learning_rate 0.0001
2017-09-28T16:38:54.045956: step 5480, loss 0.551754, acc 0.8125, learning_rate 0.0001

Evaluation:
2017-09-28T16:38:54.312728: step 5480, loss 0.776604, acc 0.693525

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-5480

2017-09-28T16:38:54.954518: step 5481, loss 0.571229, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:55.037981: step 5482, loss 0.789819, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:55.118456: step 5483, loss 0.682526, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:55.200847: step 5484, loss 0.640713, acc 0.78125, learning_rate 0.0001
2017-09-28T16:38:55.280170: step 5485, loss 0.678834, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:55.361707: step 5486, loss 0.761249, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:55.446303: step 5487, loss 0.593579, acc 0.78125, learning_rate 0.0001
2017-09-28T16:38:55.510245: step 5488, loss 0.781235, acc 0.705882, learning_rate 0.0001
2017-09-28T16:38:55.595007: step 5489, loss 0.68777, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:55.673804: step 5490, loss 0.558972, acc 0.78125, learning_rate 0.0001
2017-09-28T16:38:55.755625: step 5491, loss 0.882942, acc 0.640625, learning_rate 0.0001
2017-09-28T16:38:55.838761: step 5492, loss 0.631451, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:55.924186: step 5493, loss 0.725446, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:56.005780: step 5494, loss 0.666709, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:56.088804: step 5495, loss 0.528978, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:56.168922: step 5496, loss 0.787585, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:56.251667: step 5497, loss 0.675592, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:56.333647: step 5498, loss 0.832904, acc 0.625, learning_rate 0.0001
2017-09-28T16:38:56.415955: step 5499, loss 0.640557, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:56.497155: step 5500, loss 0.713678, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:56.577635: step 5501, loss 0.680158, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:56.657849: step 5502, loss 0.824543, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:56.739551: step 5503, loss 0.899678, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:56.818312: step 5504, loss 0.679225, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:56.902138: step 5505, loss 0.633265, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:56.982687: step 5506, loss 0.689239, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:57.064307: step 5507, loss 0.794995, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:57.145114: step 5508, loss 0.627615, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:57.226156: step 5509, loss 0.68122, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:57.303431: step 5510, loss 0.657361, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:57.385261: step 5511, loss 0.728459, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:57.464892: step 5512, loss 0.49246, acc 0.796875, learning_rate 0.0001
2017-09-28T16:38:57.549239: step 5513, loss 0.88882, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:57.630347: step 5514, loss 0.542804, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:57.708777: step 5515, loss 0.751836, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:57.787488: step 5516, loss 0.581042, acc 0.84375, learning_rate 0.0001
2017-09-28T16:38:57.866845: step 5517, loss 0.733778, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:57.947305: step 5518, loss 0.776139, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:58.029333: step 5519, loss 0.772737, acc 0.65625, learning_rate 0.0001
2017-09-28T16:38:58.109422: step 5520, loss 0.535667, acc 0.765625, learning_rate 0.0001

Evaluation:
2017-09-28T16:38:58.383455: step 5520, loss 0.775234, acc 0.686331

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-5520

2017-09-28T16:38:58.873286: step 5521, loss 0.646419, acc 0.75, learning_rate 0.0001
2017-09-28T16:38:58.957309: step 5522, loss 0.774629, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:59.039912: step 5523, loss 0.681364, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:59.118247: step 5524, loss 0.697857, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:59.198970: step 5525, loss 0.66691, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:59.279974: step 5526, loss 0.772858, acc 0.671875, learning_rate 0.0001
2017-09-28T16:38:59.361247: step 5527, loss 0.662542, acc 0.765625, learning_rate 0.0001
2017-09-28T16:38:59.440937: step 5528, loss 0.777242, acc 0.6875, learning_rate 0.0001
2017-09-28T16:38:59.522310: step 5529, loss 0.744195, acc 0.71875, learning_rate 0.0001
2017-09-28T16:38:59.609429: step 5530, loss 0.686756, acc 0.703125, learning_rate 0.0001
2017-09-28T16:38:59.689483: step 5531, loss 0.538803, acc 0.78125, learning_rate 0.0001
2017-09-28T16:38:59.768758: step 5532, loss 0.825665, acc 0.625, learning_rate 0.0001
2017-09-28T16:38:59.851662: step 5533, loss 0.650137, acc 0.78125, learning_rate 0.0001
2017-09-28T16:38:59.933478: step 5534, loss 0.802596, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:00.012599: step 5535, loss 0.603208, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:00.095833: step 5536, loss 0.791019, acc 0.640625, learning_rate 0.0001
2017-09-28T16:39:00.174223: step 5537, loss 0.743402, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:00.256930: step 5538, loss 0.734988, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:00.336978: step 5539, loss 0.754905, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:00.429941: step 5540, loss 0.771204, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:00.516227: step 5541, loss 0.622908, acc 0.84375, learning_rate 0.0001
2017-09-28T16:39:00.595526: step 5542, loss 0.634061, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:00.679983: step 5543, loss 0.752827, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:00.760762: step 5544, loss 0.60754, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:00.840957: step 5545, loss 0.723782, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:00.921314: step 5546, loss 0.835661, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:01.003632: step 5547, loss 0.463329, acc 0.84375, learning_rate 0.0001
2017-09-28T16:39:01.084754: step 5548, loss 0.683292, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:01.164749: step 5549, loss 0.694891, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:01.244638: step 5550, loss 0.628064, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:01.325161: step 5551, loss 0.878294, acc 0.609375, learning_rate 0.0001
2017-09-28T16:39:01.408441: step 5552, loss 0.588957, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:01.487598: step 5553, loss 0.76391, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:01.571250: step 5554, loss 0.667112, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:01.651131: step 5555, loss 0.64051, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:01.731118: step 5556, loss 0.643544, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:01.811677: step 5557, loss 0.723406, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:01.891239: step 5558, loss 0.746751, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:01.973803: step 5559, loss 0.797893, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:02.056582: step 5560, loss 0.908824, acc 0.546875, learning_rate 0.0001

Evaluation:
2017-09-28T16:39:02.323399: step 5560, loss 0.776759, acc 0.690647

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-5560

2017-09-28T16:39:02.875670: step 5561, loss 0.726217, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:02.959781: step 5562, loss 0.684844, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:03.041766: step 5563, loss 0.659604, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:03.121983: step 5564, loss 0.712219, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:03.202573: step 5565, loss 0.651365, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:03.282588: step 5566, loss 0.724352, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:03.362613: step 5567, loss 0.622561, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:03.447737: step 5568, loss 0.658358, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:03.529629: step 5569, loss 0.632634, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:03.609156: step 5570, loss 0.753119, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:03.688816: step 5571, loss 0.746968, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:03.770555: step 5572, loss 0.770532, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:03.854607: step 5573, loss 0.707209, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:03.936434: step 5574, loss 0.657746, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:04.016376: step 5575, loss 0.669426, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:04.100560: step 5576, loss 0.716496, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:04.180497: step 5577, loss 0.682386, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:04.260028: step 5578, loss 0.784982, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:04.344741: step 5579, loss 0.740649, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:04.425505: step 5580, loss 0.645188, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:04.506334: step 5581, loss 0.526915, acc 0.828125, learning_rate 0.0001
2017-09-28T16:39:04.586691: step 5582, loss 0.832939, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:04.671281: step 5583, loss 0.593709, acc 0.8125, learning_rate 0.0001
2017-09-28T16:39:04.755650: step 5584, loss 0.742637, acc 0.640625, learning_rate 0.0001
2017-09-28T16:39:04.838523: step 5585, loss 0.676618, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:04.905623: step 5586, loss 0.604071, acc 0.803922, learning_rate 0.0001
2017-09-28T16:39:04.988257: step 5587, loss 0.571458, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:05.065280: step 5588, loss 0.601429, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:05.144878: step 5589, loss 0.676668, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:05.233420: step 5590, loss 0.614373, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:05.318667: step 5591, loss 0.774201, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:05.403695: step 5592, loss 0.705485, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:05.485160: step 5593, loss 0.811412, acc 0.609375, learning_rate 0.0001
2017-09-28T16:39:05.566963: step 5594, loss 0.630166, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:05.649700: step 5595, loss 0.739775, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:05.733759: step 5596, loss 0.768197, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:05.815910: step 5597, loss 0.664305, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:05.895837: step 5598, loss 0.677119, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:05.980166: step 5599, loss 0.851865, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:06.064427: step 5600, loss 0.543082, acc 0.796875, learning_rate 0.0001

Evaluation:
2017-09-28T16:39:06.333378: step 5600, loss 0.777502, acc 0.683453

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-5600

2017-09-28T16:39:06.890315: step 5601, loss 0.845427, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:06.970096: step 5602, loss 0.675034, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:07.050352: step 5603, loss 0.667451, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:07.135881: step 5604, loss 0.675976, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:07.219634: step 5605, loss 0.763562, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:07.304759: step 5606, loss 0.707845, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:07.388760: step 5607, loss 0.596179, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:07.471155: step 5608, loss 0.755987, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:07.552674: step 5609, loss 0.653002, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:07.637691: step 5610, loss 0.588447, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:07.722038: step 5611, loss 0.562742, acc 0.8125, learning_rate 0.0001
2017-09-28T16:39:07.802012: step 5612, loss 0.763106, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:07.885487: step 5613, loss 0.775026, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:07.967617: step 5614, loss 0.646009, acc 0.8125, learning_rate 0.0001
2017-09-28T16:39:08.048704: step 5615, loss 0.725021, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:08.128051: step 5616, loss 0.702574, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:08.211823: step 5617, loss 0.842187, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:08.292363: step 5618, loss 0.753275, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:08.369555: step 5619, loss 0.750045, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:08.451382: step 5620, loss 0.828238, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:08.533392: step 5621, loss 0.701076, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:08.615346: step 5622, loss 0.75833, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:08.698000: step 5623, loss 0.765094, acc 0.625, learning_rate 0.0001
2017-09-28T16:39:08.780476: step 5624, loss 0.747155, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:08.862865: step 5625, loss 0.743166, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:08.946739: step 5626, loss 0.732929, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:09.028959: step 5627, loss 0.619808, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:09.109751: step 5628, loss 0.448777, acc 0.875, learning_rate 0.0001
2017-09-28T16:39:09.193283: step 5629, loss 0.738723, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:09.273384: step 5630, loss 0.690465, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:09.356068: step 5631, loss 0.608086, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:09.439324: step 5632, loss 0.547651, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:09.520181: step 5633, loss 0.676509, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:09.600008: step 5634, loss 0.817232, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:09.688221: step 5635, loss 0.629864, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:09.769256: step 5636, loss 0.55313, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:09.853009: step 5637, loss 0.750466, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:09.937156: step 5638, loss 0.576639, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:10.021637: step 5639, loss 0.679025, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:10.101608: step 5640, loss 0.868725, acc 0.53125, learning_rate 0.0001

Evaluation:
2017-09-28T16:39:10.370704: step 5640, loss 0.775594, acc 0.694964

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-5640

2017-09-28T16:39:11.013578: step 5641, loss 0.813767, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:11.094838: step 5642, loss 0.749194, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:11.176195: step 5643, loss 0.739126, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:11.257557: step 5644, loss 0.762012, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:11.342303: step 5645, loss 0.713178, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:11.423181: step 5646, loss 0.830733, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:11.502945: step 5647, loss 0.703366, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:11.584926: step 5648, loss 0.667568, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:11.665919: step 5649, loss 0.674963, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:11.746984: step 5650, loss 0.533513, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:11.830302: step 5651, loss 0.68158, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:11.912334: step 5652, loss 0.6902, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:11.993569: step 5653, loss 0.637052, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:12.073807: step 5654, loss 0.860766, acc 0.625, learning_rate 0.0001
2017-09-28T16:39:12.155541: step 5655, loss 0.859957, acc 0.640625, learning_rate 0.0001
2017-09-28T16:39:12.236574: step 5656, loss 0.640659, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:12.317820: step 5657, loss 0.570642, acc 0.8125, learning_rate 0.0001
2017-09-28T16:39:12.401527: step 5658, loss 0.612773, acc 0.8125, learning_rate 0.0001
2017-09-28T16:39:12.482509: step 5659, loss 0.761021, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:12.566217: step 5660, loss 0.642886, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:12.647051: step 5661, loss 0.687583, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:12.728034: step 5662, loss 0.577131, acc 0.828125, learning_rate 0.0001
2017-09-28T16:39:12.809590: step 5663, loss 0.743798, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:12.890162: step 5664, loss 0.759343, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:12.972934: step 5665, loss 0.791305, acc 0.640625, learning_rate 0.0001
2017-09-28T16:39:13.054385: step 5666, loss 0.640939, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:13.134873: step 5667, loss 0.736088, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:13.215364: step 5668, loss 0.841049, acc 0.640625, learning_rate 0.0001
2017-09-28T16:39:13.296711: step 5669, loss 0.824658, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:13.377811: step 5670, loss 0.929855, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:13.461655: step 5671, loss 0.709879, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:13.541553: step 5672, loss 0.655003, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:13.621277: step 5673, loss 0.884331, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:13.708536: step 5674, loss 0.477538, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:13.790636: step 5675, loss 0.884331, acc 0.609375, learning_rate 0.0001
2017-09-28T16:39:13.871506: step 5676, loss 0.447799, acc 0.875, learning_rate 0.0001
2017-09-28T16:39:13.958531: step 5677, loss 0.622073, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:14.039415: step 5678, loss 0.775397, acc 0.640625, learning_rate 0.0001
2017-09-28T16:39:14.122177: step 5679, loss 0.684589, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:14.202843: step 5680, loss 0.670579, acc 0.671875, learning_rate 0.0001

Evaluation:
2017-09-28T16:39:14.471168: step 5680, loss 0.775933, acc 0.696403

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-5680

2017-09-28T16:39:14.981872: step 5681, loss 0.54835, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:15.063985: step 5682, loss 0.819268, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:15.144395: step 5683, loss 0.743788, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:15.208666: step 5684, loss 0.707002, acc 0.686275, learning_rate 0.0001
2017-09-28T16:39:15.288812: step 5685, loss 0.818277, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:15.370624: step 5686, loss 0.557418, acc 0.84375, learning_rate 0.0001
2017-09-28T16:39:15.452433: step 5687, loss 0.711017, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:15.533040: step 5688, loss 0.689766, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:15.616376: step 5689, loss 0.732331, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:15.697708: step 5690, loss 0.594741, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:15.779007: step 5691, loss 0.786963, acc 0.609375, learning_rate 0.0001
2017-09-28T16:39:15.863452: step 5692, loss 0.699184, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:15.940411: step 5693, loss 0.667194, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:16.022054: step 5694, loss 0.788994, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:16.102580: step 5695, loss 0.659548, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:16.185424: step 5696, loss 0.652327, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:16.269896: step 5697, loss 0.753253, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:16.351769: step 5698, loss 0.647532, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:16.433881: step 5699, loss 0.701307, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:16.513878: step 5700, loss 0.784295, acc 0.59375, learning_rate 0.0001
2017-09-28T16:39:16.596638: step 5701, loss 0.62918, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:16.678636: step 5702, loss 0.707989, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:16.757685: step 5703, loss 0.678398, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:16.839565: step 5704, loss 0.508729, acc 0.8125, learning_rate 0.0001
2017-09-28T16:39:16.921913: step 5705, loss 0.79697, acc 0.625, learning_rate 0.0001
2017-09-28T16:39:17.004584: step 5706, loss 0.743577, acc 0.625, learning_rate 0.0001
2017-09-28T16:39:17.083666: step 5707, loss 0.7888, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:17.164403: step 5708, loss 0.633353, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:17.246433: step 5709, loss 0.631865, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:17.325713: step 5710, loss 0.709976, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:17.407159: step 5711, loss 0.51102, acc 0.859375, learning_rate 0.0001
2017-09-28T16:39:17.488796: step 5712, loss 0.548303, acc 0.8125, learning_rate 0.0001
2017-09-28T16:39:17.569517: step 5713, loss 0.589738, acc 0.828125, learning_rate 0.0001
2017-09-28T16:39:17.650164: step 5714, loss 0.760454, acc 0.625, learning_rate 0.0001
2017-09-28T16:39:17.732222: step 5715, loss 0.61987, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:17.818457: step 5716, loss 0.611008, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:17.902572: step 5717, loss 0.735177, acc 0.640625, learning_rate 0.0001
2017-09-28T16:39:17.985756: step 5718, loss 0.611035, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:18.069359: step 5719, loss 0.66659, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:18.152467: step 5720, loss 0.59585, acc 0.71875, learning_rate 0.0001

Evaluation:
2017-09-28T16:39:18.422117: step 5720, loss 0.774265, acc 0.683453

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-5720

2017-09-28T16:39:18.980155: step 5721, loss 0.6568, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:19.062904: step 5722, loss 0.640135, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:19.143096: step 5723, loss 0.755965, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:19.230984: step 5724, loss 0.733856, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:19.309259: step 5725, loss 0.722708, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:19.391190: step 5726, loss 0.786574, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:19.473678: step 5727, loss 0.675659, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:19.555900: step 5728, loss 0.757274, acc 0.640625, learning_rate 0.0001
2017-09-28T16:39:19.641797: step 5729, loss 0.69992, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:19.730737: step 5730, loss 0.766507, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:19.813942: step 5731, loss 0.591091, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:19.896237: step 5732, loss 0.765941, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:19.977491: step 5733, loss 0.697967, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:20.063374: step 5734, loss 0.731614, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:20.153243: step 5735, loss 0.847058, acc 0.625, learning_rate 0.0001
2017-09-28T16:39:20.237136: step 5736, loss 0.565321, acc 0.8125, learning_rate 0.0001
2017-09-28T16:39:20.317307: step 5737, loss 0.789906, acc 0.640625, learning_rate 0.0001
2017-09-28T16:39:20.402114: step 5738, loss 0.656519, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:20.484867: step 5739, loss 0.610937, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:20.567270: step 5740, loss 0.634621, acc 0.8125, learning_rate 0.0001
2017-09-28T16:39:20.651708: step 5741, loss 0.654125, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:20.733426: step 5742, loss 0.836809, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:20.814382: step 5743, loss 0.458325, acc 0.90625, learning_rate 0.0001
2017-09-28T16:39:20.896793: step 5744, loss 0.800985, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:20.978938: step 5745, loss 0.937747, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:21.062042: step 5746, loss 0.725531, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:21.146854: step 5747, loss 0.617493, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:21.229460: step 5748, loss 0.688996, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:21.312147: step 5749, loss 1.03302, acc 0.609375, learning_rate 0.0001
2017-09-28T16:39:21.396580: step 5750, loss 0.533294, acc 0.84375, learning_rate 0.0001
2017-09-28T16:39:21.476100: step 5751, loss 0.670285, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:21.558902: step 5752, loss 0.708723, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:21.639664: step 5753, loss 0.588644, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:21.724683: step 5754, loss 0.61537, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:21.805997: step 5755, loss 0.596083, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:21.887726: step 5756, loss 0.71176, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:21.971805: step 5757, loss 0.573087, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:22.054102: step 5758, loss 0.659499, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:22.135302: step 5759, loss 0.795435, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:22.217209: step 5760, loss 0.756673, acc 0.625, learning_rate 0.0001

Evaluation:
2017-09-28T16:39:22.486593: step 5760, loss 0.771009, acc 0.693525

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-5760

2017-09-28T16:39:23.041561: step 5761, loss 0.663692, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:23.121731: step 5762, loss 0.671959, acc 0.8125, learning_rate 0.0001
2017-09-28T16:39:23.203614: step 5763, loss 0.545533, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:23.286293: step 5764, loss 0.719477, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:23.369288: step 5765, loss 0.73, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:23.451624: step 5766, loss 0.688667, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:23.533572: step 5767, loss 0.736961, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:23.612357: step 5768, loss 0.566857, acc 0.8125, learning_rate 0.0001
2017-09-28T16:39:23.690633: step 5769, loss 0.810519, acc 0.625, learning_rate 0.0001
2017-09-28T16:39:23.773154: step 5770, loss 0.831213, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:23.855361: step 5771, loss 0.789393, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:23.936129: step 5772, loss 0.666483, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:24.016771: step 5773, loss 0.676577, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:24.100747: step 5774, loss 0.874075, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:24.181269: step 5775, loss 0.761462, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:24.264361: step 5776, loss 0.745362, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:24.346551: step 5777, loss 0.794587, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:24.430527: step 5778, loss 0.644528, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:24.514994: step 5779, loss 0.651239, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:24.598863: step 5780, loss 0.680105, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:24.682305: step 5781, loss 0.613511, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:24.753807: step 5782, loss 0.780618, acc 0.686275, learning_rate 0.0001
2017-09-28T16:39:24.835245: step 5783, loss 0.626646, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:24.917710: step 5784, loss 0.679775, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:25.001975: step 5785, loss 0.688964, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:25.085353: step 5786, loss 0.601113, acc 0.828125, learning_rate 0.0001
2017-09-28T16:39:25.172908: step 5787, loss 0.596394, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:25.254165: step 5788, loss 0.698761, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:25.339108: step 5789, loss 0.596437, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:25.423710: step 5790, loss 0.839947, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:25.503575: step 5791, loss 0.544326, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:25.585211: step 5792, loss 0.737805, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:25.668534: step 5793, loss 0.933097, acc 0.640625, learning_rate 0.0001
2017-09-28T16:39:25.751881: step 5794, loss 0.77704, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:25.834285: step 5795, loss 0.839959, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:25.915829: step 5796, loss 0.726439, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:26.004385: step 5797, loss 0.728581, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:26.091373: step 5798, loss 0.699684, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:26.176180: step 5799, loss 0.628603, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:26.257616: step 5800, loss 0.790472, acc 0.703125, learning_rate 0.0001

Evaluation:
2017-09-28T16:39:26.530314: step 5800, loss 0.774198, acc 0.686331

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-5800

2017-09-28T16:39:27.162507: step 5801, loss 0.600968, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:27.246305: step 5802, loss 0.772769, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:27.331694: step 5803, loss 0.718546, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:27.415901: step 5804, loss 0.633686, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:27.494730: step 5805, loss 0.686397, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:27.576526: step 5806, loss 0.682609, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:27.658113: step 5807, loss 0.585259, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:27.738565: step 5808, loss 0.795716, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:27.821783: step 5809, loss 0.721056, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:27.903689: step 5810, loss 0.782659, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:27.982919: step 5811, loss 0.720514, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:28.067191: step 5812, loss 0.625732, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:28.147712: step 5813, loss 0.751266, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:28.234186: step 5814, loss 0.768669, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:28.320297: step 5815, loss 0.543418, acc 0.84375, learning_rate 0.0001
2017-09-28T16:39:28.403442: step 5816, loss 0.792701, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:28.485896: step 5817, loss 0.53031, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:28.564655: step 5818, loss 0.576873, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:28.646774: step 5819, loss 0.705875, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:28.726801: step 5820, loss 0.516231, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:28.810842: step 5821, loss 0.657856, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:28.892787: step 5822, loss 0.700683, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:28.976694: step 5823, loss 0.810823, acc 0.640625, learning_rate 0.0001
2017-09-28T16:39:29.057919: step 5824, loss 0.629496, acc 0.8125, learning_rate 0.0001
2017-09-28T16:39:29.137290: step 5825, loss 0.689851, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:29.222344: step 5826, loss 0.693344, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:29.303881: step 5827, loss 0.691018, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:29.387006: step 5828, loss 0.758675, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:29.467758: step 5829, loss 0.610775, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:29.547142: step 5830, loss 0.881123, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:29.627848: step 5831, loss 0.777806, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:29.709075: step 5832, loss 0.562258, acc 0.828125, learning_rate 0.0001
2017-09-28T16:39:29.798219: step 5833, loss 0.701752, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:29.880001: step 5834, loss 0.792031, acc 0.59375, learning_rate 0.0001
2017-09-28T16:39:29.959449: step 5835, loss 0.692191, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:30.044575: step 5836, loss 0.538679, acc 0.8125, learning_rate 0.0001
2017-09-28T16:39:30.127589: step 5837, loss 0.76142, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:30.210219: step 5838, loss 0.602322, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:30.292517: step 5839, loss 0.621798, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:30.372716: step 5840, loss 0.514089, acc 0.859375, learning_rate 0.0001

Evaluation:
2017-09-28T16:39:30.640875: step 5840, loss 0.771867, acc 0.693525

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-5840

2017-09-28T16:39:31.136643: step 5841, loss 0.84506, acc 0.609375, learning_rate 0.0001
2017-09-28T16:39:31.216329: step 5842, loss 0.777358, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:31.299763: step 5843, loss 0.733175, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:31.381441: step 5844, loss 0.710563, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:31.463987: step 5845, loss 0.771015, acc 0.640625, learning_rate 0.0001
2017-09-28T16:39:31.544852: step 5846, loss 0.742863, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:31.624042: step 5847, loss 0.849515, acc 0.625, learning_rate 0.0001
2017-09-28T16:39:31.707795: step 5848, loss 0.638274, acc 0.8125, learning_rate 0.0001
2017-09-28T16:39:31.789906: step 5849, loss 0.719817, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:31.872825: step 5850, loss 0.530862, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:31.956040: step 5851, loss 0.721616, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:32.035864: step 5852, loss 0.530449, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:32.117898: step 5853, loss 0.649575, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:32.201233: step 5854, loss 0.746686, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:32.279515: step 5855, loss 0.684007, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:32.360474: step 5856, loss 0.592316, acc 0.859375, learning_rate 0.0001
2017-09-28T16:39:32.439243: step 5857, loss 0.717221, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:32.523085: step 5858, loss 0.757622, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:32.604822: step 5859, loss 0.780537, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:32.684140: step 5860, loss 0.773834, acc 0.640625, learning_rate 0.0001
2017-09-28T16:39:32.765182: step 5861, loss 0.519817, acc 0.8125, learning_rate 0.0001
2017-09-28T16:39:32.846625: step 5862, loss 0.69693, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:32.930401: step 5863, loss 0.603085, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:33.012994: step 5864, loss 0.52663, acc 0.8125, learning_rate 0.0001
2017-09-28T16:39:33.093948: step 5865, loss 0.782233, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:33.172648: step 5866, loss 0.786321, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:33.254683: step 5867, loss 0.492724, acc 0.84375, learning_rate 0.0001
2017-09-28T16:39:33.336137: step 5868, loss 0.835995, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:33.417673: step 5869, loss 0.542339, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:33.499762: step 5870, loss 0.601731, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:33.580828: step 5871, loss 0.770191, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:33.661713: step 5872, loss 0.62242, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:33.741720: step 5873, loss 0.903495, acc 0.609375, learning_rate 0.0001
2017-09-28T16:39:33.822312: step 5874, loss 0.676792, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:33.902652: step 5875, loss 0.647598, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:33.981386: step 5876, loss 0.66723, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:34.064928: step 5877, loss 0.741654, acc 0.640625, learning_rate 0.0001
2017-09-28T16:39:34.149720: step 5878, loss 0.599551, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:34.233031: step 5879, loss 0.670256, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:34.297345: step 5880, loss 0.768758, acc 0.72549, learning_rate 0.0001

Evaluation:
2017-09-28T16:39:34.559175: step 5880, loss 0.769284, acc 0.697842

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-5880

2017-09-28T16:39:35.120291: step 5881, loss 0.855608, acc 0.625, learning_rate 0.0001
2017-09-28T16:39:35.200810: step 5882, loss 0.698894, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:35.285304: step 5883, loss 0.635565, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:35.366112: step 5884, loss 0.720021, acc 0.625, learning_rate 0.0001
2017-09-28T16:39:35.449443: step 5885, loss 0.593788, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:35.529080: step 5886, loss 0.676792, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:35.610997: step 5887, loss 0.73125, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:35.692269: step 5888, loss 0.603509, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:35.775410: step 5889, loss 0.729459, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:35.856370: step 5890, loss 0.722461, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:35.940235: step 5891, loss 0.758559, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:36.022973: step 5892, loss 0.637444, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:36.105482: step 5893, loss 0.785935, acc 0.625, learning_rate 0.0001
2017-09-28T16:39:36.186365: step 5894, loss 0.744565, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:36.269393: step 5895, loss 0.684922, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:36.347544: step 5896, loss 0.82363, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:36.429663: step 5897, loss 0.595873, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:36.508812: step 5898, loss 0.559033, acc 0.8125, learning_rate 0.0001
2017-09-28T16:39:36.594688: step 5899, loss 0.732689, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:36.677325: step 5900, loss 0.666363, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:36.761485: step 5901, loss 0.763918, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:36.846417: step 5902, loss 0.589759, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:36.932432: step 5903, loss 0.517813, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:37.015805: step 5904, loss 0.730523, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:37.098868: step 5905, loss 0.683714, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:37.189448: step 5906, loss 0.748912, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:37.274636: step 5907, loss 0.705706, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:37.359139: step 5908, loss 0.63266, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:37.438660: step 5909, loss 0.591883, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:37.520506: step 5910, loss 0.613745, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:37.600696: step 5911, loss 0.657998, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:37.684577: step 5912, loss 0.579363, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:37.769459: step 5913, loss 0.75311, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:37.851170: step 5914, loss 0.579546, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:37.934706: step 5915, loss 0.790398, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:38.016197: step 5916, loss 0.53482, acc 0.8125, learning_rate 0.0001
2017-09-28T16:39:38.096940: step 5917, loss 0.717631, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:38.178072: step 5918, loss 0.801662, acc 0.609375, learning_rate 0.0001
2017-09-28T16:39:38.257944: step 5919, loss 0.981709, acc 0.59375, learning_rate 0.0001
2017-09-28T16:39:38.338950: step 5920, loss 0.651988, acc 0.6875, learning_rate 0.0001

Evaluation:
2017-09-28T16:39:38.611355: step 5920, loss 0.76859, acc 0.696403

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-5920

2017-09-28T16:39:39.164509: step 5921, loss 0.71298, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:39.245062: step 5922, loss 0.626657, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:39.327562: step 5923, loss 0.656448, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:39.410424: step 5924, loss 0.778366, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:39.491386: step 5925, loss 0.640383, acc 0.8125, learning_rate 0.0001
2017-09-28T16:39:39.570443: step 5926, loss 0.54044, acc 0.8125, learning_rate 0.0001
2017-09-28T16:39:39.650287: step 5927, loss 0.642551, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:39.731115: step 5928, loss 0.56723, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:39.812171: step 5929, loss 0.699348, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:39.898034: step 5930, loss 0.77118, acc 0.640625, learning_rate 0.0001
2017-09-28T16:39:39.975916: step 5931, loss 0.568748, acc 0.8125, learning_rate 0.0001
2017-09-28T16:39:40.058011: step 5932, loss 0.871113, acc 0.640625, learning_rate 0.0001
2017-09-28T16:39:40.139945: step 5933, loss 0.59183, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:40.220995: step 5934, loss 0.588778, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:40.302215: step 5935, loss 0.752653, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:40.383937: step 5936, loss 0.749347, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:40.470109: step 5937, loss 0.804454, acc 0.625, learning_rate 0.0001
2017-09-28T16:39:40.552151: step 5938, loss 0.623378, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:40.631229: step 5939, loss 0.682604, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:40.713438: step 5940, loss 0.668375, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:40.797976: step 5941, loss 0.623385, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:40.877543: step 5942, loss 0.583978, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:40.960214: step 5943, loss 0.522503, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:41.042957: step 5944, loss 0.644763, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:41.125001: step 5945, loss 0.795401, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:41.204357: step 5946, loss 0.852385, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:41.284998: step 5947, loss 0.717779, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:41.366167: step 5948, loss 0.811854, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:41.450050: step 5949, loss 0.739894, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:41.530435: step 5950, loss 0.712652, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:41.610917: step 5951, loss 0.782897, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:41.690493: step 5952, loss 0.787908, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:41.770619: step 5953, loss 0.685003, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:41.855337: step 5954, loss 0.838006, acc 0.640625, learning_rate 0.0001
2017-09-28T16:39:41.937507: step 5955, loss 0.720511, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:42.018982: step 5956, loss 0.722031, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:42.101022: step 5957, loss 0.617252, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:42.180052: step 5958, loss 0.551487, acc 0.8125, learning_rate 0.0001
2017-09-28T16:39:42.260534: step 5959, loss 0.776993, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:42.343094: step 5960, loss 0.650479, acc 0.75, learning_rate 0.0001

Evaluation:
2017-09-28T16:39:42.613403: step 5960, loss 0.770283, acc 0.686331

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-5960

2017-09-28T16:39:43.244973: step 5961, loss 0.676708, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:43.329517: step 5962, loss 0.835059, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:43.409493: step 5963, loss 0.774822, acc 0.640625, learning_rate 0.0001
2017-09-28T16:39:43.493557: step 5964, loss 0.923895, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:43.579066: step 5965, loss 0.604864, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:43.659685: step 5966, loss 0.753226, acc 0.609375, learning_rate 0.0001
2017-09-28T16:39:43.740787: step 5967, loss 0.727991, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:43.823728: step 5968, loss 0.784268, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:43.903360: step 5969, loss 0.665244, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:43.982655: step 5970, loss 0.648983, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:44.064951: step 5971, loss 0.727952, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:44.143898: step 5972, loss 0.78295, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:44.222869: step 5973, loss 0.584927, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:44.306228: step 5974, loss 0.685393, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:44.390754: step 5975, loss 0.600683, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:44.468793: step 5976, loss 0.606926, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:44.548863: step 5977, loss 0.700623, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:44.614068: step 5978, loss 0.901085, acc 0.588235, learning_rate 0.0001
2017-09-28T16:39:44.695289: step 5979, loss 0.699709, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:44.776246: step 5980, loss 0.801115, acc 0.640625, learning_rate 0.0001
2017-09-28T16:39:44.860808: step 5981, loss 0.694565, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:44.949546: step 5982, loss 0.618814, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:45.031373: step 5983, loss 0.910637, acc 0.609375, learning_rate 0.0001
2017-09-28T16:39:45.113415: step 5984, loss 0.611396, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:45.193613: step 5985, loss 0.709763, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:45.279512: step 5986, loss 0.568414, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:45.361975: step 5987, loss 0.548685, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:45.444748: step 5988, loss 0.66053, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:45.526959: step 5989, loss 0.76134, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:45.610613: step 5990, loss 0.754512, acc 0.609375, learning_rate 0.0001
2017-09-28T16:39:45.690774: step 5991, loss 0.632505, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:45.769125: step 5992, loss 0.550052, acc 0.84375, learning_rate 0.0001
2017-09-28T16:39:45.848836: step 5993, loss 0.670841, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:45.927920: step 5994, loss 0.743048, acc 0.671875, learning_rate 0.0001
2017-09-28T16:39:46.006707: step 5995, loss 0.713557, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:46.088830: step 5996, loss 0.555684, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:46.171644: step 5997, loss 0.739774, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:46.253843: step 5998, loss 0.634671, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:46.335847: step 5999, loss 0.560982, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:46.420309: step 6000, loss 0.643202, acc 0.703125, learning_rate 0.0001

Evaluation:
2017-09-28T16:39:46.688859: step 6000, loss 0.770246, acc 0.694964

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-6000

2017-09-28T16:39:47.194314: step 6001, loss 0.617674, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:47.280367: step 6002, loss 0.612125, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:47.368573: step 6003, loss 0.879927, acc 0.578125, learning_rate 0.0001
2017-09-28T16:39:47.452352: step 6004, loss 0.605983, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:47.532664: step 6005, loss 0.699852, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:47.615091: step 6006, loss 0.646797, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:47.697202: step 6007, loss 0.859518, acc 0.59375, learning_rate 0.0001
2017-09-28T16:39:47.778544: step 6008, loss 0.562143, acc 0.828125, learning_rate 0.0001
2017-09-28T16:39:47.859914: step 6009, loss 0.534919, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:47.940492: step 6010, loss 0.736508, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:48.021558: step 6011, loss 0.640925, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:48.101585: step 6012, loss 0.65881, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:48.182885: step 6013, loss 0.699508, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:48.265128: step 6014, loss 0.688335, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:48.347762: step 6015, loss 0.784432, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:48.430099: step 6016, loss 0.545642, acc 0.8125, learning_rate 0.0001
2017-09-28T16:39:48.513869: step 6017, loss 0.838985, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:48.592826: step 6018, loss 0.583974, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:48.673169: step 6019, loss 0.61511, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:48.751439: step 6020, loss 0.701063, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:48.833906: step 6021, loss 0.67621, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:48.914030: step 6022, loss 0.809193, acc 0.625, learning_rate 0.0001
2017-09-28T16:39:48.993392: step 6023, loss 0.913753, acc 0.59375, learning_rate 0.0001
2017-09-28T16:39:49.074798: step 6024, loss 0.67383, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:49.154387: step 6025, loss 0.704992, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:49.234233: step 6026, loss 0.72481, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:49.312330: step 6027, loss 0.660718, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:49.391879: step 6028, loss 0.732516, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:49.470754: step 6029, loss 0.656723, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:49.551070: step 6030, loss 0.672351, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:49.630667: step 6031, loss 0.707918, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:49.713137: step 6032, loss 0.689557, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:49.794088: step 6033, loss 0.593588, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:49.877667: step 6034, loss 0.785162, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:49.958267: step 6035, loss 0.704412, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:50.040627: step 6036, loss 0.676027, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:50.122039: step 6037, loss 0.945082, acc 0.609375, learning_rate 0.0001
2017-09-28T16:39:50.207635: step 6038, loss 0.663251, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:50.288848: step 6039, loss 0.540979, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:50.367433: step 6040, loss 0.629567, acc 0.734375, learning_rate 0.0001

Evaluation:
2017-09-28T16:39:50.637970: step 6040, loss 0.768872, acc 0.696403

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-6040

2017-09-28T16:39:51.193379: step 6041, loss 0.713495, acc 0.640625, learning_rate 0.0001
2017-09-28T16:39:51.274305: step 6042, loss 0.782988, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:51.355873: step 6043, loss 0.745546, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:51.437818: step 6044, loss 0.642732, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:51.519867: step 6045, loss 0.542747, acc 0.8125, learning_rate 0.0001
2017-09-28T16:39:51.606453: step 6046, loss 0.716433, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:51.688474: step 6047, loss 0.874114, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:51.768544: step 6048, loss 0.64078, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:51.852378: step 6049, loss 0.855166, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:51.934389: step 6050, loss 0.814494, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:52.016774: step 6051, loss 0.73631, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:52.095422: step 6052, loss 0.682394, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:52.175949: step 6053, loss 0.655406, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:52.257252: step 6054, loss 0.641366, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:52.340037: step 6055, loss 0.650051, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:52.420998: step 6056, loss 0.677941, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:52.501192: step 6057, loss 0.598894, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:52.585410: step 6058, loss 0.758323, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:52.666790: step 6059, loss 0.556777, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:52.745905: step 6060, loss 0.809041, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:52.827728: step 6061, loss 0.698314, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:52.907178: step 6062, loss 0.946361, acc 0.59375, learning_rate 0.0001
2017-09-28T16:39:52.991244: step 6063, loss 0.696305, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:53.074531: step 6064, loss 0.736382, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:53.154978: step 6065, loss 0.548388, acc 0.828125, learning_rate 0.0001
2017-09-28T16:39:53.236662: step 6066, loss 0.659035, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:53.318057: step 6067, loss 0.838371, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:53.402607: step 6068, loss 0.649262, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:53.481373: step 6069, loss 0.61764, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:53.561207: step 6070, loss 0.611744, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:53.642220: step 6071, loss 0.658163, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:53.724185: step 6072, loss 0.683938, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:53.805914: step 6073, loss 0.575253, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:53.889292: step 6074, loss 0.602887, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:53.971473: step 6075, loss 0.634896, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:54.040723: step 6076, loss 0.812734, acc 0.686275, learning_rate 0.0001
2017-09-28T16:39:54.123649: step 6077, loss 0.676021, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:54.206608: step 6078, loss 0.661476, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:54.288657: step 6079, loss 0.711587, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:54.370420: step 6080, loss 0.565602, acc 0.75, learning_rate 0.0001

Evaluation:
2017-09-28T16:39:54.645431: step 6080, loss 0.766313, acc 0.693525

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-6080

2017-09-28T16:39:55.208701: step 6081, loss 0.629639, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:55.289246: step 6082, loss 0.772224, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:55.371937: step 6083, loss 0.622792, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:55.453384: step 6084, loss 0.550653, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:55.533173: step 6085, loss 0.784764, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:55.610913: step 6086, loss 0.63634, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:55.693868: step 6087, loss 0.709664, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:55.776529: step 6088, loss 0.653144, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:55.857812: step 6089, loss 0.888178, acc 0.625, learning_rate 0.0001
2017-09-28T16:39:55.937976: step 6090, loss 0.69869, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:56.018746: step 6091, loss 0.585404, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:56.100953: step 6092, loss 0.64629, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:56.180662: step 6093, loss 0.883833, acc 0.59375, learning_rate 0.0001
2017-09-28T16:39:56.262935: step 6094, loss 0.703277, acc 0.703125, learning_rate 0.0001
2017-09-28T16:39:56.345776: step 6095, loss 0.751329, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:56.429132: step 6096, loss 0.704902, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:56.510097: step 6097, loss 0.510395, acc 0.828125, learning_rate 0.0001
2017-09-28T16:39:56.589640: step 6098, loss 0.638279, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:56.673266: step 6099, loss 0.66591, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:56.754024: step 6100, loss 0.918536, acc 0.59375, learning_rate 0.0001
2017-09-28T16:39:56.834608: step 6101, loss 0.797812, acc 0.609375, learning_rate 0.0001
2017-09-28T16:39:56.917862: step 6102, loss 0.947353, acc 0.625, learning_rate 0.0001
2017-09-28T16:39:57.000242: step 6103, loss 0.742603, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:57.082346: step 6104, loss 0.72839, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:57.164101: step 6105, loss 0.783492, acc 0.640625, learning_rate 0.0001
2017-09-28T16:39:57.244899: step 6106, loss 0.716381, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:57.324406: step 6107, loss 0.71985, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:57.406563: step 6108, loss 0.788723, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:57.486238: step 6109, loss 0.618773, acc 0.75, learning_rate 0.0001
2017-09-28T16:39:57.565886: step 6110, loss 0.556652, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:57.646425: step 6111, loss 0.520872, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:57.727909: step 6112, loss 0.760695, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:57.808781: step 6113, loss 0.733311, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:57.889659: step 6114, loss 0.920182, acc 0.609375, learning_rate 0.0001
2017-09-28T16:39:57.972037: step 6115, loss 0.577617, acc 0.828125, learning_rate 0.0001
2017-09-28T16:39:58.054379: step 6116, loss 0.904808, acc 0.609375, learning_rate 0.0001
2017-09-28T16:39:58.138478: step 6117, loss 0.567843, acc 0.796875, learning_rate 0.0001
2017-09-28T16:39:58.219766: step 6118, loss 0.761986, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:58.300924: step 6119, loss 0.704751, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:58.382750: step 6120, loss 0.62205, acc 0.734375, learning_rate 0.0001

Evaluation:
2017-09-28T16:39:58.646874: step 6120, loss 0.769208, acc 0.68777

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-6120

2017-09-28T16:39:59.286459: step 6121, loss 0.612061, acc 0.765625, learning_rate 0.0001
2017-09-28T16:39:59.368229: step 6122, loss 0.797062, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:59.450869: step 6123, loss 0.806526, acc 0.71875, learning_rate 0.0001
2017-09-28T16:39:59.531727: step 6124, loss 0.676625, acc 0.734375, learning_rate 0.0001
2017-09-28T16:39:59.614369: step 6125, loss 0.636115, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:59.694489: step 6126, loss 0.570992, acc 0.78125, learning_rate 0.0001
2017-09-28T16:39:59.776674: step 6127, loss 0.667987, acc 0.6875, learning_rate 0.0001
2017-09-28T16:39:59.857524: step 6128, loss 0.855327, acc 0.65625, learning_rate 0.0001
2017-09-28T16:39:59.945114: step 6129, loss 0.728359, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:00.026134: step 6130, loss 0.651394, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:00.109703: step 6131, loss 0.626657, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:00.192050: step 6132, loss 0.73067, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:00.277231: step 6133, loss 0.563135, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:00.359696: step 6134, loss 0.69954, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:00.440247: step 6135, loss 0.757459, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:00.519518: step 6136, loss 0.597611, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:00.601172: step 6137, loss 0.629989, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:00.682793: step 6138, loss 0.648101, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:00.764417: step 6139, loss 0.423552, acc 0.859375, learning_rate 0.0001
2017-09-28T16:40:00.846108: step 6140, loss 0.611978, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:00.928798: step 6141, loss 0.641867, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:01.011115: step 6142, loss 0.685715, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:01.092177: step 6143, loss 0.68435, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:01.173862: step 6144, loss 0.716601, acc 0.65625, learning_rate 0.0001
2017-09-28T16:40:01.254129: step 6145, loss 0.669481, acc 0.671875, learning_rate 0.0001
2017-09-28T16:40:01.332576: step 6146, loss 0.610342, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:01.412028: step 6147, loss 0.785472, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:01.493062: step 6148, loss 0.649467, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:01.575669: step 6149, loss 0.660091, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:01.658164: step 6150, loss 0.711207, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:01.738657: step 6151, loss 0.722967, acc 0.640625, learning_rate 0.0001
2017-09-28T16:40:01.819208: step 6152, loss 0.651175, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:01.898703: step 6153, loss 0.743449, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:01.979204: step 6154, loss 0.795931, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:02.062483: step 6155, loss 0.560889, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:02.141882: step 6156, loss 0.599796, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:02.222438: step 6157, loss 0.704509, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:02.301970: step 6158, loss 0.483306, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:02.381640: step 6159, loss 0.601929, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:02.462941: step 6160, loss 0.65817, acc 0.75, learning_rate 0.0001

Evaluation:
2017-09-28T16:40:02.727662: step 6160, loss 0.765925, acc 0.693525

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-6160

2017-09-28T16:40:03.217666: step 6161, loss 0.703018, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:03.296751: step 6162, loss 0.560234, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:03.375610: step 6163, loss 0.678113, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:03.459642: step 6164, loss 0.753495, acc 0.65625, learning_rate 0.0001
2017-09-28T16:40:03.542040: step 6165, loss 0.555309, acc 0.828125, learning_rate 0.0001
2017-09-28T16:40:03.624785: step 6166, loss 0.748372, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:03.710505: step 6167, loss 0.77271, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:03.793759: step 6168, loss 0.600114, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:03.877029: step 6169, loss 0.614217, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:03.962994: step 6170, loss 0.564131, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:04.058368: step 6171, loss 0.654173, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:04.145830: step 6172, loss 0.845801, acc 0.53125, learning_rate 0.0001
2017-09-28T16:40:04.227460: step 6173, loss 0.735004, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:04.293765: step 6174, loss 0.574268, acc 0.843137, learning_rate 0.0001
2017-09-28T16:40:04.379881: step 6175, loss 0.794423, acc 0.640625, learning_rate 0.0001
2017-09-28T16:40:04.464940: step 6176, loss 0.859167, acc 0.640625, learning_rate 0.0001
2017-09-28T16:40:04.546677: step 6177, loss 0.633704, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:04.628187: step 6178, loss 0.527825, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:04.710656: step 6179, loss 0.595491, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:04.791104: step 6180, loss 0.809431, acc 0.625, learning_rate 0.0001
2017-09-28T16:40:04.873958: step 6181, loss 0.644613, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:04.958924: step 6182, loss 0.526526, acc 0.859375, learning_rate 0.0001
2017-09-28T16:40:05.042958: step 6183, loss 0.496537, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:05.124064: step 6184, loss 0.646434, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:05.205837: step 6185, loss 0.666846, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:05.285237: step 6186, loss 0.831433, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:05.367148: step 6187, loss 0.66065, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:05.454902: step 6188, loss 0.635403, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:05.535209: step 6189, loss 0.629041, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:05.614634: step 6190, loss 0.60336, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:05.695717: step 6191, loss 0.748131, acc 0.671875, learning_rate 0.0001
2017-09-28T16:40:05.778287: step 6192, loss 0.619019, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:05.860164: step 6193, loss 0.825548, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:05.942881: step 6194, loss 0.74422, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:06.026905: step 6195, loss 0.79116, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:06.108044: step 6196, loss 0.702556, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:06.188512: step 6197, loss 0.499172, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:06.266056: step 6198, loss 0.72549, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:06.346941: step 6199, loss 0.846182, acc 0.625, learning_rate 0.0001
2017-09-28T16:40:06.428977: step 6200, loss 0.704349, acc 0.703125, learning_rate 0.0001

Evaluation:
2017-09-28T16:40:06.693968: step 6200, loss 0.765399, acc 0.696403

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-6200

2017-09-28T16:40:07.249541: step 6201, loss 0.655557, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:07.332361: step 6202, loss 0.747217, acc 0.671875, learning_rate 0.0001
2017-09-28T16:40:07.413194: step 6203, loss 0.602886, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:07.496248: step 6204, loss 0.761632, acc 0.671875, learning_rate 0.0001
2017-09-28T16:40:07.579757: step 6205, loss 0.868071, acc 0.625, learning_rate 0.0001
2017-09-28T16:40:07.662784: step 6206, loss 0.573404, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:07.745710: step 6207, loss 0.650524, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:07.825340: step 6208, loss 0.6739, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:07.906278: step 6209, loss 0.564825, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:07.986686: step 6210, loss 0.660985, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:08.071871: step 6211, loss 0.548298, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:08.155863: step 6212, loss 0.608388, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:08.238009: step 6213, loss 0.672093, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:08.320761: step 6214, loss 1.1004, acc 0.59375, learning_rate 0.0001
2017-09-28T16:40:08.401721: step 6215, loss 0.469861, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:08.483128: step 6216, loss 0.838855, acc 0.609375, learning_rate 0.0001
2017-09-28T16:40:08.564127: step 6217, loss 0.559315, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:08.648068: step 6218, loss 0.624035, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:08.730170: step 6219, loss 0.714063, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:08.813336: step 6220, loss 0.627425, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:08.895652: step 6221, loss 0.596509, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:08.975526: step 6222, loss 0.675642, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:09.054990: step 6223, loss 0.660892, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:09.136953: step 6224, loss 0.789633, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:09.220433: step 6225, loss 0.703214, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:09.304110: step 6226, loss 0.801737, acc 0.671875, learning_rate 0.0001
2017-09-28T16:40:09.386521: step 6227, loss 0.728341, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:09.466954: step 6228, loss 0.652994, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:09.548643: step 6229, loss 0.763066, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:09.631698: step 6230, loss 0.724708, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:09.712321: step 6231, loss 0.675218, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:09.793536: step 6232, loss 0.712741, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:09.874802: step 6233, loss 0.706937, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:09.958365: step 6234, loss 0.617598, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:10.046693: step 6235, loss 0.714245, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:10.129235: step 6236, loss 0.701633, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:10.210436: step 6237, loss 0.714784, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:10.293632: step 6238, loss 0.533459, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:10.378588: step 6239, loss 0.741487, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:10.459495: step 6240, loss 0.683807, acc 0.71875, learning_rate 0.0001

Evaluation:
2017-09-28T16:40:10.732342: step 6240, loss 0.768322, acc 0.699281

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-6240

2017-09-28T16:40:11.292905: step 6241, loss 0.813287, acc 0.671875, learning_rate 0.0001
2017-09-28T16:40:11.375570: step 6242, loss 0.715215, acc 0.640625, learning_rate 0.0001
2017-09-28T16:40:11.459457: step 6243, loss 0.554518, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:11.542491: step 6244, loss 0.625058, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:11.623066: step 6245, loss 1.03702, acc 0.59375, learning_rate 0.0001
2017-09-28T16:40:11.707401: step 6246, loss 0.778764, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:11.790283: step 6247, loss 0.649975, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:11.871509: step 6248, loss 0.832428, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:11.952186: step 6249, loss 0.678105, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:12.032285: step 6250, loss 0.576862, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:12.114252: step 6251, loss 0.561803, acc 0.828125, learning_rate 0.0001
2017-09-28T16:40:12.194623: step 6252, loss 0.646058, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:12.273612: step 6253, loss 0.628855, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:12.356170: step 6254, loss 0.631061, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:12.438980: step 6255, loss 0.773983, acc 0.609375, learning_rate 0.0001
2017-09-28T16:40:12.519857: step 6256, loss 0.557451, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:12.600766: step 6257, loss 0.737659, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:12.683070: step 6258, loss 0.740929, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:12.762366: step 6259, loss 0.623677, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:12.842037: step 6260, loss 0.510278, acc 0.828125, learning_rate 0.0001
2017-09-28T16:40:12.925302: step 6261, loss 0.609848, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:13.006841: step 6262, loss 0.595961, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:13.090807: step 6263, loss 0.592706, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:13.170471: step 6264, loss 0.926314, acc 0.578125, learning_rate 0.0001
2017-09-28T16:40:13.247306: step 6265, loss 0.870245, acc 0.609375, learning_rate 0.0001
2017-09-28T16:40:13.325620: step 6266, loss 0.75714, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:13.405817: step 6267, loss 0.724427, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:13.488649: step 6268, loss 0.5486, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:13.569166: step 6269, loss 0.691714, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:13.650358: step 6270, loss 0.658055, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:13.735806: step 6271, loss 0.561808, acc 0.828125, learning_rate 0.0001
2017-09-28T16:40:13.801442: step 6272, loss 0.610736, acc 0.705882, learning_rate 0.0001
2017-09-28T16:40:13.883439: step 6273, loss 0.607768, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:13.965677: step 6274, loss 0.676474, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:14.046663: step 6275, loss 0.635979, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:14.129895: step 6276, loss 0.629504, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:14.212290: step 6277, loss 0.731421, acc 0.671875, learning_rate 0.0001
2017-09-28T16:40:14.291794: step 6278, loss 0.619702, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:14.370672: step 6279, loss 0.747029, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:14.451296: step 6280, loss 0.579662, acc 0.75, learning_rate 0.0001

Evaluation:
2017-09-28T16:40:14.718943: step 6280, loss 0.765279, acc 0.689209

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-6280

2017-09-28T16:40:15.359821: step 6281, loss 0.615755, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:15.443350: step 6282, loss 0.65187, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:15.524305: step 6283, loss 0.790829, acc 0.625, learning_rate 0.0001
2017-09-28T16:40:15.607303: step 6284, loss 0.498215, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:15.689598: step 6285, loss 0.49588, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:15.771757: step 6286, loss 0.728261, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:15.852624: step 6287, loss 0.737426, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:15.935099: step 6288, loss 0.645925, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:16.018044: step 6289, loss 0.730211, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:16.101011: step 6290, loss 0.825235, acc 0.671875, learning_rate 0.0001
2017-09-28T16:40:16.184120: step 6291, loss 0.562543, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:16.265958: step 6292, loss 0.57168, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:16.346673: step 6293, loss 0.670829, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:16.427983: step 6294, loss 0.722926, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:16.512882: step 6295, loss 0.534651, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:16.596718: step 6296, loss 0.75506, acc 0.625, learning_rate 0.0001
2017-09-28T16:40:16.679068: step 6297, loss 0.847763, acc 0.671875, learning_rate 0.0001
2017-09-28T16:40:16.757106: step 6298, loss 0.661367, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:16.841171: step 6299, loss 0.851705, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:16.922166: step 6300, loss 0.644016, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:17.006522: step 6301, loss 0.519407, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:17.089214: step 6302, loss 0.705248, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:17.170986: step 6303, loss 0.602839, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:17.252915: step 6304, loss 0.739106, acc 0.640625, learning_rate 0.0001
2017-09-28T16:40:17.334067: step 6305, loss 0.662587, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:17.413762: step 6306, loss 0.692787, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:17.495347: step 6307, loss 0.561616, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:17.577417: step 6308, loss 0.663995, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:17.658768: step 6309, loss 0.581834, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:17.737479: step 6310, loss 0.641835, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:17.819279: step 6311, loss 0.676134, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:17.901386: step 6312, loss 0.408807, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:17.982835: step 6313, loss 0.470249, acc 0.828125, learning_rate 0.0001
2017-09-28T16:40:18.063475: step 6314, loss 0.887206, acc 0.671875, learning_rate 0.0001
2017-09-28T16:40:18.149069: step 6315, loss 0.610765, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:18.231290: step 6316, loss 0.565201, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:18.311923: step 6317, loss 0.779165, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:18.396047: step 6318, loss 0.645803, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:18.478578: step 6319, loss 0.599393, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:18.557407: step 6320, loss 0.628534, acc 0.796875, learning_rate 0.0001

Evaluation:
2017-09-28T16:40:18.827118: step 6320, loss 0.762347, acc 0.693525

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-6320

2017-09-28T16:40:19.321309: step 6321, loss 0.753982, acc 0.671875, learning_rate 0.0001
2017-09-28T16:40:19.404390: step 6322, loss 0.689059, acc 0.65625, learning_rate 0.0001
2017-09-28T16:40:19.483883: step 6323, loss 0.535852, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:19.566191: step 6324, loss 0.566469, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:19.646944: step 6325, loss 0.711604, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:19.724942: step 6326, loss 0.601816, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:19.804804: step 6327, loss 0.772174, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:19.886072: step 6328, loss 0.680471, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:19.963761: step 6329, loss 0.706272, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:20.052665: step 6330, loss 0.789581, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:20.134309: step 6331, loss 0.64893, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:20.215521: step 6332, loss 0.569416, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:20.296230: step 6333, loss 0.651211, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:20.378325: step 6334, loss 0.794446, acc 0.65625, learning_rate 0.0001
2017-09-28T16:40:20.462359: step 6335, loss 0.635105, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:20.543291: step 6336, loss 0.740552, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:20.624939: step 6337, loss 0.691063, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:20.706523: step 6338, loss 0.550434, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:20.787012: step 6339, loss 0.579859, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:20.869303: step 6340, loss 0.840463, acc 0.609375, learning_rate 0.0001
2017-09-28T16:40:20.951618: step 6341, loss 0.649153, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:21.033076: step 6342, loss 0.711718, acc 0.671875, learning_rate 0.0001
2017-09-28T16:40:21.117907: step 6343, loss 0.680527, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:21.198382: step 6344, loss 0.785215, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:21.284472: step 6345, loss 0.650496, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:21.368926: step 6346, loss 0.589682, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:21.451716: step 6347, loss 0.895311, acc 0.65625, learning_rate 0.0001
2017-09-28T16:40:21.530152: step 6348, loss 0.638247, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:21.611739: step 6349, loss 0.611766, acc 0.828125, learning_rate 0.0001
2017-09-28T16:40:21.692868: step 6350, loss 0.681823, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:21.770661: step 6351, loss 0.850931, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:21.852302: step 6352, loss 0.704537, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:21.933081: step 6353, loss 0.634609, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:22.013445: step 6354, loss 0.572099, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:22.092179: step 6355, loss 0.629309, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:22.174569: step 6356, loss 0.73716, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:22.254097: step 6357, loss 0.844401, acc 0.609375, learning_rate 0.0001
2017-09-28T16:40:22.332807: step 6358, loss 0.934794, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:22.415802: step 6359, loss 0.693877, acc 0.671875, learning_rate 0.0001
2017-09-28T16:40:22.497334: step 6360, loss 0.728191, acc 0.640625, learning_rate 0.0001

Evaluation:
2017-09-28T16:40:22.769821: step 6360, loss 0.764217, acc 0.697842

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-6360

2017-09-28T16:40:23.326423: step 6361, loss 0.857736, acc 0.640625, learning_rate 0.0001
2017-09-28T16:40:23.410962: step 6362, loss 0.749649, acc 0.65625, learning_rate 0.0001
2017-09-28T16:40:23.492854: step 6363, loss 0.832069, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:23.575142: step 6364, loss 0.484408, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:23.655968: step 6365, loss 0.736529, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:23.737539: step 6366, loss 0.791831, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:23.819339: step 6367, loss 0.91483, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:23.902028: step 6368, loss 0.773507, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:23.984491: step 6369, loss 0.82592, acc 0.640625, learning_rate 0.0001
2017-09-28T16:40:24.049159: step 6370, loss 0.74882, acc 0.686275, learning_rate 0.0001
2017-09-28T16:40:24.130569: step 6371, loss 0.678284, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:24.214699: step 6372, loss 0.65383, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:24.298546: step 6373, loss 0.639587, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:24.379035: step 6374, loss 0.634091, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:24.462945: step 6375, loss 0.698415, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:24.547220: step 6376, loss 0.653263, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:24.629375: step 6377, loss 0.604095, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:24.711557: step 6378, loss 0.681171, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:24.796096: step 6379, loss 0.7199, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:24.878690: step 6380, loss 0.738066, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:24.962424: step 6381, loss 0.550771, acc 0.84375, learning_rate 0.0001
2017-09-28T16:40:25.042210: step 6382, loss 0.617256, acc 0.828125, learning_rate 0.0001
2017-09-28T16:40:25.134441: step 6383, loss 0.560055, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:25.214693: step 6384, loss 0.608519, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:25.301047: step 6385, loss 0.747105, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:25.382760: step 6386, loss 0.51255, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:25.466089: step 6387, loss 0.719407, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:25.548486: step 6388, loss 0.556448, acc 0.84375, learning_rate 0.0001
2017-09-28T16:40:25.630402: step 6389, loss 0.539003, acc 0.875, learning_rate 0.0001
2017-09-28T16:40:25.713359: step 6390, loss 0.729289, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:25.794306: step 6391, loss 0.734474, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:25.876482: step 6392, loss 0.672987, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:25.957967: step 6393, loss 0.608412, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:26.039281: step 6394, loss 0.587141, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:26.126486: step 6395, loss 0.519826, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:26.206705: step 6396, loss 0.628028, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:26.285914: step 6397, loss 0.854028, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:26.364720: step 6398, loss 0.623952, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:26.446399: step 6399, loss 0.751561, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:26.525734: step 6400, loss 0.789292, acc 0.671875, learning_rate 0.0001

Evaluation:
2017-09-28T16:40:26.792853: step 6400, loss 0.762039, acc 0.699281

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-6400

2017-09-28T16:40:27.349618: step 6401, loss 0.761264, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:27.432071: step 6402, loss 0.645563, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:27.513851: step 6403, loss 0.550152, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:27.596902: step 6404, loss 0.550321, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:27.679074: step 6405, loss 0.683736, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:27.761818: step 6406, loss 0.663192, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:27.844035: step 6407, loss 0.527554, acc 0.828125, learning_rate 0.0001
2017-09-28T16:40:27.925911: step 6408, loss 0.695246, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:28.010589: step 6409, loss 0.704296, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:28.092459: step 6410, loss 0.677332, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:28.174388: step 6411, loss 0.758883, acc 0.671875, learning_rate 0.0001
2017-09-28T16:40:28.255736: step 6412, loss 0.572068, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:28.337711: step 6413, loss 0.561622, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:28.423048: step 6414, loss 0.756921, acc 0.65625, learning_rate 0.0001
2017-09-28T16:40:28.501930: step 6415, loss 0.722189, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:28.583932: step 6416, loss 0.760653, acc 0.609375, learning_rate 0.0001
2017-09-28T16:40:28.670491: step 6417, loss 0.585989, acc 0.828125, learning_rate 0.0001
2017-09-28T16:40:28.753491: step 6418, loss 0.694723, acc 0.671875, learning_rate 0.0001
2017-09-28T16:40:28.833547: step 6419, loss 0.815127, acc 0.65625, learning_rate 0.0001
2017-09-28T16:40:28.914816: step 6420, loss 0.665154, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:28.996189: step 6421, loss 0.631509, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:29.074999: step 6422, loss 0.734773, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:29.156441: step 6423, loss 0.643465, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:29.237926: step 6424, loss 0.790617, acc 0.671875, learning_rate 0.0001
2017-09-28T16:40:29.318550: step 6425, loss 0.797984, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:29.401066: step 6426, loss 0.721754, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:29.485211: step 6427, loss 0.744491, acc 0.671875, learning_rate 0.0001
2017-09-28T16:40:29.568780: step 6428, loss 0.652436, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:29.651387: step 6429, loss 0.591311, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:29.731015: step 6430, loss 0.747876, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:29.813165: step 6431, loss 0.747958, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:29.896052: step 6432, loss 0.605556, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:29.976603: step 6433, loss 0.473199, acc 0.84375, learning_rate 0.0001
2017-09-28T16:40:30.054342: step 6434, loss 0.795899, acc 0.671875, learning_rate 0.0001
2017-09-28T16:40:30.144103: step 6435, loss 0.582931, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:30.223769: step 6436, loss 0.753983, acc 0.65625, learning_rate 0.0001
2017-09-28T16:40:30.305194: step 6437, loss 0.639277, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:30.387260: step 6438, loss 0.851101, acc 0.640625, learning_rate 0.0001
2017-09-28T16:40:30.470581: step 6439, loss 0.617409, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:30.552718: step 6440, loss 0.510445, acc 0.796875, learning_rate 0.0001

Evaluation:
2017-09-28T16:40:30.816722: step 6440, loss 0.763715, acc 0.690647

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-6440

2017-09-28T16:40:31.443730: step 6441, loss 0.677748, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:31.524589: step 6442, loss 0.632874, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:31.607071: step 6443, loss 0.574292, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:31.686153: step 6444, loss 0.838529, acc 0.640625, learning_rate 0.0001
2017-09-28T16:40:31.769702: step 6445, loss 0.628612, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:31.849364: step 6446, loss 0.624437, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:31.930719: step 6447, loss 0.571271, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:32.011089: step 6448, loss 0.716206, acc 0.625, learning_rate 0.0001
2017-09-28T16:40:32.091530: step 6449, loss 0.570451, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:32.175667: step 6450, loss 0.739874, acc 0.671875, learning_rate 0.0001
2017-09-28T16:40:32.257799: step 6451, loss 0.766178, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:32.338698: step 6452, loss 0.846804, acc 0.625, learning_rate 0.0001
2017-09-28T16:40:32.420056: step 6453, loss 0.512885, acc 0.828125, learning_rate 0.0001
2017-09-28T16:40:32.501572: step 6454, loss 0.610856, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:32.584370: step 6455, loss 0.970415, acc 0.671875, learning_rate 0.0001
2017-09-28T16:40:32.664796: step 6456, loss 0.676033, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:32.745938: step 6457, loss 0.569362, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:32.824737: step 6458, loss 0.593567, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:32.906615: step 6459, loss 0.795052, acc 0.65625, learning_rate 0.0001
2017-09-28T16:40:32.989138: step 6460, loss 0.671384, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:33.073988: step 6461, loss 0.59211, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:33.152600: step 6462, loss 0.832977, acc 0.65625, learning_rate 0.0001
2017-09-28T16:40:33.235150: step 6463, loss 0.669995, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:33.316007: step 6464, loss 0.767928, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:33.398660: step 6465, loss 0.628217, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:33.475129: step 6466, loss 0.680503, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:33.557395: step 6467, loss 0.773371, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:33.621883: step 6468, loss 0.63578, acc 0.764706, learning_rate 0.0001
2017-09-28T16:40:33.702433: step 6469, loss 0.678301, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:33.785125: step 6470, loss 0.664642, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:33.866295: step 6471, loss 0.761453, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:33.951261: step 6472, loss 0.698008, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:34.033844: step 6473, loss 0.595315, acc 0.84375, learning_rate 0.0001
2017-09-28T16:40:34.119886: step 6474, loss 0.806912, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:34.202324: step 6475, loss 0.68534, acc 0.671875, learning_rate 0.0001
2017-09-28T16:40:34.284673: step 6476, loss 0.56064, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:34.364767: step 6477, loss 0.681481, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:34.446611: step 6478, loss 0.647344, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:34.531083: step 6479, loss 0.848337, acc 0.640625, learning_rate 0.0001
2017-09-28T16:40:34.615024: step 6480, loss 0.588441, acc 0.765625, learning_rate 0.0001

Evaluation:
2017-09-28T16:40:34.885471: step 6480, loss 0.762381, acc 0.697842

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-6480

2017-09-28T16:40:35.378756: step 6481, loss 0.694128, acc 0.671875, learning_rate 0.0001
2017-09-28T16:40:35.459241: step 6482, loss 0.642956, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:35.538501: step 6483, loss 0.677859, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:35.619872: step 6484, loss 0.713654, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:35.701605: step 6485, loss 0.769167, acc 0.640625, learning_rate 0.0001
2017-09-28T16:40:35.782381: step 6486, loss 0.871025, acc 0.65625, learning_rate 0.0001
2017-09-28T16:40:35.863149: step 6487, loss 0.579599, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:35.946109: step 6488, loss 0.662856, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:36.025723: step 6489, loss 0.798326, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:36.105309: step 6490, loss 0.804016, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:36.186149: step 6491, loss 0.705172, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:36.265470: step 6492, loss 0.501453, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:36.348033: step 6493, loss 0.59751, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:36.427180: step 6494, loss 0.616063, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:36.506115: step 6495, loss 0.602552, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:36.586294: step 6496, loss 0.56656, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:36.669369: step 6497, loss 0.706284, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:36.748956: step 6498, loss 0.694557, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:36.828581: step 6499, loss 0.634323, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:36.909725: step 6500, loss 0.740867, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:36.990814: step 6501, loss 0.535787, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:37.071654: step 6502, loss 0.854711, acc 0.65625, learning_rate 0.0001
2017-09-28T16:40:37.153961: step 6503, loss 0.546379, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:37.235620: step 6504, loss 0.893072, acc 0.578125, learning_rate 0.0001
2017-09-28T16:40:37.317129: step 6505, loss 0.770794, acc 0.671875, learning_rate 0.0001
2017-09-28T16:40:37.399024: step 6506, loss 0.641116, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:37.480861: step 6507, loss 0.529546, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:37.561346: step 6508, loss 0.569266, acc 0.828125, learning_rate 0.0001
2017-09-28T16:40:37.642065: step 6509, loss 0.496863, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:37.724885: step 6510, loss 0.743713, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:37.805368: step 6511, loss 0.688311, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:37.884257: step 6512, loss 0.529896, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:37.966363: step 6513, loss 0.580867, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:38.048470: step 6514, loss 0.624459, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:38.131828: step 6515, loss 0.657941, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:38.212548: step 6516, loss 0.729198, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:38.292952: step 6517, loss 0.701342, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:38.374540: step 6518, loss 0.710685, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:38.454176: step 6519, loss 0.773574, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:38.533336: step 6520, loss 0.706009, acc 0.65625, learning_rate 0.0001

Evaluation:
2017-09-28T16:40:38.804438: step 6520, loss 0.760273, acc 0.690647

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-6520

2017-09-28T16:40:39.363872: step 6521, loss 0.725263, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:39.442685: step 6522, loss 0.684619, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:39.525648: step 6523, loss 0.777805, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:39.611939: step 6524, loss 0.676948, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:39.692831: step 6525, loss 0.542196, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:39.771470: step 6526, loss 0.67436, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:39.851219: step 6527, loss 0.472579, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:39.929526: step 6528, loss 0.730726, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:40.010530: step 6529, loss 0.733439, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:40.091179: step 6530, loss 0.662485, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:40.183633: step 6531, loss 0.805398, acc 0.59375, learning_rate 0.0001
2017-09-28T16:40:40.264528: step 6532, loss 0.710568, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:40.350994: step 6533, loss 0.625656, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:40.434872: step 6534, loss 0.665106, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:40.518228: step 6535, loss 0.719369, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:40.601146: step 6536, loss 0.667471, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:40.683369: step 6537, loss 0.480961, acc 0.859375, learning_rate 0.0001
2017-09-28T16:40:40.765670: step 6538, loss 0.568376, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:40.848023: step 6539, loss 0.563022, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:40.928133: step 6540, loss 0.614366, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:41.011891: step 6541, loss 0.70082, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:41.093838: step 6542, loss 0.622107, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:41.175231: step 6543, loss 0.636979, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:41.255133: step 6544, loss 0.540772, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:41.336232: step 6545, loss 0.515855, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:41.421112: step 6546, loss 0.729271, acc 0.65625, learning_rate 0.0001
2017-09-28T16:40:41.500002: step 6547, loss 0.75867, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:41.582357: step 6548, loss 0.733424, acc 0.671875, learning_rate 0.0001
2017-09-28T16:40:41.664323: step 6549, loss 0.720763, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:41.746117: step 6550, loss 0.807896, acc 0.609375, learning_rate 0.0001
2017-09-28T16:40:41.824549: step 6551, loss 0.727553, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:41.905274: step 6552, loss 0.707664, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:41.988469: step 6553, loss 0.719776, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:42.068531: step 6554, loss 0.686919, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:42.152206: step 6555, loss 0.57877, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:42.234130: step 6556, loss 0.543169, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:42.314920: step 6557, loss 0.604774, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:42.398607: step 6558, loss 0.81675, acc 0.65625, learning_rate 0.0001
2017-09-28T16:40:42.478974: step 6559, loss 0.631962, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:42.563846: step 6560, loss 0.683197, acc 0.6875, learning_rate 0.0001

Evaluation:
2017-09-28T16:40:42.826931: step 6560, loss 0.759702, acc 0.697842

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-6560

2017-09-28T16:40:43.386850: step 6561, loss 0.830598, acc 0.609375, learning_rate 0.0001
2017-09-28T16:40:43.468525: step 6562, loss 0.627971, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:43.547095: step 6563, loss 0.625722, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:43.627252: step 6564, loss 0.660059, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:43.708332: step 6565, loss 0.766265, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:43.772403: step 6566, loss 0.715522, acc 0.686275, learning_rate 0.0001
2017-09-28T16:40:43.854857: step 6567, loss 0.605134, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:43.932482: step 6568, loss 0.718322, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:44.014133: step 6569, loss 0.565486, acc 0.828125, learning_rate 0.0001
2017-09-28T16:40:44.096844: step 6570, loss 0.507834, acc 0.859375, learning_rate 0.0001
2017-09-28T16:40:44.188565: step 6571, loss 0.921241, acc 0.59375, learning_rate 0.0001
2017-09-28T16:40:44.267927: step 6572, loss 0.609232, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:44.351166: step 6573, loss 0.740271, acc 0.65625, learning_rate 0.0001
2017-09-28T16:40:44.433531: step 6574, loss 0.72476, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:44.516973: step 6575, loss 0.689418, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:44.598594: step 6576, loss 0.550712, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:44.680916: step 6577, loss 0.485974, acc 0.84375, learning_rate 0.0001
2017-09-28T16:40:44.766923: step 6578, loss 0.662093, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:44.846677: step 6579, loss 0.767252, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:44.929858: step 6580, loss 0.670831, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:45.015371: step 6581, loss 0.49864, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:45.096294: step 6582, loss 0.673518, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:45.181891: step 6583, loss 0.613675, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:45.276789: step 6584, loss 0.717654, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:45.355741: step 6585, loss 0.716199, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:45.439815: step 6586, loss 0.603592, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:45.520729: step 6587, loss 0.865564, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:45.604863: step 6588, loss 0.519592, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:45.686507: step 6589, loss 0.65867, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:45.766076: step 6590, loss 0.651343, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:45.845787: step 6591, loss 0.744871, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:45.928315: step 6592, loss 0.830484, acc 0.65625, learning_rate 0.0001
2017-09-28T16:40:46.008885: step 6593, loss 0.542772, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:46.090592: step 6594, loss 0.628001, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:46.174381: step 6595, loss 0.660108, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:46.255887: step 6596, loss 0.628969, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:46.337931: step 6597, loss 0.90319, acc 0.625, learning_rate 0.0001
2017-09-28T16:40:46.421159: step 6598, loss 0.635321, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:46.501800: step 6599, loss 0.603867, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:46.582932: step 6600, loss 0.689089, acc 0.75, learning_rate 0.0001

Evaluation:
2017-09-28T16:40:46.848482: step 6600, loss 0.759451, acc 0.690647

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-6600

2017-09-28T16:40:47.481438: step 6601, loss 0.512737, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:47.566084: step 6602, loss 0.623244, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:47.646364: step 6603, loss 0.525939, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:47.729129: step 6604, loss 0.574759, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:47.808523: step 6605, loss 0.544759, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:47.889961: step 6606, loss 0.728465, acc 0.59375, learning_rate 0.0001
2017-09-28T16:40:47.973539: step 6607, loss 0.711701, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:48.050476: step 6608, loss 0.627163, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:48.134008: step 6609, loss 0.858308, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:48.214553: step 6610, loss 0.639887, acc 0.84375, learning_rate 0.0001
2017-09-28T16:40:48.301371: step 6611, loss 0.448881, acc 0.828125, learning_rate 0.0001
2017-09-28T16:40:48.382060: step 6612, loss 0.70457, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:48.461921: step 6613, loss 0.776068, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:48.544457: step 6614, loss 0.743935, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:48.628170: step 6615, loss 0.811065, acc 0.640625, learning_rate 0.0001
2017-09-28T16:40:48.710898: step 6616, loss 0.554596, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:48.791956: step 6617, loss 0.628918, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:48.873686: step 6618, loss 0.811467, acc 0.640625, learning_rate 0.0001
2017-09-28T16:40:48.951540: step 6619, loss 0.673821, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:49.035128: step 6620, loss 0.900775, acc 0.578125, learning_rate 0.0001
2017-09-28T16:40:49.116497: step 6621, loss 0.70017, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:49.199724: step 6622, loss 0.932792, acc 0.65625, learning_rate 0.0001
2017-09-28T16:40:49.278857: step 6623, loss 0.782136, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:49.360935: step 6624, loss 0.679904, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:49.443847: step 6625, loss 0.592387, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:49.524531: step 6626, loss 0.656384, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:49.604767: step 6627, loss 0.812206, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:49.686214: step 6628, loss 0.564859, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:49.768361: step 6629, loss 0.506478, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:49.848435: step 6630, loss 0.517476, acc 0.84375, learning_rate 0.0001
2017-09-28T16:40:49.927878: step 6631, loss 0.687745, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:50.011066: step 6632, loss 0.620378, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:50.094202: step 6633, loss 0.665878, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:50.177069: step 6634, loss 0.682611, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:50.264623: step 6635, loss 0.645138, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:50.344465: step 6636, loss 0.795556, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:50.428955: step 6637, loss 0.733485, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:50.511468: step 6638, loss 0.550335, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:50.593228: step 6639, loss 0.67184, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:50.675719: step 6640, loss 0.658643, acc 0.71875, learning_rate 0.0001

Evaluation:
2017-09-28T16:40:50.944920: step 6640, loss 0.758502, acc 0.697842

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-6640

2017-09-28T16:40:51.441001: step 6641, loss 0.90433, acc 0.625, learning_rate 0.0001
2017-09-28T16:40:51.521213: step 6642, loss 0.622153, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:51.601892: step 6643, loss 0.632378, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:51.685691: step 6644, loss 0.694642, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:51.768991: step 6645, loss 0.614309, acc 0.671875, learning_rate 0.0001
2017-09-28T16:40:51.848816: step 6646, loss 0.553276, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:51.930501: step 6647, loss 0.587559, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:52.012494: step 6648, loss 0.563344, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:52.094142: step 6649, loss 0.856122, acc 0.609375, learning_rate 0.0001
2017-09-28T16:40:52.179397: step 6650, loss 0.824059, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:52.260918: step 6651, loss 0.756316, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:52.341417: step 6652, loss 0.66069, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:52.422274: step 6653, loss 0.614692, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:52.504179: step 6654, loss 0.691183, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:52.587071: step 6655, loss 0.671035, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:52.666625: step 6656, loss 0.862179, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:52.748369: step 6657, loss 0.677302, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:52.832477: step 6658, loss 0.747013, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:52.916464: step 6659, loss 0.748145, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:52.998245: step 6660, loss 0.605419, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:53.078719: step 6661, loss 0.531993, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:53.159918: step 6662, loss 0.617077, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:53.241395: step 6663, loss 0.608902, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:53.306060: step 6664, loss 0.560589, acc 0.803922, learning_rate 0.0001
2017-09-28T16:40:53.388482: step 6665, loss 0.572822, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:53.470607: step 6666, loss 0.980498, acc 0.578125, learning_rate 0.0001
2017-09-28T16:40:53.555544: step 6667, loss 0.638235, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:53.637401: step 6668, loss 0.698309, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:53.715787: step 6669, loss 0.686666, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:53.798608: step 6670, loss 0.587015, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:53.881996: step 6671, loss 0.759598, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:53.963198: step 6672, loss 0.788873, acc 0.65625, learning_rate 0.0001
2017-09-28T16:40:54.045779: step 6673, loss 0.702407, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:54.129184: step 6674, loss 0.832503, acc 0.65625, learning_rate 0.0001
2017-09-28T16:40:54.212846: step 6675, loss 0.661396, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:54.292267: step 6676, loss 0.668355, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:54.374066: step 6677, loss 0.829177, acc 0.625, learning_rate 0.0001
2017-09-28T16:40:54.453260: step 6678, loss 0.730602, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:54.533430: step 6679, loss 0.617258, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:54.614208: step 6680, loss 0.633798, acc 0.71875, learning_rate 0.0001

Evaluation:
2017-09-28T16:40:54.881452: step 6680, loss 0.757772, acc 0.690647

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-6680

2017-09-28T16:40:55.440363: step 6681, loss 0.803869, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:55.523050: step 6682, loss 0.590189, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:55.606966: step 6683, loss 0.480143, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:55.688559: step 6684, loss 0.638198, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:55.768817: step 6685, loss 0.54357, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:55.852437: step 6686, loss 0.803974, acc 0.640625, learning_rate 0.0001
2017-09-28T16:40:55.931463: step 6687, loss 0.837085, acc 0.65625, learning_rate 0.0001
2017-09-28T16:40:56.013403: step 6688, loss 0.502928, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:56.094323: step 6689, loss 0.534833, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:56.176342: step 6690, loss 0.52168, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:56.257445: step 6691, loss 0.734218, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:56.340598: step 6692, loss 0.532424, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:56.421943: step 6693, loss 0.763771, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:56.505636: step 6694, loss 0.702529, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:56.588872: step 6695, loss 0.533601, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:56.669052: step 6696, loss 0.453781, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:56.751707: step 6697, loss 0.719991, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:56.834660: step 6698, loss 0.682203, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:56.916304: step 6699, loss 0.636917, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:56.997468: step 6700, loss 0.490592, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:57.078858: step 6701, loss 0.936656, acc 0.640625, learning_rate 0.0001
2017-09-28T16:40:57.157264: step 6702, loss 0.723842, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:57.240796: step 6703, loss 0.690693, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:57.322608: step 6704, loss 0.621585, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:57.404332: step 6705, loss 0.537102, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:57.489282: step 6706, loss 0.597024, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:57.570725: step 6707, loss 0.568296, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:57.654077: step 6708, loss 0.606429, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:57.735861: step 6709, loss 0.66407, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:57.816107: step 6710, loss 0.628931, acc 0.8125, learning_rate 0.0001
2017-09-28T16:40:57.896486: step 6711, loss 0.580408, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:57.978127: step 6712, loss 0.693289, acc 0.71875, learning_rate 0.0001
2017-09-28T16:40:58.057307: step 6713, loss 0.643371, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:58.139125: step 6714, loss 0.664369, acc 0.75, learning_rate 0.0001
2017-09-28T16:40:58.222548: step 6715, loss 0.796506, acc 0.640625, learning_rate 0.0001
2017-09-28T16:40:58.304313: step 6716, loss 0.566642, acc 0.78125, learning_rate 0.0001
2017-09-28T16:40:58.384233: step 6717, loss 0.781114, acc 0.703125, learning_rate 0.0001
2017-09-28T16:40:58.469956: step 6718, loss 0.657674, acc 0.796875, learning_rate 0.0001
2017-09-28T16:40:58.552350: step 6719, loss 0.780519, acc 0.65625, learning_rate 0.0001
2017-09-28T16:40:58.633201: step 6720, loss 0.662163, acc 0.734375, learning_rate 0.0001

Evaluation:
2017-09-28T16:40:58.899009: step 6720, loss 0.756761, acc 0.693525

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-6720

2017-09-28T16:40:59.461199: step 6721, loss 0.484777, acc 0.890625, learning_rate 0.0001
2017-09-28T16:40:59.540839: step 6722, loss 0.799271, acc 0.625, learning_rate 0.0001
2017-09-28T16:40:59.622655: step 6723, loss 0.752697, acc 0.65625, learning_rate 0.0001
2017-09-28T16:40:59.702011: step 6724, loss 0.576646, acc 0.765625, learning_rate 0.0001
2017-09-28T16:40:59.782545: step 6725, loss 0.658161, acc 0.734375, learning_rate 0.0001
2017-09-28T16:40:59.862307: step 6726, loss 0.924816, acc 0.6875, learning_rate 0.0001
2017-09-28T16:40:59.941867: step 6727, loss 0.699628, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:00.024822: step 6728, loss 0.613915, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:00.108612: step 6729, loss 0.716694, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:00.188234: step 6730, loss 0.589752, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:00.268834: step 6731, loss 0.940767, acc 0.640625, learning_rate 0.0001
2017-09-28T16:41:00.358448: step 6732, loss 0.62493, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:00.438356: step 6733, loss 0.708816, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:00.517894: step 6734, loss 0.583485, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:00.599301: step 6735, loss 0.758204, acc 0.65625, learning_rate 0.0001
2017-09-28T16:41:00.682265: step 6736, loss 0.575226, acc 0.828125, learning_rate 0.0001
2017-09-28T16:41:00.765187: step 6737, loss 0.600187, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:00.849142: step 6738, loss 0.66407, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:00.930071: step 6739, loss 0.575913, acc 0.8125, learning_rate 0.0001
2017-09-28T16:41:01.009045: step 6740, loss 0.688217, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:01.089550: step 6741, loss 0.57112, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:01.170808: step 6742, loss 0.515061, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:01.252014: step 6743, loss 0.844167, acc 0.65625, learning_rate 0.0001
2017-09-28T16:41:01.330358: step 6744, loss 0.711349, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:01.411020: step 6745, loss 0.621634, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:01.492537: step 6746, loss 0.583879, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:01.574780: step 6747, loss 0.657303, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:01.657969: step 6748, loss 0.709676, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:01.737226: step 6749, loss 0.646131, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:01.819800: step 6750, loss 0.771301, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:01.900241: step 6751, loss 0.535161, acc 0.828125, learning_rate 0.0001
2017-09-28T16:41:01.980796: step 6752, loss 0.5561, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:02.061337: step 6753, loss 0.818012, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:02.143421: step 6754, loss 0.80623, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:02.224697: step 6755, loss 0.643207, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:02.305953: step 6756, loss 0.75882, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:02.386769: step 6757, loss 0.702153, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:02.466171: step 6758, loss 0.660452, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:02.547636: step 6759, loss 0.569075, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:02.628491: step 6760, loss 0.518371, acc 0.796875, learning_rate 0.0001

Evaluation:
2017-09-28T16:41:02.898550: step 6760, loss 0.757482, acc 0.696403

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-6760

2017-09-28T16:41:03.530004: step 6761, loss 0.690898, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:03.594099: step 6762, loss 0.64921, acc 0.72549, learning_rate 0.0001
2017-09-28T16:41:03.677778: step 6763, loss 0.654625, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:03.761254: step 6764, loss 0.628641, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:03.841526: step 6765, loss 0.734334, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:03.920433: step 6766, loss 0.745993, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:04.000969: step 6767, loss 0.575209, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:04.083958: step 6768, loss 0.574456, acc 0.890625, learning_rate 0.0001
2017-09-28T16:41:04.165453: step 6769, loss 0.66021, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:04.250858: step 6770, loss 0.653394, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:04.330799: step 6771, loss 0.746357, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:04.416828: step 6772, loss 0.530621, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:04.498862: step 6773, loss 0.687266, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:04.581111: step 6774, loss 0.496542, acc 0.828125, learning_rate 0.0001
2017-09-28T16:41:04.662422: step 6775, loss 0.62598, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:04.742641: step 6776, loss 0.748868, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:04.822210: step 6777, loss 0.650348, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:04.901975: step 6778, loss 0.715507, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:04.982071: step 6779, loss 0.587422, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:05.062090: step 6780, loss 0.664418, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:05.140845: step 6781, loss 0.695777, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:05.221533: step 6782, loss 0.615665, acc 0.625, learning_rate 0.0001
2017-09-28T16:41:05.299800: step 6783, loss 0.697627, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:05.390179: step 6784, loss 0.670379, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:05.473973: step 6785, loss 0.677694, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:05.555563: step 6786, loss 0.580749, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:05.637833: step 6787, loss 0.587089, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:05.723455: step 6788, loss 0.679724, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:05.804639: step 6789, loss 0.684588, acc 0.65625, learning_rate 0.0001
2017-09-28T16:41:05.884151: step 6790, loss 0.728215, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:05.964344: step 6791, loss 0.533374, acc 0.8125, learning_rate 0.0001
2017-09-28T16:41:06.047542: step 6792, loss 0.535682, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:06.125216: step 6793, loss 0.711081, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:06.204226: step 6794, loss 0.71124, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:06.283000: step 6795, loss 0.768221, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:06.366746: step 6796, loss 0.567093, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:06.448703: step 6797, loss 0.660249, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:06.529678: step 6798, loss 0.511166, acc 0.828125, learning_rate 0.0001
2017-09-28T16:41:06.610241: step 6799, loss 0.602103, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:06.690843: step 6800, loss 0.679898, acc 0.703125, learning_rate 0.0001

Evaluation:
2017-09-28T16:41:06.960482: step 6800, loss 0.756404, acc 0.692086

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-6800

2017-09-28T16:41:07.453380: step 6801, loss 0.675883, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:07.534591: step 6802, loss 0.652425, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:07.614459: step 6803, loss 0.86109, acc 0.59375, learning_rate 0.0001
2017-09-28T16:41:07.694862: step 6804, loss 0.701141, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:07.779260: step 6805, loss 0.707352, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:07.861878: step 6806, loss 0.614293, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:07.944540: step 6807, loss 0.625977, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:08.031265: step 6808, loss 0.590633, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:08.112907: step 6809, loss 0.609244, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:08.192579: step 6810, loss 0.508274, acc 0.84375, learning_rate 0.0001
2017-09-28T16:41:08.282263: step 6811, loss 0.646066, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:08.366508: step 6812, loss 0.513655, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:08.451548: step 6813, loss 0.595048, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:08.532286: step 6814, loss 0.668652, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:08.616353: step 6815, loss 0.657489, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:08.704213: step 6816, loss 0.475601, acc 0.84375, learning_rate 0.0001
2017-09-28T16:41:08.788489: step 6817, loss 0.567301, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:08.872110: step 6818, loss 0.554429, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:08.951748: step 6819, loss 0.616554, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:09.039747: step 6820, loss 0.785481, acc 0.640625, learning_rate 0.0001
2017-09-28T16:41:09.123458: step 6821, loss 0.847682, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:09.206154: step 6822, loss 0.554596, acc 0.8125, learning_rate 0.0001
2017-09-28T16:41:09.292288: step 6823, loss 0.857089, acc 0.625, learning_rate 0.0001
2017-09-28T16:41:09.374590: step 6824, loss 0.708281, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:09.461977: step 6825, loss 0.765556, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:09.547028: step 6826, loss 0.70624, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:09.629946: step 6827, loss 0.66398, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:09.712433: step 6828, loss 0.563816, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:09.796720: step 6829, loss 0.69083, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:09.882256: step 6830, loss 0.713731, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:09.965221: step 6831, loss 0.716558, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:10.050182: step 6832, loss 0.719797, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:10.136801: step 6833, loss 0.696419, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:10.223606: step 6834, loss 0.662838, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:10.306579: step 6835, loss 0.696954, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:10.398088: step 6836, loss 0.6549, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:10.488650: step 6837, loss 0.678848, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:10.575432: step 6838, loss 0.641689, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:10.660840: step 6839, loss 0.717406, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:10.746466: step 6840, loss 0.726053, acc 0.75, learning_rate 0.0001

Evaluation:
2017-09-28T16:41:11.021859: step 6840, loss 0.755654, acc 0.697842

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-6840

2017-09-28T16:41:11.579937: step 6841, loss 0.615095, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:11.658961: step 6842, loss 0.673669, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:11.741466: step 6843, loss 0.624119, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:11.821583: step 6844, loss 0.639586, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:11.907869: step 6845, loss 0.633775, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:12.000426: step 6846, loss 0.579239, acc 0.828125, learning_rate 0.0001
2017-09-28T16:41:12.085847: step 6847, loss 0.611611, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:12.168052: step 6848, loss 0.722433, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:12.251591: step 6849, loss 0.745483, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:12.335632: step 6850, loss 0.706382, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:12.417887: step 6851, loss 0.723039, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:12.498647: step 6852, loss 0.677017, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:12.582946: step 6853, loss 0.704233, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:12.666126: step 6854, loss 0.741325, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:12.750701: step 6855, loss 0.662546, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:12.835814: step 6856, loss 0.824597, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:12.922453: step 6857, loss 0.6944, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:13.004868: step 6858, loss 0.696726, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:13.086515: step 6859, loss 0.537053, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:13.153552: step 6860, loss 0.715248, acc 0.764706, learning_rate 0.0001
2017-09-28T16:41:13.236802: step 6861, loss 0.679104, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:13.317767: step 6862, loss 0.657647, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:13.397646: step 6863, loss 0.743101, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:13.480904: step 6864, loss 0.697919, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:13.567800: step 6865, loss 0.653584, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:13.653457: step 6866, loss 0.629163, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:13.735971: step 6867, loss 0.659226, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:13.815084: step 6868, loss 0.674567, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:13.899109: step 6869, loss 0.59924, acc 0.828125, learning_rate 0.0001
2017-09-28T16:41:13.980685: step 6870, loss 0.750255, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:14.063407: step 6871, loss 0.649186, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:14.146668: step 6872, loss 0.749909, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:14.232128: step 6873, loss 0.703546, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:14.314469: step 6874, loss 0.594264, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:14.396655: step 6875, loss 0.734055, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:14.478385: step 6876, loss 0.616199, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:14.563421: step 6877, loss 0.809399, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:14.647039: step 6878, loss 0.728724, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:14.726844: step 6879, loss 0.674024, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:14.806570: step 6880, loss 0.643867, acc 0.703125, learning_rate 0.0001

Evaluation:
2017-09-28T16:41:15.076791: step 6880, loss 0.756673, acc 0.693525

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-6880

2017-09-28T16:41:15.631648: step 6881, loss 0.627904, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:15.712512: step 6882, loss 0.822411, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:15.794708: step 6883, loss 0.722841, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:15.877265: step 6884, loss 0.551419, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:15.956544: step 6885, loss 0.556661, acc 0.84375, learning_rate 0.0001
2017-09-28T16:41:16.038604: step 6886, loss 0.766977, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:16.118864: step 6887, loss 0.657351, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:16.200200: step 6888, loss 0.581544, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:16.282645: step 6889, loss 0.719158, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:16.363116: step 6890, loss 0.87091, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:16.447629: step 6891, loss 0.75995, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:16.526955: step 6892, loss 0.657942, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:16.609900: step 6893, loss 0.61064, acc 0.8125, learning_rate 0.0001
2017-09-28T16:41:16.690191: step 6894, loss 0.570121, acc 0.84375, learning_rate 0.0001
2017-09-28T16:41:16.769053: step 6895, loss 0.837225, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:16.850325: step 6896, loss 0.576532, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:16.930129: step 6897, loss 0.582037, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:17.012779: step 6898, loss 0.519552, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:17.093466: step 6899, loss 0.503896, acc 0.84375, learning_rate 0.0001
2017-09-28T16:41:17.173174: step 6900, loss 0.623579, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:17.256443: step 6901, loss 0.806293, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:17.342348: step 6902, loss 0.785381, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:17.422967: step 6903, loss 0.667413, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:17.505570: step 6904, loss 0.537739, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:17.585141: step 6905, loss 0.630463, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:17.666691: step 6906, loss 0.722177, acc 0.609375, learning_rate 0.0001
2017-09-28T16:41:17.746922: step 6907, loss 0.668532, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:17.830075: step 6908, loss 0.650532, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:17.911142: step 6909, loss 0.522313, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:17.992875: step 6910, loss 0.830797, acc 0.625, learning_rate 0.0001
2017-09-28T16:41:18.076408: step 6911, loss 0.55207, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:18.155088: step 6912, loss 0.746396, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:18.239460: step 6913, loss 0.751587, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:18.322296: step 6914, loss 0.650761, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:18.404224: step 6915, loss 0.558844, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:18.484980: step 6916, loss 0.510453, acc 0.8125, learning_rate 0.0001
2017-09-28T16:41:18.565675: step 6917, loss 0.732798, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:18.650028: step 6918, loss 0.565532, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:18.731460: step 6919, loss 0.52412, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:18.813796: step 6920, loss 0.624496, acc 0.734375, learning_rate 0.0001

Evaluation:
2017-09-28T16:41:19.074816: step 6920, loss 0.754604, acc 0.694964

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-6920

2017-09-28T16:41:19.705119: step 6921, loss 0.516545, acc 0.8125, learning_rate 0.0001
2017-09-28T16:41:19.784997: step 6922, loss 0.581999, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:19.867973: step 6923, loss 0.581713, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:19.948738: step 6924, loss 0.608229, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:20.031613: step 6925, loss 0.746777, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:20.111996: step 6926, loss 0.629625, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:20.194414: step 6927, loss 0.717368, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:20.275100: step 6928, loss 0.686862, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:20.355971: step 6929, loss 0.639367, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:20.446261: step 6930, loss 0.697533, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:20.526661: step 6931, loss 0.565607, acc 0.828125, learning_rate 0.0001
2017-09-28T16:41:20.608785: step 6932, loss 0.634473, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:20.692158: step 6933, loss 0.835937, acc 0.640625, learning_rate 0.0001
2017-09-28T16:41:20.771114: step 6934, loss 0.627898, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:20.857150: step 6935, loss 0.632011, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:20.936161: step 6936, loss 0.551803, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:21.019185: step 6937, loss 0.644595, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:21.102865: step 6938, loss 0.719754, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:21.183522: step 6939, loss 0.726227, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:21.266959: step 6940, loss 0.710431, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:21.348583: step 6941, loss 0.474513, acc 0.84375, learning_rate 0.0001
2017-09-28T16:41:21.431332: step 6942, loss 0.666912, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:21.513014: step 6943, loss 0.637915, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:21.598767: step 6944, loss 0.576304, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:21.677259: step 6945, loss 0.617363, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:21.761294: step 6946, loss 0.60647, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:21.842797: step 6947, loss 0.759706, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:21.926025: step 6948, loss 0.911552, acc 0.65625, learning_rate 0.0001
2017-09-28T16:41:22.008047: step 6949, loss 0.666983, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:22.086132: step 6950, loss 0.713158, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:22.167969: step 6951, loss 0.610327, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:22.249544: step 6952, loss 0.666315, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:22.329283: step 6953, loss 0.649033, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:22.411756: step 6954, loss 0.657417, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:22.493732: step 6955, loss 0.55696, acc 0.8125, learning_rate 0.0001
2017-09-28T16:41:22.573537: step 6956, loss 0.699303, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:22.657131: step 6957, loss 0.490862, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:22.722688: step 6958, loss 0.823769, acc 0.588235, learning_rate 0.0001
2017-09-28T16:41:22.803408: step 6959, loss 0.530304, acc 0.84375, learning_rate 0.0001
2017-09-28T16:41:22.886767: step 6960, loss 0.574823, acc 0.765625, learning_rate 0.0001

Evaluation:
2017-09-28T16:41:23.155884: step 6960, loss 0.753666, acc 0.690647

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-6960

2017-09-28T16:41:23.655536: step 6961, loss 0.688145, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:23.736032: step 6962, loss 0.613265, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:23.817614: step 6963, loss 0.555064, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:23.900429: step 6964, loss 0.716089, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:23.980844: step 6965, loss 0.758872, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:24.062101: step 6966, loss 0.572839, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:24.143649: step 6967, loss 0.640055, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:24.225859: step 6968, loss 0.68444, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:24.307834: step 6969, loss 0.651703, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:24.386957: step 6970, loss 0.758711, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:24.469947: step 6971, loss 0.581906, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:24.555263: step 6972, loss 0.654738, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:24.639820: step 6973, loss 0.730143, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:24.722101: step 6974, loss 0.708027, acc 0.65625, learning_rate 0.0001
2017-09-28T16:41:24.804047: step 6975, loss 0.699887, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:24.885485: step 6976, loss 0.685104, acc 0.65625, learning_rate 0.0001
2017-09-28T16:41:24.969514: step 6977, loss 0.770773, acc 0.640625, learning_rate 0.0001
2017-09-28T16:41:25.049306: step 6978, loss 0.648649, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:25.129639: step 6979, loss 0.593096, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:25.211504: step 6980, loss 0.666804, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:25.294774: step 6981, loss 0.431159, acc 0.859375, learning_rate 0.0001
2017-09-28T16:41:25.381535: step 6982, loss 0.5668, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:25.470779: step 6983, loss 0.682763, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:25.551908: step 6984, loss 0.641129, acc 0.828125, learning_rate 0.0001
2017-09-28T16:41:25.632016: step 6985, loss 0.681499, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:25.714718: step 6986, loss 0.736199, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:25.796306: step 6987, loss 0.64495, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:25.883657: step 6988, loss 0.5971, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:25.964554: step 6989, loss 0.638417, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:26.045270: step 6990, loss 0.713429, acc 0.65625, learning_rate 0.0001
2017-09-28T16:41:26.129099: step 6991, loss 0.635347, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:26.211952: step 6992, loss 0.76985, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:26.302598: step 6993, loss 0.76534, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:26.392065: step 6994, loss 0.718632, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:26.476598: step 6995, loss 0.614552, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:26.556871: step 6996, loss 0.541261, acc 0.84375, learning_rate 0.0001
2017-09-28T16:41:26.637176: step 6997, loss 0.841977, acc 0.625, learning_rate 0.0001
2017-09-28T16:41:26.717726: step 6998, loss 0.62852, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:26.800329: step 6999, loss 0.677779, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:26.881276: step 7000, loss 0.503288, acc 0.78125, learning_rate 0.0001

Evaluation:
2017-09-28T16:41:27.148436: step 7000, loss 0.753745, acc 0.699281

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-7000

2017-09-28T16:41:27.710483: step 7001, loss 0.816332, acc 0.65625, learning_rate 0.0001
2017-09-28T16:41:27.788515: step 7002, loss 0.645821, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:27.867533: step 7003, loss 0.570566, acc 0.8125, learning_rate 0.0001
2017-09-28T16:41:27.951980: step 7004, loss 0.942926, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:28.032707: step 7005, loss 0.73815, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:28.115216: step 7006, loss 0.634896, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:28.196496: step 7007, loss 0.660494, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:28.281518: step 7008, loss 0.702098, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:28.365066: step 7009, loss 0.567703, acc 0.84375, learning_rate 0.0001
2017-09-28T16:41:28.445784: step 7010, loss 0.620505, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:28.529419: step 7011, loss 0.763882, acc 0.640625, learning_rate 0.0001
2017-09-28T16:41:28.611360: step 7012, loss 0.565931, acc 0.828125, learning_rate 0.0001
2017-09-28T16:41:28.692260: step 7013, loss 0.579101, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:28.774593: step 7014, loss 0.589453, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:28.859032: step 7015, loss 0.542225, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:28.937865: step 7016, loss 0.76871, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:29.020398: step 7017, loss 0.679749, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:29.101956: step 7018, loss 0.696888, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:29.180903: step 7019, loss 0.708589, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:29.263948: step 7020, loss 0.586696, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:29.342420: step 7021, loss 0.714036, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:29.420608: step 7022, loss 0.710186, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:29.503700: step 7023, loss 0.642768, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:29.584520: step 7024, loss 0.612167, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:29.664247: step 7025, loss 0.682703, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:29.746835: step 7026, loss 0.708534, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:29.827864: step 7027, loss 0.749328, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:29.912121: step 7028, loss 0.725624, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:29.994672: step 7029, loss 0.675175, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:30.079073: step 7030, loss 0.778825, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:30.160519: step 7031, loss 0.759627, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:30.246736: step 7032, loss 0.677873, acc 0.640625, learning_rate 0.0001
2017-09-28T16:41:30.328283: step 7033, loss 0.571516, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:30.411125: step 7034, loss 0.802791, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:30.497617: step 7035, loss 0.653588, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:30.577541: step 7036, loss 0.493339, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:30.659137: step 7037, loss 0.540476, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:30.741770: step 7038, loss 0.849859, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:30.823900: step 7039, loss 0.605624, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:30.903652: step 7040, loss 0.606657, acc 0.78125, learning_rate 0.0001

Evaluation:
2017-09-28T16:41:31.168425: step 7040, loss 0.753598, acc 0.690647

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-7040

2017-09-28T16:41:31.723524: step 7041, loss 0.698972, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:31.805444: step 7042, loss 0.715209, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:31.885269: step 7043, loss 0.697931, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:31.966338: step 7044, loss 0.619449, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:32.047413: step 7045, loss 0.4144, acc 0.875, learning_rate 0.0001
2017-09-28T16:41:32.129214: step 7046, loss 0.687329, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:32.208558: step 7047, loss 0.480844, acc 0.8125, learning_rate 0.0001
2017-09-28T16:41:32.288690: step 7048, loss 0.87082, acc 0.640625, learning_rate 0.0001
2017-09-28T16:41:32.368062: step 7049, loss 0.716983, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:32.451500: step 7050, loss 0.52982, acc 0.828125, learning_rate 0.0001
2017-09-28T16:41:32.532052: step 7051, loss 0.693755, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:32.613573: step 7052, loss 0.621357, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:32.694551: step 7053, loss 0.633467, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:32.774209: step 7054, loss 0.749581, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:32.855693: step 7055, loss 0.54782, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:32.920256: step 7056, loss 0.735711, acc 0.803922, learning_rate 0.0001
2017-09-28T16:41:33.002865: step 7057, loss 0.615376, acc 0.828125, learning_rate 0.0001
2017-09-28T16:41:33.082976: step 7058, loss 0.843818, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:33.164285: step 7059, loss 0.665914, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:33.246519: step 7060, loss 0.848505, acc 0.65625, learning_rate 0.0001
2017-09-28T16:41:33.328753: step 7061, loss 0.52575, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:33.411301: step 7062, loss 0.692929, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:33.491057: step 7063, loss 0.591936, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:33.573385: step 7064, loss 0.657052, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:33.654493: step 7065, loss 0.689083, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:33.735664: step 7066, loss 0.666294, acc 0.65625, learning_rate 0.0001
2017-09-28T16:41:33.818171: step 7067, loss 0.647622, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:33.900813: step 7068, loss 0.701713, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:33.979688: step 7069, loss 0.592326, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:34.061547: step 7070, loss 0.596967, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:34.146881: step 7071, loss 0.454125, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:34.226758: step 7072, loss 0.69472, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:34.305445: step 7073, loss 0.733545, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:34.383757: step 7074, loss 0.652383, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:34.465930: step 7075, loss 0.68196, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:34.548307: step 7076, loss 0.673126, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:34.630980: step 7077, loss 0.679642, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:34.715436: step 7078, loss 0.722614, acc 0.65625, learning_rate 0.0001
2017-09-28T16:41:34.797395: step 7079, loss 0.587104, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:34.880310: step 7080, loss 0.49935, acc 0.828125, learning_rate 0.0001

Evaluation:
2017-09-28T16:41:35.151011: step 7080, loss 0.752308, acc 0.692086

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-7080

2017-09-28T16:41:35.781381: step 7081, loss 0.587796, acc 0.8125, learning_rate 0.0001
2017-09-28T16:41:35.861359: step 7082, loss 0.627394, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:35.946595: step 7083, loss 0.645585, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:36.025785: step 7084, loss 0.702469, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:36.109828: step 7085, loss 0.790167, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:36.189997: step 7086, loss 0.639164, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:36.272103: step 7087, loss 0.705111, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:36.353265: step 7088, loss 0.694823, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:36.436231: step 7089, loss 0.72696, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:36.521272: step 7090, loss 0.856335, acc 0.5625, learning_rate 0.0001
2017-09-28T16:41:36.603717: step 7091, loss 0.60441, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:36.684015: step 7092, loss 0.571901, acc 0.8125, learning_rate 0.0001
2017-09-28T16:41:36.765925: step 7093, loss 0.918313, acc 0.640625, learning_rate 0.0001
2017-09-28T16:41:36.846912: step 7094, loss 0.695013, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:36.928920: step 7095, loss 0.655682, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:37.010495: step 7096, loss 0.746198, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:37.091353: step 7097, loss 0.481347, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:37.171409: step 7098, loss 0.612963, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:37.255057: step 7099, loss 0.642728, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:37.338938: step 7100, loss 0.636562, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:37.419213: step 7101, loss 0.733869, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:37.499365: step 7102, loss 0.555137, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:37.579586: step 7103, loss 0.535352, acc 0.828125, learning_rate 0.0001
2017-09-28T16:41:37.661175: step 7104, loss 0.679324, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:37.743959: step 7105, loss 0.57181, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:37.824603: step 7106, loss 0.647582, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:37.905895: step 7107, loss 0.801085, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:37.986170: step 7108, loss 0.635474, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:38.068056: step 7109, loss 0.648153, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:38.151604: step 7110, loss 0.528514, acc 0.8125, learning_rate 0.0001
2017-09-28T16:41:38.230930: step 7111, loss 0.520442, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:38.312938: step 7112, loss 0.871566, acc 0.609375, learning_rate 0.0001
2017-09-28T16:41:38.394939: step 7113, loss 0.540355, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:38.474969: step 7114, loss 0.578314, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:38.556440: step 7115, loss 0.628325, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:38.638999: step 7116, loss 0.656768, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:38.721439: step 7117, loss 0.780446, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:38.802492: step 7118, loss 0.548147, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:38.883695: step 7119, loss 0.839403, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:38.964953: step 7120, loss 0.562529, acc 0.78125, learning_rate 0.0001

Evaluation:
2017-09-28T16:41:39.231441: step 7120, loss 0.751748, acc 0.697842

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-7120

2017-09-28T16:41:39.723289: step 7121, loss 0.503298, acc 0.84375, learning_rate 0.0001
2017-09-28T16:41:39.803458: step 7122, loss 0.683555, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:39.884782: step 7123, loss 0.550575, acc 0.8125, learning_rate 0.0001
2017-09-28T16:41:39.967054: step 7124, loss 0.626182, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:40.046363: step 7125, loss 0.717502, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:40.125932: step 7126, loss 0.615775, acc 0.828125, learning_rate 0.0001
2017-09-28T16:41:40.209047: step 7127, loss 0.679113, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:40.289619: step 7128, loss 0.575089, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:40.369499: step 7129, loss 0.712124, acc 0.65625, learning_rate 0.0001
2017-09-28T16:41:40.451893: step 7130, loss 0.558801, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:40.542712: step 7131, loss 0.752741, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:40.624682: step 7132, loss 0.768574, acc 0.65625, learning_rate 0.0001
2017-09-28T16:41:40.704703: step 7133, loss 0.764701, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:40.786133: step 7134, loss 0.668911, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:40.868686: step 7135, loss 0.749456, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:40.953069: step 7136, loss 0.632716, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:41.036184: step 7137, loss 0.664678, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:41.114539: step 7138, loss 0.605187, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:41.193942: step 7139, loss 0.705504, acc 0.65625, learning_rate 0.0001
2017-09-28T16:41:41.275557: step 7140, loss 0.569949, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:41.357196: step 7141, loss 0.628462, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:41.439702: step 7142, loss 0.702471, acc 0.578125, learning_rate 0.0001
2017-09-28T16:41:41.520890: step 7143, loss 0.575836, acc 0.828125, learning_rate 0.0001
2017-09-28T16:41:41.604658: step 7144, loss 0.602853, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:41.685609: step 7145, loss 0.607997, acc 0.8125, learning_rate 0.0001
2017-09-28T16:41:41.768279: step 7146, loss 0.716236, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:41.848930: step 7147, loss 0.557933, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:41.930194: step 7148, loss 0.832313, acc 0.578125, learning_rate 0.0001
2017-09-28T16:41:42.009905: step 7149, loss 0.716002, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:42.088203: step 7150, loss 0.66955, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:42.171535: step 7151, loss 0.59168, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:42.255350: step 7152, loss 0.677884, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:42.334627: step 7153, loss 0.596549, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:42.399408: step 7154, loss 0.590601, acc 0.745098, learning_rate 0.0001
2017-09-28T16:41:42.480455: step 7155, loss 0.656016, acc 0.8125, learning_rate 0.0001
2017-09-28T16:41:42.562402: step 7156, loss 0.680042, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:42.641718: step 7157, loss 0.541148, acc 0.875, learning_rate 0.0001
2017-09-28T16:41:42.724219: step 7158, loss 0.612035, acc 0.8125, learning_rate 0.0001
2017-09-28T16:41:42.804600: step 7159, loss 0.644575, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:42.885783: step 7160, loss 0.589012, acc 0.8125, learning_rate 0.0001

Evaluation:
2017-09-28T16:41:43.149093: step 7160, loss 0.75015, acc 0.696403

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-7160

2017-09-28T16:41:43.709342: step 7161, loss 0.623188, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:43.790113: step 7162, loss 0.763569, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:43.868571: step 7163, loss 0.570635, acc 0.828125, learning_rate 0.0001
2017-09-28T16:41:43.949846: step 7164, loss 0.622201, acc 0.8125, learning_rate 0.0001
2017-09-28T16:41:44.033794: step 7165, loss 0.572926, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:44.113741: step 7166, loss 0.451802, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:44.195980: step 7167, loss 0.592021, acc 0.828125, learning_rate 0.0001
2017-09-28T16:41:44.278414: step 7168, loss 0.53801, acc 0.84375, learning_rate 0.0001
2017-09-28T16:41:44.363583: step 7169, loss 0.70843, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:44.445568: step 7170, loss 0.636847, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:44.531293: step 7171, loss 0.581797, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:44.613054: step 7172, loss 0.71218, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:44.694545: step 7173, loss 0.686261, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:44.776193: step 7174, loss 0.626518, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:44.859328: step 7175, loss 0.678563, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:44.940532: step 7176, loss 0.590475, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:45.022216: step 7177, loss 0.626726, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:45.102253: step 7178, loss 0.667812, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:45.182253: step 7179, loss 0.70758, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:45.266681: step 7180, loss 0.709355, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:45.346819: step 7181, loss 0.58552, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:45.427820: step 7182, loss 0.79393, acc 0.59375, learning_rate 0.0001
2017-09-28T16:41:45.507083: step 7183, loss 0.516589, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:45.595096: step 7184, loss 0.681622, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:45.678861: step 7185, loss 0.673901, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:45.758369: step 7186, loss 0.646034, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:45.843166: step 7187, loss 0.817215, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:45.925255: step 7188, loss 0.707578, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:46.008728: step 7189, loss 0.619949, acc 0.828125, learning_rate 0.0001
2017-09-28T16:41:46.090054: step 7190, loss 0.441417, acc 0.875, learning_rate 0.0001
2017-09-28T16:41:46.172849: step 7191, loss 0.580711, acc 0.8125, learning_rate 0.0001
2017-09-28T16:41:46.254316: step 7192, loss 0.629754, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:46.336032: step 7193, loss 0.690333, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:46.416944: step 7194, loss 0.549103, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:46.500737: step 7195, loss 0.680215, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:46.584474: step 7196, loss 0.526269, acc 0.8125, learning_rate 0.0001
2017-09-28T16:41:46.665563: step 7197, loss 0.512895, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:46.743464: step 7198, loss 0.672861, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:46.825430: step 7199, loss 0.728761, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:46.906050: step 7200, loss 0.561614, acc 0.78125, learning_rate 0.0001

Evaluation:
2017-09-28T16:41:47.175217: step 7200, loss 0.747811, acc 0.700719

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-7200

2017-09-28T16:41:47.730841: step 7201, loss 0.677711, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:47.810016: step 7202, loss 0.496886, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:47.890024: step 7203, loss 0.752611, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:47.973223: step 7204, loss 0.576135, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:48.056343: step 7205, loss 0.656782, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:48.139601: step 7206, loss 0.524344, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:48.220611: step 7207, loss 0.665202, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:48.305558: step 7208, loss 0.723369, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:48.387272: step 7209, loss 0.548956, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:48.469382: step 7210, loss 0.781529, acc 0.640625, learning_rate 0.0001
2017-09-28T16:41:48.555351: step 7211, loss 0.713319, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:48.634227: step 7212, loss 0.646746, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:48.715677: step 7213, loss 0.609134, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:48.798218: step 7214, loss 0.918889, acc 0.65625, learning_rate 0.0001
2017-09-28T16:41:48.877040: step 7215, loss 0.623242, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:48.956833: step 7216, loss 0.63351, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:49.044241: step 7217, loss 0.608195, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:49.124998: step 7218, loss 0.627111, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:49.206734: step 7219, loss 0.494285, acc 0.84375, learning_rate 0.0001
2017-09-28T16:41:49.288453: step 7220, loss 0.939167, acc 0.625, learning_rate 0.0001
2017-09-28T16:41:49.368631: step 7221, loss 0.635765, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:49.450121: step 7222, loss 0.843554, acc 0.65625, learning_rate 0.0001
2017-09-28T16:41:49.531424: step 7223, loss 0.673161, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:49.614623: step 7224, loss 0.711724, acc 0.65625, learning_rate 0.0001
2017-09-28T16:41:49.698751: step 7225, loss 0.71804, acc 0.625, learning_rate 0.0001
2017-09-28T16:41:49.779223: step 7226, loss 0.742236, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:49.860290: step 7227, loss 0.757019, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:49.940091: step 7228, loss 0.562083, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:50.021624: step 7229, loss 0.734417, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:50.104497: step 7230, loss 0.524754, acc 0.8125, learning_rate 0.0001
2017-09-28T16:41:50.184158: step 7231, loss 0.649277, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:50.266574: step 7232, loss 0.619523, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:50.347759: step 7233, loss 0.692314, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:50.429384: step 7234, loss 0.63432, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:50.512403: step 7235, loss 0.883024, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:50.597606: step 7236, loss 0.676252, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:50.683248: step 7237, loss 0.546634, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:50.765920: step 7238, loss 0.639298, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:50.845120: step 7239, loss 0.632978, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:50.927551: step 7240, loss 0.790742, acc 0.6875, learning_rate 0.0001

Evaluation:
2017-09-28T16:41:51.198909: step 7240, loss 0.751029, acc 0.694964

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-7240

2017-09-28T16:41:51.825978: step 7241, loss 0.467599, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:51.907150: step 7242, loss 0.718434, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:51.990757: step 7243, loss 0.619253, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:52.071809: step 7244, loss 0.572488, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:52.151110: step 7245, loss 0.640539, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:52.234837: step 7246, loss 0.622218, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:52.314565: step 7247, loss 0.741018, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:52.397057: step 7248, loss 0.70051, acc 0.8125, learning_rate 0.0001
2017-09-28T16:41:52.478247: step 7249, loss 0.59266, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:52.558373: step 7250, loss 0.618312, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:52.638302: step 7251, loss 0.644382, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:52.703456: step 7252, loss 0.585436, acc 0.705882, learning_rate 0.0001
2017-09-28T16:41:52.786934: step 7253, loss 0.64816, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:52.865889: step 7254, loss 0.544248, acc 0.828125, learning_rate 0.0001
2017-09-28T16:41:52.949342: step 7255, loss 0.78376, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:53.029268: step 7256, loss 0.668702, acc 0.65625, learning_rate 0.0001
2017-09-28T16:41:53.110042: step 7257, loss 0.837171, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:53.194909: step 7258, loss 0.722272, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:53.276741: step 7259, loss 0.726442, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:53.358216: step 7260, loss 0.73948, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:53.440603: step 7261, loss 0.591608, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:53.523007: step 7262, loss 0.680042, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:53.604484: step 7263, loss 0.637161, acc 0.8125, learning_rate 0.0001
2017-09-28T16:41:53.686104: step 7264, loss 0.644179, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:53.766657: step 7265, loss 0.720625, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:53.847044: step 7266, loss 0.698732, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:53.929486: step 7267, loss 0.765587, acc 0.65625, learning_rate 0.0001
2017-09-28T16:41:54.010200: step 7268, loss 0.546997, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:54.091281: step 7269, loss 0.544116, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:54.172349: step 7270, loss 0.488586, acc 0.8125, learning_rate 0.0001
2017-09-28T16:41:54.250186: step 7271, loss 0.565239, acc 0.8125, learning_rate 0.0001
2017-09-28T16:41:54.331651: step 7272, loss 0.541593, acc 0.828125, learning_rate 0.0001
2017-09-28T16:41:54.414555: step 7273, loss 0.704708, acc 0.640625, learning_rate 0.0001
2017-09-28T16:41:54.495767: step 7274, loss 0.693213, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:54.579019: step 7275, loss 0.566857, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:54.659347: step 7276, loss 0.635505, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:54.739338: step 7277, loss 0.683841, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:54.824540: step 7278, loss 0.701036, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:54.909363: step 7279, loss 0.645902, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:54.991081: step 7280, loss 0.682482, acc 0.703125, learning_rate 0.0001

Evaluation:
2017-09-28T16:41:55.261472: step 7280, loss 0.747546, acc 0.697842

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-7280

2017-09-28T16:41:55.758547: step 7281, loss 0.779009, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:55.840687: step 7282, loss 0.693177, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:55.924264: step 7283, loss 0.650187, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:56.005882: step 7284, loss 0.820463, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:56.085490: step 7285, loss 0.570555, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:56.166252: step 7286, loss 0.835472, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:56.246772: step 7287, loss 0.707838, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:56.328679: step 7288, loss 0.656017, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:56.412765: step 7289, loss 0.702871, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:56.493926: step 7290, loss 0.578954, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:56.573206: step 7291, loss 0.703758, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:56.653309: step 7292, loss 0.566083, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:56.735261: step 7293, loss 0.760373, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:56.816413: step 7294, loss 0.610071, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:56.898598: step 7295, loss 0.69437, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:56.982273: step 7296, loss 0.722448, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:57.071160: step 7297, loss 0.655706, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:57.154696: step 7298, loss 0.547009, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:57.238748: step 7299, loss 0.585064, acc 0.75, learning_rate 0.0001
2017-09-28T16:41:57.320649: step 7300, loss 0.516056, acc 0.890625, learning_rate 0.0001
2017-09-28T16:41:57.402145: step 7301, loss 0.639156, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:57.480826: step 7302, loss 0.628376, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:57.564196: step 7303, loss 0.69194, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:57.643013: step 7304, loss 0.621921, acc 0.734375, learning_rate 0.0001
2017-09-28T16:41:57.723413: step 7305, loss 0.725076, acc 0.671875, learning_rate 0.0001
2017-09-28T16:41:57.804692: step 7306, loss 0.7643, acc 0.6875, learning_rate 0.0001
2017-09-28T16:41:57.885859: step 7307, loss 0.46324, acc 0.859375, learning_rate 0.0001
2017-09-28T16:41:57.967368: step 7308, loss 0.743095, acc 0.65625, learning_rate 0.0001
2017-09-28T16:41:58.049423: step 7309, loss 0.606192, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:58.130071: step 7310, loss 0.591897, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:58.211234: step 7311, loss 0.545593, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:58.289256: step 7312, loss 0.593497, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:58.370579: step 7313, loss 0.553786, acc 0.796875, learning_rate 0.0001
2017-09-28T16:41:58.452260: step 7314, loss 0.545642, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:58.536343: step 7315, loss 0.532638, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:58.619366: step 7316, loss 0.769917, acc 0.703125, learning_rate 0.0001
2017-09-28T16:41:58.698380: step 7317, loss 0.587895, acc 0.71875, learning_rate 0.0001
2017-09-28T16:41:58.779980: step 7318, loss 0.579632, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:58.859347: step 7319, loss 0.590487, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:58.939536: step 7320, loss 0.949482, acc 0.625, learning_rate 0.0001

Evaluation:
2017-09-28T16:41:59.199339: step 7320, loss 0.751303, acc 0.696403

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-7320

2017-09-28T16:41:59.756530: step 7321, loss 0.597387, acc 0.765625, learning_rate 0.0001
2017-09-28T16:41:59.837156: step 7322, loss 0.658992, acc 0.78125, learning_rate 0.0001
2017-09-28T16:41:59.915890: step 7323, loss 0.589898, acc 0.84375, learning_rate 0.0001
2017-09-28T16:41:59.998136: step 7324, loss 0.789599, acc 0.671875, learning_rate 0.0001
2017-09-28T16:42:00.077164: step 7325, loss 0.697087, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:00.156982: step 7326, loss 0.765944, acc 0.671875, learning_rate 0.0001
2017-09-28T16:42:00.236117: step 7327, loss 0.560809, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:00.320437: step 7328, loss 0.694211, acc 0.671875, learning_rate 0.0001
2017-09-28T16:42:00.401518: step 7329, loss 0.480203, acc 0.828125, learning_rate 0.0001
2017-09-28T16:42:00.483876: step 7330, loss 0.619938, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:00.564614: step 7331, loss 0.722079, acc 0.6875, learning_rate 0.0001
2017-09-28T16:42:00.650275: step 7332, loss 0.683917, acc 0.6875, learning_rate 0.0001
2017-09-28T16:42:00.732103: step 7333, loss 0.691001, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:00.817788: step 7334, loss 0.606902, acc 0.6875, learning_rate 0.0001
2017-09-28T16:42:00.902557: step 7335, loss 0.598387, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:00.983161: step 7336, loss 0.623104, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:01.063472: step 7337, loss 0.588512, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:01.146719: step 7338, loss 0.659886, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:01.230165: step 7339, loss 0.648841, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:01.312672: step 7340, loss 0.55415, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:01.394785: step 7341, loss 0.650004, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:01.473613: step 7342, loss 0.785159, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:01.553565: step 7343, loss 0.55299, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:01.635248: step 7344, loss 0.683605, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:01.713779: step 7345, loss 0.612533, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:01.795500: step 7346, loss 0.628343, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:01.876316: step 7347, loss 0.543098, acc 0.8125, learning_rate 0.0001
2017-09-28T16:42:01.958520: step 7348, loss 0.656352, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:02.037923: step 7349, loss 0.623538, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:02.102420: step 7350, loss 0.525496, acc 0.823529, learning_rate 0.0001
2017-09-28T16:42:02.185740: step 7351, loss 0.860749, acc 0.671875, learning_rate 0.0001
2017-09-28T16:42:02.267013: step 7352, loss 0.751636, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:02.347954: step 7353, loss 0.643331, acc 0.671875, learning_rate 0.0001
2017-09-28T16:42:02.430451: step 7354, loss 0.63986, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:02.513401: step 7355, loss 0.750604, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:02.591397: step 7356, loss 0.570382, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:02.674325: step 7357, loss 0.719077, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:02.755885: step 7358, loss 0.52842, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:02.836244: step 7359, loss 0.584792, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:02.916704: step 7360, loss 0.63468, acc 0.78125, learning_rate 0.0001

Evaluation:
2017-09-28T16:42:03.187666: step 7360, loss 0.749963, acc 0.694964

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-7360

2017-09-28T16:42:03.746822: step 7361, loss 0.560467, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:03.827559: step 7362, loss 0.565677, acc 0.8125, learning_rate 0.0001
2017-09-28T16:42:03.909297: step 7363, loss 0.640916, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:03.989532: step 7364, loss 0.598848, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:04.074743: step 7365, loss 0.594805, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:04.157946: step 7366, loss 0.74999, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:04.242536: step 7367, loss 0.657498, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:04.324918: step 7368, loss 0.784196, acc 0.65625, learning_rate 0.0001
2017-09-28T16:42:04.408196: step 7369, loss 0.587445, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:04.488751: step 7370, loss 0.484826, acc 0.890625, learning_rate 0.0001
2017-09-28T16:42:04.571071: step 7371, loss 0.68642, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:04.650772: step 7372, loss 0.772136, acc 0.65625, learning_rate 0.0001
2017-09-28T16:42:04.735179: step 7373, loss 0.714787, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:04.817817: step 7374, loss 0.534696, acc 0.8125, learning_rate 0.0001
2017-09-28T16:42:04.899000: step 7375, loss 0.500668, acc 0.8125, learning_rate 0.0001
2017-09-28T16:42:04.979395: step 7376, loss 0.811447, acc 0.65625, learning_rate 0.0001
2017-09-28T16:42:05.063305: step 7377, loss 0.643615, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:05.143748: step 7378, loss 0.488075, acc 0.828125, learning_rate 0.0001
2017-09-28T16:42:05.225361: step 7379, loss 0.622046, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:05.307513: step 7380, loss 0.696861, acc 0.671875, learning_rate 0.0001
2017-09-28T16:42:05.388151: step 7381, loss 0.652709, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:05.469354: step 7382, loss 0.800843, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:05.549906: step 7383, loss 0.867389, acc 0.625, learning_rate 0.0001
2017-09-28T16:42:05.631034: step 7384, loss 0.763175, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:05.719655: step 7385, loss 0.564189, acc 0.828125, learning_rate 0.0001
2017-09-28T16:42:05.803452: step 7386, loss 0.782366, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:05.887834: step 7387, loss 0.636327, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:05.967641: step 7388, loss 0.80742, acc 0.6875, learning_rate 0.0001
2017-09-28T16:42:06.046770: step 7389, loss 0.594815, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:06.128026: step 7390, loss 0.698718, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:06.211456: step 7391, loss 0.640073, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:06.290030: step 7392, loss 0.531119, acc 0.859375, learning_rate 0.0001
2017-09-28T16:42:06.371538: step 7393, loss 0.579546, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:06.453719: step 7394, loss 0.631988, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:06.535764: step 7395, loss 0.59395, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:06.615865: step 7396, loss 0.68793, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:06.695641: step 7397, loss 0.622505, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:06.777280: step 7398, loss 0.758425, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:06.858927: step 7399, loss 0.648198, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:06.938920: step 7400, loss 0.558066, acc 0.78125, learning_rate 0.0001

Evaluation:
2017-09-28T16:42:07.205432: step 7400, loss 0.747188, acc 0.696403

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-7400

2017-09-28T16:42:07.836257: step 7401, loss 0.655634, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:07.916139: step 7402, loss 0.819111, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:07.998126: step 7403, loss 0.682385, acc 0.671875, learning_rate 0.0001
2017-09-28T16:42:08.077318: step 7404, loss 0.56785, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:08.158332: step 7405, loss 0.575704, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:08.237826: step 7406, loss 0.556205, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:08.321971: step 7407, loss 0.508235, acc 0.859375, learning_rate 0.0001
2017-09-28T16:42:08.404941: step 7408, loss 0.589482, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:08.488063: step 7409, loss 0.693269, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:08.567526: step 7410, loss 0.66622, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:08.649165: step 7411, loss 0.683126, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:08.731016: step 7412, loss 0.581803, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:08.812838: step 7413, loss 0.483591, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:08.896329: step 7414, loss 0.698745, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:08.977622: step 7415, loss 0.56894, acc 0.828125, learning_rate 0.0001
2017-09-28T16:42:09.058141: step 7416, loss 0.697681, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:09.139521: step 7417, loss 0.652859, acc 0.6875, learning_rate 0.0001
2017-09-28T16:42:09.219154: step 7418, loss 0.604684, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:09.301012: step 7419, loss 0.703179, acc 0.671875, learning_rate 0.0001
2017-09-28T16:42:09.380228: step 7420, loss 0.814055, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:09.463415: step 7421, loss 0.618591, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:09.545621: step 7422, loss 0.506799, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:09.629164: step 7423, loss 0.610921, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:09.709378: step 7424, loss 0.639392, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:09.791103: step 7425, loss 0.485574, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:09.872034: step 7426, loss 0.725896, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:09.956825: step 7427, loss 0.624112, acc 0.6875, learning_rate 0.0001
2017-09-28T16:42:10.035836: step 7428, loss 0.691309, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:10.114849: step 7429, loss 0.509154, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:10.195935: step 7430, loss 0.652538, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:10.277836: step 7431, loss 0.80326, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:10.358802: step 7432, loss 0.751701, acc 0.671875, learning_rate 0.0001
2017-09-28T16:42:10.439844: step 7433, loss 0.59944, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:10.522081: step 7434, loss 0.625239, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:10.603379: step 7435, loss 0.834632, acc 0.671875, learning_rate 0.0001
2017-09-28T16:42:10.684248: step 7436, loss 0.691428, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:10.771996: step 7437, loss 0.501503, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:10.853104: step 7438, loss 0.75303, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:10.933527: step 7439, loss 0.516748, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:11.016284: step 7440, loss 0.533472, acc 0.796875, learning_rate 0.0001

Evaluation:
2017-09-28T16:42:11.283290: step 7440, loss 0.747646, acc 0.699281

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-7440

2017-09-28T16:42:11.776368: step 7441, loss 0.69561, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:11.857999: step 7442, loss 0.613672, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:11.935974: step 7443, loss 0.719733, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:12.015823: step 7444, loss 0.526942, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:12.097694: step 7445, loss 0.685796, acc 0.671875, learning_rate 0.0001
2017-09-28T16:42:12.180431: step 7446, loss 0.697951, acc 0.6875, learning_rate 0.0001
2017-09-28T16:42:12.259110: step 7447, loss 0.629716, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:12.323928: step 7448, loss 0.693606, acc 0.705882, learning_rate 0.0001
2017-09-28T16:42:12.404498: step 7449, loss 0.729009, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:12.485631: step 7450, loss 0.785676, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:12.566307: step 7451, loss 0.479286, acc 0.828125, learning_rate 0.0001
2017-09-28T16:42:12.648910: step 7452, loss 0.903561, acc 0.6875, learning_rate 0.0001
2017-09-28T16:42:12.730024: step 7453, loss 0.768739, acc 0.65625, learning_rate 0.0001
2017-09-28T16:42:12.813537: step 7454, loss 0.733872, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:12.894982: step 7455, loss 0.632099, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:12.975618: step 7456, loss 0.512605, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:13.059667: step 7457, loss 0.710922, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:13.142182: step 7458, loss 0.656339, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:13.223290: step 7459, loss 0.77165, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:13.305298: step 7460, loss 0.610271, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:13.387698: step 7461, loss 0.546223, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:13.468204: step 7462, loss 0.656844, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:13.550886: step 7463, loss 0.514078, acc 0.8125, learning_rate 0.0001
2017-09-28T16:42:13.630650: step 7464, loss 0.520965, acc 0.8125, learning_rate 0.0001
2017-09-28T16:42:13.711255: step 7465, loss 0.626202, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:13.792200: step 7466, loss 0.560144, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:13.877431: step 7467, loss 0.624273, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:13.957830: step 7468, loss 0.594784, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:14.038133: step 7469, loss 0.666397, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:14.120556: step 7470, loss 0.572487, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:14.201519: step 7471, loss 0.617987, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:14.284495: step 7472, loss 0.6666, acc 0.6875, learning_rate 0.0001
2017-09-28T16:42:14.366010: step 7473, loss 0.732332, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:14.449091: step 7474, loss 0.597412, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:14.530153: step 7475, loss 0.551933, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:14.611089: step 7476, loss 0.688322, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:14.691840: step 7477, loss 0.646128, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:14.770902: step 7478, loss 0.636029, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:14.851560: step 7479, loss 0.601533, acc 0.828125, learning_rate 0.0001
2017-09-28T16:42:14.933022: step 7480, loss 0.639838, acc 0.71875, learning_rate 0.0001

Evaluation:
2017-09-28T16:42:15.197651: step 7480, loss 0.747396, acc 0.700719

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-7480

2017-09-28T16:42:15.755248: step 7481, loss 0.668366, acc 0.671875, learning_rate 0.0001
2017-09-28T16:42:15.840698: step 7482, loss 0.738732, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:15.919090: step 7483, loss 0.622166, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:15.999747: step 7484, loss 0.543634, acc 0.8125, learning_rate 0.0001
2017-09-28T16:42:16.080686: step 7485, loss 0.72749, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:16.160553: step 7486, loss 0.535195, acc 0.84375, learning_rate 0.0001
2017-09-28T16:42:16.242490: step 7487, loss 0.768696, acc 0.671875, learning_rate 0.0001
2017-09-28T16:42:16.325176: step 7488, loss 0.563819, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:16.407112: step 7489, loss 0.644746, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:16.489402: step 7490, loss 0.746187, acc 0.6875, learning_rate 0.0001
2017-09-28T16:42:16.570803: step 7491, loss 0.646313, acc 0.8125, learning_rate 0.0001
2017-09-28T16:42:16.653368: step 7492, loss 0.663644, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:16.733808: step 7493, loss 0.624198, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:16.813074: step 7494, loss 0.65066, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:16.895342: step 7495, loss 0.671981, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:16.977391: step 7496, loss 0.642484, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:17.058686: step 7497, loss 0.643577, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:17.139209: step 7498, loss 0.66363, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:17.222055: step 7499, loss 0.61361, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:17.303327: step 7500, loss 0.561122, acc 0.828125, learning_rate 0.0001
2017-09-28T16:42:17.386156: step 7501, loss 0.519215, acc 0.84375, learning_rate 0.0001
2017-09-28T16:42:17.466765: step 7502, loss 0.670085, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:17.549224: step 7503, loss 0.729517, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:17.632013: step 7504, loss 0.613843, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:17.713818: step 7505, loss 0.726417, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:17.793696: step 7506, loss 0.566139, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:17.876645: step 7507, loss 0.639314, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:17.953733: step 7508, loss 0.597414, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:18.036139: step 7509, loss 0.605686, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:18.124252: step 7510, loss 0.724837, acc 0.609375, learning_rate 0.0001
2017-09-28T16:42:18.204648: step 7511, loss 0.537635, acc 0.859375, learning_rate 0.0001
2017-09-28T16:42:18.283441: step 7512, loss 0.598459, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:18.370773: step 7513, loss 0.668273, acc 0.8125, learning_rate 0.0001
2017-09-28T16:42:18.448740: step 7514, loss 0.627669, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:18.529783: step 7515, loss 0.731172, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:18.611216: step 7516, loss 0.560002, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:18.691529: step 7517, loss 0.680818, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:18.772266: step 7518, loss 0.651479, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:18.850339: step 7519, loss 0.622126, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:18.933952: step 7520, loss 0.711125, acc 0.75, learning_rate 0.0001

Evaluation:
2017-09-28T16:42:19.199038: step 7520, loss 0.74697, acc 0.699281

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-7520

2017-09-28T16:42:19.750154: step 7521, loss 0.562909, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:19.834103: step 7522, loss 0.579941, acc 0.8125, learning_rate 0.0001
2017-09-28T16:42:19.914400: step 7523, loss 0.645669, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:19.994856: step 7524, loss 0.705467, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:20.075836: step 7525, loss 0.791478, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:20.156837: step 7526, loss 0.562298, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:20.238017: step 7527, loss 0.689478, acc 0.65625, learning_rate 0.0001
2017-09-28T16:42:20.322356: step 7528, loss 0.607648, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:20.404737: step 7529, loss 0.651572, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:20.486690: step 7530, loss 0.565326, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:20.570546: step 7531, loss 0.627594, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:20.651974: step 7532, loss 0.830492, acc 0.671875, learning_rate 0.0001
2017-09-28T16:42:20.734692: step 7533, loss 0.657074, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:20.821617: step 7534, loss 0.530733, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:20.903751: step 7535, loss 0.777384, acc 0.6875, learning_rate 0.0001
2017-09-28T16:42:20.983599: step 7536, loss 0.598547, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:21.064740: step 7537, loss 0.629071, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:21.147951: step 7538, loss 0.580863, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:21.229633: step 7539, loss 0.631325, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:21.309495: step 7540, loss 0.570167, acc 0.8125, learning_rate 0.0001
2017-09-28T16:42:21.397837: step 7541, loss 0.462158, acc 0.859375, learning_rate 0.0001
2017-09-28T16:42:21.477734: step 7542, loss 0.610331, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:21.558789: step 7543, loss 1.0029, acc 0.609375, learning_rate 0.0001
2017-09-28T16:42:21.638418: step 7544, loss 0.547061, acc 0.84375, learning_rate 0.0001
2017-09-28T16:42:21.719979: step 7545, loss 0.661799, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:21.786629: step 7546, loss 0.815034, acc 0.627451, learning_rate 0.0001
2017-09-28T16:42:21.865651: step 7547, loss 0.50281, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:21.947498: step 7548, loss 0.609021, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:22.029261: step 7549, loss 0.569482, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:22.110031: step 7550, loss 0.726548, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:22.191560: step 7551, loss 0.529098, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:22.275364: step 7552, loss 0.701676, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:22.356715: step 7553, loss 0.652703, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:22.438353: step 7554, loss 0.899736, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:22.520958: step 7555, loss 0.776381, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:22.602254: step 7556, loss 0.51754, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:22.683881: step 7557, loss 0.599423, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:22.761975: step 7558, loss 0.64021, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:22.842315: step 7559, loss 0.578043, acc 0.8125, learning_rate 0.0001
2017-09-28T16:42:22.926389: step 7560, loss 0.603272, acc 0.78125, learning_rate 0.0001

Evaluation:
2017-09-28T16:42:23.185247: step 7560, loss 0.744712, acc 0.699281

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-7560

2017-09-28T16:42:23.812268: step 7561, loss 0.496673, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:23.892444: step 7562, loss 0.55588, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:23.973637: step 7563, loss 0.636265, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:24.056296: step 7564, loss 0.726463, acc 0.59375, learning_rate 0.0001
2017-09-28T16:42:24.135077: step 7565, loss 0.504611, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:24.219472: step 7566, loss 0.537989, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:24.298715: step 7567, loss 0.655515, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:24.382200: step 7568, loss 0.489372, acc 0.828125, learning_rate 0.0001
2017-09-28T16:42:24.462444: step 7569, loss 0.76372, acc 0.65625, learning_rate 0.0001
2017-09-28T16:42:24.542841: step 7570, loss 0.544124, acc 0.859375, learning_rate 0.0001
2017-09-28T16:42:24.624635: step 7571, loss 0.621455, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:24.704291: step 7572, loss 0.58931, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:24.783897: step 7573, loss 0.532624, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:24.866657: step 7574, loss 0.659822, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:24.955128: step 7575, loss 0.529903, acc 0.828125, learning_rate 0.0001
2017-09-28T16:42:25.034488: step 7576, loss 0.842674, acc 0.640625, learning_rate 0.0001
2017-09-28T16:42:25.117120: step 7577, loss 0.785475, acc 0.609375, learning_rate 0.0001
2017-09-28T16:42:25.198742: step 7578, loss 0.67328, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:25.284534: step 7579, loss 0.702985, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:25.366913: step 7580, loss 0.681184, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:25.447546: step 7581, loss 0.800755, acc 0.609375, learning_rate 0.0001
2017-09-28T16:42:25.526553: step 7582, loss 0.58711, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:25.609163: step 7583, loss 0.596341, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:25.691617: step 7584, loss 0.681383, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:25.772320: step 7585, loss 0.831059, acc 0.578125, learning_rate 0.0001
2017-09-28T16:42:25.860320: step 7586, loss 0.457602, acc 0.84375, learning_rate 0.0001
2017-09-28T16:42:25.943367: step 7587, loss 0.64224, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:26.025984: step 7588, loss 0.681952, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:26.107880: step 7589, loss 0.533308, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:26.193809: step 7590, loss 0.731925, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:26.275390: step 7591, loss 0.516084, acc 0.84375, learning_rate 0.0001
2017-09-28T16:42:26.357093: step 7592, loss 0.770152, acc 0.640625, learning_rate 0.0001
2017-09-28T16:42:26.441054: step 7593, loss 0.652922, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:26.519375: step 7594, loss 0.537144, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:26.601628: step 7595, loss 0.702965, acc 0.671875, learning_rate 0.0001
2017-09-28T16:42:26.687290: step 7596, loss 0.569345, acc 0.8125, learning_rate 0.0001
2017-09-28T16:42:26.770611: step 7597, loss 0.633627, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:26.850808: step 7598, loss 0.638151, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:26.932221: step 7599, loss 0.628573, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:27.013485: step 7600, loss 0.705639, acc 0.703125, learning_rate 0.0001

Evaluation:
2017-09-28T16:42:27.289598: step 7600, loss 0.747069, acc 0.699281

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-7600

2017-09-28T16:42:27.779936: step 7601, loss 0.619385, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:27.858755: step 7602, loss 0.54948, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:27.939402: step 7603, loss 0.446878, acc 0.875, learning_rate 0.0001
2017-09-28T16:42:28.019380: step 7604, loss 0.61089, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:28.100787: step 7605, loss 0.590828, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:28.183263: step 7606, loss 0.631119, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:28.264532: step 7607, loss 0.500873, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:28.349933: step 7608, loss 0.793696, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:28.431636: step 7609, loss 0.721476, acc 0.6875, learning_rate 0.0001
2017-09-28T16:42:28.511155: step 7610, loss 0.64802, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:28.591806: step 7611, loss 0.71469, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:28.671426: step 7612, loss 0.644852, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:28.750794: step 7613, loss 0.656831, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:28.831159: step 7614, loss 0.917513, acc 0.6875, learning_rate 0.0001
2017-09-28T16:42:28.909267: step 7615, loss 0.508536, acc 0.859375, learning_rate 0.0001
2017-09-28T16:42:28.990855: step 7616, loss 0.699251, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:29.069968: step 7617, loss 0.556404, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:29.152230: step 7618, loss 0.606661, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:29.233854: step 7619, loss 0.601716, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:29.315826: step 7620, loss 0.541308, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:29.398898: step 7621, loss 0.64014, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:29.479830: step 7622, loss 0.623486, acc 0.8125, learning_rate 0.0001
2017-09-28T16:42:29.560392: step 7623, loss 0.553319, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:29.641061: step 7624, loss 0.763071, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:29.722414: step 7625, loss 0.75866, acc 0.671875, learning_rate 0.0001
2017-09-28T16:42:29.807364: step 7626, loss 0.709584, acc 0.671875, learning_rate 0.0001
2017-09-28T16:42:29.890044: step 7627, loss 0.647555, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:29.970491: step 7628, loss 0.668988, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:30.052139: step 7629, loss 0.646818, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:30.133942: step 7630, loss 0.650611, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:30.215877: step 7631, loss 0.850807, acc 0.65625, learning_rate 0.0001
2017-09-28T16:42:30.296046: step 7632, loss 0.540687, acc 0.84375, learning_rate 0.0001
2017-09-28T16:42:30.379078: step 7633, loss 0.730054, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:30.461507: step 7634, loss 0.632785, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:30.543086: step 7635, loss 0.677938, acc 0.65625, learning_rate 0.0001
2017-09-28T16:42:30.624381: step 7636, loss 0.479054, acc 0.8125, learning_rate 0.0001
2017-09-28T16:42:30.705230: step 7637, loss 0.747984, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:30.784424: step 7638, loss 0.604556, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:30.869112: step 7639, loss 0.566987, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:30.952210: step 7640, loss 0.642902, acc 0.6875, learning_rate 0.0001

Evaluation:
2017-09-28T16:42:31.221126: step 7640, loss 0.744118, acc 0.700719

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-7640

2017-09-28T16:42:31.780908: step 7641, loss 0.683578, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:31.859227: step 7642, loss 0.744297, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:31.938694: step 7643, loss 0.524454, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:32.006016: step 7644, loss 0.649628, acc 0.784314, learning_rate 0.0001
2017-09-28T16:42:32.085748: step 7645, loss 0.652995, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:32.167194: step 7646, loss 0.843431, acc 0.625, learning_rate 0.0001
2017-09-28T16:42:32.244784: step 7647, loss 0.812471, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:32.326690: step 7648, loss 0.751405, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:32.409704: step 7649, loss 0.555844, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:32.492689: step 7650, loss 0.597857, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:32.573624: step 7651, loss 0.766613, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:32.653429: step 7652, loss 0.585806, acc 0.828125, learning_rate 0.0001
2017-09-28T16:42:32.731770: step 7653, loss 0.6614, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:32.813567: step 7654, loss 0.463566, acc 0.859375, learning_rate 0.0001
2017-09-28T16:42:32.892318: step 7655, loss 0.676224, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:32.974475: step 7656, loss 0.608545, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:33.056639: step 7657, loss 0.760925, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:33.138700: step 7658, loss 0.688345, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:33.219410: step 7659, loss 0.527674, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:33.301008: step 7660, loss 0.71012, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:33.384576: step 7661, loss 0.716441, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:33.464702: step 7662, loss 0.658372, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:33.546255: step 7663, loss 0.547296, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:33.627349: step 7664, loss 0.561215, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:33.707376: step 7665, loss 0.721728, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:33.787913: step 7666, loss 0.665143, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:33.869842: step 7667, loss 0.57986, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:33.954254: step 7668, loss 0.607625, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:34.035027: step 7669, loss 0.603227, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:34.117714: step 7670, loss 0.543226, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:34.200703: step 7671, loss 0.684691, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:34.283859: step 7672, loss 0.704226, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:34.371448: step 7673, loss 0.603776, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:34.453433: step 7674, loss 0.754731, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:34.538268: step 7675, loss 0.709786, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:34.621132: step 7676, loss 0.772808, acc 0.65625, learning_rate 0.0001
2017-09-28T16:42:34.703305: step 7677, loss 0.691139, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:34.783597: step 7678, loss 0.685954, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:34.866980: step 7679, loss 0.637613, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:34.947778: step 7680, loss 0.709887, acc 0.640625, learning_rate 0.0001

Evaluation:
2017-09-28T16:42:35.212885: step 7680, loss 0.744285, acc 0.703597

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-7680

2017-09-28T16:42:35.771689: step 7681, loss 0.588744, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:35.857478: step 7682, loss 0.59449, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:35.946342: step 7683, loss 0.619727, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:36.027009: step 7684, loss 0.54816, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:36.108198: step 7685, loss 0.649966, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:36.186350: step 7686, loss 0.626236, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:36.267955: step 7687, loss 0.796986, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:36.347245: step 7688, loss 0.708933, acc 0.6875, learning_rate 0.0001
2017-09-28T16:42:36.427095: step 7689, loss 0.742042, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:36.507851: step 7690, loss 0.742926, acc 0.6875, learning_rate 0.0001
2017-09-28T16:42:36.587349: step 7691, loss 0.43004, acc 0.890625, learning_rate 0.0001
2017-09-28T16:42:36.669052: step 7692, loss 0.616987, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:36.750112: step 7693, loss 0.639377, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:36.829805: step 7694, loss 0.583177, acc 0.828125, learning_rate 0.0001
2017-09-28T16:42:36.910792: step 7695, loss 0.538987, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:36.993296: step 7696, loss 0.649704, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:37.075706: step 7697, loss 0.612564, acc 0.8125, learning_rate 0.0001
2017-09-28T16:42:37.158148: step 7698, loss 0.396027, acc 0.84375, learning_rate 0.0001
2017-09-28T16:42:37.241020: step 7699, loss 0.79368, acc 0.65625, learning_rate 0.0001
2017-09-28T16:42:37.323753: step 7700, loss 0.509121, acc 0.828125, learning_rate 0.0001
2017-09-28T16:42:37.408273: step 7701, loss 0.712388, acc 0.6875, learning_rate 0.0001
2017-09-28T16:42:37.487528: step 7702, loss 0.571286, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:37.566690: step 7703, loss 0.503223, acc 0.875, learning_rate 0.0001
2017-09-28T16:42:37.648920: step 7704, loss 0.73792, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:37.730606: step 7705, loss 0.527489, acc 0.84375, learning_rate 0.0001
2017-09-28T16:42:37.810062: step 7706, loss 0.730109, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:37.889411: step 7707, loss 0.493834, acc 0.859375, learning_rate 0.0001
2017-09-28T16:42:37.969038: step 7708, loss 0.556345, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:38.047689: step 7709, loss 0.637478, acc 0.8125, learning_rate 0.0001
2017-09-28T16:42:38.131201: step 7710, loss 0.576692, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:38.212704: step 7711, loss 0.492199, acc 0.828125, learning_rate 0.0001
2017-09-28T16:42:38.295248: step 7712, loss 0.614909, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:38.374745: step 7713, loss 0.697317, acc 0.671875, learning_rate 0.0001
2017-09-28T16:42:38.454519: step 7714, loss 0.687677, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:38.535269: step 7715, loss 0.489009, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:38.620790: step 7716, loss 0.533972, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:38.703102: step 7717, loss 0.711705, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:38.784127: step 7718, loss 0.447186, acc 0.828125, learning_rate 0.0001
2017-09-28T16:42:38.867187: step 7719, loss 0.751833, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:38.945464: step 7720, loss 0.493704, acc 0.78125, learning_rate 0.0001

Evaluation:
2017-09-28T16:42:39.211927: step 7720, loss 0.744502, acc 0.700719

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-7720

2017-09-28T16:42:39.844139: step 7721, loss 0.743188, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:39.926301: step 7722, loss 0.599307, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:40.003588: step 7723, loss 0.497394, acc 0.828125, learning_rate 0.0001
2017-09-28T16:42:40.083618: step 7724, loss 0.58016, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:40.165273: step 7725, loss 0.762137, acc 0.6875, learning_rate 0.0001
2017-09-28T16:42:40.246663: step 7726, loss 0.800867, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:40.329067: step 7727, loss 0.748725, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:40.415205: step 7728, loss 0.692112, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:40.497992: step 7729, loss 0.635561, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:40.578755: step 7730, loss 0.678565, acc 0.6875, learning_rate 0.0001
2017-09-28T16:42:40.663117: step 7731, loss 0.494618, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:40.743836: step 7732, loss 0.547238, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:40.822577: step 7733, loss 0.719087, acc 0.65625, learning_rate 0.0001
2017-09-28T16:42:40.904990: step 7734, loss 0.706353, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:40.995229: step 7735, loss 0.706354, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:41.075992: step 7736, loss 0.575751, acc 0.8125, learning_rate 0.0001
2017-09-28T16:42:41.156037: step 7737, loss 0.601567, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:41.236050: step 7738, loss 0.534784, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:41.317345: step 7739, loss 0.570406, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:41.398593: step 7740, loss 0.778753, acc 0.6875, learning_rate 0.0001
2017-09-28T16:42:41.478361: step 7741, loss 0.506313, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:41.547282: step 7742, loss 0.798032, acc 0.686275, learning_rate 0.0001
2017-09-28T16:42:41.631002: step 7743, loss 0.691379, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:41.714939: step 7744, loss 0.479177, acc 0.828125, learning_rate 0.0001
2017-09-28T16:42:41.798917: step 7745, loss 0.499901, acc 0.828125, learning_rate 0.0001
2017-09-28T16:42:41.883284: step 7746, loss 0.524985, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:41.964466: step 7747, loss 0.581414, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:42.043490: step 7748, loss 0.629511, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:42.122488: step 7749, loss 0.493826, acc 0.84375, learning_rate 0.0001
2017-09-28T16:42:42.206144: step 7750, loss 0.66952, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:42.286029: step 7751, loss 0.548203, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:42.369917: step 7752, loss 0.573872, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:42.454108: step 7753, loss 0.761907, acc 0.671875, learning_rate 0.0001
2017-09-28T16:42:42.535806: step 7754, loss 0.519192, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:42.617662: step 7755, loss 0.487887, acc 0.84375, learning_rate 0.0001
2017-09-28T16:42:42.700272: step 7756, loss 0.655998, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:42.779836: step 7757, loss 0.652641, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:42.862685: step 7758, loss 0.571142, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:42.943053: step 7759, loss 0.68169, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:43.023747: step 7760, loss 0.481645, acc 0.828125, learning_rate 0.0001

Evaluation:
2017-09-28T16:42:43.294223: step 7760, loss 0.742561, acc 0.697842

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-7760

2017-09-28T16:42:43.793467: step 7761, loss 0.808886, acc 0.6875, learning_rate 0.0001
2017-09-28T16:42:43.874990: step 7762, loss 0.533726, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:43.957815: step 7763, loss 0.651729, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:44.039151: step 7764, loss 0.657834, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:44.121779: step 7765, loss 0.717475, acc 0.671875, learning_rate 0.0001
2017-09-28T16:42:44.203355: step 7766, loss 0.583202, acc 0.8125, learning_rate 0.0001
2017-09-28T16:42:44.283506: step 7767, loss 0.524337, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:44.365438: step 7768, loss 0.774515, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:44.450189: step 7769, loss 0.568735, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:44.531437: step 7770, loss 0.557637, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:44.616593: step 7771, loss 0.816603, acc 0.6875, learning_rate 0.0001
2017-09-28T16:42:44.697210: step 7772, loss 0.610042, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:44.778162: step 7773, loss 0.412159, acc 0.84375, learning_rate 0.0001
2017-09-28T16:42:44.863155: step 7774, loss 0.658899, acc 0.6875, learning_rate 0.0001
2017-09-28T16:42:44.945866: step 7775, loss 0.66296, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:45.026448: step 7776, loss 0.617452, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:45.106901: step 7777, loss 0.739556, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:45.186406: step 7778, loss 0.639657, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:45.267459: step 7779, loss 0.617381, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:45.349423: step 7780, loss 0.537278, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:45.430289: step 7781, loss 0.693422, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:45.510442: step 7782, loss 0.644831, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:45.593606: step 7783, loss 0.749359, acc 0.625, learning_rate 0.0001
2017-09-28T16:42:45.673429: step 7784, loss 0.635376, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:45.755404: step 7785, loss 0.638241, acc 0.6875, learning_rate 0.0001
2017-09-28T16:42:45.834487: step 7786, loss 0.517749, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:45.913087: step 7787, loss 0.81764, acc 0.6875, learning_rate 0.0001
2017-09-28T16:42:45.998975: step 7788, loss 0.558126, acc 0.8125, learning_rate 0.0001
2017-09-28T16:42:46.080832: step 7789, loss 0.838369, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:46.159199: step 7790, loss 0.773682, acc 0.6875, learning_rate 0.0001
2017-09-28T16:42:46.244383: step 7791, loss 0.619811, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:46.321646: step 7792, loss 0.663486, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:46.403495: step 7793, loss 0.439522, acc 0.828125, learning_rate 0.0001
2017-09-28T16:42:46.485770: step 7794, loss 0.714128, acc 0.671875, learning_rate 0.0001
2017-09-28T16:42:46.571622: step 7795, loss 0.721979, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:46.655231: step 7796, loss 0.619291, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:46.735511: step 7797, loss 0.702286, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:46.816290: step 7798, loss 0.663649, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:46.896321: step 7799, loss 0.653252, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:46.976668: step 7800, loss 0.652774, acc 0.703125, learning_rate 0.0001

Evaluation:
2017-09-28T16:42:47.251875: step 7800, loss 0.742725, acc 0.700719

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-7800

2017-09-28T16:42:47.818284: step 7801, loss 0.577909, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:47.897549: step 7802, loss 0.529872, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:47.980265: step 7803, loss 0.631402, acc 0.734375, learning_rate 0.0001
2017-09-28T16:42:48.062887: step 7804, loss 0.600376, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:48.143541: step 7805, loss 0.829584, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:48.226204: step 7806, loss 0.603387, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:48.306692: step 7807, loss 0.578785, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:48.389510: step 7808, loss 0.655103, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:48.470067: step 7809, loss 0.665699, acc 0.8125, learning_rate 0.0001
2017-09-28T16:42:48.552700: step 7810, loss 0.781072, acc 0.6875, learning_rate 0.0001
2017-09-28T16:42:48.631708: step 7811, loss 0.589633, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:48.713492: step 7812, loss 0.781494, acc 0.640625, learning_rate 0.0001
2017-09-28T16:42:48.795374: step 7813, loss 0.844324, acc 0.578125, learning_rate 0.0001
2017-09-28T16:42:48.875959: step 7814, loss 0.718909, acc 0.625, learning_rate 0.0001
2017-09-28T16:42:48.956823: step 7815, loss 0.499945, acc 0.828125, learning_rate 0.0001
2017-09-28T16:42:49.039520: step 7816, loss 0.504016, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:49.121447: step 7817, loss 0.547574, acc 0.84375, learning_rate 0.0001
2017-09-28T16:42:49.202605: step 7818, loss 0.638432, acc 0.796875, learning_rate 0.0001
2017-09-28T16:42:49.283525: step 7819, loss 0.502837, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:49.365044: step 7820, loss 0.842964, acc 0.671875, learning_rate 0.0001
2017-09-28T16:42:49.447592: step 7821, loss 0.532907, acc 0.8125, learning_rate 0.0001
2017-09-28T16:42:49.528550: step 7822, loss 0.648376, acc 0.71875, learning_rate 0.0001
2017-09-28T16:42:49.611838: step 7823, loss 0.472363, acc 0.8125, learning_rate 0.0001
2017-09-28T16:42:49.691905: step 7824, loss 0.617248, acc 0.8125, learning_rate 0.0001
2017-09-28T16:42:49.770701: step 7825, loss 0.614763, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:49.852724: step 7826, loss 0.854599, acc 0.671875, learning_rate 0.0001
2017-09-28T16:42:49.936835: step 7827, loss 0.65888, acc 0.703125, learning_rate 0.0001
2017-09-28T16:42:50.019662: step 7828, loss 0.631184, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:50.100815: step 7829, loss 0.777025, acc 0.671875, learning_rate 0.0001
2017-09-28T16:42:50.184758: step 7830, loss 0.586923, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:50.265030: step 7831, loss 0.677876, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:50.349836: step 7832, loss 0.488355, acc 0.8125, learning_rate 0.0001
2017-09-28T16:42:50.432267: step 7833, loss 0.709794, acc 0.6875, learning_rate 0.0001
2017-09-28T16:42:50.514856: step 7834, loss 0.839244, acc 0.65625, learning_rate 0.0001
2017-09-28T16:42:50.595803: step 7835, loss 0.615779, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:50.679161: step 7836, loss 0.527821, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:50.760690: step 7837, loss 0.649332, acc 0.78125, learning_rate 0.0001
2017-09-28T16:42:50.842344: step 7838, loss 0.540355, acc 0.765625, learning_rate 0.0001
2017-09-28T16:42:50.926052: step 7839, loss 0.702478, acc 0.75, learning_rate 0.0001
2017-09-28T16:42:50.991618: step 7840, loss 0.745342, acc 0.705882, learning_rate 0.0001

Evaluation:
2017-09-28T16:42:51.265875: step 7840, loss 0.743524, acc 0.702158

Saved model checkpoint to /home/sheep/repo/CNN-text-multi-class-classification/runs/1506634174/checkpoints/model-7840

